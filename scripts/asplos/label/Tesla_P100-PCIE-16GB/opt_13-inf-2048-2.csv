op,target,_input_nodes,_args,_kwargs,users,type,_prev,_next,_erased,_repr_fn,meta,input_shapes,input_contiguous,contiguous,latency,fw_latency,bw_latency,acc_latency,output_shape,dtype,Name
placeholder,input_ids,{},(),{},"{size: None, view: None}",<class 'torch.Tensor'>,,size,False,,{},[],[],True,0.0,0.0,0,0,"(2, 2048)",torch.int64,input_ids
call_method,size,{input_ids: None},"(input_ids,)",{},"{getitem: None, getitem_1: None, getitem_2: None, getitem_3: None, getitem_4: None}",,input_ids,getitem,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2, 2048]]",[True],True,0.012761599943041801,0.012761599943041801,0,0,"(1,)",,size
call_function,<built-in function getitem>,{size: None},"(size, -1)",{},{view: None},,size,view,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.012172799929976464,0.012172799929976464,0,0,"(1,)",,getitem
call_method,view,"{input_ids: None, getitem: None}","(input_ids, -1, getitem)",{},{model_decoder_embed_tokens: None},,getitem,model_decoder_embed_tokens,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2, 2048], [1]]","[True, True]",True,0.015411199815571309,0.015411199815571309,0,0,"(2, 2048)",torch.int64,view
call_module,model.decoder.embed_tokens,{view: None},"(view,)",{},"{getattr_1: None, getattr_2: None, add_5: None}",,view,getitem_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_tokens', <class 'torch.nn.modules.sparse.Embedding'>)])}","[[2, 2048]]",[True],True,0.38323840498924255,0.38323840498924255,0,0,"(2, 2048, 2048)",torch.float32,model_decoder_embed_tokens
call_function,<built-in function getitem>,{size: None},"(size, 0)",{},{ones: None},,model_decoder_embed_tokens,getitem_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.012345599941909313,0.012345599941909313,0,0,"(1,)",,getitem_1
call_function,<built-in function getitem>,{size: None},"(size, 1)",{},{add: None},,getitem_1,add,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.012102400138974189,0.012102400138974189,0,0,"(1,)",,getitem_2
call_function,<built-in function add>,{getitem_2: None},"(0, getitem_2)",{},{ones: None},,getitem_2,getattr_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.012294400297105313,0.012294400297105313,0,0,"(1,)",,add
call_function,<built-in function getattr>,{model_decoder_embed_tokens: None},"(model_decoder_embed_tokens, 'device')",{},{ones: None},,add,ones,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2, 2048, 2048]]",[True],True,0.012460800074040889,0.012460800074040889,0,0,"(1,)",,getattr_1
call_function,<built-in method ones of type object at 0x7fe8ea474d60>,"{getitem_1: None, add: None, getattr_1: None}","(getitem_1, add)",{'device': getattr_1},"{size_1: None, size_2: None, getattr_4: None, size_5: None, getitem_9: None, getattr_6: None, long: None}",,getattr_1,getitem_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[1], [1], [1]]","[True, True, True]",True,0.025996800139546396,0.025996800139546396,0,0,"(2, 2048)",torch.float32,ones
call_function,<built-in function getitem>,{size: None},"(size, -1)",{},{add_1: None},,ones,add_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.012204800173640252,0.012204800173640252,0,0,"(1,)",,getitem_3
call_function,<built-in function add>,{getitem_3: None},"(getitem_3, 0)",{},{sub: None},,getitem_3,size_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.012166400253772736,0.012166400253772736,0,0,"(1,)",,add_1
call_method,size,{ones: None},"(ones,)",{},{},,add_1,getitem_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2, 2048]]",[True],True,0.012767999991774559,0.012767999991774559,0,0,"(1,)",,size_1
call_function,<built-in function getitem>,{size: None},"(size, -1)",{},"{gt: None, sub: None, full: None, add_3: None, expand: None, expand_1: None}",,size_1,size_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.012006399780511856,0.012006399780511856,0,0,"(1,)",,getitem_4
call_method,size,{ones: None},"(ones,)",{},{getitem_5: None},,getitem_4,getitem_5,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2, 2048]]",[True],True,0.012345600314438343,0.012345600314438343,0,0,"(1,)",,size_2
call_function,<built-in function getitem>,{size_2: None},"(size_2, 0)",{},{expand: None},,size_2,gt,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.01175680011510849,0.01175680011510849,0,0,"(1,)",,getitem_5
call_function,<built-in function gt>,{getitem_4: None},"(getitem_4, 1)",{},{},,getitem_5,sub,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.011737599968910217,0.011737599968910217,0,0,"(1,)",,gt
call_function,<built-in function sub>,"{add_1: None, getitem_4: None}","(add_1, getitem_4)",{},"{gt_1: None, add_3: None}",,gt,getattr_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[1], [1]]","[True, True]",True,0.011641599982976914,0.011641599982976914,0,0,"(1,)",,sub
call_function,<built-in function getattr>,{model_decoder_embed_tokens: None},"(model_decoder_embed_tokens, 'dtype')",{},"{finfo: None, to: None, to_1: None, finfo_1: None, finfo_2: None}",,sub,finfo,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2, 2048, 2048]]",[True],True,0.011872000060975552,0.011872000060975552,0,0,"(1,)",,getattr_2
call_function,<class 'torch.finfo'>,{getattr_2: None},"(getattr_2,)",{},{getattr_3: None},,getattr_2,getattr_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.01191679984331131,0.01191679984331131,0,0,"(1,)",,finfo
call_function,<built-in function getattr>,{finfo: None},"(finfo, 'min')",{},{full: None},,finfo,getattr_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.011814399808645248,0.011814399808645248,0,0,"(1,)",,getattr_3
call_function,<built-in function getattr>,{ones: None},"(ones, 'device')",{},"{full: None, arange: None}",,getattr_3,full,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2, 2048]]",[True],True,0.011987200006842613,0.011987200006842613,0,0,"(1,)",,getattr_4
call_function,<built-in method full of type object at 0x7fe8ea474d60>,"{getitem_4: None, getattr_3: None, getattr_4: None}","((getitem_4, getitem_4), getattr_3)",{'device': getattr_4},"{size_3: None, size_4: None, masked_fill_: None, to: None}",,getattr_4,size_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[1], [1], [1]]","[True, True, True]",True,0.04184959977865219,0.04184959977865219,0,0,"(2048, 2048)",torch.float32,full
call_method,size,{full: None},"(full, -1)",{},{arange: None},,full,arange,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048, 2048]]",[True],True,0.012211200036108493,0.012211200036108493,0,0,"(1,)",,size_3
call_function,<built-in method arange of type object at 0x7fe8ea474d60>,"{size_3: None, getattr_4: None}","(size_3,)",{'device': getattr_4},"{add_2: None, lt: None}",,size_3,add_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[1], [1]]","[True, True]",True,0.024192000180482863,0.024192000180482863,0,0,"(2048,)",torch.int64,arange
call_function,<built-in function add>,{arange: None},"(arange, 1)",{},{view_1: None},,arange,size_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[2048]],[True],True,0.026764800027012824,0.026764800027012824,0,0,"(2048,)",torch.int64,add_2
call_method,size,{full: None},"(full, -1)",{},{view_1: None},,add_2,view_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048, 2048]]",[True],True,0.01235199999064207,0.01235199999064207,0,0,"(1,)",,size_4
call_method,view,"{add_2: None, size_4: None}","(add_2, size_4, 1)",{},{lt: None},,size_4,lt,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048], [1]]","[True, True]",True,0.014918399974703789,0.014918399974703789,0,0,"(2048, 1)",torch.int64,view_1
call_function,<built-in function lt>,"{arange: None, view_1: None}","(arange, view_1)",{},{masked_fill_: None},,view_1,masked_fill_,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048], [2048, 1]]","[True, True]",True,0.09116160124540329,0.09116160124540329,0,0,"(2048, 2048)",torch.bool,lt
call_method,masked_fill_,"{full: None, lt: None}","(full, lt, 0)",{},{},,lt,to,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048, 2048], [2048, 2048]]","[True, True]",True,0.07956480234861374,0.07956480234861374,0,0,"(2048, 2048)",torch.float32,masked_fill_
call_method,to,"{full: None, getattr_2: None}","(full, getattr_2)",{},{getitem_6: None},,masked_fill_,gt_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048, 2048], [1]]","[True, True]",True,0.01257600001990795,0.01257600001990795,0,0,"(2048, 2048)",torch.float32,to
call_function,<built-in function gt>,{sub: None},"(sub, 0)",{},{},,to,getitem_6,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.011660800129175187,0.011660800129175187,0,0,"(1,)",,gt_1
call_function,<built-in function getitem>,{to: None},"(to, (None, None, slice(None, None, None), slice(None, None, None)))",{},{expand: None},,gt_1,add_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048, 2048]]",[True],True,0.023526400700211524,0.023526400700211524,0,0,"(1, 1, 2048, 2048)",torch.float32,getitem_6
call_function,<built-in function add>,"{getitem_4: None, sub: None}","(getitem_4, sub)",{},{expand: None},,getitem_6,expand,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[1], [1]]","[True, True]",True,0.011616000346839428,0.011616000346839428,0,0,"(1,)",,add_3
call_method,expand,"{getitem_6: None, getitem_5: None, getitem_4: None, add_3: None}","(getitem_6, getitem_5, 1, getitem_4, add_3)",{},{masked_fill_1: None},,add_3,size_5,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[1, 1, 2048, 2048], [1], [1], [1]]","[True, True, True, True]",False,0.01621119976043701,0.01621119976043701,0,0,"(2, 1, 2048, 2048)",torch.float32,expand
call_method,size,{ones: None},"(ones,)",{},"{getitem_7: None, getitem_8: None}",,expand,getitem_7,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2, 2048]]",[True],True,0.01219200026243925,0.01219200026243925,0,0,"(1,)",,size_5
call_function,<built-in function getitem>,{size_5: None},"(size_5, 0)",{},{expand_1: None},,size_5,getitem_8,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.011564800143241882,0.011564800143241882,0,0,"(1,)",,getitem_7
call_function,<built-in function getitem>,{size_5: None},"(size_5, 1)",{},{expand_1: None},,getitem_7,getitem_9,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.011539200134575368,0.011539200134575368,0,0,"(1,)",,getitem_8
call_function,<built-in function getitem>,{ones: None},"(ones, (slice(None, None, None), None, None, slice(None, None, None)))",{},{expand_1: None},,getitem_8,expand_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2, 2048]]",[True],True,0.022815999761223792,0.022815999761223792,0,0,"(2, 1, 1, 2048)",torch.float32,getitem_9
call_method,expand,"{getitem_9: None, getitem_7: None, getitem_4: None, getitem_8: None}","(getitem_9, getitem_7, 1, getitem_4, getitem_8)",{},{to_1: None},,getitem_9,to_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2, 1, 1, 2048], [1], [1], [1]]","[True, True, True, True]",False,0.01605119965970516,0.01605119965970516,0,0,"(2, 1, 2048, 2048)",torch.float32,expand_1
call_method,to,"{expand_1: None, getattr_2: None}","(expand_1, getattr_2)",{},{sub_1: None},,expand_1,sub_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2, 1, 2048, 2048], [1]]","[False, True]",False,0.012556800059974194,0.012556800059974194,0,0,"(2, 1, 2048, 2048)",torch.float32,to_1
call_function,<built-in function sub>,{to_1: None},"(1.0, to_1)",{},"{to_2: None, masked_fill: None}",,to_1,to_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2, 1, 2048, 2048]]",[False],True,0.1622400015592575,0.1622400015592575,0,0,"(2, 1, 2048, 2048)",torch.float32,sub_1
call_method,to,{sub_1: None},"(sub_1, torch.bool)",{},{masked_fill: None},,sub_1,finfo_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2, 1, 2048, 2048]]",[True],True,0.16755200028419495,0.16755200028419495,0,0,"(2, 1, 2048, 2048)",torch.bool,to_2
call_function,<class 'torch.finfo'>,{getattr_2: None},"(getattr_2,)",{},{getattr_5: None},,to_2,getattr_5,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.011827199906110763,0.011827199906110763,0,0,"(1,)",,finfo_1
call_function,<built-in function getattr>,{finfo_1: None},"(finfo_1, 'min')",{},{masked_fill: None},,finfo_1,masked_fill,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.011635199934244157,0.011635199934244157,0,0,"(1,)",,getattr_5
call_method,masked_fill,"{sub_1: None, to_2: None, getattr_5: None}","(sub_1, to_2, getattr_5)",{},{to_3: None},,getattr_5,getattr_6,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2, 1, 2048, 2048], [2, 1, 2048, 2048], [1]]","[True, True, True]",True,0.2839360058307648,0.2839360058307648,0,0,"(2, 1, 2048, 2048)",torch.float32,masked_fill
call_function,<built-in function getattr>,{ones: None},"(ones, 'device')",{},{to_3: None},,masked_fill,to_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2, 2048]]",[True],True,0.011820799671113491,0.011820799671113491,0,0,"(1,)",,getattr_6
call_method,to,"{masked_fill: None, getattr_6: None}","(masked_fill, getattr_6)",{},{bool_1: None},,getattr_6,bool_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2, 1, 2048, 2048], [1]]","[True, True]",True,0.013049599900841712,0.013049599900841712,0,0,"(2, 1, 2048, 2048)",torch.float32,to_3
call_method,bool,{to_3: None},"(to_3,)",{},{masked_fill_1: None},,to_3,finfo_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2, 1, 2048, 2048]]",[True],True,0.16715520322322847,0.16715520322322847,0,0,"(2, 1, 2048, 2048)",torch.bool,bool_1
call_function,<class 'torch.finfo'>,{getattr_2: None},"(getattr_2,)",{},{getattr_7: None},,bool_1,getattr_7,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.011865600012242794,0.011865600012242794,0,0,"(1,)",,finfo_2
call_function,<built-in function getattr>,{finfo_2: None},"(finfo_2, 'min')",{},{masked_fill_1: None},,finfo_2,masked_fill_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.011571200005710125,0.011571200005710125,0,0,"(1,)",,getattr_7
call_method,masked_fill,"{expand: None, bool_1: None, getattr_7: None}","(expand, bool_1, getattr_7)",{},"{size_9: None, add_6: None}",,getattr_7,long,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2, 1, 2048, 2048], [2, 1, 2048, 2048], [1]]","[False, True, True]",True,0.2803456008434296,0.2803456008434296,0,0,"(2, 1, 2048, 2048)",torch.float32,masked_fill_1
call_method,long,{ones: None},"(ones,)",{},"{cumsum: None, type_as: None, mul: None}",,masked_fill_1,cumsum,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[2, 2048]]",[True],True,0.025248000025749208,0.025248000025749208,0,0,"(2, 2048)",torch.int64,long
call_function,<built-in method cumsum of type object at 0x7fe8ea474d60>,{long: None},"(long,)",{'dim': 1},{type_as: None},,long,type_as,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[2, 2048]]",[True],True,0.021862399578094483,0.021862399578094483,0,0,"(2, 2048)",torch.int64,cumsum
call_method,type_as,"{cumsum: None, long: None}","(cumsum, long)",{},{mul: None},,cumsum,mul,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[2, 2048], [2, 2048]]","[True, True]",True,0.012569599784910679,0.012569599784910679,0,0,"(2, 2048)",torch.int64,type_as
call_function,<built-in function mul>,"{type_as: None, long: None}","(type_as, long)",{},{long_1: None},,type_as,long_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[2, 2048], [2, 2048]]","[True, True]",True,0.02259200029075146,0.02259200029075146,0,0,"(2, 2048)",torch.int64,mul
call_method,long,{mul: None},"(mul,)",{},{sub_2: None},,mul,sub_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[2, 2048]]",[True],True,0.012057599984109402,0.012057599984109402,0,0,"(2, 2048)",torch.int64,long_1
call_function,<built-in function sub>,{long_1: None},"(long_1, 1)",{},{getitem_10: None},,long_1,getitem_10,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[2, 2048]]",[True],True,0.028089600056409834,0.028089600056409834,0,0,"(2, 2048)",torch.int64,sub_2
call_function,<built-in function getitem>,{sub_2: None},"(sub_2, (slice(None, None, None), slice(0, None, None)))",{},{add_4: None},,sub_2,add_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[2, 2048]]",[True],True,0.01902720034122467,0.01902720034122467,0,0,"(2, 2048)",torch.int64,getitem_10
call_function,<built-in function add>,{getitem_10: None},"(getitem_10, 2)",{},{embedding: None},,getitem_10,model_decoder_embed_positions_weight,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[2, 2048]]",[True],True,0.02720640040934086,0.02720640040934086,0,0,"(2, 2048)",torch.int64,add_4
get_attr,model.decoder.embed_positions.weight,{},(),{},{embedding: None},,add_4,embedding,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}",[],[],True,0.0,0.0,0,0,"(2050, 2048)",torch.float32,model_decoder_embed_positions_weight
call_function,<function embedding at 0x7fe85c86b700>,"{add_4: None, model_decoder_embed_positions_weight: None}","(add_4, model_decoder_embed_positions_weight)","{'padding_idx': None, 'max_norm': None, 'norm_type': 2.0, 'scale_grad_by_freq': False, 'sparse': False}",{add_5: None},,model_decoder_embed_positions_weight,add_5,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[2, 2048], [2050, 2048]]","[True, True]",True,0.38094080090522764,0.38094080090522764,0,0,"(2, 2048, 2048)",torch.float32,embedding
call_function,<built-in function add>,"{model_decoder_embed_tokens: None, embedding: None}","(model_decoder_embed_tokens, embedding)",{},"{model_decoder_layers_0_self_attn_layer_norm: None, add_7: None}",,embedding,model_decoder_layers_0_self_attn_layer_norm,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2, 2048, 2048], [2, 2048, 2048]]","[True, True]",True,0.19211519956588746,0.19211519956588746,0,0,"(2, 2048, 2048)",torch.float32,add_5
call_module,model.decoder.layers.0.self_attn_layer_norm,{add_5: None},"(add_5,)",{},"{size_6: None, model_decoder_layers_0_self_attn_q_proj: None, model_decoder_layers_0_self_attn_k_proj: None, model_decoder_layers_0_self_attn_v_proj: None}",,add_5,size_6,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn_layer_norm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[2, 2048, 2048]]",[True],True,0.251008003950119,0.251008003950119,0,0,"(2, 2048, 2048)",torch.float32,model_decoder_layers_0_self_attn_layer_norm
call_method,size,{model_decoder_layers_0_self_attn_layer_norm: None},"(model_decoder_layers_0_self_attn_layer_norm,)",{},"{getitem_11: None, getitem_12: None, getitem_13: None}",,model_decoder_layers_0_self_attn_layer_norm,getitem_11,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 2048, 2048]]",[True],True,0.011712000146508217,0.011712000146508217,0,0,"(1,)",,size_6
call_function,<built-in function getitem>,{size_6: None},"(size_6, 0)",{},"{view_2: None, view_3: None, mul_2: None, view_4: None, mul_3: None, ne_1: None, view_8: None, mul_4: None, mul_5: None, view_10: None, reshape: None}",,size_6,getitem_12,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.011289600096642972,0.011289600096642972,0,0,"(1,)",,getitem_11
call_function,<built-in function getitem>,{size_6: None},"(size_6, 1)",{},"{view_4: None, ne: None, ne_1: None, view_8: None, view_9: None, ne_2: None, view_10: None, reshape: None}",,getitem_11,getitem_13,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.011129599995911121,0.011129599995911121,0,0,"(1,)",,getitem_12
call_function,<built-in function getitem>,{size_6: None},"(size_6, 2)",{},{},,getitem_12,model_decoder_layers_0_self_attn_q_proj,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.01163520012050867,0.01163520012050867,0,0,"(1,)",,getitem_13
call_module,model.decoder.layers.0.self_attn.q_proj,{model_decoder_layers_0_self_attn_layer_norm: None},"(model_decoder_layers_0_self_attn_layer_norm,)",{},{mul_1: None},,getitem_13,mul_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>), ('model.decoder.layers.0.self_attn.q_proj', <class 'torch.nn.modules.linear.Linear'>)])}","[[2, 2048, 2048]]",[True],True,5.266169643402099,5.266169643402099,0,0,"(2, 2048, 2048)",torch.float32,model_decoder_layers_0_self_attn_q_proj
call_function,<built-in function mul>,{model_decoder_layers_0_self_attn_q_proj: None},"(model_decoder_layers_0_self_attn_q_proj, 0.125)",{},{view_4: None},,model_decoder_layers_0_self_attn_q_proj,model_decoder_layers_0_self_attn_k_proj,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 2048, 2048]]",[True],True,0.14050560295581818,0.14050560295581818,0,0,"(2, 2048, 2048)",torch.float32,mul_1
call_module,model.decoder.layers.0.self_attn.k_proj,{model_decoder_layers_0_self_attn_layer_norm: None},"(model_decoder_layers_0_self_attn_layer_norm,)",{},{view_2: None},,mul_1,view_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>), ('model.decoder.layers.0.self_attn.k_proj', <class 'torch.nn.modules.linear.Linear'>)])}","[[2, 2048, 2048]]",[True],True,4.81077766418457,4.81077766418457,0,0,"(2, 2048, 2048)",torch.float32,model_decoder_layers_0_self_attn_k_proj
call_method,view,"{model_decoder_layers_0_self_attn_k_proj: None, getitem_11: None}","(model_decoder_layers_0_self_attn_k_proj, getitem_11, -1, 32, 64)",{},{transpose: None},,model_decoder_layers_0_self_attn_k_proj,transpose,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 2048, 2048], [1]]","[True, True]",True,0.016755199804902077,0.016755199804902077,0,0,"(2, 2048, 32, 64)",torch.float32,view_2
call_method,transpose,{view_2: None},"(view_2, 1, 2)",{},{contiguous: None},,view_2,contiguous,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 2048, 32, 64]]",[True],False,0.016595199704170227,0.016595199704170227,0,0,"(2, 32, 2048, 64)",torch.float32,transpose
call_method,contiguous,{transpose: None},"(transpose,)",{},"{view_6: None, output: None}",,transpose,model_decoder_layers_0_self_attn_v_proj,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 32, 2048, 64]]",[False],True,0.17511039972305298,0.17511039972305298,0,0,"(2, 32, 2048, 64)",torch.float32,contiguous
call_module,model.decoder.layers.0.self_attn.v_proj,{model_decoder_layers_0_self_attn_layer_norm: None},"(model_decoder_layers_0_self_attn_layer_norm,)",{},{view_3: None},,contiguous,view_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>), ('model.decoder.layers.0.self_attn.v_proj', <class 'torch.nn.modules.linear.Linear'>)])}","[[2, 2048, 2048]]",[True],True,4.795411205291748,4.795411205291748,0,0,"(2, 2048, 2048)",torch.float32,model_decoder_layers_0_self_attn_v_proj
call_method,view,"{model_decoder_layers_0_self_attn_v_proj: None, getitem_11: None}","(model_decoder_layers_0_self_attn_v_proj, getitem_11, -1, 32, 64)",{},{transpose_1: None},,model_decoder_layers_0_self_attn_v_proj,transpose_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 2048, 2048], [1]]","[True, True]",True,0.01684480011463165,0.01684480011463165,0,0,"(2, 2048, 32, 64)",torch.float32,view_3
call_method,transpose,{view_3: None},"(view_3, 1, 2)",{},{contiguous_1: None},,view_3,contiguous_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 2048, 32, 64]]",[True],False,0.016000000387430192,0.016000000387430192,0,0,"(2, 32, 2048, 64)",torch.float32,transpose_1
call_method,contiguous,{transpose_1: None},"(transpose_1,)",{},"{view_7: None, output: None}",,transpose_1,mul_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 32, 2048, 64]]",[False],True,0.17321600019931793,0.17321600019931793,0,0,"(2, 32, 2048, 64)",torch.float32,contiguous_1
call_function,<built-in function mul>,{getitem_11: None},"(getitem_11, 32)",{},"{view_5: None, view_6: None, view_7: None}",,contiguous_1,view_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.011020799912512303,0.011020799912512303,0,0,"(1,)",,mul_2
call_method,view,"{mul_1: None, getitem_11: None, getitem_12: None}","(mul_1, getitem_11, getitem_12, 32, 64)",{},{transpose_2: None},,mul_2,transpose_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 2048, 2048], [1], [1]]","[True, True, True]",True,0.016127999871969223,0.016127999871969223,0,0,"(2, 2048, 32, 64)",torch.float32,view_4
call_method,transpose,{view_4: None},"(view_4, 1, 2)",{},{contiguous_2: None},,view_4,contiguous_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 2048, 32, 64]]",[True],False,0.016524799913167954,0.016524799913167954,0,0,"(2, 32, 2048, 64)",torch.float32,transpose_2
call_method,contiguous,{transpose_2: None},"(transpose_2,)",{},{view_5: None},,transpose_2,view_5,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 32, 2048, 64]]",[False],True,0.17409279942512512,0.17409279942512512,0,0,"(2, 32, 2048, 64)",torch.float32,contiguous_2
call_method,view,"{contiguous_2: None, mul_2: None}","(contiguous_2, mul_2, -1, 64)",{},{bmm: None},,contiguous_2,view_6,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 32, 2048, 64], [1]]","[True, True]",True,0.016121599823236465,0.016121599823236465,0,0,"(64, 2048, 64)",torch.float32,view_5
call_method,view,"{contiguous: None, mul_2: None}","(contiguous, mul_2, -1, 64)",{},"{size_7: None, transpose_3: None}",,view_5,view_7,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 32, 2048, 64], [1]]","[True, True]",True,0.016460799798369407,0.016460799798369407,0,0,"(64, 2048, 64)",torch.float32,view_6
call_method,view,"{contiguous_1: None, mul_2: None}","(contiguous_1, mul_2, -1, 64)",{},{bmm_1: None},,view_6,size_7,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 32, 2048, 64], [1]]","[True, True]",True,0.016499199718236924,0.016499199718236924,0,0,"(64, 2048, 64)",torch.float32,view_7
call_method,size,{view_6: None},"(view_6, 1)",{},"{ne: None, ne_1: None, view_8: None, view_9: None}",,view_7,transpose_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[64, 2048, 64]]",[True],True,0.01214080024510622,0.01214080024510622,0,0,"(1,)",,size_7
call_method,transpose,{view_6: None},"(view_6, 1, 2)",{},{bmm: None},,size_7,bmm,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[64, 2048, 64]]",[True],False,0.015398399904370308,0.015398399904370308,0,0,"(64, 64, 2048)",torch.float32,transpose_3
call_function,<built-in method bmm of type object at 0x7fe8ea474d60>,"{view_5: None, transpose_3: None}","(view_5, transpose_3)",{},"{size_8: None, view_8: None}",,transpose_3,size_8,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[64, 2048, 64], [64, 64, 2048]]","[True, False]",True,5.003225517272949,5.003225517272949,0,0,"(64, 2048, 2048)",torch.float32,bmm
call_method,size,{bmm: None},"(bmm,)",{},{ne: None},,bmm,mul_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[64, 2048, 2048]]",[True],True,0.011750399880111218,0.011750399880111218,0,0,"(1,)",,size_8
call_function,<built-in function mul>,{getitem_11: None},"(getitem_11, 32)",{},{ne: None},,size_8,ne,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.01142400000244379,0.01142400000244379,0,0,"(1,)",,mul_3
call_function,<built-in function ne>,"{size_8: None, mul_3: None, getitem_12: None, size_7: None}","(size_8, (mul_3, getitem_12, size_7))",{},{},,mul_3,size_9,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[1], [1], [1], [1]]","[True, True, True, True]",True,0.011180799826979637,0.011180799826979637,0,0,"(1,)",,ne
call_method,size,{masked_fill_1: None},"(masked_fill_1,)",{},{ne_1: None},,ne,ne_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 1, 2048, 2048]]",[True],True,0.011852799914777279,0.011852799914777279,0,0,"(1,)",,size_9
call_function,<built-in function ne>,"{size_9: None, getitem_11: None, getitem_12: None, size_7: None}","(size_9, (getitem_11, 1, getitem_12, size_7))",{},{},,size_9,view_8,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[1], [1], [1], [1]]","[True, True, True, True]",True,0.011142399907112122,0.011142399907112122,0,0,"(1,)",,ne_1
call_method,view,"{bmm: None, getitem_11: None, getitem_12: None, size_7: None}","(bmm, getitem_11, 32, getitem_12, size_7)",{},{add_6: None},,ne_1,add_6,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[64, 2048, 2048], [1], [1], [1]]","[True, True, True, True]",True,0.01674879975616932,0.01674879975616932,0,0,"(2, 32, 2048, 2048)",torch.float32,view_8
call_function,<built-in function add>,"{view_8: None, masked_fill_1: None}","(view_8, masked_fill_1)",{},"{getattr_8: None, getattr_10: None, max_1: None}",,view_8,getattr_8,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 32, 2048, 2048], [2, 1, 2048, 2048]]","[True, True]",True,5.763353633880615,5.763353633880615,0,0,"(2, 32, 2048, 2048)",torch.float32,add_6
call_function,<built-in function getattr>,{add_6: None},"(add_6, 'dtype')",{},{finfo_3: None},,add_6,finfo_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 32, 2048, 2048]]",[True],True,0.011366400122642516,0.011366400122642516,0,0,"(1,)",,getattr_8
call_function,<class 'torch.finfo'>,{getattr_8: None},"(getattr_8,)",{},{getattr_9: None},,getattr_8,getattr_9,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.011820800229907035,0.011820800229907035,0,0,"(1,)",,finfo_3
call_function,<built-in function getattr>,{finfo_3: None},"(finfo_3, 'min')",{},{tensor: None},,finfo_3,getattr_10,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.01137279998511076,0.01137279998511076,0,0,"(1,)",,getattr_9
call_function,<built-in function getattr>,{add_6: None},"(add_6, 'device')",{},{tensor: None},,getattr_9,tensor,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 32, 2048, 2048]]",[True],True,0.011795200034976005,0.011795200034976005,0,0,"(1,)",,getattr_10
call_function,<built-in method tensor of type object at 0x7fe8ea474d60>,"{getattr_9: None, getattr_10: None}","(getattr_9,)",{'device': getattr_10},{max_1: None},,getattr_10,max_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[1], [1]]","[True, True]",True,0.03800319880247116,0.03800319880247116,0,0,"(1,)",torch.float32,tensor
call_function,<built-in method max of type object at 0x7fe8ea474d60>,"{add_6: None, tensor: None}","(add_6, tensor)",{},{view_9: None},,tensor,mul_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 32, 2048, 2048], [1]]","[True, True]",True,4.49749116897583,4.49749116897583,0,0,"(2, 32, 2048, 2048)",torch.float32,max_1
call_function,<built-in function mul>,{getitem_11: None},"(getitem_11, 32)",{},{view_9: None},,max_1,view_9,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.011487999930977821,0.011487999930977821,0,0,"(1,)",,mul_4
call_method,view,"{max_1: None, mul_4: None, getitem_12: None, size_7: None}","(max_1, mul_4, getitem_12, size_7)",{},"{getattr_11: None, softmax: None}",,mul_4,getattr_11,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 32, 2048, 2048], [1], [1], [1]]","[True, True, True, True]",True,0.016377600282430647,0.016377600282430647,0,0,"(64, 2048, 2048)",torch.float32,view_9
call_function,<built-in function getattr>,{view_9: None},"(view_9, 'dtype')",{},{eq: None},,view_9,eq,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[64, 2048, 2048]]",[True],True,0.011897600069642068,0.011897600069642068,0,0,"(1,)",,getattr_11
call_function,<built-in function eq>,{getattr_11: None},"(getattr_11, torch.float16)",{},{},,getattr_11,softmax,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.011161600053310395,0.011161600053310395,0,0,"(1,)",,eq
call_function,<function softmax at 0x7fe85c86b160>,{view_9: None},"(view_9,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{dropout: None},,eq,dropout,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[64, 2048, 2048]]",[True],True,6.376224040985107,6.376224040985107,0,0,"(64, 2048, 2048)",torch.float32,softmax
call_function,<function dropout at 0x7fe85c8675e0>,{softmax: None},"(softmax,)","{'p': 0.0, 'training': False, 'inplace': False}",{bmm_1: None},,softmax,bmm_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[64, 2048, 2048]]",[True],True,0.01586560010910034,0.01586560010910034,0,0,"(64, 2048, 2048)",torch.float32,dropout
call_function,<built-in method bmm of type object at 0x7fe8ea474d60>,"{dropout: None, view_7: None}","(dropout, view_7)",{},"{size_10: None, view_10: None}",,dropout,size_10,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[64, 2048, 2048], [64, 2048, 64]]","[True, True]",True,8.042054367065429,8.042054367065429,0,0,"(64, 2048, 64)",torch.float32,bmm_1
call_method,size,{bmm_1: None},"(bmm_1,)",{},{ne_2: None},,bmm_1,mul_5,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[64, 2048, 64]]",[True],True,0.012185599841177463,0.012185599841177463,0,0,"(1,)",,size_10
call_function,<built-in function mul>,{getitem_11: None},"(getitem_11, 32)",{},{ne_2: None},,size_10,ne_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.011244800128042697,0.011244800128042697,0,0,"(1,)",,mul_5
call_function,<built-in function ne>,"{size_10: None, mul_5: None, getitem_12: None}","(size_10, (mul_5, getitem_12, 64))",{},{},,mul_5,view_10,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[1], [1], [1]]","[True, True, True]",True,0.011289599724113942,0.011289599724113942,0,0,"(1,)",,ne_2
call_method,view,"{bmm_1: None, getitem_11: None, getitem_12: None}","(bmm_1, getitem_11, 32, getitem_12, 64)",{},{transpose_4: None},,ne_2,transpose_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[64, 2048, 64], [1], [1]]","[True, True, True]",True,0.016224000230431558,0.016224000230431558,0,0,"(2, 32, 2048, 64)",torch.float32,view_10
call_method,transpose,{view_10: None},"(view_10, 1, 2)",{},{reshape: None},,view_10,reshape,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 32, 2048, 64]]",[True],False,0.01581439971923828,0.01581439971923828,0,0,"(2, 2048, 32, 64)",torch.float32,transpose_4
call_method,reshape,"{transpose_4: None, getitem_11: None, getitem_12: None}","(transpose_4, getitem_11, getitem_12, 2048)",{},{model_decoder_layers_0_self_attn_out_proj: None},,transpose_4,model_decoder_layers_0_self_attn_out_proj,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[2, 2048, 32, 64], [1], [1]]","[False, True, True]",True,0.17778560221195222,0.17778560221195222,0,0,"(2, 2048, 2048)",torch.float32,reshape
call_module,model.decoder.layers.0.self_attn.out_proj,{reshape: None},"(reshape,)",{},{dropout_1: None},,reshape,dropout_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>), ('model.decoder.layers.0.self_attn.out_proj', <class 'torch.nn.modules.linear.Linear'>)])}","[[2, 2048, 2048]]",[True],True,4.7888383865356445,4.7888383865356445,0,0,"(2, 2048, 2048)",torch.float32,model_decoder_layers_0_self_attn_out_proj
call_function,<function dropout at 0x7fe85c8675e0>,{model_decoder_layers_0_self_attn_out_proj: None},"(model_decoder_layers_0_self_attn_out_proj,)","{'p': 0.1, 'training': False, 'inplace': False}",{add_7: None},,model_decoder_layers_0_self_attn_out_proj,add_7,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[2, 2048, 2048]]",[True],True,0.016096000373363496,0.016096000373363496,0,0,"(2, 2048, 2048)",torch.float32,dropout_1
call_function,<built-in function add>,"{add_5: None, dropout_1: None}","(add_5, dropout_1)",{},"{size_11: None, size_12: None, reshape_1: None}",,dropout_1,size_11,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[2, 2048, 2048], [2, 2048, 2048]]","[True, True]",True,0.19232639968395232,0.19232639968395232,0,0,"(2, 2048, 2048)",torch.float32,add_7
call_method,size,{add_7: None},"(add_7,)",{},{view_11: None},,add_7,size_12,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[2, 2048, 2048]]",[True],True,0.011801599711179733,0.011801599711179733,0,0,"(1,)",,size_11
call_method,size,{add_7: None},"(add_7, -1)",{},{reshape_1: None},,size_11,reshape_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[2, 2048, 2048]]",[True],True,0.011923200078308582,0.011923200078308582,0,0,"(1,)",,size_12
call_method,reshape,"{add_7: None, size_12: None}","(add_7, -1, size_12)",{},"{model_decoder_layers_0_final_layer_norm: None, add_8: None}",,size_12,model_decoder_layers_0_final_layer_norm,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[2, 2048, 2048], [1]]","[True, True]",True,0.016063999757170676,0.016063999757170676,0,0,"(4096, 2048)",torch.float32,reshape_1
call_module,model.decoder.layers.0.final_layer_norm,{reshape_1: None},"(reshape_1,)",{},{model_decoder_layers_0_fc1: None},,reshape_1,model_decoder_layers_0_fc1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.final_layer_norm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[4096, 2048]]",[True],True,0.24536960422992707,0.24536960422992707,0,0,"(4096, 2048)",torch.float32,model_decoder_layers_0_final_layer_norm
call_module,model.decoder.layers.0.fc1,{model_decoder_layers_0_final_layer_norm: None},"(model_decoder_layers_0_final_layer_norm,)",{},{model_decoder_layers_0_activation_fn: None},,model_decoder_layers_0_final_layer_norm,model_decoder_layers_0_activation_fn,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.fc1', <class 'torch.nn.modules.linear.Linear'>)])}","[[4096, 2048]]",[True],True,19.215756607055663,19.215756607055663,0,0,"(4096, 8192)",torch.float32,model_decoder_layers_0_fc1
call_module,model.decoder.layers.0.activation_fn,{model_decoder_layers_0_fc1: None},"(model_decoder_layers_0_fc1,)",{},{model_decoder_layers_0_fc2: None},,model_decoder_layers_0_fc1,model_decoder_layers_0_fc2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.activation_fn', <class 'torch.nn.modules.activation.ReLU'>)])}","[[4096, 8192]]",[True],True,0.5107264041900634,0.5107264041900634,0,0,"(4096, 8192)",torch.float32,model_decoder_layers_0_activation_fn
call_module,model.decoder.layers.0.fc2,{model_decoder_layers_0_activation_fn: None},"(model_decoder_layers_0_activation_fn,)",{},{dropout_2: None},,model_decoder_layers_0_activation_fn,dropout_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.fc2', <class 'torch.nn.modules.linear.Linear'>)])}","[[4096, 8192]]",[True],True,19.056857299804687,19.056857299804687,0,0,"(4096, 2048)",torch.float32,model_decoder_layers_0_fc2
call_function,<function dropout at 0x7fe85c8675e0>,{model_decoder_layers_0_fc2: None},"(model_decoder_layers_0_fc2,)","{'p': 0.1, 'training': False, 'inplace': False}",{add_8: None},,model_decoder_layers_0_fc2,add_8,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[4096, 2048]]",[True],True,0.015808000043034554,0.015808000043034554,0,0,"(4096, 2048)",torch.float32,dropout_2
call_function,<built-in function add>,"{reshape_1: None, dropout_2: None}","(reshape_1, dropout_2)",{},{view_11: None},,dropout_2,view_11,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[4096, 2048], [4096, 2048]]","[True, True]",True,0.19432959854602813,0.19432959854602813,0,0,"(4096, 2048)",torch.float32,add_8
call_method,view,"{add_8: None, size_11: None}","(add_8, size_11)",{},{model_decoder_final_layer_norm: None},,add_8,model_decoder_final_layer_norm,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[4096, 2048], [1]]","[True, True]",True,0.016115199774503708,0.016115199774503708,0,0,"(2, 2048, 2048)",torch.float32,view_11
call_module,model.decoder.final_layer_norm,{view_11: None},"(view_11,)",{},{lm_head: None},,view_11,lm_head,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.final_layer_norm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[2, 2048, 2048]]",[True],True,0.23948160111904143,0.23948160111904143,0,0,"(2, 2048, 2048)",torch.float32,model_decoder_final_layer_norm
call_module,lm_head,{model_decoder_final_layer_norm: None},"(model_decoder_final_layer_norm,)",{},{contiguous_3: None},,model_decoder_final_layer_norm,contiguous_3,False,,"{'nn_module_stack': OrderedDict([('lm_head', <class 'torch.nn.modules.linear.Linear'>)])}","[[2, 2048, 2048]]",[True],True,98.80611877441406,98.80611877441406,0,0,"(2, 2048, 50272)",torch.float32,lm_head
call_method,contiguous,{lm_head: None},"(lm_head,)",{},{output: None},,lm_head,output,False,,{},"[[2, 2048, 50272]]",[True],True,0.012070400081574917,0.012070400081574917,0,0,"(2, 2048, 50272)",torch.float32,contiguous_3
output,output,"{contiguous_3: None, contiguous: None, contiguous_1: None}","({'logits': contiguous_3, 'past_key_values': ((contiguous, contiguous_1),)},)",{},{},,contiguous_3,,False,,{},"[[2, 2048, 50272], [2, 32, 2048, 64], [2, 32, 2048, 64]]","[True, True, True]",True,0.0,0.0,0,0,"(2, 2048, 50272)",torch.float32,output
