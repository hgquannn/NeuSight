op,target,_input_nodes,_args,_kwargs,users,type,_prev,_next,_erased,_repr_fn,meta,input_shapes,input_contiguous,contiguous,latency,fw_latency,bw_latency,acc_latency,output_shape,dtype,Name
placeholder,input_ids,{},(),{},"{size: None, view: None}",<class 'torch.Tensor'>,,size,False,,{},[],[],True,0.0,0.0,0,0,"(8, 2048)",torch.int64,input_ids
call_method,size,{input_ids: None},"(input_ids,)",{},"{getitem: None, getitem_1: None, getitem_2: None, getitem_3: None, getitem_4: None}",,input_ids,getitem,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048]]",[True],True,0.007257600035518408,0.007257600035518408,0,0,"(1,)",,size
call_function,<built-in function getitem>,{size: None},"(size, -1)",{},{view: None},,size,view,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.00703359991312027,0.00703359991312027,0,0,"(1,)",,getitem
call_method,view,"{input_ids: None, getitem: None}","(input_ids, -1, getitem)",{},{model_decoder_embed_tokens: None},,getitem,model_decoder_embed_tokens,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048], [1]]","[True, True]",True,0.008268799819052219,0.008268799819052219,0,0,"(8, 2048)",torch.int64,view
call_module,model.decoder.embed_tokens,{view: None},"(view,)",{},"{getattr_1: None, getattr_2: None, add_5: None}",,view,getitem_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_tokens', <class 'torch.nn.modules.sparse.Embedding'>)])}","[[8, 2048]]",[True],True,0.18581759929656982,0.18581759929656982,0,0,"(8, 2048, 2048)",torch.float32,model_decoder_embed_tokens
call_function,<built-in function getitem>,{size: None},"(size, 0)",{},{ones: None},,model_decoder_embed_tokens,getitem_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.0070847999304533005,0.0070847999304533005,0,0,"(1,)",,getitem_1
call_function,<built-in function getitem>,{size: None},"(size, 1)",{},{add: None},,getitem_1,add,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.007039999961853028,0.007039999961853028,0,0,"(1,)",,getitem_2
call_function,<built-in function add>,{getitem_2: None},"(0, getitem_2)",{},{ones: None},,getitem_2,getattr_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.007059199921786785,0.007059199921786785,0,0,"(1,)",,add
call_function,<built-in function getattr>,{model_decoder_embed_tokens: None},"(model_decoder_embed_tokens, 'device')",{},{ones: None},,add,ones,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048, 2048]]",[True],True,0.007199999969452619,0.007199999969452619,0,0,"(1,)",,getattr_1
call_function,<built-in method ones of type object at 0x15552dc96d80>,"{getitem_1: None, add: None, getattr_1: None}","(getitem_1, add)",{'device': getattr_1},"{size_1: None, size_2: None, getattr_4: None, size_5: None, getitem_9: None, getattr_6: None, long: None}",,getattr_1,getitem_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[1], [1], [1]]","[True, True, True]",True,0.012633599899709224,0.012633599899709224,0,0,"(8, 2048)",torch.float32,ones
call_function,<built-in function getitem>,{size: None},"(size, -1)",{},{add_1: None},,ones,add_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006841600034385919,0.006841600034385919,0,0,"(1,)",,getitem_3
call_function,<built-in function add>,{getitem_3: None},"(getitem_3, 0)",{},{sub: None},,getitem_3,size_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006982399988919497,0.006982399988919497,0,0,"(1,)",,add_1
call_method,size,{ones: None},"(ones,)",{},{},,add_1,getitem_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048]]",[True],True,0.007052799966186285,0.007052799966186285,0,0,"(1,)",,size_1
call_function,<built-in function getitem>,{size: None},"(size, -1)",{},"{gt: None, sub: None, full: None, add_3: None, expand: None, expand_1: None}",,size_1,size_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006879999954253435,0.006879999954253435,0,0,"(1,)",,getitem_4
call_method,size,{ones: None},"(ones,)",{},{getitem_5: None},,getitem_4,getitem_5,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048]]",[True],True,0.0068095999769866465,0.0068095999769866465,0,0,"(1,)",,size_2
call_function,<built-in function getitem>,{size_2: None},"(size_2, 0)",{},{expand: None},,size_2,gt,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006617600005120039,0.006617600005120039,0,0,"(1,)",,getitem_5
call_function,<built-in function gt>,{getitem_4: None},"(getitem_4, 1)",{},{},,getitem_5,sub,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006611200049519539,0.006611200049519539,0,0,"(1,)",,gt
call_function,<built-in function sub>,"{add_1: None, getitem_4: None}","(add_1, getitem_4)",{},"{gt_1: None, add_3: None}",,gt,getattr_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[1], [1]]","[True, True]",True,0.0067200000397861,0.0067200000397861,0,0,"(1,)",,sub
call_function,<built-in function getattr>,{model_decoder_embed_tokens: None},"(model_decoder_embed_tokens, 'dtype')",{},"{finfo: None, to: None, to_1: None, finfo_1: None, finfo_2: None}",,sub,finfo,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048, 2048]]",[True],True,0.0066432000137865545,0.0066432000137865545,0,0,"(1,)",,getattr_2
call_function,<class 'torch.finfo'>,{getattr_2: None},"(getattr_2,)",{},{getattr_3: None},,getattr_2,getattr_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006732800044119358,0.006732800044119358,0,0,"(1,)",,finfo
call_function,<built-in function getattr>,{finfo: None},"(finfo, 'min')",{},{full: None},,finfo,getattr_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006752000097185374,0.006752000097185374,0,0,"(1,)",,getattr_3
call_function,<built-in function getattr>,{ones: None},"(ones, 'device')",{},"{full: None, arange: None}",,getattr_3,full,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048]]",[True],True,0.006553599983453751,0.006553599983453751,0,0,"(1,)",,getattr_4
call_function,<built-in method full of type object at 0x15552dc96d80>,"{getitem_4: None, getattr_3: None, getattr_4: None}","((getitem_4, getitem_4), getattr_3)",{'device': getattr_4},"{size_3: None, size_4: None, masked_fill_: None, to: None}",,getattr_4,size_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[1], [1], [1]]","[True, True, True]",True,0.013542400114238263,0.013542400114238263,0,0,"(2048, 2048)",torch.float32,full
call_method,size,{full: None},"(full, -1)",{},{arange: None},,full,arange,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048, 2048]]",[True],True,0.006572800129652024,0.006572800129652024,0,0,"(1,)",,size_3
call_function,<built-in method arange of type object at 0x15552dc96d80>,"{size_3: None, getattr_4: None}","(size_3,)",{'device': getattr_4},"{add_2: None, lt: None}",,size_3,add_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[1], [1]]","[True, True]",True,0.012230399996042252,0.012230399996042252,0,0,"(2048,)",torch.int64,arange
call_function,<built-in function add>,{arange: None},"(arange, 1)",{},{view_1: None},,arange,size_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[2048]],[True],True,0.01242239996790886,0.01242239996790886,0,0,"(2048,)",torch.int64,add_2
call_method,size,{full: None},"(full, -1)",{},{view_1: None},,add_2,view_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048, 2048]]",[True],True,0.006566399987787008,0.006566399987787008,0,0,"(1,)",,size_4
call_method,view,"{add_2: None, size_4: None}","(add_2, size_4, 1)",{},{lt: None},,size_4,lt,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048], [1]]","[True, True]",True,0.007667199987918138,0.007667199987918138,0,0,"(2048, 1)",torch.int64,view_1
call_function,<built-in function lt>,"{arange: None, view_1: None}","(arange, view_1)",{},{masked_fill_: None},,view_1,masked_fill_,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048], [2048, 1]]","[True, True]",True,0.01809919998049736,0.01809919998049736,0,0,"(2048, 2048)",torch.bool,lt
call_method,masked_fill_,"{full: None, lt: None}","(full, lt, 0)",{},{},,lt,to,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048, 2048], [2048, 2048]]","[True, True]",True,0.012812799960374831,0.012812799960374831,0,0,"(2048, 2048)",torch.float32,masked_fill_
call_method,to,"{full: None, getattr_2: None}","(full, getattr_2)",{},{getitem_6: None},,masked_fill_,gt_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048, 2048], [1]]","[True, True]",True,0.006726400088518858,0.006726400088518858,0,0,"(2048, 2048)",torch.float32,to
call_function,<built-in function gt>,{sub: None},"(sub, 0)",{},{},,to,getitem_6,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006483200099319219,0.006483200099319219,0,0,"(1,)",,gt_1
call_function,<built-in function getitem>,{to: None},"(to, (None, None, slice(None, None, None), slice(None, None, None)))",{},{expand: None},,gt_1,add_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048, 2048]]",[True],True,0.010943999886512757,0.010943999886512757,0,0,"(1, 1, 2048, 2048)",torch.float32,getitem_6
call_function,<built-in function add>,"{getitem_4: None, sub: None}","(getitem_4, sub)",{},{expand: None},,getitem_6,expand,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[1], [1]]","[True, True]",True,0.006476800050586462,0.006476800050586462,0,0,"(1,)",,add_3
call_method,expand,"{getitem_6: None, getitem_5: None, getitem_4: None, add_3: None}","(getitem_6, getitem_5, 1, getitem_4, add_3)",{},{masked_fill_1: None},,add_3,size_5,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[1, 1, 2048, 2048], [1], [1], [1]]","[True, True, True, True]",False,0.00800000000745058,0.00800000000745058,0,0,"(8, 1, 2048, 2048)",torch.float32,expand
call_method,size,{ones: None},"(ones,)",{},"{getitem_7: None, getitem_8: None}",,expand,getitem_7,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048]]",[True],True,0.00666880002245307,0.00666880002245307,0,0,"(1,)",,size_5
call_function,<built-in function getitem>,{size_5: None},"(size_5, 0)",{},{expand_1: None},,size_5,getitem_8,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006483200006186962,0.006483200006186962,0,0,"(1,)",,getitem_7
call_function,<built-in function getitem>,{size_5: None},"(size_5, 1)",{},{expand_1: None},,getitem_7,getitem_9,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006527999974787235,0.006527999974787235,0,0,"(1,)",,getitem_8
call_function,<built-in function getitem>,{ones: None},"(ones, (slice(None, None, None), None, None, slice(None, None, None)))",{},{expand_1: None},,getitem_8,expand_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048]]",[True],True,0.01091840025037527,0.01091840025037527,0,0,"(8, 1, 1, 2048)",torch.float32,getitem_9
call_method,expand,"{getitem_9: None, getitem_7: None, getitem_4: None, getitem_8: None}","(getitem_9, getitem_7, 1, getitem_4, getitem_8)",{},{to_1: None},,getitem_9,to_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 1, 1, 2048], [1], [1], [1]]","[True, True, True, True]",False,0.007936000078916549,0.007936000078916549,0,0,"(8, 1, 2048, 2048)",torch.float32,expand_1
call_method,to,"{expand_1: None, getattr_2: None}","(expand_1, getattr_2)",{},{sub_1: None},,expand_1,sub_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 1, 2048, 2048], [1]]","[False, True]",False,0.006777600012719631,0.006777600012719631,0,0,"(8, 1, 2048, 2048)",torch.float32,to_1
call_function,<built-in function sub>,{to_1: None},"(1.0, to_1)",{},"{to_2: None, masked_fill: None}",,to_1,to_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 1, 2048, 2048]]",[False],True,0.08848000168800355,0.08848000168800355,0,0,"(8, 1, 2048, 2048)",torch.float32,sub_1
call_method,to,{sub_1: None},"(sub_1, torch.bool)",{},{masked_fill: None},,sub_1,finfo_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 1, 2048, 2048]]",[True],True,0.10095359981060029,0.10095359981060029,0,0,"(8, 1, 2048, 2048)",torch.bool,to_2
call_function,<class 'torch.finfo'>,{getattr_2: None},"(getattr_2,)",{},{getattr_5: None},,to_2,getattr_5,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006617600005120039,0.006617600005120039,0,0,"(1,)",,finfo_1
call_function,<built-in function getattr>,{finfo_1: None},"(finfo_1, 'min')",{},{masked_fill: None},,finfo_1,masked_fill,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.00650239996612072,0.00650239996612072,0,0,"(1,)",,getattr_5
call_method,masked_fill,"{sub_1: None, to_2: None, getattr_5: None}","(sub_1, to_2, getattr_5)",{},{to_3: None},,getattr_5,getattr_6,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 1, 2048, 2048], [8, 1, 2048, 2048], [1]]","[True, True, True]",True,0.21143679916858674,0.21143679916858674,0,0,"(8, 1, 2048, 2048)",torch.float32,masked_fill
call_function,<built-in function getattr>,{ones: None},"(ones, 'device')",{},{to_3: None},,masked_fill,to_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048]]",[True],True,0.0064639999531209465,0.0064639999531209465,0,0,"(1,)",,getattr_6
call_method,to,"{masked_fill: None, getattr_6: None}","(masked_fill, getattr_6)",{},{bool_1: None},,getattr_6,bool_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 1, 2048, 2048], [1]]","[True, True]",True,0.00687359981238842,0.00687359981238842,0,0,"(8, 1, 2048, 2048)",torch.float32,to_3
call_method,bool,{to_3: None},"(to_3,)",{},{masked_fill_1: None},,to_3,finfo_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 1, 2048, 2048]]",[True],True,0.10117119997739792,0.10117119997739792,0,0,"(8, 1, 2048, 2048)",torch.bool,bool_1
call_function,<class 'torch.finfo'>,{getattr_2: None},"(getattr_2,)",{},{getattr_7: None},,bool_1,getattr_7,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.00649600001052022,0.00649600001052022,0,0,"(1,)",,finfo_2
call_function,<built-in function getattr>,{finfo_2: None},"(finfo_2, 'min')",{},{masked_fill_1: None},,finfo_2,masked_fill_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006483200006186962,0.006483200006186962,0,0,"(1,)",,getattr_7
call_method,masked_fill,"{expand: None, bool_1: None, getattr_7: None}","(expand, bool_1, getattr_7)",{},"{size_9: None, add_6: None}",,getattr_7,long,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 1, 2048, 2048], [8, 1, 2048, 2048], [1]]","[False, True, True]",True,0.19752960205078124,0.19752960205078124,0,0,"(8, 1, 2048, 2048)",torch.float32,masked_fill_1
call_method,long,{ones: None},"(ones,)",{},"{cumsum: None, type_as: None, mul: None}",,masked_fill_1,cumsum,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[8, 2048]]",[True],True,0.01192959975451231,0.01192959975451231,0,0,"(8, 2048)",torch.int64,long
call_function,<built-in method cumsum of type object at 0x15552dc96d80>,{long: None},"(long,)",{'dim': 1},{type_as: None},,long,type_as,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[8, 2048]]",[True],True,0.013504000008106231,0.013504000008106231,0,0,"(8, 2048)",torch.int64,cumsum
call_method,type_as,"{cumsum: None, long: None}","(cumsum, long)",{},{mul: None},,cumsum,mul,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[8, 2048], [8, 2048]]","[True, True]",True,0.006771199870854616,0.006771199870854616,0,0,"(8, 2048)",torch.int64,type_as
call_function,<built-in function mul>,"{type_as: None, long: None}","(type_as, long)",{},{long_1: None},,type_as,long_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[8, 2048], [8, 2048]]","[True, True]",True,0.011366400122642516,0.011366400122642516,0,0,"(8, 2048)",torch.int64,mul
call_method,long,{mul: None},"(mul,)",{},{sub_2: None},,mul,sub_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[8, 2048]]",[True],True,0.006662400066852569,0.006662400066852569,0,0,"(8, 2048)",torch.int64,long_1
call_function,<built-in function sub>,{long_1: None},"(long_1, 1)",{},{getitem_10: None},,long_1,getitem_10,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[8, 2048]]",[True],True,0.012748799845576286,0.012748799845576286,0,0,"(8, 2048)",torch.int64,sub_2
call_function,<built-in function getitem>,{sub_2: None},"(sub_2, (slice(None, None, None), slice(0, None, None)))",{},{add_4: None},,sub_2,add_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[8, 2048]]",[True],True,0.009542400203645229,0.009542400203645229,0,0,"(8, 2048)",torch.int64,getitem_10
call_function,<built-in function add>,{getitem_10: None},"(getitem_10, 2)",{},{embedding: None},,getitem_10,model_decoder_embed_positions_weight,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[8, 2048]]",[True],True,0.01260799989104271,0.01260799989104271,0,0,"(8, 2048)",torch.int64,add_4
get_attr,model.decoder.embed_positions.weight,{},(),{},{embedding: None},,add_4,embedding,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}",[],[],True,0.0,0.0,0,0,"(2050, 2048)",torch.float32,model_decoder_embed_positions_weight
call_function,<function embedding at 0x15543f931f30>,"{add_4: None, model_decoder_embed_positions_weight: None}","(add_4, model_decoder_embed_positions_weight)","{'padding_idx': None, 'max_norm': None, 'norm_type': 2.0, 'scale_grad_by_freq': False, 'sparse': False}",{add_5: None},,model_decoder_embed_positions_weight,add_5,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[8, 2048], [2050, 2048]]","[True, True]",True,0.22908799946308137,0.22908799946308137,0,0,"(8, 2048, 2048)",torch.float32,embedding
call_function,<built-in function add>,"{model_decoder_embed_tokens: None, embedding: None}","(model_decoder_embed_tokens, embedding)",{},"{model_decoder_layers_0_self_attn_layer_norm: None, add_7: None}",,embedding,model_decoder_layers_0_self_attn_layer_norm,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048, 2048], [8, 2048, 2048]]","[True, True]",True,0.13726720213890076,0.13726720213890076,0,0,"(8, 2048, 2048)",torch.float32,add_5
call_module,model.decoder.layers.0.self_attn_layer_norm,{add_5: None},"(add_5,)",{},"{size_6: None, model_decoder_layers_0_self_attn_q_proj: None, model_decoder_layers_0_self_attn_k_proj: None, model_decoder_layers_0_self_attn_v_proj: None}",,add_5,size_6,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn_layer_norm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 2048, 2048]]",[True],True,0.11757439970970154,0.11757439970970154,0,0,"(8, 2048, 2048)",torch.float32,model_decoder_layers_0_self_attn_layer_norm
call_method,size,{model_decoder_layers_0_self_attn_layer_norm: None},"(model_decoder_layers_0_self_attn_layer_norm,)",{},"{getitem_11: None, getitem_12: None, getitem_13: None}",,model_decoder_layers_0_self_attn_layer_norm,getitem_11,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 2048, 2048]]",[True],True,0.006656000018119812,0.006656000018119812,0,0,"(1,)",,size_6
call_function,<built-in function getitem>,{size_6: None},"(size_6, 0)",{},"{view_2: None, view_3: None, mul_2: None, view_4: None, mul_3: None, ne_1: None, view_8: None, mul_4: None, mul_5: None, view_10: None, reshape: None}",,size_6,getitem_12,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.006425599940121174,0.006425599940121174,0,0,"(1,)",,getitem_11
call_function,<built-in function getitem>,{size_6: None},"(size_6, 1)",{},"{view_4: None, ne: None, ne_1: None, view_8: None, view_9: None, ne_2: None, view_10: None, reshape: None}",,getitem_11,getitem_13,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.006323199905455113,0.006323199905455113,0,0,"(1,)",,getitem_12
call_function,<built-in function getitem>,{size_6: None},"(size_6, 2)",{},{},,getitem_12,model_decoder_layers_0_self_attn_q_proj,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.006495999917387962,0.006495999917387962,0,0,"(1,)",,getitem_13
call_module,model.decoder.layers.0.self_attn.q_proj,{model_decoder_layers_0_self_attn_layer_norm: None},"(model_decoder_layers_0_self_attn_layer_norm,)",{},{mul_1: None},,getitem_13,mul_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>), ('model.decoder.layers.0.self_attn.q_proj', <class 'torch.nn.modules.linear.Linear'>)])}","[[8, 2048, 2048]]",[True],True,2.738976001739502,2.738976001739502,0,0,"(8, 2048, 2048)",torch.float32,model_decoder_layers_0_self_attn_q_proj
call_function,<built-in function mul>,{model_decoder_layers_0_self_attn_q_proj: None},"(model_decoder_layers_0_self_attn_q_proj, 0.125)",{},{view_4: None},,model_decoder_layers_0_self_attn_q_proj,model_decoder_layers_0_self_attn_k_proj,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 2048, 2048]]",[True],True,0.09722239822149277,0.09722239822149277,0,0,"(8, 2048, 2048)",torch.float32,mul_1
call_module,model.decoder.layers.0.self_attn.k_proj,{model_decoder_layers_0_self_attn_layer_norm: None},"(model_decoder_layers_0_self_attn_layer_norm,)",{},{view_2: None},,mul_1,view_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>), ('model.decoder.layers.0.self_attn.k_proj', <class 'torch.nn.modules.linear.Linear'>)])}","[[8, 2048, 2048]]",[True],True,2.7400959968566894,2.7400959968566894,0,0,"(8, 2048, 2048)",torch.float32,model_decoder_layers_0_self_attn_k_proj
call_method,view,"{model_decoder_layers_0_self_attn_k_proj: None, getitem_11: None}","(model_decoder_layers_0_self_attn_k_proj, getitem_11, -1, 32, 64)",{},{transpose: None},,model_decoder_layers_0_self_attn_k_proj,transpose,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 2048, 2048], [1]]","[True, True]",True,0.00825599990785122,0.00825599990785122,0,0,"(8, 2048, 32, 64)",torch.float32,view_2
call_method,transpose,{view_2: None},"(view_2, 1, 2)",{},{contiguous: None},,view_2,contiguous,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 2048, 32, 64]]",[True],False,0.008217599615454674,0.008217599615454674,0,0,"(8, 32, 2048, 64)",torch.float32,transpose
call_method,contiguous,{transpose: None},"(transpose,)",{},"{view_6: None, output: None}",,transpose,model_decoder_layers_0_self_attn_v_proj,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 64]]",[False],True,0.12280960083007812,0.12280960083007812,0,0,"(8, 32, 2048, 64)",torch.float32,contiguous
call_module,model.decoder.layers.0.self_attn.v_proj,{model_decoder_layers_0_self_attn_layer_norm: None},"(model_decoder_layers_0_self_attn_layer_norm,)",{},{view_3: None},,contiguous,view_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>), ('model.decoder.layers.0.self_attn.v_proj', <class 'torch.nn.modules.linear.Linear'>)])}","[[8, 2048, 2048]]",[True],True,2.7394688606262205,2.7394688606262205,0,0,"(8, 2048, 2048)",torch.float32,model_decoder_layers_0_self_attn_v_proj
call_method,view,"{model_decoder_layers_0_self_attn_v_proj: None, getitem_11: None}","(model_decoder_layers_0_self_attn_v_proj, getitem_11, -1, 32, 64)",{},{transpose_1: None},,model_decoder_layers_0_self_attn_v_proj,transpose_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 2048, 2048], [1]]","[True, True]",True,0.00834559965878725,0.00834559965878725,0,0,"(8, 2048, 32, 64)",torch.float32,view_3
call_method,transpose,{view_3: None},"(view_3, 1, 2)",{},{contiguous_1: None},,view_3,contiguous_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 2048, 32, 64]]",[True],False,0.008275200054049492,0.008275200054049492,0,0,"(8, 32, 2048, 64)",torch.float32,transpose_1
call_method,contiguous,{transpose_1: None},"(transpose_1,)",{},"{view_7: None, output: None}",,transpose_1,mul_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 64]]",[False],True,0.12264960110187531,0.12264960110187531,0,0,"(8, 32, 2048, 64)",torch.float32,contiguous_1
call_function,<built-in function mul>,{getitem_11: None},"(getitem_11, 32)",{},"{view_5: None, view_6: None, view_7: None}",,contiguous_1,view_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.006438399944454431,0.006438399944454431,0,0,"(1,)",,mul_2
call_method,view,"{mul_1: None, getitem_11: None, getitem_12: None}","(mul_1, getitem_11, getitem_12, 32, 64)",{},{transpose_2: None},,mul_2,transpose_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 2048, 2048], [1], [1]]","[True, True, True]",True,0.0081343999132514,0.0081343999132514,0,0,"(8, 2048, 32, 64)",torch.float32,view_4
call_method,transpose,{view_4: None},"(view_4, 1, 2)",{},{contiguous_2: None},,view_4,contiguous_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 2048, 32, 64]]",[True],False,0.00830719992518425,0.00830719992518425,0,0,"(8, 32, 2048, 64)",torch.float32,transpose_2
call_method,contiguous,{transpose_2: None},"(transpose_2,)",{},{view_5: None},,transpose_2,view_5,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 64]]",[False],True,0.12285440117120743,0.12285440117120743,0,0,"(8, 32, 2048, 64)",torch.float32,contiguous_2
call_method,view,"{contiguous_2: None, mul_2: None}","(contiguous_2, mul_2, -1, 64)",{},{bmm: None},,contiguous_2,view_6,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 64], [1]]","[True, True]",True,0.008326399885118008,0.008326399885118008,0,0,"(256, 2048, 64)",torch.float32,view_5
call_method,view,"{contiguous: None, mul_2: None}","(contiguous, mul_2, -1, 64)",{},"{size_7: None, transpose_3: None}",,view_5,view_7,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 64], [1]]","[True, True]",True,0.008230399899184703,0.008230399899184703,0,0,"(256, 2048, 64)",torch.float32,view_6
call_method,view,"{contiguous_1: None, mul_2: None}","(contiguous_1, mul_2, -1, 64)",{},{bmm_1: None},,view_6,size_7,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 64], [1]]","[True, True]",True,0.008025600016117096,0.008025600016117096,0,0,"(256, 2048, 64)",torch.float32,view_7
call_method,size,{view_6: None},"(view_6, 1)",{},"{ne: None, ne_1: None, view_8: None, view_9: None}",,view_7,transpose_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 64]]",[True],True,0.006515199970453978,0.006515199970453978,0,0,"(1,)",,size_7
call_method,transpose,{view_6: None},"(view_6, 1, 2)",{},{bmm: None},,size_7,bmm,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 64]]",[True],False,0.008223999850451946,0.008223999850451946,0,0,"(256, 64, 2048)",torch.float32,transpose_3
call_function,<built-in method bmm of type object at 0x15552dc96d80>,"{view_5: None, transpose_3: None}","(view_5, transpose_3)",{},"{size_8: None, view_8: None}",,transpose_3,size_8,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 64], [256, 64, 2048]]","[True, False]",True,4.019161701202393,4.019161701202393,0,0,"(256, 2048, 2048)",torch.float32,bmm
call_method,size,{bmm: None},"(bmm,)",{},{ne: None},,bmm,mul_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 2048]]",[True],True,0.006604800093919038,0.006604800093919038,0,0,"(1,)",,size_8
call_function,<built-in function mul>,{getitem_11: None},"(getitem_11, 32)",{},{ne: None},,size_8,ne,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.006451199948787689,0.006451199948787689,0,0,"(1,)",,mul_3
call_function,<built-in function ne>,"{size_8: None, mul_3: None, getitem_12: None, size_7: None}","(size_8, (mul_3, getitem_12, size_7))",{},{},,mul_3,size_9,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[1], [1], [1], [1]]","[True, True, True, True]",True,0.006508800014853477,0.006508800014853477,0,0,"(1,)",,ne
call_method,size,{masked_fill_1: None},"(masked_fill_1,)",{},{ne_1: None},,ne,ne_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 1, 2048, 2048]]",[True],True,0.006694400124251843,0.006694400124251843,0,0,"(1,)",,size_9
call_function,<built-in function ne>,"{size_9: None, getitem_11: None, getitem_12: None, size_7: None}","(size_9, (getitem_11, 1, getitem_12, size_7))",{},{},,size_9,view_8,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[1], [1], [1], [1]]","[True, True, True, True]",True,0.006585600040853024,0.006585600040853024,0,0,"(1,)",,ne_1
call_method,view,"{bmm: None, getitem_11: None, getitem_12: None, size_7: None}","(bmm, getitem_11, 32, getitem_12, size_7)",{},{add_6: None},,ne_1,add_6,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 2048], [1], [1], [1]]","[True, True, True, True]",True,0.008147200010716915,0.008147200010716915,0,0,"(8, 32, 2048, 2048)",torch.float32,view_8
call_function,<built-in function add>,"{view_8: None, masked_fill_1: None}","(view_8, masked_fill_1)",{},"{getattr_8: None, getattr_10: None, max_1: None}",,view_8,getattr_8,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 2048], [8, 1, 2048, 2048]]","[True, True]",True,4.603398323059082,4.603398323059082,0,0,"(8, 32, 2048, 2048)",torch.float32,add_6
call_function,<built-in function getattr>,{add_6: None},"(add_6, 'dtype')",{},{finfo_3: None},,add_6,finfo_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 2048]]",[True],True,0.006649600062519312,0.006649600062519312,0,0,"(1,)",,getattr_8
call_function,<class 'torch.finfo'>,{getattr_8: None},"(getattr_8,)",{},{getattr_9: None},,getattr_8,getattr_9,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.006681600026786328,0.006681600026786328,0,0,"(1,)",,finfo_3
call_function,<built-in function getattr>,{finfo_3: None},"(finfo_3, 'min')",{},{tensor: None},,finfo_3,getattr_10,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.006406399887055159,0.006406399887055159,0,0,"(1,)",,getattr_9
call_function,<built-in function getattr>,{add_6: None},"(add_6, 'device')",{},{tensor: None},,getattr_9,tensor,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 2048]]",[True],True,0.006470400001853704,0.006470400001853704,0,0,"(1,)",,getattr_10
call_function,<built-in method tensor of type object at 0x15552dc96d80>,"{getattr_9: None, getattr_10: None}","(getattr_9,)",{'device': getattr_10},{max_1: None},,getattr_10,max_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[1], [1]]","[True, True]",True,0.01911039985716343,0.01911039985716343,0,0,"(1,)",torch.float32,tensor
call_function,<built-in method max of type object at 0x15552dc96d80>,"{add_6: None, tensor: None}","(add_6, tensor)",{},{view_9: None},,tensor,mul_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 2048], [1]]","[True, True]",True,3.4673791885375977,3.4673791885375977,0,0,"(8, 32, 2048, 2048)",torch.float32,max_1
call_function,<built-in function mul>,{getitem_11: None},"(getitem_11, 32)",{},{view_9: None},,max_1,view_9,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.006617600005120039,0.006617600005120039,0,0,"(1,)",,mul_4
call_method,view,"{max_1: None, mul_4: None, getitem_12: None, size_7: None}","(max_1, mul_4, getitem_12, size_7)",{},"{getattr_11: None, softmax: None}",,mul_4,getattr_11,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 2048], [1], [1], [1]]","[True, True, True, True]",True,0.00808319989591837,0.00808319989591837,0,0,"(256, 2048, 2048)",torch.float32,view_9
call_function,<built-in function getattr>,{view_9: None},"(view_9, 'dtype')",{},{eq: None},,view_9,eq,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 2048]]",[True],True,0.006624000053852797,0.006624000053852797,0,0,"(1,)",,getattr_11
call_function,<built-in function eq>,{getattr_11: None},"(getattr_11, torch.float16)",{},{},,getattr_11,softmax,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.00650879992172122,0.00650879992172122,0,0,"(1,)",,eq
call_function,<function softmax at 0x15543f931900>,{view_9: None},"(view_9,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{dropout: None},,eq,dropout,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 2048]]",[True],True,3.3031872272491456,3.3031872272491456,0,0,"(256, 2048, 2048)",torch.float32,softmax
call_function,<function dropout at 0x15543f930d30>,{softmax: None},"(softmax,)","{'p': 0.0, 'training': False, 'inplace': False}",{bmm_1: None},,softmax,bmm_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 2048]]",[True],True,0.00876799989491701,0.00876799989491701,0,0,"(256, 2048, 2048)",torch.float32,dropout
call_function,<built-in method bmm of type object at 0x15552dc96d80>,"{dropout: None, view_7: None}","(dropout, view_7)",{},"{size_10: None, view_10: None}",,dropout,size_10,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 2048], [256, 2048, 64]]","[True, True]",True,2.9571648120880125,2.9571648120880125,0,0,"(256, 2048, 64)",torch.float32,bmm_1
call_method,size,{bmm_1: None},"(bmm_1,)",{},{ne_2: None},,bmm_1,mul_5,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 64]]",[True],True,0.006694400031119585,0.006694400031119585,0,0,"(1,)",,size_10
call_function,<built-in function mul>,{getitem_11: None},"(getitem_11, 32)",{},{ne_2: None},,size_10,ne_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.0064640000462532045,0.0064640000462532045,0,0,"(1,)",,mul_5
call_function,<built-in function ne>,"{size_10: None, mul_5: None, getitem_12: None}","(size_10, (mul_5, getitem_12, 64))",{},{},,mul_5,view_10,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[1], [1], [1]]","[True, True, True]",True,0.006457599997520447,0.006457599997520447,0,0,"(1,)",,ne_2
call_method,view,"{bmm_1: None, getitem_11: None, getitem_12: None}","(bmm_1, getitem_11, 32, getitem_12, 64)",{},{transpose_4: None},,ne_2,transpose_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 64], [1], [1]]","[True, True, True]",True,0.008019199967384339,0.008019199967384339,0,0,"(8, 32, 2048, 64)",torch.float32,view_10
call_method,transpose,{view_10: None},"(view_10, 1, 2)",{},{reshape: None},,view_10,reshape,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 64]]",[True],False,0.008198399841785432,0.008198399841785432,0,0,"(8, 2048, 32, 64)",torch.float32,transpose_4
call_method,reshape,"{transpose_4: None, getitem_11: None, getitem_12: None}","(transpose_4, getitem_11, getitem_12, 2048)",{},{model_decoder_layers_0_self_attn_out_proj: None},,transpose_4,model_decoder_layers_0_self_attn_out_proj,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 2048, 32, 64], [1], [1]]","[False, True, True]",True,0.12195200026035309,0.12195200026035309,0,0,"(8, 2048, 2048)",torch.float32,reshape
call_module,model.decoder.layers.0.self_attn.out_proj,{reshape: None},"(reshape,)",{},{dropout_1: None},,reshape,dropout_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>), ('model.decoder.layers.0.self_attn.out_proj', <class 'torch.nn.modules.linear.Linear'>)])}","[[8, 2048, 2048]]",[True],True,2.737785577774048,2.737785577774048,0,0,"(8, 2048, 2048)",torch.float32,model_decoder_layers_0_self_attn_out_proj
call_function,<function dropout at 0x15543f930d30>,{model_decoder_layers_0_self_attn_out_proj: None},"(model_decoder_layers_0_self_attn_out_proj,)","{'p': 0.1, 'training': False, 'inplace': False}",{add_7: None},,model_decoder_layers_0_self_attn_out_proj,add_7,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[8, 2048, 2048]]",[True],True,0.008620799891650677,0.008620799891650677,0,0,"(8, 2048, 2048)",torch.float32,dropout_1
call_function,<built-in function add>,"{add_5: None, dropout_1: None}","(add_5, dropout_1)",{},"{size_11: None, size_12: None, reshape_1: None}",,dropout_1,size_11,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[8, 2048, 2048], [8, 2048, 2048]]","[True, True]",True,0.1370368033647537,0.1370368033647537,0,0,"(8, 2048, 2048)",torch.float32,add_7
call_method,size,{add_7: None},"(add_7,)",{},{view_11: None},,add_7,size_12,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[8, 2048, 2048]]",[True],True,0.0064639999531209465,0.0064639999531209465,0,0,"(1,)",,size_11
call_method,size,{add_7: None},"(add_7, -1)",{},{reshape_1: None},,size_11,reshape_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[8, 2048, 2048]]",[True],True,0.0066304000094532965,0.0066304000094532965,0,0,"(1,)",,size_12
call_method,reshape,"{add_7: None, size_12: None}","(add_7, -1, size_12)",{},"{model_decoder_layers_0_final_layer_norm: None, add_8: None}",,size_12,model_decoder_layers_0_final_layer_norm,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[8, 2048, 2048], [1]]","[True, True]",True,0.008185600116848945,0.008185600116848945,0,0,"(16384, 2048)",torch.float32,reshape_1
call_module,model.decoder.layers.0.final_layer_norm,{reshape_1: None},"(reshape_1,)",{},{model_decoder_layers_0_fc1: None},,reshape_1,model_decoder_layers_0_fc1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.final_layer_norm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16384, 2048]]",[True],True,0.11681919991970062,0.11681919991970062,0,0,"(16384, 2048)",torch.float32,model_decoder_layers_0_final_layer_norm
call_module,model.decoder.layers.0.fc1,{model_decoder_layers_0_final_layer_norm: None},"(model_decoder_layers_0_final_layer_norm,)",{},{model_decoder_layers_0_activation_fn: None},,model_decoder_layers_0_final_layer_norm,model_decoder_layers_0_activation_fn,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.fc1', <class 'torch.nn.modules.linear.Linear'>)])}","[[16384, 2048]]",[True],True,10.73633918762207,10.73633918762207,0,0,"(16384, 8192)",torch.float32,model_decoder_layers_0_fc1
call_module,model.decoder.layers.0.activation_fn,{model_decoder_layers_0_fc1: None},"(model_decoder_layers_0_fc1,)",{},{model_decoder_layers_0_fc2: None},,model_decoder_layers_0_fc1,model_decoder_layers_0_fc2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.activation_fn', <class 'torch.nn.modules.activation.ReLU'>)])}","[[16384, 8192]]",[True],True,0.35989760160446166,0.35989760160446166,0,0,"(16384, 8192)",torch.float32,model_decoder_layers_0_activation_fn
call_module,model.decoder.layers.0.fc2,{model_decoder_layers_0_activation_fn: None},"(model_decoder_layers_0_activation_fn,)",{},{dropout_2: None},,model_decoder_layers_0_activation_fn,dropout_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.fc2', <class 'torch.nn.modules.linear.Linear'>)])}","[[16384, 8192]]",[True],True,10.816185760498048,10.816185760498048,0,0,"(16384, 2048)",torch.float32,model_decoder_layers_0_fc2
call_function,<function dropout at 0x15543f930d30>,{model_decoder_layers_0_fc2: None},"(model_decoder_layers_0_fc2,)","{'p': 0.1, 'training': False, 'inplace': False}",{add_8: None},,model_decoder_layers_0_fc2,add_8,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[16384, 2048]]",[True],True,0.008780800178647042,0.008780800178647042,0,0,"(16384, 2048)",torch.float32,dropout_2
call_function,<built-in function add>,"{reshape_1: None, dropout_2: None}","(reshape_1, dropout_2)",{},{view_11: None},,dropout_2,view_11,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[16384, 2048], [16384, 2048]]","[True, True]",True,0.13707520067691803,0.13707520067691803,0,0,"(16384, 2048)",torch.float32,add_8
call_method,view,"{add_8: None, size_11: None}","(add_8, size_11)",{},{model_decoder_final_layer_norm: None},,add_8,model_decoder_final_layer_norm,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[16384, 2048], [1]]","[True, True]",True,0.008134399726986884,0.008134399726986884,0,0,"(8, 2048, 2048)",torch.float32,view_11
call_module,model.decoder.final_layer_norm,{view_11: None},"(view_11,)",{},{lm_head: None},,view_11,lm_head,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.final_layer_norm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 2048, 2048]]",[True],True,0.11723520159721375,0.11723520159721375,0,0,"(8, 2048, 2048)",torch.float32,model_decoder_final_layer_norm
call_module,lm_head,{model_decoder_final_layer_norm: None},"(model_decoder_final_layer_norm,)",{},{contiguous_3: None},,model_decoder_final_layer_norm,contiguous_3,False,,"{'nn_module_stack': OrderedDict([('lm_head', <class 'torch.nn.modules.linear.Linear'>)])}","[[8, 2048, 2048]]",[True],True,65.2539566040039,65.2539566040039,0,0,"(8, 2048, 50272)",torch.float32,lm_head
call_method,contiguous,{lm_head: None},"(lm_head,)",{},{output: None},,lm_head,output,False,,{},"[[8, 2048, 50272]]",[True],True,0.006777600105851889,0.006777600105851889,0,0,"(8, 2048, 50272)",torch.float32,contiguous_3
output,output,"{contiguous_3: None, contiguous: None, contiguous_1: None}","({'logits': contiguous_3, 'past_key_values': ((contiguous, contiguous_1),)},)",{},{},,contiguous_3,,False,,{},"[[8, 2048, 50272], [8, 32, 2048, 64], [8, 32, 2048, 64]]","[True, True, True]",True,0.0,0.0,0,0,"(8, 2048, 50272)",torch.float32,output
