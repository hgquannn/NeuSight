op,target,_input_nodes,_args,_kwargs,users,type,_prev,_next,_erased,_repr_fn,meta,input_shapes,input_contiguous,contiguous,latency,fw_latency,bw_latency,acc_latency,output_shape,dtype,Name
placeholder,input_ids,{},(),{},"{size: None, view: None}",<class 'torch.Tensor'>,,size,False,,{},[],[],True,0.0,0.0,0,0,"(8, 2048)",torch.int64,input_ids
call_method,size,{input_ids: None},"(input_ids,)",{},"{getitem: None, getitem_2: None, getitem_3: None}",,input_ids,getitem,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 2048]]",[True],True,0.007110399939119816,0.007110399939119816,0,0,"(1,)",,size
call_function,<built-in function getitem>,{size: None},"(size, -1)",{},{view: None},,size,view,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.0068223999813199045,0.0068223999813199045,0,0,"(1,)",,getitem
call_method,view,"{input_ids: None, getitem: None}","(input_ids, -1, getitem)",{},"{size_1: None, getattr_1: None, transformer_wte: None}",,getitem,size_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 2048], [1]]","[True, True]",True,0.008127999864518643,0.008127999864518643,0,0,"(8, 2048)",torch.int64,view
call_method,size,{view: None},"(view,)",{},{getitem_1: None},,view,getitem_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 2048]]",[True],True,0.006975999940186739,0.006975999940186739,0,0,"(1,)",,size_1
call_function,<built-in function getitem>,{size_1: None},"(size_1, 0)",{},{},,size_1,getitem_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.0068223999813199045,0.0068223999813199045,0,0,"(1,)",,getitem_1
call_function,<built-in function getitem>,{size: None},"(size, -1)",{},{add: None},,getitem_1,add,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.006828800030052662,0.006828800030052662,0,0,"(1,)",,getitem_2
call_function,<built-in function add>,{getitem_2: None},"(getitem_2, 0)",{},{arange: None},,getitem_2,getattr_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.0067136000841856005,0.0067136000841856005,0,0,"(1,)",,add
call_function,<built-in function getattr>,{view: None},"(view, 'device')",{},{arange: None},,add,arange,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 2048]]",[True],True,0.006752000004053116,0.006752000004053116,0,0,"(1,)",,getattr_1
call_function,<built-in method arange of type object at 0x15552dc96d80>,"{add: None, getattr_1: None}","(0, add)","{'dtype': torch.int64, 'device': getattr_1}",{unsqueeze: None},,getattr_1,unsqueeze,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[1], [1]]","[True, True]",True,0.012211200222373009,0.012211200222373009,0,0,"(2048,)",torch.int64,arange
call_method,unsqueeze,{arange: None},"(arange, 0)",{},{transformer_wpe: None},,arange,transformer_wte,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[2048]],[True],True,0.008006400056183338,0.008006400056183338,0,0,"(1, 2048)",torch.int64,unsqueeze
call_module,transformer.wte,{view: None},"(view,)",{},{add_1: None},,unsqueeze,transformer_wpe,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.wte', <class 'torch.nn.modules.sparse.Embedding'>)])}","[[8, 2048]]",[True],True,0.2738367974758148,0.2738367974758148,0,0,"(8, 2048, 3072)",torch.float32,transformer_wte
call_module,transformer.wpe,{unsqueeze: None},"(unsqueeze,)",{},{add_1: None},,transformer_wte,add_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.wpe', <class 'torch.nn.modules.sparse.Embedding'>)])}","[[1, 2048]]",[True],True,0.05731840133666992,0.05731840133666992,0,0,"(1, 2048, 3072)",torch.float32,transformer_wpe
call_function,<built-in function add>,"{transformer_wte: None, transformer_wpe: None}","(transformer_wte, transformer_wpe)",{},{transformer_drop: None},,transformer_wpe,transformer_drop,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 2048, 3072], [1, 2048, 3072]]","[True, True]",True,0.22290559709072114,0.22290559709072114,0,0,"(8, 2048, 3072)",torch.float32,add_1
call_module,transformer.drop,{add_1: None},"(add_1,)",{},"{size_2: None, transformer_h_0_ln_1: None, add_10: None}",,add_1,getitem_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.drop', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 2048, 3072]]",[True],True,0.00974080003798008,0.00974080003798008,0,0,"(8, 2048, 3072)",torch.float32,transformer_drop
call_function,<built-in function getitem>,{size: None},"(size, slice(1, None, None))",{},{add_2: None},,transformer_drop,add_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.006470400001853704,0.006470400001853704,0,0,"(1,)",,getitem_3
call_function,<built-in function add>,{getitem_3: None},"((-1,), getitem_3)",{},{add_3: None},,getitem_3,size_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.006355199869722128,0.006355199869722128,0,0,"(1,)",,add_2
call_method,size,{transformer_drop: None},"(transformer_drop, -1)",{},{add_3: None},,add_2,add_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 2048, 3072]]",[True],True,0.006745600141584873,0.006745600141584873,0,0,"(1,)",,size_2
call_function,<built-in function add>,"{add_2: None, size_2: None}","(add_2, (size_2,))",{},{view_13: None},,size_2,transformer_h_0_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[1], [1]]","[True, True]",True,0.006528000067919493,0.006528000067919493,0,0,"(1,)",,add_3
call_module,transformer.h.0.ln_1,{transformer_drop: None},"(transformer_drop,)",{},"{size_3: None, size_4: None, view_1: None}",,add_3,size_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 2048, 3072]]",[True],True,0.16989440023899077,0.16989440023899077,0,0,"(8, 2048, 3072)",torch.float32,transformer_h_0_ln_1
call_method,size,{transformer_h_0_ln_1: None},"(transformer_h_0_ln_1,)",{},{getitem_4: None},,transformer_h_0_ln_1,getitem_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 2048, 3072]]",[True],True,0.006495999917387962,0.006495999917387962,0,0,"(1,)",,size_3
call_function,<built-in function getitem>,{size_3: None},"(size_3, slice(None, -1, None))",{},{add_4: None},,size_3,add_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.006431999895721674,0.006431999895721674,0,0,"(1,)",,getitem_4
call_function,<built-in function add>,{getitem_4: None},"(getitem_4, (9216,))",{},{view_2: None},,getitem_4,transformer_h_0_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.006374399922788143,0.006374399922788143,0,0,"(1,)",,add_4
get_attr,transformer.h.0.attn.c_attn.bias,{},(),{},{addmm: None},,add_4,size_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(9216,)",torch.float32,transformer_h_0_attn_c_attn_bias
call_method,size,{transformer_h_0_ln_1: None},"(transformer_h_0_ln_1, -1)",{},{view_1: None},,transformer_h_0_attn_c_attn_bias,view_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 2048, 3072]]",[True],True,0.006438399944454431,0.006438399944454431,0,0,"(1,)",,size_4
call_method,view,"{transformer_h_0_ln_1: None, size_4: None}","(transformer_h_0_ln_1, -1, size_4)",{},{addmm: None},,size_4,transformer_h_0_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 2048, 3072], [1]]","[True, True]",True,0.007871999964118003,0.007871999964118003,0,0,"(16384, 3072)",torch.float32,view_1
get_attr,transformer.h.0.attn.c_attn.weight,{},(),{},{addmm: None},,view_1,addmm,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(3072, 9216)",torch.float32,transformer_h_0_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x15552dc96d80>,"{transformer_h_0_attn_c_attn_bias: None, view_1: None, transformer_h_0_attn_c_attn_weight: None}","(transformer_h_0_attn_c_attn_bias, view_1, transformer_h_0_attn_c_attn_weight)",{},{view_2: None},,transformer_h_0_attn_c_attn_weight,view_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[9216], [16384, 3072], [3072, 9216]]","[True, True, True]",True,18.330918502807616,18.330918502807616,0,0,"(16384, 9216)",torch.float32,addmm
call_method,view,"{addmm: None, add_4: None}","(addmm, add_4)",{},{split: None},,addmm,split,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[16384, 9216], [1]]","[True, True]",True,0.008147200010716915,0.008147200010716915,0,0,"(8, 2048, 9216)",torch.float32,view_2
call_method,split,{view_2: None},"(view_2, 3072)",{'dim': 2},"{getitem_5: None, getitem_6: None, getitem_7: None}",,view_2,getitem_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 2048, 9216]]",[True],True,0.012256000190973282,0.012256000190973282,0,0,"(1,)",,split
call_function,<built-in function getitem>,{split: None},"(split, 0)",{},"{size_5: None, view_3: None}",,split,getitem_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,0.006361599918454886,0.006361599918454886,0,0,"(8, 2048, 3072)",torch.float32,getitem_5
call_function,<built-in function getitem>,{split: None},"(split, 1)",{},"{size_6: None, view_4: None}",,getitem_5,getitem_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,0.006508800014853477,0.006508800014853477,0,0,"(8, 2048, 3072)",torch.float32,getitem_6
call_function,<built-in function getitem>,{split: None},"(split, 2)",{},"{size_7: None, view_5: None}",,getitem_6,size_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,0.006489599961787463,0.006489599961787463,0,0,"(8, 2048, 3072)",torch.float32,getitem_7
call_method,size,{getitem_5: None},"(getitem_5,)",{},{getitem_8: None},,getitem_7,getitem_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 2048, 3072]]",[False],True,0.006675200071185827,0.006675200071185827,0,0,"(1,)",,size_5
call_function,<built-in function getitem>,{size_5: None},"(size_5, slice(None, -1, None))",{},{add_5: None},,size_5,add_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.00665600011125207,0.00665600011125207,0,0,"(1,)",,getitem_8
call_function,<built-in function add>,{getitem_8: None},"(getitem_8, (24, 128))",{},{view_3: None},,getitem_8,view_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006598400045186281,0.006598400045186281,0,0,"(1,)",,add_5
call_method,view,"{getitem_5: None, add_5: None}","(getitem_5, add_5)",{},{permute: None},,add_5,permute,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 2048, 3072], [1]]","[False, True]",False,0.00825599990785122,0.00825599990785122,0,0,"(8, 2048, 24, 128)",torch.float32,view_3
call_method,permute,{view_3: None},"(view_3, 0, 2, 1, 3)",{},"{matmul: None, size_9: None}",,view_3,size_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 2048, 24, 128]]",[False],False,0.008358399756252766,0.008358399756252766,0,0,"(8, 24, 2048, 128)",torch.float32,permute
call_method,size,{getitem_6: None},"(getitem_6,)",{},{getitem_9: None},,permute,getitem_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 2048, 3072]]",[False],True,0.006649599969387054,0.006649599969387054,0,0,"(1,)",,size_6
call_function,<built-in function getitem>,{size_6: None},"(size_6, slice(None, -1, None))",{},{add_6: None},,size_6,add_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006496000103652477,0.006496000103652477,0,0,"(1,)",,getitem_9
call_function,<built-in function add>,{getitem_9: None},"(getitem_9, (24, 128))",{},{view_4: None},,getitem_9,view_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006508800014853477,0.006508800014853477,0,0,"(1,)",,add_6
call_method,view,"{getitem_6: None, add_6: None}","(getitem_6, add_6)",{},{permute_1: None},,add_6,permute_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 2048, 3072], [1]]","[False, True]",False,0.008115199953317642,0.008115199953317642,0,0,"(8, 2048, 24, 128)",torch.float32,view_4
call_method,permute,{view_4: None},"(view_4, 0, 2, 1, 3)",{},"{transpose: None, size_10: None, output: None}",,view_4,size_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 2048, 24, 128]]",[False],False,0.008537599816918373,0.008537599816918373,0,0,"(8, 24, 2048, 128)",torch.float32,permute_1
call_method,size,{getitem_7: None},"(getitem_7,)",{},{getitem_10: None},,permute_1,getitem_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 2048, 3072]]",[False],True,0.006611199956387282,0.006611199956387282,0,0,"(1,)",,size_7
call_function,<built-in function getitem>,{size_7: None},"(size_7, slice(None, -1, None))",{},{add_7: None},,size_7,add_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.0064639999531209465,0.0064639999531209465,0,0,"(1,)",,getitem_10
call_function,<built-in function add>,{getitem_10: None},"(getitem_10, (24, 128))",{},{view_5: None},,getitem_10,view_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.0064640000462532045,0.0064640000462532045,0,0,"(1,)",,add_7
call_method,view,"{getitem_7: None, add_7: None}","(getitem_7, add_7)",{},{permute_2: None},,add_7,permute_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 2048, 3072], [1]]","[False, True]",False,0.008230399899184703,0.008230399899184703,0,0,"(8, 2048, 24, 128)",torch.float32,view_5
call_method,permute,{view_5: None},"(view_5, 0, 2, 1, 3)",{},"{size_8: None, getattr_9: None, matmul_1: None, output: None}",,view_5,transpose,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 2048, 24, 128]]",[False],False,0.008416000194847584,0.008416000194847584,0,0,"(8, 24, 2048, 128)",torch.float32,permute_2
call_method,transpose,{permute_1: None},"(permute_1, -1, -2)",{},{matmul: None},,permute_2,matmul,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 24, 2048, 128]]",[False],False,0.008134400099515915,0.008134400099515915,0,0,"(8, 24, 128, 2048)",torch.float32,transpose
call_function,<built-in method matmul of type object at 0x15552dc96d80>,"{permute: None, transpose: None}","(permute, transpose)",{},"{getattr_2: None, getattr_3: None, truediv: None}",,transpose,size_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 24, 2048, 128], [8, 24, 128, 2048]]","[False, False]",True,5.224223995208741,5.224223995208741,0,0,"(8, 24, 2048, 2048)",torch.float32,matmul
call_method,size,{permute_2: None},"(permute_2, -1)",{},{pow_1: None},,matmul,pow_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 24, 2048, 128]]",[False],True,0.006438399944454431,0.006438399944454431,0,0,"(1,)",,size_8
call_function,<built-in function pow>,{size_8: None},"(size_8, 0.5)",{},{full: None},,size_8,getattr_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006431999988853932,0.006431999988853932,0,0,"(1,)",,pow_1
call_function,<built-in function getattr>,{matmul: None},"(matmul, 'dtype')",{},{full: None},,pow_1,getattr_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 24, 2048, 2048]]",[True],True,0.006355199962854385,0.006355199962854385,0,0,"(1,)",,getattr_2
call_function,<built-in function getattr>,{matmul: None},"(matmul, 'device')",{},{full: None},,getattr_2,full,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 24, 2048, 2048]]",[True],True,0.006355199869722128,0.006355199869722128,0,0,"(1,)",,getattr_3
call_function,<built-in method full of type object at 0x15552dc96d80>,"{pow_1: None, getattr_2: None, getattr_3: None}","([], pow_1)","{'dtype': getattr_2, 'device': getattr_3}",{truediv: None},,getattr_3,truediv,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,0.011737600155174732,0.011737600155174732,0,0,"(1,)",torch.float32,full
call_function,<built-in function truediv>,"{matmul: None, full: None}","(matmul, full)",{},"{getattr_4: None, getattr_6: None, getattr_7: None, getattr_8: None, to: None}",,full,size_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 24, 2048, 2048], [1]]","[True, True]",True,2.57738881111145,2.57738881111145,0,0,"(8, 24, 2048, 2048)",torch.float32,truediv
call_method,size,{permute: None},"(permute, -2)",{},{sub: None},,truediv,size_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 24, 2048, 128]]",[False],True,0.006348799820989371,0.006348799820989371,0,0,"(1,)",,size_9
call_method,size,{permute_1: None},"(permute_1, -2)",{},"{sub: None, getitem_11: None}",,size_9,transformer_h_0_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 24, 2048, 128]]",[False],True,0.006431999988853932,0.006431999988853932,0,0,"(1,)",,size_10
get_attr,transformer.h.0.attn.bias,{},(),{},{getitem_11: None},,size_10,sub,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,0.0,0.0,0,0,"(1, 1, 2048, 2048)",torch.bool,transformer_h_0_attn_bias
call_function,<built-in function sub>,"{size_10: None, size_9: None}","(size_10, size_9)",{},{getitem_11: None},,transformer_h_0_attn_bias,getitem_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,0.006399999931454658,0.006399999931454658,0,0,"(1,)",,sub
call_function,<built-in function getitem>,"{transformer_h_0_attn_bias: None, sub: None, size_10: None}","(transformer_h_0_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub, size_10, None), slice(None, size_10, None)))",{},{where: None},,sub,getattr_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 2048, 2048], [1], [1]]","[True, True, True]",True,0.009932800196111202,0.009932800196111202,0,0,"(1, 1, 2048, 2048)",torch.bool,getitem_11
call_function,<built-in function getattr>,{truediv: None},"(truediv, 'dtype')",{},{finfo: None},,getitem_11,finfo,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 24, 2048, 2048]]",[True],True,0.006336000002920628,0.006336000002920628,0,0,"(1,)",,getattr_4
call_function,<class 'torch.finfo'>,{getattr_4: None},"(getattr_4,)",{},{getattr_5: None},,getattr_4,getattr_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006348800007253885,0.006348800007253885,0,0,"(1,)",,finfo
call_function,<built-in function getattr>,{finfo: None},"(finfo, 'min')",{},{full_1: None},,finfo,getattr_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006220799777656794,0.006220799777656794,0,0,"(1,)",,getattr_5
call_function,<built-in function getattr>,{truediv: None},"(truediv, 'dtype')",{},{full_1: None},,getattr_5,getattr_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 24, 2048, 2048]]",[True],True,0.006419199891388417,0.006419199891388417,0,0,"(1,)",,getattr_6
call_function,<built-in function getattr>,{truediv: None},"(truediv, 'device')",{},{full_1: None},,getattr_6,full_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 24, 2048, 2048]]",[True],True,0.006265600025653839,0.006265600025653839,0,0,"(1,)",,getattr_7
call_function,<built-in method full of type object at 0x15552dc96d80>,"{getattr_5: None, getattr_6: None, getattr_7: None}","([], getattr_5)","{'dtype': getattr_6, 'device': getattr_7}",{where: None},,getattr_7,getattr_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,0.01178239993751049,0.01178239993751049,0,0,"(1,)",torch.float32,full_1
call_function,<built-in function getattr>,{truediv: None},"(truediv, 'dtype')",{},{to: None},,full_1,to,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 24, 2048, 2048]]",[True],True,0.0064512000419199465,0.0064512000419199465,0,0,"(1,)",,getattr_8
call_method,to,"{truediv: None, getattr_8: None}","(truediv, getattr_8)",{},{where: None},,getattr_8,where,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 24, 2048, 2048], [1]]","[True, True]",True,0.006636800058186054,0.006636800058186054,0,0,"(8, 24, 2048, 2048)",torch.float32,to
call_function,<built-in method where of type object at 0x15552dc96d80>,"{getitem_11: None, to: None, full_1: None}","(getitem_11, to, full_1)",{},{softmax: None},,to,softmax,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 2048, 2048], [8, 24, 2048, 2048], [1]]","[True, True, True]",True,2.553343963623047,2.553343963623047,0,0,"(8, 24, 2048, 2048)",torch.float32,where
call_function,<function softmax at 0x15543f939900>,{where: None},"(where,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_1: None},,where,getattr_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 24, 2048, 2048]]",[True],True,2.4714560508728027,2.4714560508728027,0,0,"(8, 24, 2048, 2048)",torch.float32,softmax
call_function,<built-in function getattr>,{permute_2: None},"(permute_2, 'dtype')",{},{type_1: None},,softmax,type_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 24, 2048, 128]]",[False],True,0.006457599997520447,0.006457599997520447,0,0,"(1,)",,getattr_9
call_method,type,"{softmax: None, getattr_9: None}","(softmax, getattr_9)",{},{transformer_h_0_attn_attn_dropout: None},,getattr_9,transformer_h_0_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 24, 2048, 2048], [1]]","[True, True]",True,0.006566400080919266,0.006566400080919266,0,0,"(8, 24, 2048, 2048)",torch.float32,type_1
call_module,transformer.h.0.attn.attn_dropout,{type_1: None},"(type_1,)",{},{matmul_1: None},,type_1,matmul_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 24, 2048, 2048]]",[True],True,0.009094399772584439,0.009094399772584439,0,0,"(8, 24, 2048, 2048)",torch.float32,transformer_h_0_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x15552dc96d80>,"{transformer_h_0_attn_attn_dropout: None, permute_2: None}","(transformer_h_0_attn_attn_dropout, permute_2)",{},{permute_3: None},,transformer_h_0_attn_attn_dropout,permute_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 24, 2048, 2048], [8, 24, 2048, 128]]","[True, False]",True,4.039161682128906,4.039161682128906,0,0,"(8, 24, 2048, 128)",torch.float32,matmul_1
call_method,permute,{matmul_1: None},"(matmul_1, 0, 2, 1, 3)",{},{contiguous: None},,matmul_1,contiguous,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 24, 2048, 128]]",[True],False,0.008448000065982342,0.008448000065982342,0,0,"(8, 2048, 24, 128)",torch.float32,permute_3
call_method,contiguous,{permute_3: None},"(permute_3,)",{},"{size_11: None, view_6: None}",,permute_3,size_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 2048, 24, 128]]",[False],True,0.17729920148849487,0.17729920148849487,0,0,"(8, 2048, 24, 128)",torch.float32,contiguous
call_method,size,{contiguous: None},"(contiguous,)",{},{getitem_12: None},,contiguous,getitem_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 2048, 24, 128]]",[True],True,0.006553599983453751,0.006553599983453751,0,0,"(1,)",,size_11
call_function,<built-in function getitem>,{size_11: None},"(size_11, slice(None, -2, None))",{},{add_8: None},,size_11,add_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006412800028920173,0.006412800028920173,0,0,"(1,)",,getitem_12
call_function,<built-in function add>,{getitem_12: None},"(getitem_12, (3072,))",{},{view_6: None},,getitem_12,view_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006291199941188097,0.006291199941188097,0,0,"(1,)",,add_8
call_method,view,"{contiguous: None, add_8: None}","(contiguous, add_8)",{},"{size_12: None, size_13: None, view_7: None}",,add_8,size_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 2048, 24, 128], [1]]","[True, True]",True,0.00796159990131855,0.00796159990131855,0,0,"(8, 2048, 3072)",torch.float32,view_6
call_method,size,{view_6: None},"(view_6,)",{},{getitem_13: None},,view_6,getitem_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 2048, 3072]]",[True],True,0.006419199984520674,0.006419199984520674,0,0,"(1,)",,size_12
call_function,<built-in function getitem>,{size_12: None},"(size_12, slice(None, -1, None))",{},{add_9: None},,size_12,add_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.006412799935787916,0.006412799935787916,0,0,"(1,)",,getitem_13
call_function,<built-in function add>,{getitem_13: None},"(getitem_13, (3072,))",{},{view_8: None},,getitem_13,transformer_h_0_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.00665600011125207,0.00665600011125207,0,0,"(1,)",,add_9
get_attr,transformer.h.0.attn.c_proj.bias,{},(),{},{addmm_1: None},,add_9,size_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(3072,)",torch.float32,transformer_h_0_attn_c_proj_bias
call_method,size,{view_6: None},"(view_6, -1)",{},{view_7: None},,transformer_h_0_attn_c_proj_bias,view_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 2048, 3072]]",[True],True,0.00650879992172122,0.00650879992172122,0,0,"(1,)",,size_13
call_method,view,"{view_6: None, size_13: None}","(view_6, -1, size_13)",{},{addmm_1: None},,size_13,transformer_h_0_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 2048, 3072], [1]]","[True, True]",True,0.008140799961984158,0.008140799961984158,0,0,"(16384, 3072)",torch.float32,view_7
get_attr,transformer.h.0.attn.c_proj.weight,{},(),{},{addmm_1: None},,view_7,addmm_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(3072, 3072)",torch.float32,transformer_h_0_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x15552dc96d80>,"{transformer_h_0_attn_c_proj_bias: None, view_7: None, transformer_h_0_attn_c_proj_weight: None}","(transformer_h_0_attn_c_proj_bias, view_7, transformer_h_0_attn_c_proj_weight)",{},{view_8: None},,transformer_h_0_attn_c_proj_weight,view_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3072], [16384, 3072], [3072, 3072]]","[True, True, True]",True,6.285542297363281,6.285542297363281,0,0,"(16384, 3072)",torch.float32,addmm_1
call_method,view,"{addmm_1: None, add_9: None}","(addmm_1, add_9)",{},{transformer_h_0_attn_resid_dropout: None},,addmm_1,transformer_h_0_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[16384, 3072], [1]]","[True, True]",True,0.0077759999781847,0.0077759999781847,0,0,"(8, 2048, 3072)",torch.float32,view_8
call_module,transformer.h.0.attn.resid_dropout,{view_8: None},"(view_8,)",{},{add_10: None},,view_8,add_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 2048, 3072]]",[True],True,0.009369600005447865,0.009369600005447865,0,0,"(8, 2048, 3072)",torch.float32,transformer_h_0_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_0_attn_resid_dropout: None, transformer_drop: None}","(transformer_h_0_attn_resid_dropout, transformer_drop)",{},"{transformer_h_0_ln_2: None, add_15: None}",,transformer_h_0_attn_resid_dropout,transformer_h_0_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 2048, 3072], [8, 2048, 3072]]","[True, True]",True,0.2021504044532776,0.2021504044532776,0,0,"(8, 2048, 3072)",torch.float32,add_10
call_module,transformer.h.0.ln_2,{add_10: None},"(add_10,)",{},"{size_14: None, size_15: None, view_9: None}",,add_10,size_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 2048, 3072]]",[True],True,0.16964479982852937,0.16964479982852937,0,0,"(8, 2048, 3072)",torch.float32,transformer_h_0_ln_2
call_method,size,{transformer_h_0_ln_2: None},"(transformer_h_0_ln_2,)",{},{getitem_14: None},,transformer_h_0_ln_2,getitem_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 2048, 3072]]",[True],True,0.006393599975854159,0.006393599975854159,0,0,"(1,)",,size_14
call_function,<built-in function getitem>,{size_14: None},"(size_14, slice(None, -1, None))",{},{add_11: None},,size_14,add_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.006419199891388417,0.006419199891388417,0,0,"(1,)",,getitem_14
call_function,<built-in function add>,{getitem_14: None},"(getitem_14, (12288,))",{},{view_10: None},,getitem_14,transformer_h_0_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.006399999931454658,0.006399999931454658,0,0,"(1,)",,add_11
get_attr,transformer.h.0.mlp.c_fc.bias,{},(),{},{addmm_2: None},,add_11,size_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(12288,)",torch.float32,transformer_h_0_mlp_c_fc_bias
call_method,size,{transformer_h_0_ln_2: None},"(transformer_h_0_ln_2, -1)",{},{view_9: None},,transformer_h_0_mlp_c_fc_bias,view_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 2048, 3072]]",[True],True,0.006515200063586235,0.006515200063586235,0,0,"(1,)",,size_15
call_method,view,"{transformer_h_0_ln_2: None, size_15: None}","(transformer_h_0_ln_2, -1, size_15)",{},{addmm_2: None},,size_15,transformer_h_0_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 2048, 3072], [1]]","[True, True]",True,0.007942399941384792,0.007942399941384792,0,0,"(16384, 3072)",torch.float32,view_9
get_attr,transformer.h.0.mlp.c_fc.weight,{},(),{},{addmm_2: None},,view_9,addmm_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(3072, 12288)",torch.float32,transformer_h_0_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x15552dc96d80>,"{transformer_h_0_mlp_c_fc_bias: None, view_9: None, transformer_h_0_mlp_c_fc_weight: None}","(transformer_h_0_mlp_c_fc_bias, view_9, transformer_h_0_mlp_c_fc_weight)",{},{view_10: None},,transformer_h_0_mlp_c_fc_weight,view_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[12288], [16384, 3072], [3072, 12288]]","[True, True, True]",True,24.47744674682617,24.47744674682617,0,0,"(16384, 12288)",torch.float32,addmm_2
call_method,view,"{addmm_2: None, add_11: None}","(addmm_2, add_11)",{},"{mul: None, pow_2: None, add_12: None}",,addmm_2,mul,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[16384, 12288], [1]]","[True, True]",True,0.007967999950051308,0.007967999950051308,0,0,"(8, 2048, 12288)",torch.float32,view_10
call_function,<built-in function mul>,{view_10: None},"(0.5, view_10)",{},{mul_3: None},,view_10,pow_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 2048, 12288]]",[True],True,0.5351103901863098,0.5351103901863098,0,0,"(8, 2048, 12288)",torch.float32,mul
call_function,<built-in method pow of type object at 0x15552dc96d80>,{view_10: None},"(view_10, 3.0)",{},{mul_1: None},,mul,mul_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 2048, 12288]]",[True],True,0.5351040124893188,0.5351040124893188,0,0,"(8, 2048, 12288)",torch.float32,pow_2
call_function,<built-in function mul>,{pow_2: None},"(0.044715, pow_2)",{},{add_12: None},,pow_2,add_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 2048, 12288]]",[True],True,0.5356351971626282,0.5356351971626282,0,0,"(8, 2048, 12288)",torch.float32,mul_1
call_function,<built-in function add>,"{view_10: None, mul_1: None}","(view_10, mul_1)",{},{mul_2: None},,mul_1,mul_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 2048, 12288], [8, 2048, 12288]]","[True, True]",True,0.7845888018608094,0.7845888018608094,0,0,"(8, 2048, 12288)",torch.float32,add_12
call_function,<built-in function mul>,{add_12: None},"(0.7978845608028654, add_12)",{},{tanh: None},,add_12,tanh,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 2048, 12288]]",[True],True,0.5360448002815247,0.5360448002815247,0,0,"(8, 2048, 12288)",torch.float32,mul_2
call_function,<built-in method tanh of type object at 0x15552dc96d80>,{mul_2: None},"(mul_2,)",{},{add_13: None},,mul_2,add_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 2048, 12288]]",[True],True,0.5338880062103272,0.5338880062103272,0,0,"(8, 2048, 12288)",torch.float32,tanh
call_function,<built-in function add>,{tanh: None},"(1.0, tanh)",{},{mul_3: None},,tanh,mul_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 2048, 12288]]",[True],True,0.5359552145004273,0.5359552145004273,0,0,"(8, 2048, 12288)",torch.float32,add_13
call_function,<built-in function mul>,"{mul: None, add_13: None}","(mul, add_13)",{},"{size_16: None, size_17: None, view_11: None}",,add_13,size_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 2048, 12288], [8, 2048, 12288]]","[True, True]",True,0.7835456013679505,0.7835456013679505,0,0,"(8, 2048, 12288)",torch.float32,mul_3
call_method,size,{mul_3: None},"(mul_3,)",{},{getitem_15: None},,mul_3,getitem_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 2048, 12288]]",[True],True,0.00650239996612072,0.00650239996612072,0,0,"(1,)",,size_16
call_function,<built-in function getitem>,{size_16: None},"(size_16, slice(None, -1, None))",{},{add_14: None},,size_16,add_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.00650879992172122,0.00650879992172122,0,0,"(1,)",,getitem_15
call_function,<built-in function add>,{getitem_15: None},"(getitem_15, (3072,))",{},{view_12: None},,getitem_15,transformer_h_0_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.0062847999855875965,0.0062847999855875965,0,0,"(1,)",,add_14
get_attr,transformer.h.0.mlp.c_proj.bias,{},(),{},{addmm_3: None},,add_14,size_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(3072,)",torch.float32,transformer_h_0_mlp_c_proj_bias
call_method,size,{mul_3: None},"(mul_3, -1)",{},{view_11: None},,transformer_h_0_mlp_c_proj_bias,view_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 2048, 12288]]",[True],True,0.006348800007253885,0.006348800007253885,0,0,"(1,)",,size_17
call_method,view,"{mul_3: None, size_17: None}","(mul_3, -1, size_17)",{},{addmm_3: None},,size_17,transformer_h_0_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 2048, 12288], [1]]","[True, True]",True,0.007846400048583746,0.007846400048583746,0,0,"(16384, 12288)",torch.float32,view_11
get_attr,transformer.h.0.mlp.c_proj.weight,{},(),{},{addmm_3: None},,view_11,addmm_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(12288, 3072)",torch.float32,transformer_h_0_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x15552dc96d80>,"{transformer_h_0_mlp_c_proj_bias: None, view_11: None, transformer_h_0_mlp_c_proj_weight: None}","(transformer_h_0_mlp_c_proj_bias, view_11, transformer_h_0_mlp_c_proj_weight)",{},{view_12: None},,transformer_h_0_mlp_c_proj_weight,view_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3072], [16384, 12288], [12288, 3072]]","[True, True, True]",True,24.608236694335936,24.608236694335936,0,0,"(16384, 3072)",torch.float32,addmm_3
call_method,view,"{addmm_3: None, add_14: None}","(addmm_3, add_14)",{},{transformer_h_0_mlp_dropout: None},,addmm_3,transformer_h_0_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[16384, 3072], [1]]","[True, True]",True,0.007859199959784745,0.007859199959784745,0,0,"(8, 2048, 3072)",torch.float32,view_12
call_module,transformer.h.0.mlp.dropout,{view_12: None},"(view_12,)",{},{add_15: None},,view_12,add_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 2048, 3072]]",[True],True,0.009401600062847137,0.009401600062847137,0,0,"(8, 2048, 3072)",torch.float32,transformer_h_0_mlp_dropout
call_function,<built-in function add>,"{add_10: None, transformer_h_0_mlp_dropout: None}","(add_10, transformer_h_0_mlp_dropout)",{},{transformer_ln_f: None},,transformer_h_0_mlp_dropout,transformer_ln_f,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 2048, 3072], [8, 2048, 3072]]","[True, True]",True,0.20226559937000274,0.20226559937000274,0,0,"(8, 2048, 3072)",torch.float32,add_15
call_module,transformer.ln_f,{add_15: None},"(add_15,)",{},{view_13: None},,add_15,view_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.ln_f', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 2048, 3072]]",[True],True,0.16924800276756286,0.16924800276756286,0,0,"(8, 2048, 3072)",torch.float32,transformer_ln_f
call_method,view,"{transformer_ln_f: None, add_3: None}","(transformer_ln_f, add_3)",{},{lm_head: None},,transformer_ln_f,lm_head,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 2048, 3072], [1]]","[True, True]",True,0.007827200088649988,0.007827200088649988,0,0,"(8, 2048, 3072)",torch.float32,view_13
call_module,lm_head,{view_13: None},"(view_13,)",{},{output: None},,view_13,output,False,,"{'nn_module_stack': OrderedDict([('lm_head', <class 'torch.nn.modules.linear.Linear'>)])}","[[8, 2048, 3072]]",[True],True,96.02393035888672,96.02393035888672,0,0,"(8, 2048, 50257)",torch.float32,lm_head
output,output,"{lm_head: None, permute_1: None, permute_2: None}","({'logits': lm_head, 'past_key_values': ((permute_1, permute_2),)},)",{},{},,lm_head,,False,,{},"[[8, 2048, 50257], [8, 24, 2048, 128], [8, 24, 2048, 128]]","[True, False, False]",True,0.0,0.0,0,0,"(8, 2048, 50257)",torch.float32,output
