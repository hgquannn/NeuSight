op,target,_input_nodes,_args,_kwargs,users,type,_prev,_next,_erased,_repr_fn,meta,input_shapes,input_contiguous,contiguous,latency,fw_latency,bw_latency,acc_latency,output_shape,dtype,Name
placeholder,input_ids,{},(),{},"{size: None, view: None}",<class 'torch.Tensor'>,,size,False,,{},[],[],True,0.0,0.0,0,0,"(2, 2048)",torch.int64,input_ids
call_method,size,{input_ids: None},"(input_ids,)",{},"{getitem: None, getitem_2: None, getitem_3: None}",,input_ids,getitem,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[2, 2048]]",[True],True,0.007539199944585562,0.007539199944585562,0,0,"(1,)",,size
call_function,<built-in function getitem>,{size: None},"(size, -1)",{},{view: None},,size,view,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.007187200058251619,0.007187200058251619,0,0,"(1,)",,getitem
call_method,view,"{input_ids: None, getitem: None}","(input_ids, -1, getitem)",{},"{size_1: None, getattr_1: None, transformer_wte: None}",,getitem,size_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[2, 2048], [1]]","[True, True]",True,0.008614400029182434,0.008614400029182434,0,0,"(2, 2048)",torch.int64,view
call_method,size,{view: None},"(view,)",{},{getitem_1: None},,view,getitem_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[2, 2048]]",[True],True,0.0075136001221835615,0.0075136001221835615,0,0,"(1,)",,size_1
call_function,<built-in function getitem>,{size_1: None},"(size_1, 0)",{},{},,size_1,getitem_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.007270400132983923,0.007270400132983923,0,0,"(1,)",,getitem_1
call_function,<built-in function getitem>,{size: None},"(size, -1)",{},{add: None},,getitem_1,add,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.007500800024718046,0.007500800024718046,0,0,"(1,)",,getitem_2
call_function,<built-in function add>,{getitem_2: None},"(getitem_2, 0)",{},{arange: None},,getitem_2,getattr_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.007328000012785196,0.007328000012785196,0,0,"(1,)",,add
call_function,<built-in function getattr>,{view: None},"(view, 'device')",{},{arange: None},,add,arange,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[2, 2048]]",[True],True,0.007308800052851438,0.007308800052851438,0,0,"(1,)",,getattr_1
call_function,<built-in method arange of type object at 0x15552dc96d80>,"{add: None, getattr_1: None}","(0, add)","{'dtype': torch.int64, 'device': getattr_1}",{unsqueeze: None},,getattr_1,unsqueeze,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[1], [1]]","[True, True]",True,0.012563199922442436,0.012563199922442436,0,0,"(2048,)",torch.int64,arange
call_method,unsqueeze,{arange: None},"(arange, 0)",{},{transformer_wpe: None},,arange,transformer_wte,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[2048]],[True],True,0.008364799991250038,0.008364799991250038,0,0,"(1, 2048)",torch.int64,unsqueeze
call_module,transformer.wte,{view: None},"(view,)",{},{add_1: None},,unsqueeze,transformer_wpe,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.wte', <class 'torch.nn.modules.sparse.Embedding'>)])}","[[2, 2048]]",[True],True,0.06817279905080795,0.06817279905080795,0,0,"(2, 2048, 2560)",torch.float32,transformer_wte
call_module,transformer.wpe,{unsqueeze: None},"(unsqueeze,)",{},{add_1: None},,transformer_wte,add_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.wpe', <class 'torch.nn.modules.sparse.Embedding'>)])}","[[1, 2048]]",[True],True,0.047520000487565994,0.047520000487565994,0,0,"(1, 2048, 2560)",torch.float32,transformer_wpe
call_function,<built-in function add>,"{transformer_wte: None, transformer_wpe: None}","(transformer_wte, transformer_wpe)",{},{transformer_drop: None},,transformer_wpe,transformer_drop,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[2, 2048, 2560], [1, 2048, 2560]]","[True, True]",True,0.05389440059661865,0.05389440059661865,0,0,"(2, 2048, 2560)",torch.float32,add_1
call_module,transformer.drop,{add_1: None},"(add_1,)",{},"{size_2: None, transformer_h_0_ln_1: None, add_10: None}",,add_1,getitem_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.drop', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[2, 2048, 2560]]",[True],True,0.010080000013113022,0.010080000013113022,0,0,"(2, 2048, 2560)",torch.float32,transformer_drop
call_function,<built-in function getitem>,{size: None},"(size, slice(1, None, None))",{},{add_2: None},,transformer_drop,add_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.006777600105851889,0.006777600105851889,0,0,"(1,)",,getitem_3
call_function,<built-in function add>,{getitem_3: None},"((-1,), getitem_3)",{},{add_3: None},,getitem_3,size_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.00684799998998642,0.00684799998998642,0,0,"(1,)",,add_2
call_method,size,{transformer_drop: None},"(transformer_drop, -1)",{},{add_3: None},,add_2,add_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[2, 2048, 2560]]",[True],True,0.0070847999304533005,0.0070847999304533005,0,0,"(1,)",,size_2
call_function,<built-in function add>,"{add_2: None, size_2: None}","(add_2, (size_2,))",{},{view_13: None},,size_2,transformer_h_0_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[1], [1]]","[True, True]",True,0.006924800015985966,0.006924800015985966,0,0,"(1,)",,add_3
call_module,transformer.h.0.ln_1,{transformer_drop: None},"(transformer_drop,)",{},"{size_3: None, size_4: None, view_1: None}",,add_3,size_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[2, 2048, 2560]]",[True],True,0.05196160078048706,0.05196160078048706,0,0,"(2, 2048, 2560)",torch.float32,transformer_h_0_ln_1
call_method,size,{transformer_h_0_ln_1: None},"(transformer_h_0_ln_1,)",{},{getitem_4: None},,transformer_h_0_ln_1,getitem_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[2, 2048, 2560]]",[True],True,0.006969599891453982,0.006969599891453982,0,0,"(1,)",,size_3
call_function,<built-in function getitem>,{size_3: None},"(size_3, slice(None, -1, None))",{},{add_4: None},,size_3,add_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.006732799950987101,0.006732799950987101,0,0,"(1,)",,getitem_4
call_function,<built-in function add>,{getitem_4: None},"(getitem_4, (7680,))",{},{view_2: None},,getitem_4,transformer_h_0_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.0067136000841856005,0.0067136000841856005,0,0,"(1,)",,add_4
get_attr,transformer.h.0.attn.c_attn.bias,{},(),{},{addmm: None},,add_4,size_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(7680,)",torch.float32,transformer_h_0_attn_c_attn_bias
call_method,size,{transformer_h_0_ln_1: None},"(transformer_h_0_ln_1, -1)",{},{view_1: None},,transformer_h_0_attn_c_attn_bias,view_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[2, 2048, 2560]]",[True],True,0.0067200000397861,0.0067200000397861,0,0,"(1,)",,size_4
call_method,view,"{transformer_h_0_ln_1: None, size_4: None}","(transformer_h_0_ln_1, -1, size_4)",{},{addmm: None},,size_4,transformer_h_0_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[2, 2048, 2560], [1]]","[True, True]",True,0.008153599873185157,0.008153599873185157,0,0,"(4096, 2560)",torch.float32,view_1
get_attr,transformer.h.0.attn.c_attn.weight,{},(),{},{addmm: None},,view_1,addmm,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(2560, 7680)",torch.float32,transformer_h_0_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x15552dc96d80>,"{transformer_h_0_attn_c_attn_bias: None, view_1: None, transformer_h_0_attn_c_attn_weight: None}","(transformer_h_0_attn_c_attn_bias, view_1, transformer_h_0_attn_c_attn_weight)",{},{view_2: None},,transformer_h_0_attn_c_attn_weight,view_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[7680], [4096, 2560], [2560, 7680]]","[True, True, True]",True,3.4154688358306884,3.4154688358306884,0,0,"(4096, 7680)",torch.float32,addmm
call_method,view,"{addmm: None, add_4: None}","(addmm, add_4)",{},{split: None},,addmm,split,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[4096, 7680], [1]]","[True, True]",True,0.0081343999132514,0.0081343999132514,0,0,"(2, 2048, 7680)",torch.float32,view_2
call_method,split,{view_2: None},"(view_2, 2560)",{'dim': 2},"{getitem_5: None, getitem_6: None, getitem_7: None}",,view_2,getitem_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 2048, 7680]]",[True],True,0.012172800116240978,0.012172800116240978,0,0,"(1,)",,split
call_function,<built-in function getitem>,{split: None},"(split, 0)",{},"{size_5: None, view_3: None}",,split,getitem_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,0.0066304000094532965,0.0066304000094532965,0,0,"(2, 2048, 2560)",torch.float32,getitem_5
call_function,<built-in function getitem>,{split: None},"(split, 1)",{},"{size_6: None, view_4: None}",,getitem_5,getitem_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,0.006483200006186962,0.006483200006186962,0,0,"(2, 2048, 2560)",torch.float32,getitem_6
call_function,<built-in function getitem>,{split: None},"(split, 2)",{},"{size_7: None, view_5: None}",,getitem_6,size_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,0.00650879992172122,0.00650879992172122,0,0,"(2, 2048, 2560)",torch.float32,getitem_7
call_method,size,{getitem_5: None},"(getitem_5,)",{},{getitem_8: None},,getitem_7,getitem_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 2048, 2560]]",[False],True,0.006726400088518858,0.006726400088518858,0,0,"(1,)",,size_5
call_function,<built-in function getitem>,{size_5: None},"(size_5, slice(None, -1, None))",{},{add_5: None},,size_5,add_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006592000089585781,0.006592000089585781,0,0,"(1,)",,getitem_8
call_function,<built-in function add>,{getitem_8: None},"(getitem_8, (32, 80))",{},{view_3: None},,getitem_8,view_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006636799965053797,0.006636799965053797,0,0,"(1,)",,add_5
call_method,view,"{getitem_5: None, add_5: None}","(getitem_5, add_5)",{},{permute: None},,add_5,permute,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 2048, 2560], [1]]","[False, True]",False,0.008428799919784069,0.008428799919784069,0,0,"(2, 2048, 32, 80)",torch.float32,view_3
call_method,permute,{view_3: None},"(view_3, 0, 2, 1, 3)",{},"{matmul: None, size_9: None}",,view_3,size_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 2048, 32, 80]]",[False],False,0.008569600246846675,0.008569600246846675,0,0,"(2, 32, 2048, 80)",torch.float32,permute
call_method,size,{getitem_6: None},"(getitem_6,)",{},{getitem_9: None},,permute,getitem_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 2048, 2560]]",[False],True,0.006956799980252981,0.006956799980252981,0,0,"(1,)",,size_6
call_function,<built-in function getitem>,{size_6: None},"(size_6, slice(None, -1, None))",{},{add_6: None},,size_6,add_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.00666880002245307,0.00666880002245307,0,0,"(1,)",,getitem_9
call_function,<built-in function add>,{getitem_9: None},"(getitem_9, (32, 80))",{},{view_4: None},,getitem_9,view_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006681600119918585,0.006681600119918585,0,0,"(1,)",,add_6
call_method,view,"{getitem_6: None, add_6: None}","(getitem_6, add_6)",{},{permute_1: None},,add_6,permute_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 2048, 2560], [1]]","[False, True]",False,0.008351999893784523,0.008351999893784523,0,0,"(2, 2048, 32, 80)",torch.float32,view_4
call_method,permute,{view_4: None},"(view_4, 0, 2, 1, 3)",{},"{transpose: None, size_10: None, output: None}",,view_4,size_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 2048, 32, 80]]",[False],False,0.008710400201380253,0.008710400201380253,0,0,"(2, 32, 2048, 80)",torch.float32,permute_1
call_method,size,{getitem_7: None},"(getitem_7,)",{},{getitem_10: None},,permute_1,getitem_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 2048, 2560]]",[False],True,0.0071807999163866045,0.0071807999163866045,0,0,"(1,)",,size_7
call_function,<built-in function getitem>,{size_7: None},"(size_7, slice(None, -1, None))",{},{add_7: None},,size_7,add_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006668800115585327,0.006668800115585327,0,0,"(1,)",,getitem_10
call_function,<built-in function add>,{getitem_10: None},"(getitem_10, (32, 80))",{},{view_5: None},,getitem_10,view_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006649599969387054,0.006649599969387054,0,0,"(1,)",,add_7
call_method,view,"{getitem_7: None, add_7: None}","(getitem_7, add_7)",{},{permute_2: None},,add_7,permute_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 2048, 2560], [1]]","[False, True]",False,0.008345599845051765,0.008345599845051765,0,0,"(2, 2048, 32, 80)",torch.float32,view_5
call_method,permute,{view_5: None},"(view_5, 0, 2, 1, 3)",{},"{size_8: None, getattr_9: None, matmul_1: None, output: None}",,view_5,transpose,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 2048, 32, 80]]",[False],False,0.008697599917650223,0.008697599917650223,0,0,"(2, 32, 2048, 80)",torch.float32,permute_2
call_method,transpose,{permute_1: None},"(permute_1, -1, -2)",{},{matmul: None},,permute_2,matmul,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 32, 2048, 80]]",[False],False,0.008396799862384795,0.008396799862384795,0,0,"(2, 32, 80, 2048)",torch.float32,transpose
call_function,<built-in method matmul of type object at 0x15552dc96d80>,"{permute: None, transpose: None}","(permute, transpose)",{},"{getattr_2: None, getattr_3: None, truediv: None}",,transpose,size_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 32, 2048, 80], [2, 32, 80, 2048]]","[False, False]",True,1.2809983730316161,1.2809983730316161,0,0,"(2, 32, 2048, 2048)",torch.float32,matmul
call_method,size,{permute_2: None},"(permute_2, -1)",{},{pow_1: None},,matmul,pow_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 32, 2048, 80]]",[False],True,0.006899199914187193,0.006899199914187193,0,0,"(1,)",,size_8
call_function,<built-in function pow>,{size_8: None},"(size_8, 0.5)",{},{full: None},,size_8,getattr_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006604799907654524,0.006604799907654524,0,0,"(1,)",,pow_1
call_function,<built-in function getattr>,{matmul: None},"(matmul, 'dtype')",{},{full: None},,pow_1,getattr_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 32, 2048, 2048]]",[True],True,0.0070783999748528,0.0070783999748528,0,0,"(1,)",,getattr_2
call_function,<built-in function getattr>,{matmul: None},"(matmul, 'device')",{},{full: None},,getattr_2,full,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 32, 2048, 2048]]",[True],True,0.006899199914187193,0.006899199914187193,0,0,"(1,)",,getattr_3
call_function,<built-in method full of type object at 0x15552dc96d80>,"{pow_1: None, getattr_2: None, getattr_3: None}","([], pow_1)","{'dtype': getattr_2, 'device': getattr_3}",{truediv: None},,getattr_3,truediv,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,0.011942399851977824,0.011942399851977824,0,0,"(1,)",torch.float32,full
call_function,<built-in function truediv>,"{matmul: None, full: None}","(matmul, full)",{},"{getattr_4: None, getattr_6: None, getattr_7: None, getattr_8: None, to: None}",,full,size_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 32, 2048, 2048], [1]]","[True, True]",True,0.8651648044586182,0.8651648044586182,0,0,"(2, 32, 2048, 2048)",torch.float32,truediv
call_method,size,{permute: None},"(permute, -2)",{},{sub: None},,truediv,size_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 32, 2048, 80]]",[False],True,0.006822400074452162,0.006822400074452162,0,0,"(1,)",,size_9
call_method,size,{permute_1: None},"(permute_1, -2)",{},"{sub: None, getitem_11: None}",,size_9,transformer_h_0_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 32, 2048, 80]]",[False],True,0.006886399909853935,0.006886399909853935,0,0,"(1,)",,size_10
get_attr,transformer.h.0.attn.bias,{},(),{},{getitem_11: None},,size_10,sub,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,0.0,0.0,0,0,"(1, 1, 2048, 2048)",torch.bool,transformer_h_0_attn_bias
call_function,<built-in function sub>,"{size_10: None, size_9: None}","(size_10, size_9)",{},{getitem_11: None},,transformer_h_0_attn_bias,getitem_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,0.006585600040853024,0.006585600040853024,0,0,"(1,)",,sub
call_function,<built-in function getitem>,"{transformer_h_0_attn_bias: None, sub: None, size_10: None}","(transformer_h_0_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub, size_10, None), slice(None, size_10, None)))",{},{where: None},,sub,getattr_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 2048, 2048], [1], [1]]","[True, True, True]",True,0.010220800153911113,0.010220800153911113,0,0,"(1, 1, 2048, 2048)",torch.bool,getitem_11
call_function,<built-in function getattr>,{truediv: None},"(truediv, 'dtype')",{},{finfo: None},,getitem_11,finfo,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 32, 2048, 2048]]",[True],True,0.006783999968320131,0.006783999968320131,0,0,"(1,)",,getattr_4
call_function,<class 'torch.finfo'>,{getattr_4: None},"(getattr_4,)",{},{getattr_5: None},,getattr_4,getattr_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.007142399996519088,0.007142399996519088,0,0,"(1,)",,finfo
call_function,<built-in function getattr>,{finfo: None},"(finfo, 'min')",{},{full_1: None},,finfo,getattr_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.0066304000094532965,0.0066304000094532965,0,0,"(1,)",,getattr_5
call_function,<built-in function getattr>,{truediv: None},"(truediv, 'dtype')",{},{full_1: None},,getattr_5,getattr_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 32, 2048, 2048]]",[True],True,0.0067135999910533425,0.0067135999910533425,0,0,"(1,)",,getattr_6
call_function,<built-in function getattr>,{truediv: None},"(truediv, 'device')",{},{full_1: None},,getattr_6,full_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 32, 2048, 2048]]",[True],True,0.006937600020319223,0.006937600020319223,0,0,"(1,)",,getattr_7
call_function,<built-in method full of type object at 0x15552dc96d80>,"{getattr_5: None, getattr_6: None, getattr_7: None}","([], getattr_5)","{'dtype': getattr_6, 'device': getattr_7}",{where: None},,getattr_7,getattr_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,0.012287999875843525,0.012287999875843525,0,0,"(1,)",torch.float32,full_1
call_function,<built-in function getattr>,{truediv: None},"(truediv, 'dtype')",{},{to: None},,full_1,to,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 32, 2048, 2048]]",[True],True,0.006777600012719631,0.006777600012719631,0,0,"(1,)",,getattr_8
call_method,to,"{truediv: None, getattr_8: None}","(truediv, getattr_8)",{},{where: None},,getattr_8,where,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 32, 2048, 2048], [1]]","[True, True]",True,0.007046399917453527,0.007046399917453527,0,0,"(2, 32, 2048, 2048)",torch.float32,to
call_function,<built-in method where of type object at 0x15552dc96d80>,"{getitem_11: None, to: None, full_1: None}","(getitem_11, to, full_1)",{},{softmax: None},,to,softmax,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 2048, 2048], [2, 32, 2048, 2048], [1]]","[True, True, True]",True,0.8588544130325317,0.8588544130325317,0,0,"(2, 32, 2048, 2048)",torch.float32,where
call_function,<function softmax at 0x15543f939900>,{where: None},"(where,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_1: None},,where,getattr_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 32, 2048, 2048]]",[True],True,0.8355776071548462,0.8355776071548462,0,0,"(2, 32, 2048, 2048)",torch.float32,softmax
call_function,<built-in function getattr>,{permute_2: None},"(permute_2, 'dtype')",{},{type_1: None},,softmax,type_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 32, 2048, 80]]",[False],True,0.0066432000137865545,0.0066432000137865545,0,0,"(1,)",,getattr_9
call_method,type,"{softmax: None, getattr_9: None}","(softmax, getattr_9)",{},{transformer_h_0_attn_attn_dropout: None},,getattr_9,transformer_h_0_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 32, 2048, 2048], [1]]","[True, True]",True,0.007129599992185831,0.007129599992185831,0,0,"(2, 32, 2048, 2048)",torch.float32,type_1
call_module,transformer.h.0.attn.attn_dropout,{type_1: None},"(type_1,)",{},{matmul_1: None},,type_1,matmul_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[2, 32, 2048, 2048]]",[True],True,0.009919999912381173,0.009919999912381173,0,0,"(2, 32, 2048, 2048)",torch.float32,transformer_h_0_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x15552dc96d80>,"{transformer_h_0_attn_attn_dropout: None, permute_2: None}","(transformer_h_0_attn_attn_dropout, permute_2)",{},{permute_3: None},,transformer_h_0_attn_attn_dropout,permute_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 32, 2048, 2048], [2, 32, 2048, 80]]","[True, False]",True,1.4342015743255616,1.4342015743255616,0,0,"(2, 32, 2048, 80)",torch.float32,matmul_1
call_method,permute,{matmul_1: None},"(matmul_1, 0, 2, 1, 3)",{},{contiguous: None},,matmul_1,contiguous,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 32, 2048, 80]]",[True],False,0.008473599888384342,0.008473599888384342,0,0,"(2, 2048, 32, 80)",torch.float32,permute_3
call_method,contiguous,{permute_3: None},"(permute_3,)",{},"{size_11: None, view_6: None}",,permute_3,size_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 2048, 32, 80]]",[False],True,0.04789760038256645,0.04789760038256645,0,0,"(2, 2048, 32, 80)",torch.float32,contiguous
call_method,size,{contiguous: None},"(contiguous,)",{},{getitem_12: None},,contiguous,getitem_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 2048, 32, 80]]",[True],True,0.006924800015985966,0.006924800015985966,0,0,"(1,)",,size_11
call_function,<built-in function getitem>,{size_11: None},"(size_11, slice(None, -2, None))",{},{add_8: None},,size_11,add_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.0067263999953866005,0.0067263999953866005,0,0,"(1,)",,getitem_12
call_function,<built-in function add>,{getitem_12: None},"(getitem_12, (2560,))",{},{view_6: None},,getitem_12,view_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006886399909853935,0.006886399909853935,0,0,"(1,)",,add_8
call_method,view,"{contiguous: None, add_8: None}","(contiguous, add_8)",{},"{size_12: None, size_13: None, view_7: None}",,add_8,size_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[2, 2048, 32, 80], [1]]","[True, True]",True,0.008358399756252766,0.008358399756252766,0,0,"(2, 2048, 2560)",torch.float32,view_6
call_method,size,{view_6: None},"(view_6,)",{},{getitem_13: None},,view_6,getitem_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[2, 2048, 2560]]",[True],True,0.006764799915254116,0.006764799915254116,0,0,"(1,)",,size_12
call_function,<built-in function getitem>,{size_12: None},"(size_12, slice(None, -1, None))",{},{add_9: None},,size_12,add_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.006899199914187193,0.006899199914187193,0,0,"(1,)",,getitem_13
call_function,<built-in function add>,{getitem_13: None},"(getitem_13, (2560,))",{},{view_8: None},,getitem_13,transformer_h_0_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.006835199985653162,0.006835199985653162,0,0,"(1,)",,add_9
get_attr,transformer.h.0.attn.c_proj.bias,{},(),{},{addmm_1: None},,add_9,size_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(2560,)",torch.float32,transformer_h_0_attn_c_proj_bias
call_method,size,{view_6: None},"(view_6, -1)",{},{view_7: None},,transformer_h_0_attn_c_proj_bias,view_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[2, 2048, 2560]]",[True],True,0.007302399910986424,0.007302399910986424,0,0,"(1,)",,size_13
call_method,view,"{view_6: None, size_13: None}","(view_6, -1, size_13)",{},{addmm_1: None},,size_13,transformer_h_0_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[2, 2048, 2560], [1]]","[True, True]",True,0.008326399885118008,0.008326399885118008,0,0,"(4096, 2560)",torch.float32,view_7
get_attr,transformer.h.0.attn.c_proj.weight,{},(),{},{addmm_1: None},,view_7,addmm_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(2560, 2560)",torch.float32,transformer_h_0_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x15552dc96d80>,"{transformer_h_0_attn_c_proj_bias: None, view_7: None, transformer_h_0_attn_c_proj_weight: None}","(transformer_h_0_attn_c_proj_bias, view_7, transformer_h_0_attn_c_proj_weight)",{},{view_8: None},,transformer_h_0_attn_c_proj_weight,view_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[2560], [4096, 2560], [2560, 2560]]","[True, True, True]",True,1.130502414703369,1.130502414703369,0,0,"(4096, 2560)",torch.float32,addmm_1
call_method,view,"{addmm_1: None, add_9: None}","(addmm_1, add_9)",{},{transformer_h_0_attn_resid_dropout: None},,addmm_1,transformer_h_0_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[4096, 2560], [1]]","[True, True]",True,0.008236799947917461,0.008236799947917461,0,0,"(2, 2048, 2560)",torch.float32,view_8
call_module,transformer.h.0.attn.resid_dropout,{view_8: None},"(view_8,)",{},{add_10: None},,view_8,add_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[2, 2048, 2560]]",[True],True,0.009727999940514565,0.009727999940514565,0,0,"(2, 2048, 2560)",torch.float32,transformer_h_0_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_0_attn_resid_dropout: None, transformer_drop: None}","(transformer_h_0_attn_resid_dropout, transformer_drop)",{},"{transformer_h_0_ln_2: None, add_15: None}",,transformer_h_0_attn_resid_dropout,transformer_h_0_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[2, 2048, 2560], [2, 2048, 2560]]","[True, True]",True,0.048838400095701215,0.048838400095701215,0,0,"(2, 2048, 2560)",torch.float32,add_10
call_module,transformer.h.0.ln_2,{add_10: None},"(add_10,)",{},"{size_14: None, size_15: None, view_9: None}",,add_10,size_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[2, 2048, 2560]]",[True],True,0.05175039917230606,0.05175039917230606,0,0,"(2, 2048, 2560)",torch.float32,transformer_h_0_ln_2
call_method,size,{transformer_h_0_ln_2: None},"(transformer_h_0_ln_2,)",{},{getitem_14: None},,transformer_h_0_ln_2,getitem_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[2, 2048, 2560]]",[True],True,0.0069055999629199505,0.0069055999629199505,0,0,"(1,)",,size_14
call_function,<built-in function getitem>,{size_14: None},"(size_14, slice(None, -1, None))",{},{add_11: None},,size_14,add_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.006867199949920177,0.006867199949920177,0,0,"(1,)",,getitem_14
call_function,<built-in function add>,{getitem_14: None},"(getitem_14, (10240,))",{},{view_10: None},,getitem_14,transformer_h_0_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.0067968000657856464,0.0067968000657856464,0,0,"(1,)",,add_11
get_attr,transformer.h.0.mlp.c_fc.bias,{},(),{},{addmm_2: None},,add_11,size_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(10240,)",torch.float32,transformer_h_0_mlp_c_fc_bias
call_method,size,{transformer_h_0_ln_2: None},"(transformer_h_0_ln_2, -1)",{},{view_9: None},,transformer_h_0_mlp_c_fc_bias,view_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[2, 2048, 2560]]",[True],True,0.00685439994558692,0.00685439994558692,0,0,"(1,)",,size_15
call_method,view,"{transformer_h_0_ln_2: None, size_15: None}","(transformer_h_0_ln_2, -1, size_15)",{},{addmm_2: None},,size_15,transformer_h_0_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[2, 2048, 2560], [1]]","[True, True]",True,0.008320000022649765,0.008320000022649765,0,0,"(4096, 2560)",torch.float32,view_9
get_attr,transformer.h.0.mlp.c_fc.weight,{},(),{},{addmm_2: None},,view_9,addmm_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(2560, 10240)",torch.float32,transformer_h_0_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x15552dc96d80>,"{transformer_h_0_mlp_c_fc_bias: None, view_9: None, transformer_h_0_mlp_c_fc_weight: None}","(transformer_h_0_mlp_c_fc_bias, view_9, transformer_h_0_mlp_c_fc_weight)",{},{view_10: None},,transformer_h_0_mlp_c_fc_weight,view_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[10240], [4096, 2560], [2560, 10240]]","[True, True, True]",True,4.408921623229981,4.408921623229981,0,0,"(4096, 10240)",torch.float32,addmm_2
call_method,view,"{addmm_2: None, add_11: None}","(addmm_2, add_11)",{},"{mul: None, pow_2: None, add_12: None}",,addmm_2,mul,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[4096, 10240], [1]]","[True, True]",True,0.008352000080049039,0.008352000080049039,0,0,"(2, 2048, 10240)",torch.float32,view_10
call_function,<built-in function mul>,{view_10: None},"(0.5, view_10)",{},{mul_3: None},,view_10,pow_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[2, 2048, 10240]]",[True],True,0.11812479943037033,0.11812479943037033,0,0,"(2, 2048, 10240)",torch.float32,mul
call_function,<built-in method pow of type object at 0x15552dc96d80>,{view_10: None},"(view_10, 3.0)",{},{mul_1: None},,mul,mul_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[2, 2048, 10240]]",[True],True,0.11797760128974914,0.11797760128974914,0,0,"(2, 2048, 10240)",torch.float32,pow_2
call_function,<built-in function mul>,{pow_2: None},"(0.044715, pow_2)",{},{add_12: None},,pow_2,add_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[2, 2048, 10240]]",[True],True,0.11813760101795197,0.11813760101795197,0,0,"(2, 2048, 10240)",torch.float32,mul_1
call_function,<built-in function add>,"{view_10: None, mul_1: None}","(view_10, mul_1)",{},{mul_2: None},,mul_1,mul_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[2, 2048, 10240], [2, 2048, 10240]]","[True, True]",True,0.16951040029525757,0.16951040029525757,0,0,"(2, 2048, 10240)",torch.float32,add_12
call_function,<built-in function mul>,{add_12: None},"(0.7978845608028654, add_12)",{},{tanh: None},,add_12,tanh,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[2, 2048, 10240]]",[True],True,0.11795200109481811,0.11795200109481811,0,0,"(2, 2048, 10240)",torch.float32,mul_2
call_function,<built-in method tanh of type object at 0x15552dc96d80>,{mul_2: None},"(mul_2,)",{},{add_13: None},,mul_2,add_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[2, 2048, 10240]]",[True],True,0.11720959991216659,0.11720959991216659,0,0,"(2, 2048, 10240)",torch.float32,tanh
call_function,<built-in function add>,{tanh: None},"(1.0, tanh)",{},{mul_3: None},,tanh,mul_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[2, 2048, 10240]]",[True],True,0.11796480119228363,0.11796480119228363,0,0,"(2, 2048, 10240)",torch.float32,add_13
call_function,<built-in function mul>,"{mul: None, add_13: None}","(mul, add_13)",{},"{size_16: None, size_17: None, view_11: None}",,add_13,size_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[2, 2048, 10240], [2, 2048, 10240]]","[True, True]",True,0.1698368012905121,0.1698368012905121,0,0,"(2, 2048, 10240)",torch.float32,mul_3
call_method,size,{mul_3: None},"(mul_3,)",{},{getitem_15: None},,mul_3,getitem_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[2, 2048, 10240]]",[True],True,0.006707200035452843,0.006707200035452843,0,0,"(1,)",,size_16
call_function,<built-in function getitem>,{size_16: None},"(size_16, slice(None, -1, None))",{},{add_14: None},,size_16,add_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.0067968000657856464,0.0067968000657856464,0,0,"(1,)",,getitem_15
call_function,<built-in function add>,{getitem_15: None},"(getitem_15, (2560,))",{},{view_12: None},,getitem_15,transformer_h_0_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.006790400110185146,0.006790400110185146,0,0,"(1,)",,add_14
get_attr,transformer.h.0.mlp.c_proj.bias,{},(),{},{addmm_3: None},,add_14,size_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(2560,)",torch.float32,transformer_h_0_mlp_c_proj_bias
call_method,size,{mul_3: None},"(mul_3, -1)",{},{view_11: None},,transformer_h_0_mlp_c_proj_bias,view_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[2, 2048, 10240]]",[True],True,0.006732799950987101,0.006732799950987101,0,0,"(1,)",,size_17
call_method,view,"{mul_3: None, size_17: None}","(mul_3, -1, size_17)",{},{addmm_3: None},,size_17,transformer_h_0_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[2, 2048, 10240], [1]]","[True, True]",True,0.008435199968516827,0.008435199968516827,0,0,"(4096, 10240)",torch.float32,view_11
get_attr,transformer.h.0.mlp.c_proj.weight,{},(),{},{addmm_3: None},,view_11,addmm_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(10240, 2560)",torch.float32,transformer_h_0_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x15552dc96d80>,"{transformer_h_0_mlp_c_proj_bias: None, view_11: None, transformer_h_0_mlp_c_proj_weight: None}","(transformer_h_0_mlp_c_proj_bias, view_11, transformer_h_0_mlp_c_proj_weight)",{},{view_12: None},,transformer_h_0_mlp_c_proj_weight,view_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[2560], [4096, 10240], [10240, 2560]]","[True, True, True]",True,4.742169570922852,4.742169570922852,0,0,"(4096, 2560)",torch.float32,addmm_3
call_method,view,"{addmm_3: None, add_14: None}","(addmm_3, add_14)",{},{transformer_h_0_mlp_dropout: None},,addmm_3,transformer_h_0_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[4096, 2560], [1]]","[True, True]",True,0.00853119995445013,0.00853119995445013,0,0,"(2, 2048, 2560)",torch.float32,view_12
call_module,transformer.h.0.mlp.dropout,{view_12: None},"(view_12,)",{},{add_15: None},,view_12,add_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[2, 2048, 2560]]",[True],True,0.009734399802982806,0.009734399802982806,0,0,"(2, 2048, 2560)",torch.float32,transformer_h_0_mlp_dropout
call_function,<built-in function add>,"{add_10: None, transformer_h_0_mlp_dropout: None}","(add_10, transformer_h_0_mlp_dropout)",{},{transformer_ln_f: None},,transformer_h_0_mlp_dropout,transformer_ln_f,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[2, 2048, 2560], [2, 2048, 2560]]","[True, True]",True,0.04899200052022934,0.04899200052022934,0,0,"(2, 2048, 2560)",torch.float32,add_15
call_module,transformer.ln_f,{add_15: None},"(add_15,)",{},{view_13: None},,add_15,view_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.ln_f', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[2, 2048, 2560]]",[True],True,0.052153599262237546,0.052153599262237546,0,0,"(2, 2048, 2560)",torch.float32,transformer_ln_f
call_method,view,"{transformer_ln_f: None, add_3: None}","(transformer_ln_f, add_3)",{},{lm_head: None},,transformer_ln_f,lm_head,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[2, 2048, 2560], [1]]","[True, True]",True,0.008332799933850766,0.008332799933850766,0,0,"(2, 2048, 2560)",torch.float32,view_13
call_module,lm_head,{view_13: None},"(view_13,)",{},{output: None},,view_13,output,False,,"{'nn_module_stack': OrderedDict([('lm_head', <class 'torch.nn.modules.linear.Linear'>)])}","[[2, 2048, 2560]]",[True],True,19.99708137512207,19.99708137512207,0,0,"(2, 2048, 50257)",torch.float32,lm_head
output,output,"{lm_head: None, permute_1: None, permute_2: None}","({'logits': lm_head, 'past_key_values': ((permute_1, permute_2),)},)",{},{},,lm_head,,False,,{},"[[2, 2048, 50257], [2, 32, 2048, 80], [2, 32, 2048, 80]]","[True, False, False]",True,0.0,0.0,0,0,"(2, 2048, 50257)",torch.float32,output
