op,target,_input_nodes,_args,_kwargs,users,type,_prev,_next,_erased,_repr_fn,meta,input_shapes,input_contiguous,contiguous,latency,fw_latency,bw_latency,acc_latency,output_shape,dtype,Name
placeholder,input_ids,{},(),{},"{size: None, view: None}",<class 'torch.Tensor'>,,size,False,,{},[],[],True,0.0,0.0,0,0,"(8, 1024)",torch.int64,input_ids
call_method,size,{input_ids: None},"(input_ids,)",{},"{getitem: None, getitem_2: None, getitem_3: None}",,input_ids,getitem,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 1024]]",[True],True,0.0071680000051856044,0.0071680000051856044,0,0,"(1,)",,size
call_function,<built-in function getitem>,{size: None},"(size, -1)",{},{view: None},,size,view,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.006924799922853708,0.006924799922853708,0,0,"(1,)",,getitem
call_method,view,"{input_ids: None, getitem: None}","(input_ids, -1, getitem)",{},"{size_1: None, getattr_1: None, transformer_wte: None}",,getitem,size_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 1024], [1]]","[True, True]",True,0.00818559993058443,0.00818559993058443,0,0,"(8, 1024)",torch.int64,view
call_method,size,{view: None},"(view,)",{},{getitem_1: None},,view,getitem_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 1024]]",[True],True,0.007366400025784969,0.007366400025784969,0,0,"(1,)",,size_1
call_function,<built-in function getitem>,{size_1: None},"(size_1, 0)",{},{},,size_1,getitem_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.007046399917453527,0.007046399917453527,0,0,"(1,)",,getitem_1
call_function,<built-in function getitem>,{size: None},"(size, -1)",{},{add: None},,getitem_1,add,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.006931199971586466,0.006931199971586466,0,0,"(1,)",,getitem_2
call_function,<built-in function add>,{getitem_2: None},"(getitem_2, 0)",{},{arange: None},,getitem_2,getattr_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.006886399909853935,0.006886399909853935,0,0,"(1,)",,add
call_function,<built-in function getattr>,{view: None},"(view, 'device')",{},{arange: None},,add,arange,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 1024]]",[True],True,0.006918400060385466,0.006918400060385466,0,0,"(1,)",,getattr_1
call_function,<built-in method arange of type object at 0x15552dc96d80>,"{add: None, getattr_1: None}","(0, add)","{'dtype': torch.int64, 'device': getattr_1}",{unsqueeze: None},,getattr_1,unsqueeze,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[1], [1]]","[True, True]",True,0.012678400054574013,0.012678400054574013,0,0,"(1024,)",torch.int64,arange
call_method,unsqueeze,{arange: None},"(arange, 0)",{},{transformer_wpe: None},,arange,transformer_wte,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1024]],[True],True,0.008153599873185157,0.008153599873185157,0,0,"(1, 1024)",torch.int64,unsqueeze
call_module,transformer.wte,{view: None},"(view,)",{},{add_1: None},,unsqueeze,transformer_wpe,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.wte', <class 'torch.nn.modules.sparse.Embedding'>)])}","[[8, 1024]]",[True],True,0.06821119785308838,0.06821119785308838,0,0,"(8, 1024, 1280)",torch.float32,transformer_wte
call_module,transformer.wpe,{unsqueeze: None},"(unsqueeze,)",{},{add_1: None},,transformer_wte,add_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.wpe', <class 'torch.nn.modules.sparse.Embedding'>)])}","[[1, 1024]]",[True],True,0.02030080035328865,0.02030080035328865,0,0,"(1, 1024, 1280)",torch.float32,transformer_wpe
call_function,<built-in function add>,"{transformer_wte: None, transformer_wpe: None}","(transformer_wte, transformer_wpe)",{},{transformer_drop: None},,transformer_wpe,transformer_drop,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 1024, 1280], [1, 1024, 1280]]","[True, True]",True,0.04352639988064766,0.04352639988064766,0,0,"(8, 1024, 1280)",torch.float32,add_1
call_module,transformer.drop,{add_1: None},"(add_1,)",{},"{size_2: None, transformer_h_0_ln_1: None, add_10: None}",,add_1,getitem_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.drop', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,0.009849599935114384,0.009849599935114384,0,0,"(8, 1024, 1280)",torch.float32,transformer_drop
call_function,<built-in function getitem>,{size: None},"(size, slice(1, None, None))",{},{add_2: None},,transformer_drop,add_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.006726400088518858,0.006726400088518858,0,0,"(1,)",,getitem_3
call_function,<built-in function add>,{getitem_3: None},"((-1,), getitem_3)",{},{add_3: None},,getitem_3,size_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.006617600005120039,0.006617600005120039,0,0,"(1,)",,add_2
call_method,size,{transformer_drop: None},"(transformer_drop, -1)",{},{add_3: None},,add_2,add_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 1024, 1280]]",[True],True,0.006790399923920632,0.006790399923920632,0,0,"(1,)",,size_2
call_function,<built-in function add>,"{add_2: None, size_2: None}","(add_2, (size_2,))",{},{view_13: None},,size_2,transformer_h_0_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[1], [1]]","[True, True]",True,0.0066304001025855545,0.0066304001025855545,0,0,"(1,)",,add_3
call_module,transformer.h.0.ln_1,{transformer_drop: None},"(transformer_drop,)",{},"{size_3: None, size_4: None, view_1: None}",,add_3,size_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,0.05379200056195259,0.05379200056195259,0,0,"(8, 1024, 1280)",torch.float32,transformer_h_0_ln_1
call_method,size,{transformer_h_0_ln_1: None},"(transformer_h_0_ln_1,)",{},{getitem_4: None},,transformer_h_0_ln_1,getitem_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,0.006508800107985735,0.006508800107985735,0,0,"(1,)",,size_3
call_function,<built-in function getitem>,{size_3: None},"(size_3, slice(None, -1, None))",{},{add_4: None},,size_3,add_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.00650239996612072,0.00650239996612072,0,0,"(1,)",,getitem_4
call_function,<built-in function add>,{getitem_4: None},"(getitem_4, (3840,))",{},{view_2: None},,getitem_4,transformer_h_0_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.006687999982386827,0.006687999982386827,0,0,"(1,)",,add_4
get_attr,transformer.h.0.attn.c_attn.bias,{},(),{},{addmm: None},,add_4,size_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(3840,)",torch.float32,transformer_h_0_attn_c_attn_bias
call_method,size,{transformer_h_0_ln_1: None},"(transformer_h_0_ln_1, -1)",{},{view_1: None},,transformer_h_0_attn_c_attn_bias,view_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,0.006604800000786781,0.006604800000786781,0,0,"(1,)",,size_4
call_method,view,"{transformer_h_0_ln_1: None, size_4: None}","(transformer_h_0_ln_1, -1, size_4)",{},{addmm: None},,size_4,transformer_h_0_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,0.008019200060516596,0.008019200060516596,0,0,"(8192, 1280)",torch.float32,view_1
get_attr,transformer.h.0.attn.c_attn.weight,{},(),{},{addmm: None},,view_1,addmm,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(1280, 3840)",torch.float32,transformer_h_0_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x15552dc96d80>,"{transformer_h_0_attn_c_attn_bias: None, view_1: None, transformer_h_0_attn_c_attn_weight: None}","(transformer_h_0_attn_c_attn_bias, view_1, transformer_h_0_attn_c_attn_weight)",{},{view_2: None},,transformer_h_0_attn_c_attn_weight,view_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,1.6370111942291259,1.6370111942291259,0,0,"(8192, 3840)",torch.float32,addmm
call_method,view,"{addmm: None, add_4: None}","(addmm, add_4)",{},{split: None},,addmm,split,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,0.007980800047516824,0.007980800047516824,0,0,"(8, 1024, 3840)",torch.float32,view_2
call_method,split,{view_2: None},"(view_2, 1280)",{'dim': 2},"{getitem_5: None, getitem_6: None, getitem_7: None}",,view_2,getitem_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,0.012479999847710133,0.012479999847710133,0,0,"(1,)",,split
call_function,<built-in function getitem>,{split: None},"(split, 0)",{},"{size_5: None, view_3: None}",,split,getitem_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,0.0067200000397861,0.0067200000397861,0,0,"(8, 1024, 1280)",torch.float32,getitem_5
call_function,<built-in function getitem>,{split: None},"(split, 1)",{},"{size_6: None, view_4: None}",,getitem_5,getitem_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,0.006758400145918131,0.006758400145918131,0,0,"(8, 1024, 1280)",torch.float32,getitem_6
call_function,<built-in function getitem>,{split: None},"(split, 2)",{},"{size_7: None, view_5: None}",,getitem_6,size_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,0.006745600048452616,0.006745600048452616,0,0,"(8, 1024, 1280)",torch.float32,getitem_7
call_method,size,{getitem_5: None},"(getitem_5,)",{},{getitem_8: None},,getitem_7,getitem_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,0.006752000097185374,0.006752000097185374,0,0,"(1,)",,size_5
call_function,<built-in function getitem>,{size_5: None},"(size_5, slice(None, -1, None))",{},{add_5: None},,size_5,add_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006803200114518404,0.006803200114518404,0,0,"(1,)",,getitem_8
call_function,<built-in function add>,{getitem_8: None},"(getitem_8, (20, 64))",{},{view_3: None},,getitem_8,view_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.0065727999433875086,0.0065727999433875086,0,0,"(1,)",,add_5
call_method,view,"{getitem_5: None, add_5: None}","(getitem_5, add_5)",{},{permute: None},,add_5,permute,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,0.008313600160181522,0.008313600160181522,0,0,"(8, 1024, 20, 64)",torch.float32,view_3
call_method,permute,{view_3: None},"(view_3, 0, 2, 1, 3)",{},"{matmul: None, size_9: None}",,view_3,size_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,0.008620800077915191,0.008620800077915191,0,0,"(8, 20, 1024, 64)",torch.float32,permute
call_method,size,{getitem_6: None},"(getitem_6,)",{},{getitem_9: None},,permute,getitem_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,0.006739200092852116,0.006739200092852116,0,0,"(1,)",,size_6
call_function,<built-in function getitem>,{size_6: None},"(size_6, slice(None, -1, None))",{},{add_6: None},,size_6,add_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006732800044119358,0.006732800044119358,0,0,"(1,)",,getitem_9
call_function,<built-in function add>,{getitem_9: None},"(getitem_9, (20, 64))",{},{view_4: None},,getitem_9,view_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006739200092852116,0.006739200092852116,0,0,"(1,)",,add_6
call_method,view,"{getitem_6: None, add_6: None}","(getitem_6, add_6)",{},{permute_1: None},,add_6,permute_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,0.008396800048649311,0.008396800048649311,0,0,"(8, 1024, 20, 64)",torch.float32,view_4
call_method,permute,{view_4: None},"(view_4, 0, 2, 1, 3)",{},"{transpose: None, size_10: None, output: None}",,view_4,size_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,0.008550399914383888,0.008550399914383888,0,0,"(8, 20, 1024, 64)",torch.float32,permute_1
call_method,size,{getitem_7: None},"(getitem_7,)",{},{getitem_10: None},,permute_1,getitem_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,0.006841599941253662,0.006841599941253662,0,0,"(1,)",,size_7
call_function,<built-in function getitem>,{size_7: None},"(size_7, slice(None, -1, None))",{},{add_7: None},,size_7,add_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006764800008386374,0.006764800008386374,0,0,"(1,)",,getitem_10
call_function,<built-in function add>,{getitem_10: None},"(getitem_10, (20, 64))",{},{view_5: None},,getitem_10,view_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006694400124251843,0.006694400124251843,0,0,"(1,)",,add_7
call_method,view,"{getitem_7: None, add_7: None}","(getitem_7, add_7)",{},{permute_2: None},,add_7,permute_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,0.008499199897050858,0.008499199897050858,0,0,"(8, 1024, 20, 64)",torch.float32,view_5
call_method,permute,{view_5: None},"(view_5, 0, 2, 1, 3)",{},"{size_8: None, getattr_9: None, matmul_1: None, output: None}",,view_5,transpose,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,0.008499199897050858,0.008499199897050858,0,0,"(8, 20, 1024, 64)",torch.float32,permute_2
call_method,transpose,{permute_1: None},"(permute_1, -1, -2)",{},{matmul: None},,permute_2,matmul,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,0.00840959995985031,0.00840959995985031,0,0,"(8, 20, 64, 1024)",torch.float32,transpose
call_function,<built-in method matmul of type object at 0x15552dc96d80>,"{permute: None, transpose: None}","(permute, transpose)",{},"{getattr_2: None, getattr_3: None, truediv: None}",,transpose,size_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,0.7688448190689087,0.7688448190689087,0,0,"(8, 20, 1024, 1024)",torch.float32,matmul
call_method,size,{permute_2: None},"(permute_2, -1)",{},{pow_1: None},,matmul,pow_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,0.006694400031119585,0.006694400031119585,0,0,"(1,)",,size_8
call_function,<built-in function pow>,{size_8: None},"(size_8, 0.5)",{},{full: None},,size_8,getattr_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006425600033253431,0.006425600033253431,0,0,"(1,)",,pow_1
call_function,<built-in function getattr>,{matmul: None},"(matmul, 'dtype')",{},{full: None},,pow_1,getattr_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,0.006483200006186962,0.006483200006186962,0,0,"(1,)",,getattr_2
call_function,<built-in function getattr>,{matmul: None},"(matmul, 'device')",{},{full: None},,getattr_2,full,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,0.006566400080919266,0.006566400080919266,0,0,"(1,)",,getattr_3
call_function,<built-in method full of type object at 0x15552dc96d80>,"{pow_1: None, getattr_2: None, getattr_3: None}","([], pow_1)","{'dtype': getattr_2, 'device': getattr_3}",{truediv: None},,getattr_3,truediv,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,0.012211200036108493,0.012211200036108493,0,0,"(1,)",torch.float32,full
call_function,<built-in function truediv>,"{matmul: None, full: None}","(matmul, full)",{},"{getattr_4: None, getattr_6: None, getattr_7: None, getattr_8: None, to: None}",,full,size_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,0.5436416029930115,0.5436416029930115,0,0,"(8, 20, 1024, 1024)",torch.float32,truediv
call_method,size,{permute: None},"(permute, -2)",{},{sub: None},,truediv,size_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,0.0065600000321865085,0.0065600000321865085,0,0,"(1,)",,size_9
call_method,size,{permute_1: None},"(permute_1, -2)",{},"{sub: None, getitem_11: None}",,size_9,transformer_h_0_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,0.00667519997805357,0.00667519997805357,0,0,"(1,)",,size_10
get_attr,transformer.h.0.attn.bias,{},(),{},{getitem_11: None},,size_10,sub,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,0.0,0.0,0,0,"(1, 1, 1024, 1024)",torch.bool,transformer_h_0_attn_bias
call_function,<built-in function sub>,"{size_10: None, size_9: None}","(size_10, size_9)",{},{getitem_11: None},,transformer_h_0_attn_bias,getitem_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,0.006393600068986416,0.006393600068986416,0,0,"(1,)",,sub
call_function,<built-in function getitem>,"{transformer_h_0_attn_bias: None, sub: None, size_10: None}","(transformer_h_0_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub, size_10, None), slice(None, size_10, None)))",{},{where: None},,sub,getattr_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,0.009945599921047687,0.009945599921047687,0,0,"(1, 1, 1024, 1024)",torch.bool,getitem_11
call_function,<built-in function getattr>,{truediv: None},"(truediv, 'dtype')",{},{finfo: None},,getitem_11,finfo,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,0.006483200006186962,0.006483200006186962,0,0,"(1,)",,getattr_4
call_function,<class 'torch.finfo'>,{getattr_4: None},"(getattr_4,)",{},{getattr_5: None},,getattr_4,getattr_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.00633599990978837,0.00633599990978837,0,0,"(1,)",,finfo
call_function,<built-in function getattr>,{finfo: None},"(finfo, 'min')",{},{full_1: None},,finfo,getattr_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006400000024586916,0.006400000024586916,0,0,"(1,)",,getattr_5
call_function,<built-in function getattr>,{truediv: None},"(truediv, 'dtype')",{},{full_1: None},,getattr_5,getattr_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,0.006521600019186735,0.006521600019186735,0,0,"(1,)",,getattr_6
call_function,<built-in function getattr>,{truediv: None},"(truediv, 'device')",{},{full_1: None},,getattr_6,full_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,0.006579200085252523,0.006579200085252523,0,0,"(1,)",,getattr_7
call_function,<built-in method full of type object at 0x15552dc96d80>,"{getattr_5: None, getattr_6: None, getattr_7: None}","([], getattr_5)","{'dtype': getattr_6, 'device': getattr_7}",{where: None},,getattr_7,getattr_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,0.012185600027441979,0.012185600027441979,0,0,"(1,)",torch.float32,full_1
call_function,<built-in function getattr>,{truediv: None},"(truediv, 'dtype')",{},{to: None},,full_1,to,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,0.006431999988853932,0.006431999988853932,0,0,"(1,)",,getattr_8
call_method,to,"{truediv: None, getattr_8: None}","(truediv, getattr_8)",{},{where: None},,getattr_8,where,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,0.006662400066852569,0.006662400066852569,0,0,"(8, 20, 1024, 1024)",torch.float32,to
call_function,<built-in method where of type object at 0x15552dc96d80>,"{getitem_11: None, to: None, full_1: None}","(getitem_11, to, full_1)",{},{softmax: None},,to,softmax,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,0.4902976036071777,0.4902976036071777,0,0,"(8, 20, 1024, 1024)",torch.float32,where
call_function,<function softmax at 0x15543f939a20>,{where: None},"(where,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_1: None},,where,getattr_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,0.45816320180892944,0.45816320180892944,0,0,"(8, 20, 1024, 1024)",torch.float32,softmax
call_function,<built-in function getattr>,{permute_2: None},"(permute_2, 'dtype')",{},{type_1: None},,softmax,type_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,0.006534399930387735,0.006534399930387735,0,0,"(1,)",,getattr_9
call_method,type,"{softmax: None, getattr_9: None}","(softmax, getattr_9)",{},{transformer_h_0_attn_attn_dropout: None},,getattr_9,transformer_h_0_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,0.006745600048452616,0.006745600048452616,0,0,"(8, 20, 1024, 1024)",torch.float32,type_1
call_module,transformer.h.0.attn.attn_dropout,{type_1: None},"(type_1,)",{},{matmul_1: None},,type_1,matmul_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,0.00961920004338026,0.00961920004338026,0,0,"(8, 20, 1024, 1024)",torch.float32,transformer_h_0_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x15552dc96d80>,"{transformer_h_0_attn_attn_dropout: None, permute_2: None}","(transformer_h_0_attn_attn_dropout, permute_2)",{},{permute_3: None},,transformer_h_0_attn_attn_dropout,permute_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,0.5262655973434448,0.5262655973434448,0,0,"(8, 20, 1024, 64)",torch.float32,matmul_1
call_method,permute,{matmul_1: None},"(matmul_1, 0, 2, 1, 3)",{},{contiguous: None},,matmul_1,contiguous,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,0.008377600088715553,0.008377600088715553,0,0,"(8, 1024, 20, 64)",torch.float32,permute_3
call_method,contiguous,{permute_3: None},"(permute_3,)",{},"{size_11: None, view_6: None}",,permute_3,size_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,0.04452480003237724,0.04452480003237724,0,0,"(8, 1024, 20, 64)",torch.float32,contiguous
call_method,size,{contiguous: None},"(contiguous,)",{},{getitem_12: None},,contiguous,getitem_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,0.006681600026786328,0.006681600026786328,0,0,"(1,)",,size_11
call_function,<built-in function getitem>,{size_11: None},"(size_11, slice(None, -2, None))",{},{add_8: None},,size_11,add_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006540799885988236,0.006540799885988236,0,0,"(1,)",,getitem_12
call_function,<built-in function add>,{getitem_12: None},"(getitem_12, (1280,))",{},{view_6: None},,getitem_12,view_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.006611200049519539,0.006611200049519539,0,0,"(1,)",,add_8
call_method,view,"{contiguous: None, add_8: None}","(contiguous, add_8)",{},"{size_12: None, size_13: None, view_7: None}",,add_8,size_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,0.008063999935984612,0.008063999935984612,0,0,"(8, 1024, 1280)",torch.float32,view_6
call_method,size,{view_6: None},"(view_6,)",{},{getitem_13: None},,view_6,getitem_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,0.0065727999433875086,0.0065727999433875086,0,0,"(1,)",,size_12
call_function,<built-in function getitem>,{size_12: None},"(size_12, slice(None, -1, None))",{},{add_9: None},,size_12,add_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.006566400080919266,0.006566400080919266,0,0,"(1,)",,getitem_13
call_function,<built-in function add>,{getitem_13: None},"(getitem_13, (1280,))",{},{view_8: None},,getitem_13,transformer_h_0_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.00654080007225275,0.00654080007225275,0,0,"(1,)",,add_9
get_attr,transformer.h.0.attn.c_proj.bias,{},(),{},{addmm_1: None},,add_9,size_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(1280,)",torch.float32,transformer_h_0_attn_c_proj_bias
call_method,size,{view_6: None},"(view_6, -1)",{},{view_7: None},,transformer_h_0_attn_c_proj_bias,view_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,0.006592000089585781,0.006592000089585781,0,0,"(1,)",,size_13
call_method,view,"{view_6: None, size_13: None}","(view_6, -1, size_13)",{},{addmm_1: None},,size_13,transformer_h_0_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,0.0081216000020504,0.0081216000020504,0,0,"(8192, 1280)",torch.float32,view_7
get_attr,transformer.h.0.attn.c_proj.weight,{},(),{},{addmm_1: None},,view_7,addmm_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(1280, 1280)",torch.float32,transformer_h_0_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x15552dc96d80>,"{transformer_h_0_attn_c_proj_bias: None, view_7: None, transformer_h_0_attn_c_proj_weight: None}","(transformer_h_0_attn_c_proj_bias, view_7, transformer_h_0_attn_c_proj_weight)",{},{view_8: None},,transformer_h_0_attn_c_proj_weight,view_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,0.5816960096359253,0.5816960096359253,0,0,"(8192, 1280)",torch.float32,addmm_1
call_method,view,"{addmm_1: None, add_9: None}","(addmm_1, add_9)",{},{transformer_h_0_attn_resid_dropout: None},,addmm_1,transformer_h_0_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,0.008115199953317642,0.008115199953317642,0,0,"(8, 1024, 1280)",torch.float32,view_8
call_module,transformer.h.0.attn.resid_dropout,{view_8: None},"(view_8,)",{},{add_10: None},,view_8,add_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,0.009587199985980987,0.009587199985980987,0,0,"(8, 1024, 1280)",torch.float32,transformer_h_0_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_0_attn_resid_dropout: None, transformer_drop: None}","(transformer_h_0_attn_resid_dropout, transformer_drop)",{},"{transformer_h_0_ln_2: None, add_15: None}",,transformer_h_0_attn_resid_dropout,transformer_h_0_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,0.04930559992790222,0.04930559992790222,0,0,"(8, 1024, 1280)",torch.float32,add_10
call_module,transformer.h.0.ln_2,{add_10: None},"(add_10,)",{},"{size_14: None, size_15: None, view_9: None}",,add_10,size_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,0.05368320047855377,0.05368320047855377,0,0,"(8, 1024, 1280)",torch.float32,transformer_h_0_ln_2
call_method,size,{transformer_h_0_ln_2: None},"(transformer_h_0_ln_2,)",{},{getitem_14: None},,transformer_h_0_ln_2,getitem_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,0.006585600040853024,0.006585600040853024,0,0,"(1,)",,size_14
call_function,<built-in function getitem>,{size_14: None},"(size_14, slice(None, -1, None))",{},{add_11: None},,size_14,add_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.006585600040853024,0.006585600040853024,0,0,"(1,)",,getitem_14
call_function,<built-in function add>,{getitem_14: None},"(getitem_14, (5120,))",{},{view_10: None},,getitem_14,transformer_h_0_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.0065472000278532505,0.0065472000278532505,0,0,"(1,)",,add_11
get_attr,transformer.h.0.mlp.c_fc.bias,{},(),{},{addmm_2: None},,add_11,size_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(5120,)",torch.float32,transformer_h_0_mlp_c_fc_bias
call_method,size,{transformer_h_0_ln_2: None},"(transformer_h_0_ln_2, -1)",{},{view_9: None},,transformer_h_0_mlp_c_fc_bias,view_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,0.006617600005120039,0.006617600005120039,0,0,"(1,)",,size_15
call_method,view,"{transformer_h_0_ln_2: None, size_15: None}","(transformer_h_0_ln_2, -1, size_15)",{},{addmm_2: None},,size_15,transformer_h_0_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,0.008031999971717597,0.008031999971717597,0,0,"(8192, 1280)",torch.float32,view_9
get_attr,transformer.h.0.mlp.c_fc.weight,{},(),{},{addmm_2: None},,view_9,addmm_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(1280, 5120)",torch.float32,transformer_h_0_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x15552dc96d80>,"{transformer_h_0_mlp_c_fc_bias: None, view_9: None, transformer_h_0_mlp_c_fc_weight: None}","(transformer_h_0_mlp_c_fc_bias, view_9, transformer_h_0_mlp_c_fc_weight)",{},{view_10: None},,transformer_h_0_mlp_c_fc_weight,view_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,2.2226176261901855,2.2226176261901855,0,0,"(8192, 5120)",torch.float32,addmm_2
call_method,view,"{addmm_2: None, add_11: None}","(addmm_2, add_11)",{},"{mul: None, pow_2: None, add_12: None}",,addmm_2,mul,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,0.0080960001796484,0.0080960001796484,0,0,"(8, 1024, 5120)",torch.float32,view_10
call_function,<built-in function mul>,{view_10: None},"(0.5, view_10)",{},{mul_3: None},,view_10,pow_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,0.11889919936656952,0.11889919936656952,0,0,"(8, 1024, 5120)",torch.float32,mul
call_function,<built-in method pow of type object at 0x15552dc96d80>,{view_10: None},"(view_10, 3.0)",{},{mul_1: None},,mul,mul_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,0.11791360080242157,0.11791360080242157,0,0,"(8, 1024, 5120)",torch.float32,pow_2
call_function,<built-in function mul>,{pow_2: None},"(0.044715, pow_2)",{},{add_12: None},,pow_2,add_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,0.11811200231313705,0.11811200231313705,0,0,"(8, 1024, 5120)",torch.float32,mul_1
call_function,<built-in function add>,"{view_10: None, mul_1: None}","(view_10, mul_1)",{},{mul_2: None},,mul_1,mul_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,0.16952319741249083,0.16952319741249083,0,0,"(8, 1024, 5120)",torch.float32,add_12
call_function,<built-in function mul>,{add_12: None},"(0.7978845608028654, add_12)",{},{tanh: None},,add_12,tanh,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,0.11827200055122375,0.11827200055122375,0,0,"(8, 1024, 5120)",torch.float32,mul_2
call_function,<built-in method tanh of type object at 0x15552dc96d80>,{mul_2: None},"(mul_2,)",{},{add_13: None},,mul_2,add_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,0.11715840101242066,0.11715840101242066,0,0,"(8, 1024, 5120)",torch.float32,tanh
call_function,<built-in function add>,{tanh: None},"(1.0, tanh)",{},{mul_3: None},,tanh,mul_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,0.11827200055122375,0.11827200055122375,0,0,"(8, 1024, 5120)",torch.float32,add_13
call_function,<built-in function mul>,"{mul: None, add_13: None}","(mul, add_13)",{},"{size_16: None, size_17: None, view_11: None}",,add_13,size_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,0.1695871978998184,0.1695871978998184,0,0,"(8, 1024, 5120)",torch.float32,mul_3
call_method,size,{mul_3: None},"(mul_3,)",{},{getitem_15: None},,mul_3,getitem_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,0.006579200085252523,0.006579200085252523,0,0,"(1,)",,size_16
call_function,<built-in function getitem>,{size_16: None},"(size_16, slice(None, -1, None))",{},{add_14: None},,size_16,add_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.006617600005120039,0.006617600005120039,0,0,"(1,)",,getitem_15
call_function,<built-in function add>,{getitem_15: None},"(getitem_15, (1280,))",{},{view_12: None},,getitem_15,transformer_h_0_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.006592000089585781,0.006592000089585781,0,0,"(1,)",,add_14
get_attr,transformer.h.0.mlp.c_proj.bias,{},(),{},{addmm_3: None},,add_14,size_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(1280,)",torch.float32,transformer_h_0_mlp_c_proj_bias
call_method,size,{mul_3: None},"(mul_3, -1)",{},{view_11: None},,transformer_h_0_mlp_c_proj_bias,view_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,0.0064767999574542046,0.0064767999574542046,0,0,"(1,)",,size_17
call_method,view,"{mul_3: None, size_17: None}","(mul_3, -1, size_17)",{},{addmm_3: None},,size_17,transformer_h_0_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,0.008006399869918824,0.008006399869918824,0,0,"(8192, 5120)",torch.float32,view_11
get_attr,transformer.h.0.mlp.c_proj.weight,{},(),{},{addmm_3: None},,view_11,addmm_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0,0,"(5120, 1280)",torch.float32,transformer_h_0_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x15552dc96d80>,"{transformer_h_0_mlp_c_proj_bias: None, view_11: None, transformer_h_0_mlp_c_proj_weight: None}","(transformer_h_0_mlp_c_proj_bias, view_11, transformer_h_0_mlp_c_proj_weight)",{},{view_12: None},,transformer_h_0_mlp_c_proj_weight,view_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,2.4197440147399902,2.4197440147399902,0,0,"(8192, 1280)",torch.float32,addmm_3
call_method,view,"{addmm_3: None, add_14: None}","(addmm_3, add_14)",{},{transformer_h_0_mlp_dropout: None},,addmm_3,transformer_h_0_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,0.008095999993383885,0.008095999993383885,0,0,"(8, 1024, 1280)",torch.float32,view_12
call_module,transformer.h.0.mlp.dropout,{view_12: None},"(view_12,)",{},{add_15: None},,view_12,add_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,0.00951039995998144,0.00951039995998144,0,0,"(8, 1024, 1280)",torch.float32,transformer_h_0_mlp_dropout
call_function,<built-in function add>,"{add_10: None, transformer_h_0_mlp_dropout: None}","(add_10, transformer_h_0_mlp_dropout)",{},{transformer_ln_f: None},,transformer_h_0_mlp_dropout,transformer_ln_f,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,0.04878720045089722,0.04878720045089722,0,0,"(8, 1024, 1280)",torch.float32,add_15
call_module,transformer.ln_f,{add_15: None},"(add_15,)",{},{view_13: None},,add_15,view_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.ln_f', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,0.053888000547885895,0.053888000547885895,0,0,"(8, 1024, 1280)",torch.float32,transformer_ln_f
call_method,view,"{transformer_ln_f: None, add_3: None}","(transformer_ln_f, add_3)",{},{lm_head: None},,transformer_ln_f,lm_head,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,0.007878400105983018,0.007878400105983018,0,0,"(8, 1024, 1280)",torch.float32,view_13
call_module,lm_head,{view_13: None},"(view_13,)",{},{output: None},,view_13,output,False,,"{'nn_module_stack': OrderedDict([('lm_head', <class 'torch.nn.modules.linear.Linear'>)])}","[[8, 1024, 1280]]",[True],True,19.97226905822754,19.97226905822754,0,0,"(8, 1024, 50257)",torch.float32,lm_head
output,output,"{lm_head: None, permute_1: None, permute_2: None}","({'logits': lm_head, 'past_key_values': ((permute_1, permute_2),)},)",{},{},,lm_head,,False,,{},"[[8, 1024, 50257], [8, 20, 1024, 64], [8, 20, 1024, 64]]","[True, False, False]",True,0.0,0.0,0,0,"(8, 1024, 50257)",torch.float32,output
