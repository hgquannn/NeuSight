op,target,_input_nodes,_args,_kwargs,users,type,_prev,_next,_erased,_repr_fn,meta,input_shapes,input_contiguous,contiguous,latency,fw_latency,bw_latency,acc_latency,output_shape,dtype,Name
placeholder,input_ids,{},(),{},"{size: None, view: None}",<class 'torch.Tensor'>,,size,False,,{},[],[],True,0.0,0.0,0.0,0.0,"(1, 1024)",torch.int64,input_ids
call_method,size,{input_ids: None},"(input_ids,)",{},"{getitem: None, getitem_2: None, getitem_3: None}",,input_ids,getitem,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[1, 1024]]",[True],True,0.013311999849975109,0.013311999849975109,0.0,0.0,"(1,)",,size
call_function,<built-in function getitem>,{size: None},"(size, -1)",{},{view: None},,size,view,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.012684800289571285,0.012684800289571285,0.0,0.0,"(1,)",,getitem
call_method,view,"{input_ids: None, getitem: None}","(input_ids, -1, getitem)",{},"{size_1: None, getattr_1: None, transformer_wte: None}",,getitem,size_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[1, 1024], [1]]","[True, True]",True,0.014374400302767754,0.014374400302767754,0.0,0.0,"(1, 1024)",torch.int64,view
call_method,size,{view: None},"(view,)",{},{getitem_1: None},,view,getitem_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[1, 1024]]",[True],True,0.012896000035107135,0.012896000035107135,0.0,0.0,"(1,)",,size_1
call_function,<built-in function getitem>,{size_1: None},"(size_1, 0)",{},{},,size_1,getitem_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.011078399978578091,0.011078399978578091,0.0,0.0,"(1,)",,getitem_1
call_function,<built-in function getitem>,{size: None},"(size, -1)",{},{add: None},,getitem_1,add,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.011264000087976456,0.011264000087976456,0.0,0.0,"(1,)",,getitem_2
call_function,<built-in function add>,{getitem_2: None},"(getitem_2, 0)",{},{arange: None},,getitem_2,getattr_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.010828799940645695,0.010828799940645695,0.0,0.0,"(1,)",,add
call_function,<built-in function getattr>,{view: None},"(view, 'device')",{},{arange: None},,add,arange,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[1, 1024]]",[True],True,0.011264000087976456,0.011264000087976456,0.0,0.0,"(1,)",,getattr_1
call_function,<built-in method arange of type object at 0x15552dc96d80>,"{add: None, getattr_1: None}","(0, add)","{'dtype': torch.int64, 'device': getattr_1}",{unsqueeze: None},,getattr_1,unsqueeze,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[1], [1]]","[True, True]",True,0.023552000522613525,0.023552000522613525,0.0,0.0,"(1024,)",torch.int64,arange
call_method,unsqueeze,{arange: None},"(arange, 0)",{},{transformer_wpe: None},,arange,transformer_wte,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1024]],[True],True,0.014323200099170208,0.014323200099170208,0.0,0.0,"(1, 1024)",torch.int64,unsqueeze
call_module,transformer.wte,{view: None},"(view,)",{},{add_1: None},,unsqueeze,transformer_wpe,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.wte', <class 'torch.nn.modules.sparse.Embedding'>)])}","[[1, 1024]]",[True],True,1.3801151901483535,0.044012799859046936,0.40755200386047363,0.928550386428833,"(1, 1024, 1280)",torch.float32,transformer_wte
call_module,transformer.wpe,{unsqueeze: None},"(unsqueeze,)",{},{add_1: None},,transformer_wte,add_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.wpe', <class 'torch.nn.modules.sparse.Embedding'>)])}","[[1, 1024]]",[True],True,0.18308480232954025,0.0530303992331028,0.09707520306110382,0.03297920003533363,"(1, 1024, 1280)",torch.float32,transformer_wpe
call_function,<built-in function add>,"{transformer_wte: None, transformer_wpe: None}","(transformer_wte, transformer_wpe)",{},{transformer_drop: None},,transformer_wpe,transformer_drop,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[1, 1024, 1280], [1, 1024, 1280]]","[True, True]",True,0.0448512002825737,0.033587200194597246,0.011264000087976456,0.0,"(1, 1024, 1280)",torch.float32,add_1
call_module,transformer.drop,{add_1: None},"(add_1,)",{},"{size_2: None, transformer_h_0_ln_1: None, add_10: None}",,add_1,getitem_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.drop', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[1, 1024, 1280]]",[True],True,0.10117120072245597,0.04199039936065674,0.05918080136179924,0.0,"(1, 1024, 1280)",torch.float32,transformer_drop
call_function,<built-in function getitem>,{size: None},"(size, slice(1, None, None))",{},{add_2: None},,transformer_drop,add_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.010239999741315842,0.010239999741315842,0.0,0.0,"(1,)",,getitem_3
call_function,<built-in function add>,{getitem_3: None},"((-1,), getitem_3)",{},{add_3: None},,getitem_3,size_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,0.010233599878847598,0.010233599878847598,0.0,0.0,"(1,)",,add_2
call_method,size,{transformer_drop: None},"(transformer_drop, -1)",{},{add_3: None},,add_2,add_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[1, 1024, 1280]]",[True],True,0.010233599878847598,0.010233599878847598,0.0,0.0,"(1,)",,size_2
call_function,<built-in function add>,"{add_2: None, size_2: None}","(add_2, (size_2,))",{},{view_13: None},,size_2,transformer_h_0_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[1], [1]]","[True, True]",True,0.010233599878847598,0.010233599878847598,0.0,0.0,"(1,)",,add_3
call_module,transformer.h.0.ln_1,{transformer_drop: None},"(transformer_drop,)",{},"{size_3: None, size_4: None, view_1: None}",,add_3,size_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[1, 1024, 1280]]",[True],True,0.16032000184059142,0.04709760099649429,0.06796800047159195,0.04525440037250519,"(1, 1024, 1280)",torch.float32,transformer_h_0_ln_1
call_method,size,{transformer_h_0_ln_1: None},"(transformer_h_0_ln_1,)",{},{getitem_4: None},,transformer_h_0_ln_1,getitem_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1, 1024, 1280]]",[True],True,0.010444799810647965,0.010444799810647965,0.0,0.0,"(1,)",,size_3
call_function,<built-in function getitem>,{size_3: None},"(size_3, slice(None, -1, None))",{},{add_4: None},,size_3,add_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.011231999844312668,0.011231999844312668,0.0,0.0,"(1,)",,getitem_4
call_function,<built-in function add>,{getitem_4: None},"(getitem_4, (3840,))",{},{view_2: None},,getitem_4,transformer_h_0_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.010649599879980088,0.010649599879980088,0.0,0.0,"(1,)",,add_4
get_attr,transformer.h.0.attn.c_attn.bias,{},(),{},{addmm: None},,add_4,size_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0.0,0.0,"(3840,)",torch.float32,transformer_h_0_attn_c_attn_bias
call_method,size,{transformer_h_0_ln_1: None},"(transformer_h_0_ln_1, -1)",{},{view_1: None},,transformer_h_0_attn_c_attn_bias,view_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1, 1024, 1280]]",[True],True,0.010239999741315842,0.010239999741315842,0.0,0.0,"(1,)",,size_4
call_method,view,"{transformer_h_0_ln_1: None, size_4: None}","(transformer_h_0_ln_1, -1, size_4)",{},{addmm: None},,size_4,transformer_h_0_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1, 1024, 1280], [1]]","[True, True]",True,0.014950400032103062,0.014950400032103062,0.0,0.0,"(1024, 1280)",torch.float32,view_1
get_attr,transformer.h.0.attn.c_attn.weight,{},(),{},{addmm: None},,view_1,addmm,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0.0,0.0,"(1280, 3840)",torch.float32,transformer_h_0_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x15552dc96d80>,"{transformer_h_0_attn_c_attn_bias: None, view_1: None, transformer_h_0_attn_c_attn_weight: None}","(transformer_h_0_attn_c_attn_bias, view_1, transformer_h_0_attn_c_attn_weight)",{},{view_2: None},,transformer_h_0_attn_c_attn_weight,view_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [1024, 1280], [1280, 3840]]","[True, True, True]",True,2.651935961842537,0.8536064028739929,1.7168383598327637,0.08149119913578033,"(1024, 3840)",torch.float32,addmm
call_method,view,"{addmm: None, add_4: None}","(addmm, add_4)",{},{split: None},,addmm,split,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1024, 3840], [1]]","[True, True]",True,0.014937599934637547,0.014937599934637547,0.0,0.0,"(1, 1024, 3840)",torch.float32,view_2
call_method,split,{view_2: None},"(view_2, 1280)",{'dim': 2},"{getitem_5: None, getitem_6: None, getitem_7: None}",,view_2,getitem_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1024, 3840]]",[True],True,0.024480000138282776,0.024480000138282776,0.0,0.0,"(1,)",,split
call_function,<built-in function getitem>,{split: None},"(split, 0)",{},"{size_5: None, view_3: None}",,split,getitem_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,0.010342399775981902,0.010342399775981902,0.0,0.0,"(1, 1024, 1280)",torch.float32,getitem_5
call_function,<built-in function getitem>,{split: None},"(split, 1)",{},"{size_6: None, view_4: None}",,getitem_5,getitem_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,0.010182400047779084,0.010182400047779084,0.0,0.0,"(1, 1024, 1280)",torch.float32,getitem_6
call_function,<built-in function getitem>,{split: None},"(split, 2)",{},"{size_7: None, view_5: None}",,getitem_6,size_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,0.010591999813914298,0.010591999813914298,0.0,0.0,"(1, 1024, 1280)",torch.float32,getitem_7
call_method,size,{getitem_5: None},"(getitem_5,)",{},{getitem_8: None},,getitem_7,getitem_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1024, 1280]]",[False],True,0.010444799996912479,0.010444799996912479,0.0,0.0,"(1,)",,size_5
call_function,<built-in function getitem>,{size_5: None},"(size_5, slice(None, -1, None))",{},{add_5: None},,size_5,add_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.010905600152909756,0.010905600152909756,0.0,0.0,"(1,)",,getitem_8
call_function,<built-in function add>,{getitem_8: None},"(getitem_8, (20, 64))",{},{view_3: None},,getitem_8,view_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.010790400207042694,0.010790400207042694,0.0,0.0,"(1,)",,add_5
call_method,view,"{getitem_5: None, add_5: None}","(getitem_5, add_5)",{},{permute: None},,add_5,permute,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1024, 1280], [1]]","[False, True]",False,0.015776000544428827,0.015776000544428827,0.0,0.0,"(1, 1024, 20, 64)",torch.float32,view_3
call_method,permute,{view_3: None},"(view_3, 0, 2, 1, 3)",{},"{matmul: None, size_9: None}",,view_3,size_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1024, 20, 64]]",[False],False,0.01639680005609989,0.01639680005609989,0.0,0.0,"(1, 20, 1024, 64)",torch.float32,permute
call_method,size,{getitem_6: None},"(getitem_6,)",{},{getitem_9: None},,permute,getitem_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1024, 1280]]",[False],True,0.011020800098776817,0.011020800098776817,0.0,0.0,"(1,)",,size_6
call_function,<built-in function getitem>,{size_6: None},"(size_6, slice(None, -1, None))",{},{add_6: None},,size_6,add_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.010899200104176998,0.010899200104176998,0.0,0.0,"(1,)",,getitem_9
call_function,<built-in function add>,{getitem_9: None},"(getitem_9, (20, 64))",{},{view_4: None},,getitem_9,view_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.01020160000771284,0.01020160000771284,0.0,0.0,"(1,)",,add_6
call_method,view,"{getitem_6: None, add_6: None}","(getitem_6, add_6)",{},{permute_1: None},,add_6,permute_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1024, 1280], [1]]","[False, True]",False,0.01565439999103546,0.01565439999103546,0.0,0.0,"(1, 1024, 20, 64)",torch.float32,view_4
call_method,permute,{view_4: None},"(view_4, 0, 2, 1, 3)",{},"{transpose: None, size_10: None, output: None}",,view_4,size_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1024, 20, 64]]",[False],False,0.016441600024700166,0.016441600024700166,0.0,0.0,"(1, 20, 1024, 64)",torch.float32,permute_1
call_method,size,{getitem_7: None},"(getitem_7,)",{},{getitem_10: None},,permute_1,getitem_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1024, 1280]]",[False],True,0.010969599895179271,0.010969599895179271,0.0,0.0,"(1,)",,size_7
call_function,<built-in function getitem>,{size_7: None},"(size_7, slice(None, -1, None))",{},{add_7: None},,size_7,add_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.011961599998176097,0.011961599998176097,0.0,0.0,"(1,)",,getitem_10
call_function,<built-in function add>,{getitem_10: None},"(getitem_10, (20, 64))",{},{view_5: None},,getitem_10,view_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.010822400264441968,0.010822400264441968,0.0,0.0,"(1,)",,add_7
call_method,view,"{getitem_7: None, add_7: None}","(getitem_7, add_7)",{},{permute_2: None},,add_7,permute_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1024, 1280], [1]]","[False, True]",False,0.015827199444174767,0.015827199444174767,0.0,0.0,"(1, 1024, 20, 64)",torch.float32,view_5
call_method,permute,{view_5: None},"(view_5, 0, 2, 1, 3)",{},"{size_8: None, getattr_9: None, matmul_1: None, output: None}",,view_5,transpose,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1024, 20, 64]]",[False],False,0.017696000263094903,0.017696000263094903,0.0,0.0,"(1, 20, 1024, 64)",torch.float32,permute_2
call_method,transpose,{permute_1: None},"(permute_1, -1, -2)",{},{matmul: None},,permute_2,matmul,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 20, 1024, 64]]",[False],False,0.01574400011450052,0.01574400011450052,0.0,0.0,"(1, 20, 64, 1024)",torch.float32,transpose
call_function,<built-in method matmul of type object at 0x15552dc96d80>,"{permute: None, transpose: None}","(permute, transpose)",{},"{getattr_2: None, getattr_3: None, truediv: None}",,transpose,size_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 20, 1024, 64], [1, 20, 64, 1024]]","[False, False]",True,0.8947583804838359,0.3295167922973633,0.5652415881864726,0.0,"(1, 20, 1024, 1024)",torch.float32,matmul
call_method,size,{permute_2: None},"(permute_2, -1)",{},{pow_1: None},,matmul,pow_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 20, 1024, 64]]",[False],True,0.010438399761915207,0.010438399761915207,0.0,0.0,"(1,)",,size_8
call_function,<built-in function pow>,{size_8: None},"(size_8, 0.5)",{},{full: None},,size_8,getattr_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.010239999741315842,0.010239999741315842,0.0,0.0,"(1,)",,pow_1
call_function,<built-in function getattr>,{matmul: None},"(matmul, 'dtype')",{},{full: None},,pow_1,getattr_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 20, 1024, 1024]]",[True],True,0.010239999741315842,0.010239999741315842,0.0,0.0,"(1,)",,getattr_2
call_function,<built-in function getattr>,{matmul: None},"(matmul, 'device')",{},{full: None},,getattr_2,full,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 20, 1024, 1024]]",[True],True,0.010239999741315842,0.010239999741315842,0.0,0.0,"(1,)",,getattr_3
call_function,<built-in method full of type object at 0x15552dc96d80>,"{pow_1: None, getattr_2: None, getattr_3: None}","([], pow_1)","{'dtype': getattr_2, 'device': getattr_3}",{truediv: None},,getattr_3,truediv,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,0.023552000522613525,0.023552000522613525,0.0,0.0,"(1,)",torch.float32,full
call_function,<built-in function truediv>,"{matmul: None, full: None}","(matmul, full)",{},"{getattr_4: None, getattr_6: None, getattr_7: None, getattr_8: None, to: None}",,full,size_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 20, 1024, 1024], [1]]","[True, True]",True,0.4441791921854019,0.2230143964290619,0.22116479575634002,0.0,"(1, 20, 1024, 1024)",torch.float32,truediv
call_method,size,{permute: None},"(permute, -2)",{},{sub: None},,truediv,size_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 20, 1024, 64]]",[False],True,0.010649599879980088,0.010649599879980088,0.0,0.0,"(1,)",,size_9
call_method,size,{permute_1: None},"(permute_1, -2)",{},"{sub: None, getitem_11: None}",,size_9,transformer_h_0_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 20, 1024, 64]]",[False],True,0.010233599878847598,0.010233599878847598,0.0,0.0,"(1,)",,size_10
get_attr,transformer.h.0.attn.bias,{},(),{},{getitem_11: None},,size_10,sub,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,0.0,0.0,0.0,0.0,"(1, 1, 1024, 1024)",torch.bool,transformer_h_0_attn_bias
call_function,<built-in function sub>,"{size_10: None, size_9: None}","(size_10, size_9)",{},{getitem_11: None},,transformer_h_0_attn_bias,getitem_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,0.010239999741315842,0.010239999741315842,0.0,0.0,"(1,)",,sub
call_function,<built-in function getitem>,"{transformer_h_0_attn_bias: None, sub: None, size_10: None}","(transformer_h_0_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub, size_10, None), slice(None, size_10, None)))",{},{where: None},,sub,getattr_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,0.01863040067255497,0.01863040067255497,0.0,0.0,"(1, 1, 1024, 1024)",torch.bool,getitem_11
call_function,<built-in function getattr>,{truediv: None},"(truediv, 'dtype')",{},{finfo: None},,getitem_11,finfo,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 20, 1024, 1024]]",[True],True,0.010227200016379357,0.010227200016379357,0.0,0.0,"(1,)",,getattr_4
call_function,<class 'torch.finfo'>,{getattr_4: None},"(getattr_4,)",{},{getattr_5: None},,getattr_4,getattr_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.010035199858248234,0.010035199858248234,0.0,0.0,"(1,)",,finfo
call_function,<built-in function getattr>,{finfo: None},"(finfo, 'min')",{},{full_1: None},,finfo,getattr_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.010239999741315842,0.010239999741315842,0.0,0.0,"(1,)",,getattr_5
call_function,<built-in function getattr>,{truediv: None},"(truediv, 'dtype')",{},{full_1: None},,getattr_5,getattr_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 20, 1024, 1024]]",[True],True,0.01125119999051094,0.01125119999051094,0.0,0.0,"(1,)",,getattr_6
call_function,<built-in function getattr>,{truediv: None},"(truediv, 'device')",{},{full_1: None},,getattr_6,full_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 20, 1024, 1024]]",[True],True,0.010233599878847598,0.010233599878847598,0.0,0.0,"(1,)",,getattr_7
call_function,<built-in method full of type object at 0x15552dc96d80>,"{getattr_5: None, getattr_6: None, getattr_7: None}","([], getattr_5)","{'dtype': getattr_6, 'device': getattr_7}",{where: None},,getattr_7,getattr_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,0.02353920042514801,0.02353920042514801,0.0,0.0,"(1,)",torch.float32,full_1
call_function,<built-in function getattr>,{truediv: None},"(truediv, 'dtype')",{},{to: None},,full_1,to,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 20, 1024, 1024]]",[True],True,0.010239999741315842,0.010239999741315842,0.0,0.0,"(1,)",,getattr_8
call_method,to,"{truediv: None, getattr_8: None}","(truediv, getattr_8)",{},{where: None},,getattr_8,where,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 20, 1024, 1024], [1]]","[True, True]",True,0.01125119999051094,0.01125119999051094,0.0,0.0,"(1, 20, 1024, 1024)",torch.float32,to
call_function,<built-in method where of type object at 0x15552dc96d80>,"{getitem_11: None, to: None, full_1: None}","(getitem_11, to, full_1)",{},{softmax: None},,to,softmax,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1, 20, 1024, 1024], [1]]","[True, True, True]",True,0.46713600158691404,0.23059840202331544,0.23653759956359863,0.0,"(1, 20, 1024, 1024)",torch.float32,where
call_function,<function softmax at 0x1554c57f5a20>,{where: None},"(where,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_1: None},,where,getattr_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 20, 1024, 1024]]",[True],True,0.8632256120443345,0.2430976003408432,0.6201280117034912,0.0,"(1, 20, 1024, 1024)",torch.float32,softmax
call_function,<built-in function getattr>,{permute_2: None},"(permute_2, 'dtype')",{},{type_1: None},,softmax,type_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 20, 1024, 64]]",[False],True,0.010233599878847598,0.010233599878847598,0.0,0.0,"(1,)",,getattr_9
call_method,type,"{softmax: None, getattr_9: None}","(softmax, getattr_9)",{},{transformer_h_0_attn_attn_dropout: None},,getattr_9,transformer_h_0_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 20, 1024, 1024], [1]]","[True, True]",True,0.011046399921178817,0.011046399921178817,0.0,0.0,"(1, 20, 1024, 1024)",torch.float32,type_1
call_module,transformer.h.0.attn.attn_dropout,{type_1: None},"(type_1,)",{},{matmul_1: None},,type_1,matmul_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[1, 20, 1024, 1024]]",[True],True,0.9549888014793396,0.27074559926986697,0.6842432022094727,0.0,"(1, 20, 1024, 1024)",torch.float32,transformer_h_0_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x15552dc96d80>,"{transformer_h_0_attn_attn_dropout: None, permute_2: None}","(transformer_h_0_attn_attn_dropout, permute_2)",{},{permute_3: None},,transformer_h_0_attn_attn_dropout,permute_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 20, 1024, 1024], [1, 20, 1024, 64]]","[True, False]",True,0.9074624129571021,0.3037184000015259,0.6037440129555762,0.0,"(1, 20, 1024, 64)",torch.float32,matmul_1
call_method,permute,{matmul_1: None},"(matmul_1, 0, 2, 1, 3)",{},{contiguous: None},,matmul_1,contiguous,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 20, 1024, 64]]",[True],False,0.01637119986116886,0.01637119986116886,0.0,0.0,"(1, 1024, 20, 64)",torch.float32,permute_3
call_method,contiguous,{permute_3: None},"(permute_3,)",{},"{size_11: None, view_6: None}",,permute_3,size_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1024, 20, 64]]",[False],True,0.03131519965827465,0.03131519965827465,0.0,0.0,"(1, 1024, 20, 64)",torch.float32,contiguous
call_method,size,{contiguous: None},"(contiguous,)",{},{getitem_12: None},,contiguous,getitem_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1024, 20, 64]]",[True],True,0.010239999741315842,0.010239999741315842,0.0,0.0,"(1,)",,size_11
call_function,<built-in function getitem>,{size_11: None},"(size_11, slice(None, -2, None))",{},{add_8: None},,size_11,add_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.0102463997900486,0.0102463997900486,0.0,0.0,"(1,)",,getitem_12
call_function,<built-in function add>,{getitem_12: None},"(getitem_12, (1280,))",{},{view_6: None},,getitem_12,view_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,0.010239999927580356,0.010239999927580356,0.0,0.0,"(1,)",,add_8
call_method,view,"{contiguous: None, add_8: None}","(contiguous, add_8)",{},"{size_12: None, size_13: None, view_7: None}",,add_8,size_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1024, 20, 64], [1]]","[True, True]",True,0.01535359974950552,0.01535359974950552,0.0,0.0,"(1, 1024, 1280)",torch.float32,view_6
call_method,size,{view_6: None},"(view_6,)",{},{getitem_13: None},,view_6,getitem_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1, 1024, 1280]]",[True],True,0.010239999741315842,0.010239999741315842,0.0,0.0,"(1,)",,size_12
call_function,<built-in function getitem>,{size_12: None},"(size_12, slice(None, -1, None))",{},{add_9: None},,size_12,add_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.010233599878847598,0.010233599878847598,0.0,0.0,"(1,)",,getitem_13
call_function,<built-in function add>,{getitem_13: None},"(getitem_13, (1280,))",{},{view_8: None},,getitem_13,transformer_h_0_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.010239999741315842,0.010239999741315842,0.0,0.0,"(1,)",,add_9
get_attr,transformer.h.0.attn.c_proj.bias,{},(),{},{addmm_1: None},,add_9,size_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0.0,0.0,"(1280,)",torch.float32,transformer_h_0_attn_c_proj_bias
call_method,size,{view_6: None},"(view_6, -1)",{},{view_7: None},,transformer_h_0_attn_c_proj_bias,view_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1, 1024, 1280]]",[True],True,0.011468800157308579,0.011468800157308579,0.0,0.0,"(1,)",,size_13
call_method,view,"{view_6: None, size_13: None}","(view_6, -1, size_13)",{},{addmm_1: None},,size_13,transformer_h_0_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1, 1024, 1280], [1]]","[True, True]",True,0.01535359974950552,0.01535359974950552,0.0,0.0,"(1024, 1280)",torch.float32,view_7
get_attr,transformer.h.0.attn.c_proj.weight,{},(),{},{addmm_1: None},,view_7,addmm_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0.0,0.0,"(1280, 1280)",torch.float32,transformer_h_0_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x15552dc96d80>,"{transformer_h_0_attn_c_proj_bias: None, view_7: None, transformer_h_0_attn_c_proj_weight: None}","(transformer_h_0_attn_c_proj_bias, view_7, transformer_h_0_attn_c_proj_weight)",{},{view_8: None},,transformer_h_0_attn_c_proj_weight,view_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [1024, 1280], [1280, 1280]]","[True, True, True]",True,0.9553855773061515,0.3002303957939148,0.6205439805984497,0.03461120091378689,"(1024, 1280)",torch.float32,addmm_1
call_method,view,"{addmm_1: None, add_9: None}","(addmm_1, add_9)",{},{transformer_h_0_attn_resid_dropout: None},,addmm_1,transformer_h_0_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1024, 1280], [1]]","[True, True]",True,0.016179199889302255,0.016179199889302255,0.0,0.0,"(1, 1024, 1280)",torch.float32,view_8
call_module,transformer.h.0.attn.resid_dropout,{view_8: None},"(view_8,)",{},{add_10: None},,view_8,add_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[1, 1024, 1280]]",[True],True,0.10094080045819283,0.041971199214458466,0.05896960124373436,0.0,"(1, 1024, 1280)",torch.float32,transformer_h_0_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_0_attn_resid_dropout: None, transformer_drop: None}","(transformer_h_0_attn_resid_dropout, transformer_drop)",{},"{transformer_h_0_ln_2: None, add_15: None}",,transformer_h_0_attn_resid_dropout,transformer_h_0_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[1, 1024, 1280], [1, 1024, 1280]]","[True, True]",True,0.04503040015697479,0.033772800117731094,0.011257600039243698,0.0,"(1, 1024, 1280)",torch.float32,add_10
call_module,transformer.h.0.ln_2,{add_10: None},"(add_10,)",{},"{size_14: None, size_15: None, view_9: None}",,add_10,size_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[1, 1024, 1280]]",[True],True,0.15970560163259506,0.04707840085029602,0.06757760047912598,0.045049600303173065,"(1, 1024, 1280)",torch.float32,transformer_h_0_ln_2
call_method,size,{transformer_h_0_ln_2: None},"(transformer_h_0_ln_2,)",{},{getitem_14: None},,transformer_h_0_ln_2,getitem_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1, 1024, 1280]]",[True],True,0.0102463997900486,0.0102463997900486,0.0,0.0,"(1,)",,size_14
call_function,<built-in function getitem>,{size_14: None},"(size_14, slice(None, -1, None))",{},{add_11: None},,size_14,add_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.01084160003811121,0.01084160003811121,0.0,0.0,"(1,)",,getitem_14
call_function,<built-in function add>,{getitem_14: None},"(getitem_14, (5120,))",{},{view_10: None},,getitem_14,transformer_h_0_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.010239999741315842,0.010239999741315842,0.0,0.0,"(1,)",,add_11
get_attr,transformer.h.0.mlp.c_fc.bias,{},(),{},{addmm_2: None},,add_11,size_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0.0,0.0,"(5120,)",torch.float32,transformer_h_0_mlp_c_fc_bias
call_method,size,{transformer_h_0_ln_2: None},"(transformer_h_0_ln_2, -1)",{},{view_9: None},,transformer_h_0_mlp_c_fc_bias,view_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1, 1024, 1280]]",[True],True,0.010444799810647965,0.010444799810647965,0.0,0.0,"(1,)",,size_15
call_method,view,"{transformer_h_0_ln_2: None, size_15: None}","(transformer_h_0_ln_2, -1, size_15)",{},{addmm_2: None},,size_15,transformer_h_0_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1, 1024, 1280], [1]]","[True, True]",True,0.015155199728906155,0.015155199728906155,0.0,0.0,"(1024, 1280)",torch.float32,view_9
get_attr,transformer.h.0.mlp.c_fc.weight,{},(),{},{addmm_2: None},,view_9,addmm_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0.0,0.0,"(1280, 5120)",torch.float32,transformer_h_0_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x15552dc96d80>,"{transformer_h_0_mlp_c_fc_bias: None, view_9: None, transformer_h_0_mlp_c_fc_weight: None}","(transformer_h_0_mlp_c_fc_bias, view_9, transformer_h_0_mlp_c_fc_weight)",{},{view_10: None},,transformer_h_0_mlp_c_fc_weight,view_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [1024, 1280], [1280, 5120]]","[True, True, True]",True,3.5360512882471085,1.1630528211593627,2.2683584690093994,0.10463999807834626,"(1024, 5120)",torch.float32,addmm_2
call_method,view,"{addmm_2: None, add_11: None}","(addmm_2, add_11)",{},"{mul: None, pow_2: None, add_12: None}",,addmm_2,mul,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1024, 5120], [1]]","[True, True]",True,0.015327999927103519,0.015327999927103519,0.0,0.0,"(1, 1024, 5120)",torch.float32,view_10
call_function,<built-in function mul>,{view_10: None},"(0.5, view_10)",{},{mul_3: None},,view_10,pow_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[1, 1024, 5120]]",[True],True,0.13170560002326964,0.06779520064592362,0.06391039937734604,0.0,"(1, 1024, 5120)",torch.float32,mul
call_function,<built-in method pow of type object at 0x15552dc96d80>,{view_10: None},"(view_10, 3.0)",{},{mul_1: None},,mul,mul_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[1, 1024, 5120]]",[True],True,0.2652159959077835,0.06696960031986236,0.19824639558792115,0.0,"(1, 1024, 5120)",torch.float32,pow_2
call_function,<built-in function mul>,{pow_2: None},"(0.044715, pow_2)",{},{add_12: None},,pow_2,add_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[1, 1024, 5120]]",[True],True,0.13414400070905685,0.07065600156784058,0.06348799914121628,0.0,"(1, 1024, 5120)",torch.float32,mul_1
call_function,<built-in function add>,"{view_10: None, mul_1: None}","(view_10, mul_1)",{},{mul_2: None},,mul_1,mul_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[1, 1024, 5120], [1, 1024, 5120]]","[True, True]",True,0.1013760007917881,0.09011200070381165,0.011264000087976456,0.0,"(1, 1024, 5120)",torch.float32,add_12
call_function,<built-in function mul>,{add_12: None},"(0.7978845608028654, add_12)",{},{tanh: None},,add_12,tanh,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[1, 1024, 5120]]",[True],True,0.131904000043869,0.06840320080518722,0.0635007992386818,0.0,"(1, 1024, 5120)",torch.float32,mul_2
call_function,<built-in method tanh of type object at 0x15552dc96d80>,{mul_2: None},"(mul_2,)",{},{add_13: None},,mul_2,add_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[1, 1024, 5120]]",[True],True,0.1550336003303528,0.06492159962654113,0.09011200070381165,0.0,"(1, 1024, 5120)",torch.float32,tanh
call_function,<built-in function add>,{tanh: None},"(1.0, tanh)",{},{mul_3: None},,tanh,mul_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[1, 1024, 5120]]",[True],True,0.07884800061583519,0.06758400052785873,0.011264000087976456,0.0,"(1, 1024, 5120)",torch.float32,add_13
call_function,<built-in function mul>,"{mul: None, add_13: None}","(mul, add_13)",{},"{size_16: None, size_17: None, view_11: None}",,add_13,size_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[1, 1024, 5120], [1, 1024, 5120]]","[True, True]",True,0.2590784028172493,0.09051520079374313,0.16856320202350616,0.0,"(1, 1024, 5120)",torch.float32,mul_3
call_method,size,{mul_3: None},"(mul_3,)",{},{getitem_15: None},,mul_3,getitem_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1, 1024, 5120]]",[True],True,0.010239999741315842,0.010239999741315842,0.0,0.0,"(1,)",,size_16
call_function,<built-in function getitem>,{size_16: None},"(size_16, slice(None, -1, None))",{},{add_14: None},,size_16,add_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.010239999741315842,0.010239999741315842,0.0,0.0,"(1,)",,getitem_15
call_function,<built-in function add>,{getitem_15: None},"(getitem_15, (1280,))",{},{view_12: None},,getitem_15,transformer_h_0_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,0.010239999741315842,0.010239999741315842,0.0,0.0,"(1,)",,add_14
get_attr,transformer.h.0.mlp.c_proj.bias,{},(),{},{addmm_3: None},,add_14,size_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0.0,0.0,"(1280,)",torch.float32,transformer_h_0_mlp_c_proj_bias
call_method,size,{mul_3: None},"(mul_3, -1)",{},{view_11: None},,transformer_h_0_mlp_c_proj_bias,view_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1, 1024, 5120]]",[True],True,0.010259199887514114,0.010259199887514114,0.0,0.0,"(1,)",,size_17
call_method,view,"{mul_3: None, size_17: None}","(mul_3, -1, size_17)",{},{addmm_3: None},,size_17,transformer_h_0_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1, 1024, 5120], [1]]","[True, True]",True,0.015148800052702426,0.015148800052702426,0.0,0.0,"(1024, 5120)",torch.float32,view_11
get_attr,transformer.h.0.mlp.c_proj.weight,{},(),{},{addmm_3: None},,view_11,addmm_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,0.0,0.0,0.0,0.0,"(5120, 1280)",torch.float32,transformer_h_0_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x15552dc96d80>,"{transformer_h_0_mlp_c_proj_bias: None, view_11: None, transformer_h_0_mlp_c_proj_weight: None}","(transformer_h_0_mlp_c_proj_bias, view_11, transformer_h_0_mlp_c_proj_weight)",{},{view_12: None},,transformer_h_0_mlp_c_proj_weight,view_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [1024, 5120], [5120, 1280]]","[True, True, True]",True,3.2128895163536066,1.0246143817901612,2.0832255363464354,0.1050495982170105,"(1024, 1280)",torch.float32,addmm_3
call_method,view,"{addmm_3: None, add_14: None}","(addmm_3, add_14)",{},{transformer_h_0_mlp_dropout: None},,addmm_3,transformer_h_0_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1024, 1280], [1]]","[True, True]",True,0.015155199728906155,0.015155199728906155,0.0,0.0,"(1, 1024, 1280)",torch.float32,view_12
call_module,transformer.h.0.mlp.dropout,{view_12: None},"(view_12,)",{},{add_15: None},,view_12,add_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[1, 1024, 1280]]",[True],True,0.09973760023713113,0.04177919924259186,0.057958400994539264,0.0,"(1, 1024, 1280)",torch.float32,transformer_h_0_mlp_dropout
call_function,<built-in function add>,"{add_10: None, transformer_h_0_mlp_dropout: None}","(add_10, transformer_h_0_mlp_dropout)",{},{transformer_ln_f: None},,transformer_h_0_mlp_dropout,transformer_ln_f,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[1, 1024, 1280], [1, 1024, 1280]]","[True, True]",True,0.044844800233840944,0.03357440009713173,0.011270400136709213,0.0,"(1, 1024, 1280)",torch.float32,add_15
call_module,transformer.ln_f,{add_15: None},"(add_15,)",{},{view_13: None},,add_15,view_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.ln_f', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[1, 1024, 1280]]",[True],True,0.15625600069761278,0.04524160027503967,0.06574719995260239,0.0452672004699707,"(1, 1024, 1280)",torch.float32,transformer_ln_f
call_method,view,"{transformer_ln_f: None, add_3: None}","(transformer_ln_f, add_3)",{},{lm_head: None},,transformer_ln_f,lm_head,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[1, 1024, 1280], [1]]","[True, True]",True,0.014361600019037723,0.014361600019037723,0.0,0.0,"(1, 1024, 1280)",torch.float32,view_13
call_module,lm_head,{view_13: None},"(view_13,)",{},{output: None},,view_13,output,False,,"{'nn_module_stack': OrderedDict([('lm_head', <class 'torch.nn.modules.linear.Linear'>)])}","[[1, 1024, 1280]]",[True],True,30.038604782917535,9.889997100830078,19.2128956903005,0.9357119917869567,"(1, 1024, 50257)",torch.float32,lm_head
output,output,"{lm_head: None, permute_1: None, permute_2: None}","({'logits': lm_head, 'past_key_values': ((permute_1, permute_2),)},)",{},{},,lm_head,,False,,{},"[[1, 1024, 50257], [1, 20, 1024, 64], [1, 20, 1024, 64]]","[True, False, False]",True,0.0,0.0,0.0,0.0,"(1, 1024, 50257)",torch.float32,output
