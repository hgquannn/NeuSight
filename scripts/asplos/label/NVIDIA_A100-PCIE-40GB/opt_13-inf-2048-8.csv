op,target,_input_nodes,_args,_kwargs,users,type,_prev,_next,_erased,_repr_fn,meta,input_shapes,input_contiguous,contiguous,latency,fw_latency,bw_latency,acc_latency,output_shape,dtype,Name
placeholder,input_ids,{},(),{},"{size: None, view: None}",<class 'torch.Tensor'>,,size,False,,{},[],[],True,0.0,0.0,0,0,"(8, 2048)",torch.int64,input_ids
call_method,size,{input_ids: None},"(input_ids,)",{},"{getitem: None, getitem_1: None, getitem_2: None, getitem_3: None, getitem_4: None}",,input_ids,getitem,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048]]",[True],True,0.006553600169718265,0.006553600169718265,0,0,"(1,)",,size
call_function,<built-in function getitem>,{size: None},"(size, -1)",{},{view: None},,size,view,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,getitem
call_method,view,"{input_ids: None, getitem: None}","(input_ids, -1, getitem)",{},{model_decoder_embed_tokens: None},,getitem,model_decoder_embed_tokens,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048], [1]]","[True, True]",True,0.008191999979317188,0.008191999979317188,0,0,"(8, 2048)",torch.int64,view
call_module,model.decoder.embed_tokens,{view: None},"(view,)",{},"{getattr_1: None, getattr_2: None, add_5: None}",,view,getitem_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_tokens', <class 'torch.nn.modules.sparse.Embedding'>)])}","[[8, 2048]]",[True],True,0.33812479972839354,0.33812479972839354,0,0,"(8, 2048, 2048)",torch.float32,model_decoder_embed_tokens
call_function,<built-in function getitem>,{size: None},"(size, 0)",{},{ones: None},,model_decoder_embed_tokens,getitem_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,getitem_1
call_function,<built-in function getitem>,{size: None},"(size, 1)",{},{add: None},,getitem_1,add,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,getitem_2
call_function,<built-in function add>,{getitem_2: None},"(0, getitem_2)",{},{ones: None},,getitem_2,getattr_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,add
call_function,<built-in function getattr>,{model_decoder_embed_tokens: None},"(model_decoder_embed_tokens, 'device')",{},{ones: None},,add,ones,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048, 2048]]",[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,getattr_1
call_function,<built-in method ones of type object at 0x15552dc96d80>,"{getitem_1: None, add: None, getattr_1: None}","(getitem_1, add)",{'device': getattr_1},"{size_1: None, size_2: None, getattr_4: None, size_5: None, getitem_9: None, getattr_6: None, long: None}",,getattr_1,getitem_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[1], [1], [1]]","[True, True, True]",True,0.01576959975063801,0.01576959975063801,0,0,"(8, 2048)",torch.float32,ones
call_function,<built-in function getitem>,{size: None},"(size, -1)",{},{add_1: None},,ones,add_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,getitem_3
call_function,<built-in function add>,{getitem_3: None},"(getitem_3, 0)",{},{sub: None},,getitem_3,size_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,add_1
call_method,size,{ones: None},"(ones,)",{},{},,add_1,getitem_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048]]",[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,size_1
call_function,<built-in function getitem>,{size: None},"(size, -1)",{},"{gt: None, sub: None, full: None, add_3: None, expand: None, expand_1: None}",,size_1,size_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,getitem_4
call_method,size,{ones: None},"(ones,)",{},{getitem_5: None},,getitem_4,getitem_5,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048]]",[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,size_2
call_function,<built-in function getitem>,{size_2: None},"(size_2, 0)",{},{expand: None},,size_2,gt,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,getitem_5
call_function,<built-in function gt>,{getitem_4: None},"(getitem_4, 1)",{},{},,getitem_5,sub,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.005734400078654289,0.005734400078654289,0,0,"(1,)",,gt
call_function,<built-in function sub>,"{add_1: None, getitem_4: None}","(add_1, getitem_4)",{},"{gt_1: None, add_3: None}",,gt,getattr_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[1], [1]]","[True, True]",True,0.005939200147986412,0.005939200147986412,0,0,"(1,)",,sub
call_function,<built-in function getattr>,{model_decoder_embed_tokens: None},"(model_decoder_embed_tokens, 'dtype')",{},"{finfo: None, to: None, to_1: None, finfo_1: None, finfo_2: None}",,sub,finfo,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048, 2048]]",[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,getattr_2
call_function,<class 'torch.finfo'>,{getattr_2: None},"(getattr_2,)",{},{getattr_3: None},,getattr_2,getattr_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,finfo
call_function,<built-in function getattr>,{finfo: None},"(finfo, 'min')",{},{full: None},,finfo,getattr_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,getattr_3
call_function,<built-in function getattr>,{ones: None},"(ones, 'device')",{},"{full: None, arange: None}",,getattr_3,full,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048]]",[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,getattr_4
call_function,<built-in method full of type object at 0x15552dc96d80>,"{getitem_4: None, getattr_3: None, getattr_4: None}","((getitem_4, getitem_4), getattr_3)",{'device': getattr_4},"{size_3: None, size_4: None, masked_fill_: None, to: None}",,getattr_4,size_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[1], [1], [1]]","[True, True, True]",True,0.022937600314617158,0.022937600314617158,0,0,"(2048, 2048)",torch.float32,full
call_method,size,{full: None},"(full, -1)",{},{arange: None},,full,arange,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048, 2048]]",[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,size_3
call_function,<built-in method arange of type object at 0x15552dc96d80>,"{size_3: None, getattr_4: None}","(size_3,)",{'device': getattr_4},"{add_2: None, lt: None}",,size_3,add_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[1], [1]]","[True, True]",True,0.015359999611973763,0.015359999611973763,0,0,"(2048,)",torch.int64,arange
call_function,<built-in function add>,{arange: None},"(arange, 1)",{},{view_1: None},,arange,size_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[2048]],[True],True,0.01740800030529499,0.01740800030529499,0,0,"(2048,)",torch.int64,add_2
call_method,size,{full: None},"(full, -1)",{},{view_1: None},,add_2,view_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048, 2048]]",[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,size_4
call_method,view,"{add_2: None, size_4: None}","(add_2, size_4, 1)",{},{lt: None},,size_4,lt,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048], [1]]","[True, True]",True,0.007577600050717592,0.007577600050717592,0,0,"(2048, 1)",torch.int64,view_1
call_function,<built-in function lt>,"{arange: None, view_1: None}","(arange, view_1)",{},{masked_fill_: None},,view_1,masked_fill_,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048], [2048, 1]]","[True, True]",True,0.04095999896526337,0.04095999896526337,0,0,"(2048, 2048)",torch.bool,lt
call_method,masked_fill_,"{full: None, lt: None}","(full, lt, 0)",{},{},,lt,to,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048, 2048], [2048, 2048]]","[True, True]",True,0.02457600086927414,0.02457600086927414,0,0,"(2048, 2048)",torch.float32,masked_fill_
call_method,to,"{full: None, getattr_2: None}","(full, getattr_2)",{},{getitem_6: None},,masked_fill_,gt_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048, 2048], [1]]","[True, True]",True,0.006144000217318535,0.006144000217318535,0,0,"(2048, 2048)",torch.float32,to
call_function,<built-in function gt>,{sub: None},"(sub, 0)",{},{},,to,getitem_6,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,gt_1
call_function,<built-in function getitem>,{to: None},"(to, (None, None, slice(None, None, None), slice(None, None, None)))",{},{expand: None},,gt_1,add_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[2048, 2048]]",[True],True,0.01228800043463707,0.01228800043463707,0,0,"(1, 1, 2048, 2048)",torch.float32,getitem_6
call_function,<built-in function add>,"{getitem_4: None, sub: None}","(getitem_4, sub)",{},{expand: None},,getitem_6,expand,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[1], [1]]","[True, True]",True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,add_3
call_method,expand,"{getitem_6: None, getitem_5: None, getitem_4: None, add_3: None}","(getitem_6, getitem_5, 1, getitem_4, add_3)",{},{masked_fill_1: None},,add_3,size_5,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[1, 1, 2048, 2048], [1], [1], [1]]","[True, True, True, True]",False,0.008191999979317188,0.008191999979317188,0,0,"(8, 1, 2048, 2048)",torch.float32,expand
call_method,size,{ones: None},"(ones,)",{},"{getitem_7: None, getitem_8: None}",,expand,getitem_7,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048]]",[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,size_5
call_function,<built-in function getitem>,{size_5: None},"(size_5, 0)",{},{expand_1: None},,size_5,getitem_8,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,getitem_7
call_function,<built-in function getitem>,{size_5: None},"(size_5, 1)",{},{expand_1: None},,getitem_7,getitem_9,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,getitem_8
call_function,<built-in function getitem>,{ones: None},"(ones, (slice(None, None, None), None, None, slice(None, None, None)))",{},{expand_1: None},,getitem_8,expand_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048]]",[True],True,0.012083200365304947,0.012083200365304947,0,0,"(8, 1, 1, 2048)",torch.float32,getitem_9
call_method,expand,"{getitem_9: None, getitem_7: None, getitem_4: None, getitem_8: None}","(getitem_9, getitem_7, 1, getitem_4, getitem_8)",{},{to_1: None},,getitem_9,to_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 1, 1, 2048], [1], [1], [1]]","[True, True, True, True]",False,0.008191999979317188,0.008191999979317188,0,0,"(8, 1, 2048, 2048)",torch.float32,expand_1
call_method,to,"{expand_1: None, getattr_2: None}","(expand_1, getattr_2)",{},{sub_1: None},,expand_1,sub_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 1, 2048, 2048], [1]]","[False, True]",False,0.006144000217318535,0.006144000217318535,0,0,"(8, 1, 2048, 2048)",torch.float32,to_1
call_function,<built-in function sub>,{to_1: None},"(1.0, to_1)",{},"{to_2: None, masked_fill: None}",,to_1,to_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 1, 2048, 2048]]",[False],True,0.211763197183609,0.211763197183609,0,0,"(8, 1, 2048, 2048)",torch.float32,sub_1
call_method,to,{sub_1: None},"(sub_1, torch.bool)",{},{masked_fill: None},,sub_1,finfo_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 1, 2048, 2048]]",[True],True,0.26111999750137327,0.26111999750137327,0,0,"(8, 1, 2048, 2048)",torch.bool,to_2
call_function,<class 'torch.finfo'>,{getattr_2: None},"(getattr_2,)",{},{getattr_5: None},,to_2,getattr_5,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,finfo_1
call_function,<built-in function getattr>,{finfo_1: None},"(finfo_1, 'min')",{},{masked_fill: None},,finfo_1,masked_fill,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,getattr_5
call_method,masked_fill,"{sub_1: None, to_2: None, getattr_5: None}","(sub_1, to_2, getattr_5)",{},{to_3: None},,getattr_5,getattr_6,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 1, 2048, 2048], [8, 1, 2048, 2048], [1]]","[True, True, True]",True,0.45629440546035765,0.45629440546035765,0,0,"(8, 1, 2048, 2048)",torch.float32,masked_fill
call_function,<built-in function getattr>,{ones: None},"(ones, 'device')",{},{to_3: None},,masked_fill,to_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048]]",[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,getattr_6
call_method,to,"{masked_fill: None, getattr_6: None}","(masked_fill, getattr_6)",{},{bool_1: None},,getattr_6,bool_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 1, 2048, 2048], [1]]","[True, True]",True,0.006144000217318535,0.006144000217318535,0,0,"(8, 1, 2048, 2048)",torch.float32,to_3
call_method,bool,{to_3: None},"(to_3,)",{},{masked_fill_1: None},,to_3,finfo_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 1, 2048, 2048]]",[True],True,0.260915195941925,0.260915195941925,0,0,"(8, 1, 2048, 2048)",torch.bool,bool_1
call_function,<class 'torch.finfo'>,{getattr_2: None},"(getattr_2,)",{},{getattr_7: None},,bool_1,getattr_7,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,finfo_2
call_function,<built-in function getattr>,{finfo_2: None},"(finfo_2, 'min')",{},{masked_fill_1: None},,finfo_2,masked_fill_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}",[[1]],[True],True,0.005939200147986412,0.005939200147986412,0,0,"(1,)",,getattr_7
call_method,masked_fill,"{expand: None, bool_1: None, getattr_7: None}","(expand, bool_1, getattr_7)",{},"{size_9: None, add_6: None}",,getattr_7,long,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 1, 2048, 2048], [8, 1, 2048, 2048], [1]]","[False, True, True]",True,0.4792320132255554,0.4792320132255554,0,0,"(8, 1, 2048, 2048)",torch.float32,masked_fill_1
call_method,long,{ones: None},"(ones,)",{},"{cumsum: None, type_as: None, mul: None}",,masked_fill_1,cumsum,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[8, 2048]]",[True],True,0.01576959975063801,0.01576959975063801,0,0,"(8, 2048)",torch.int64,long
call_function,<built-in method cumsum of type object at 0x15552dc96d80>,{long: None},"(long,)",{'dim': 1},{type_as: None},,long,type_as,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[8, 2048]]",[True],True,0.025599999353289604,0.025599999353289604,0,0,"(8, 2048)",torch.int64,cumsum
call_method,type_as,"{cumsum: None, long: None}","(cumsum, long)",{},{mul: None},,cumsum,mul,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[8, 2048], [8, 2048]]","[True, True]",True,0.006144000217318535,0.006144000217318535,0,0,"(8, 2048)",torch.int64,type_as
call_function,<built-in function mul>,"{type_as: None, long: None}","(type_as, long)",{},{long_1: None},,type_as,long_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[8, 2048], [8, 2048]]","[True, True]",True,0.014336000196635723,0.014336000196635723,0,0,"(8, 2048)",torch.int64,mul
call_method,long,{mul: None},"(mul,)",{},{sub_2: None},,mul,sub_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[8, 2048]]",[True],True,0.006144000217318535,0.006144000217318535,0,0,"(8, 2048)",torch.int64,long_1
call_function,<built-in function sub>,{long_1: None},"(long_1, 1)",{},{getitem_10: None},,long_1,getitem_10,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[8, 2048]]",[True],True,0.01720320023596287,0.01720320023596287,0,0,"(8, 2048)",torch.int64,sub_2
call_function,<built-in function getitem>,{sub_2: None},"(sub_2, (slice(None, None, None), slice(0, None, None)))",{},{add_4: None},,sub_2,add_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[8, 2048]]",[True],True,0.010239999741315842,0.010239999741315842,0,0,"(8, 2048)",torch.int64,getitem_10
call_function,<built-in function add>,{getitem_10: None},"(getitem_10, 2)",{},{embedding: None},,getitem_10,model_decoder_embed_positions_weight,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[8, 2048]]",[True],True,0.01720320023596287,0.01720320023596287,0,0,"(8, 2048)",torch.int64,add_4
get_attr,model.decoder.embed_positions.weight,{},(),{},{embedding: None},,add_4,embedding,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}",[],[],True,0.0,0.0,0,0,"(2050, 2048)",torch.float32,model_decoder_embed_positions_weight
call_function,<function embedding at 0x1554949ddf30>,"{add_4: None, model_decoder_embed_positions_weight: None}","(add_4, model_decoder_embed_positions_weight)","{'padding_idx': None, 'max_norm': None, 'norm_type': 2.0, 'scale_grad_by_freq': False, 'sparse': False}",{add_5: None},,model_decoder_embed_positions_weight,add_5,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.embed_positions', <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'>)])}","[[8, 2048], [2050, 2048]]","[True, True]",True,0.7038976073265075,0.7038976073265075,0,0,"(8, 2048, 2048)",torch.float32,embedding
call_function,<built-in function add>,"{model_decoder_embed_tokens: None, embedding: None}","(model_decoder_embed_tokens, embedding)",{},"{model_decoder_layers_0_self_attn_layer_norm: None, add_7: None}",,embedding,model_decoder_layers_0_self_attn_layer_norm,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>)])}","[[8, 2048, 2048], [8, 2048, 2048]]","[True, True]",True,0.2977792024612427,0.2977792024612427,0,0,"(8, 2048, 2048)",torch.float32,add_5
call_module,model.decoder.layers.0.self_attn_layer_norm,{add_5: None},"(add_5,)",{},"{size_6: None, model_decoder_layers_0_self_attn_q_proj: None, model_decoder_layers_0_self_attn_k_proj: None, model_decoder_layers_0_self_attn_v_proj: None}",,add_5,size_6,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn_layer_norm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 2048, 2048]]",[True],True,0.2641920030117035,0.2641920030117035,0,0,"(8, 2048, 2048)",torch.float32,model_decoder_layers_0_self_attn_layer_norm
call_method,size,{model_decoder_layers_0_self_attn_layer_norm: None},"(model_decoder_layers_0_self_attn_layer_norm,)",{},"{getitem_11: None, getitem_12: None, getitem_13: None}",,model_decoder_layers_0_self_attn_layer_norm,getitem_11,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 2048, 2048]]",[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,size_6
call_function,<built-in function getitem>,{size_6: None},"(size_6, 0)",{},"{view_2: None, view_3: None, mul_2: None, view_4: None, mul_3: None, ne_1: None, view_8: None, mul_4: None, mul_5: None, view_10: None, reshape: None}",,size_6,getitem_12,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,getitem_11
call_function,<built-in function getitem>,{size_6: None},"(size_6, 1)",{},"{view_4: None, ne: None, ne_1: None, view_8: None, view_9: None, ne_2: None, view_10: None, reshape: None}",,getitem_11,getitem_13,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.005939200147986412,0.005939200147986412,0,0,"(1,)",,getitem_12
call_function,<built-in function getitem>,{size_6: None},"(size_6, 2)",{},{},,getitem_12,model_decoder_layers_0_self_attn_q_proj,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.005939200147986412,0.005939200147986412,0,0,"(1,)",,getitem_13
call_module,model.decoder.layers.0.self_attn.q_proj,{model_decoder_layers_0_self_attn_layer_norm: None},"(model_decoder_layers_0_self_attn_layer_norm,)",{},{mul_1: None},,getitem_13,mul_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>), ('model.decoder.layers.0.self_attn.q_proj', <class 'torch.nn.modules.linear.Linear'>)])}","[[8, 2048, 2048]]",[True],True,9.611059188842773,9.611059188842773,0,0,"(8, 2048, 2048)",torch.float32,model_decoder_layers_0_self_attn_q_proj
call_function,<built-in function mul>,{model_decoder_layers_0_self_attn_q_proj: None},"(model_decoder_layers_0_self_attn_q_proj, 0.125)",{},{view_4: None},,model_decoder_layers_0_self_attn_q_proj,model_decoder_layers_0_self_attn_k_proj,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 2048, 2048]]",[True],True,0.20377599596977233,0.20377599596977233,0,0,"(8, 2048, 2048)",torch.float32,mul_1
call_module,model.decoder.layers.0.self_attn.k_proj,{model_decoder_layers_0_self_attn_layer_norm: None},"(model_decoder_layers_0_self_attn_layer_norm,)",{},{view_2: None},,mul_1,view_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>), ('model.decoder.layers.0.self_attn.k_proj', <class 'torch.nn.modules.linear.Linear'>)])}","[[8, 2048, 2048]]",[True],True,7.513907241821289,7.513907241821289,0,0,"(8, 2048, 2048)",torch.float32,model_decoder_layers_0_self_attn_k_proj
call_method,view,"{model_decoder_layers_0_self_attn_k_proj: None, getitem_11: None}","(model_decoder_layers_0_self_attn_k_proj, getitem_11, -1, 32, 64)",{},{transpose: None},,model_decoder_layers_0_self_attn_k_proj,transpose,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 2048, 2048], [1]]","[True, True]",True,0.008806400187313556,0.008806400187313556,0,0,"(8, 2048, 32, 64)",torch.float32,view_2
call_method,transpose,{view_2: None},"(view_2, 1, 2)",{},{contiguous: None},,view_2,contiguous,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 2048, 32, 64]]",[True],False,0.008191999979317188,0.008191999979317188,0,0,"(8, 32, 2048, 64)",torch.float32,transpose
call_method,contiguous,{transpose: None},"(transpose,)",{},"{view_6: None, output: None}",,transpose,model_decoder_layers_0_self_attn_v_proj,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 64]]",[False],True,0.2209791958332062,0.2209791958332062,0,0,"(8, 32, 2048, 64)",torch.float32,contiguous
call_module,model.decoder.layers.0.self_attn.v_proj,{model_decoder_layers_0_self_attn_layer_norm: None},"(model_decoder_layers_0_self_attn_layer_norm,)",{},{view_3: None},,contiguous,view_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>), ('model.decoder.layers.0.self_attn.v_proj', <class 'torch.nn.modules.linear.Linear'>)])}","[[8, 2048, 2048]]",[True],True,7.494655990600586,7.494655990600586,0,0,"(8, 2048, 2048)",torch.float32,model_decoder_layers_0_self_attn_v_proj
call_method,view,"{model_decoder_layers_0_self_attn_v_proj: None, getitem_11: None}","(model_decoder_layers_0_self_attn_v_proj, getitem_11, -1, 32, 64)",{},{transpose_1: None},,model_decoder_layers_0_self_attn_v_proj,transpose_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 2048, 2048], [1]]","[True, True]",True,0.009011200256645679,0.009011200256645679,0,0,"(8, 2048, 32, 64)",torch.float32,view_3
call_method,transpose,{view_3: None},"(view_3, 1, 2)",{},{contiguous_1: None},,view_3,contiguous_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 2048, 32, 64]]",[True],False,0.008191999979317188,0.008191999979317188,0,0,"(8, 32, 2048, 64)",torch.float32,transpose_1
call_method,contiguous,{transpose_1: None},"(transpose_1,)",{},"{view_7: None, output: None}",,transpose_1,mul_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 64]]",[False],True,0.22118399441242217,0.22118399441242217,0,0,"(8, 32, 2048, 64)",torch.float32,contiguous_1
call_function,<built-in function mul>,{getitem_11: None},"(getitem_11, 32)",{},"{view_5: None, view_6: None, view_7: None}",,contiguous_1,view_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.005939200147986412,0.005939200147986412,0,0,"(1,)",,mul_2
call_method,view,"{mul_1: None, getitem_11: None, getitem_12: None}","(mul_1, getitem_11, getitem_12, 32, 64)",{},{transpose_2: None},,mul_2,transpose_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 2048, 2048], [1], [1]]","[True, True, True]",True,0.008191999979317188,0.008191999979317188,0,0,"(8, 2048, 32, 64)",torch.float32,view_4
call_method,transpose,{view_4: None},"(view_4, 1, 2)",{},{contiguous_2: None},,view_4,contiguous_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 2048, 32, 64]]",[True],False,0.009011200256645679,0.009011200256645679,0,0,"(8, 32, 2048, 64)",torch.float32,transpose_2
call_method,contiguous,{transpose_2: None},"(transpose_2,)",{},{view_5: None},,transpose_2,view_5,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 64]]",[False],True,0.22077439725399017,0.22077439725399017,0,0,"(8, 32, 2048, 64)",torch.float32,contiguous_2
call_method,view,"{contiguous_2: None, mul_2: None}","(contiguous_2, mul_2, -1, 64)",{},{bmm: None},,contiguous_2,view_6,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 64], [1]]","[True, True]",True,0.008191999979317188,0.008191999979317188,0,0,"(256, 2048, 64)",torch.float32,view_5
call_method,view,"{contiguous: None, mul_2: None}","(contiguous, mul_2, -1, 64)",{},"{size_7: None, transpose_3: None}",,view_5,view_7,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 64], [1]]","[True, True]",True,0.008396800048649311,0.008396800048649311,0,0,"(256, 2048, 64)",torch.float32,view_6
call_method,view,"{contiguous_1: None, mul_2: None}","(contiguous_1, mul_2, -1, 64)",{},{bmm_1: None},,view_6,size_7,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 64], [1]]","[True, True]",True,0.008191999979317188,0.008191999979317188,0,0,"(256, 2048, 64)",torch.float32,view_7
call_method,size,{view_6: None},"(view_6, 1)",{},"{ne: None, ne_1: None, view_8: None, view_9: None}",,view_7,transpose_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 64]]",[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,size_7
call_method,transpose,{view_6: None},"(view_6, 1, 2)",{},{bmm: None},,size_7,bmm,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 64]]",[True],False,0.008191999979317188,0.008191999979317188,0,0,"(256, 64, 2048)",torch.float32,transpose_3
call_function,<built-in method bmm of type object at 0x15552dc96d80>,"{view_5: None, transpose_3: None}","(view_5, transpose_3)",{},"{size_8: None, view_8: None}",,transpose_3,size_8,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 64], [256, 64, 2048]]","[True, False]",True,8.75233268737793,8.75233268737793,0,0,"(256, 2048, 2048)",torch.float32,bmm
call_method,size,{bmm: None},"(bmm,)",{},{ne: None},,bmm,mul_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 2048]]",[True],True,0.005939200147986412,0.005939200147986412,0,0,"(1,)",,size_8
call_function,<built-in function mul>,{getitem_11: None},"(getitem_11, 32)",{},{ne: None},,size_8,ne,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,mul_3
call_function,<built-in function ne>,"{size_8: None, mul_3: None, getitem_12: None, size_7: None}","(size_8, (mul_3, getitem_12, size_7))",{},{},,mul_3,size_9,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[1], [1], [1], [1]]","[True, True, True, True]",True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,ne
call_method,size,{masked_fill_1: None},"(masked_fill_1,)",{},{ne_1: None},,ne,ne_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 1, 2048, 2048]]",[True],True,0.005939200147986412,0.005939200147986412,0,0,"(1,)",,size_9
call_function,<built-in function ne>,"{size_9: None, getitem_11: None, getitem_12: None, size_7: None}","(size_9, (getitem_11, 1, getitem_12, size_7))",{},{},,size_9,view_8,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[1], [1], [1], [1]]","[True, True, True, True]",True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,ne_1
call_method,view,"{bmm: None, getitem_11: None, getitem_12: None, size_7: None}","(bmm, getitem_11, 32, getitem_12, size_7)",{},{add_6: None},,ne_1,add_6,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 2048], [1], [1], [1]]","[True, True, True, True]",True,0.008191999979317188,0.008191999979317188,0,0,"(8, 32, 2048, 2048)",torch.float32,view_8
call_function,<built-in function add>,"{view_8: None, masked_fill_1: None}","(view_8, masked_fill_1)",{},"{getattr_8: None, getattr_10: None, max_1: None}",,view_8,getattr_8,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 2048], [8, 1, 2048, 2048]]","[True, True]",True,9.27457275390625,9.27457275390625,0,0,"(8, 32, 2048, 2048)",torch.float32,add_6
call_function,<built-in function getattr>,{add_6: None},"(add_6, 'dtype')",{},{finfo_3: None},,add_6,finfo_3,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 2048]]",[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,getattr_8
call_function,<class 'torch.finfo'>,{getattr_8: None},"(getattr_8,)",{},{getattr_9: None},,getattr_8,getattr_9,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,finfo_3
call_function,<built-in function getattr>,{finfo_3: None},"(finfo_3, 'min')",{},{tensor: None},,finfo_3,getattr_10,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.005939200147986412,0.005939200147986412,0,0,"(1,)",,getattr_9
call_function,<built-in function getattr>,{add_6: None},"(add_6, 'device')",{},{tensor: None},,getattr_9,tensor,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 2048]]",[True],True,0.005939200147986412,0.005939200147986412,0,0,"(1,)",,getattr_10
call_function,<built-in method tensor of type object at 0x15552dc96d80>,"{getattr_9: None, getattr_10: None}","(getattr_9,)",{'device': getattr_10},{max_1: None},,getattr_10,max_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[1], [1]]","[True, True]",True,0.02744319997727871,0.02744319997727871,0,0,"(1,)",torch.float32,tensor
call_function,<built-in method max of type object at 0x15552dc96d80>,"{add_6: None, tensor: None}","(add_6, tensor)",{},{view_9: None},,tensor,mul_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 2048], [1]]","[True, True]",True,6.329753589630127,6.329753589630127,0,0,"(8, 32, 2048, 2048)",torch.float32,max_1
call_function,<built-in function mul>,{getitem_11: None},"(getitem_11, 32)",{},{view_9: None},,max_1,view_9,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.005939200147986412,0.005939200147986412,0,0,"(1,)",,mul_4
call_method,view,"{max_1: None, mul_4: None, getitem_12: None, size_7: None}","(max_1, mul_4, getitem_12, size_7)",{},"{getattr_11: None, softmax: None}",,mul_4,getattr_11,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 2048], [1], [1], [1]]","[True, True, True, True]",True,0.008191999979317188,0.008191999979317188,0,0,"(256, 2048, 2048)",torch.float32,view_9
call_function,<built-in function getattr>,{view_9: None},"(view_9, 'dtype')",{},{eq: None},,view_9,eq,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 2048]]",[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,getattr_11
call_function,<built-in function eq>,{getattr_11: None},"(getattr_11, torch.float16)",{},{},,getattr_11,softmax,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,eq
call_function,<function softmax at 0x1554949dd900>,{view_9: None},"(view_9,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{dropout: None},,eq,dropout,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 2048]]",[True],True,6.817382335662842,6.817382335662842,0,0,"(256, 2048, 2048)",torch.float32,softmax
call_function,<function dropout at 0x1554949dcd30>,{softmax: None},"(softmax,)","{'p': 0.0, 'training': False, 'inplace': False}",{bmm_1: None},,softmax,bmm_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 2048]]",[True],True,0.008191999979317188,0.008191999979317188,0,0,"(256, 2048, 2048)",torch.float32,dropout
call_function,<built-in method bmm of type object at 0x15552dc96d80>,"{dropout: None, view_7: None}","(dropout, view_7)",{},"{size_10: None, view_10: None}",,dropout,size_10,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 2048], [256, 2048, 64]]","[True, True]",True,14.9106689453125,14.9106689453125,0,0,"(256, 2048, 64)",torch.float32,bmm_1
call_method,size,{bmm_1: None},"(bmm_1,)",{},{ne_2: None},,bmm_1,mul_5,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 64]]",[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,size_10
call_function,<built-in function mul>,{getitem_11: None},"(getitem_11, 32)",{},{ne_2: None},,size_10,ne_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}",[[1]],[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,mul_5
call_function,<built-in function ne>,"{size_10: None, mul_5: None, getitem_12: None}","(size_10, (mul_5, getitem_12, 64))",{},{},,mul_5,view_10,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[1], [1], [1]]","[True, True, True]",True,0.005939200147986412,0.005939200147986412,0,0,"(1,)",,ne_2
call_method,view,"{bmm_1: None, getitem_11: None, getitem_12: None}","(bmm_1, getitem_11, 32, getitem_12, 64)",{},{transpose_4: None},,ne_2,transpose_4,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[256, 2048, 64], [1], [1]]","[True, True, True]",True,0.008396800048649311,0.008396800048649311,0,0,"(8, 32, 2048, 64)",torch.float32,view_10
call_method,transpose,{view_10: None},"(view_10, 1, 2)",{},{reshape: None},,view_10,reshape,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 32, 2048, 64]]",[True],False,0.008396800048649311,0.008396800048649311,0,0,"(8, 2048, 32, 64)",torch.float32,transpose_4
call_method,reshape,"{transpose_4: None, getitem_11: None, getitem_12: None}","(transpose_4, getitem_11, getitem_12, 2048)",{},{model_decoder_layers_0_self_attn_out_proj: None},,transpose_4,model_decoder_layers_0_self_attn_out_proj,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>)])}","[[8, 2048, 32, 64], [1], [1]]","[False, True, True]",True,0.2303999960422516,0.2303999960422516,0,0,"(8, 2048, 2048)",torch.float32,reshape
call_module,model.decoder.layers.0.self_attn.out_proj,{reshape: None},"(reshape,)",{},{dropout_1: None},,reshape,dropout_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.self_attn', <class 'transformers.models.opt.modeling_opt.OPTAttention'>), ('model.decoder.layers.0.self_attn.out_proj', <class 'torch.nn.modules.linear.Linear'>)])}","[[8, 2048, 2048]]",[True],True,7.503462409973144,7.503462409973144,0,0,"(8, 2048, 2048)",torch.float32,model_decoder_layers_0_self_attn_out_proj
call_function,<function dropout at 0x1554949dcd30>,{model_decoder_layers_0_self_attn_out_proj: None},"(model_decoder_layers_0_self_attn_out_proj,)","{'p': 0.1, 'training': False, 'inplace': False}",{add_7: None},,model_decoder_layers_0_self_attn_out_proj,add_7,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[8, 2048, 2048]]",[True],True,0.008191999979317188,0.008191999979317188,0,0,"(8, 2048, 2048)",torch.float32,dropout_1
call_function,<built-in function add>,"{add_5: None, dropout_1: None}","(add_5, dropout_1)",{},"{size_11: None, size_12: None, reshape_1: None}",,dropout_1,size_11,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[8, 2048, 2048], [8, 2048, 2048]]","[True, True]",True,0.3063808083534241,0.3063808083534241,0,0,"(8, 2048, 2048)",torch.float32,add_7
call_method,size,{add_7: None},"(add_7,)",{},{view_11: None},,add_7,size_12,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[8, 2048, 2048]]",[True],True,0.006144000217318535,0.006144000217318535,0,0,"(1,)",,size_11
call_method,size,{add_7: None},"(add_7, -1)",{},{reshape_1: None},,size_11,reshape_1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[8, 2048, 2048]]",[True],True,0.005939200147986412,0.005939200147986412,0,0,"(1,)",,size_12
call_method,reshape,"{add_7: None, size_12: None}","(add_7, -1, size_12)",{},"{model_decoder_layers_0_final_layer_norm: None, add_8: None}",,size_12,model_decoder_layers_0_final_layer_norm,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[8, 2048, 2048], [1]]","[True, True]",True,0.008191999979317188,0.008191999979317188,0,0,"(16384, 2048)",torch.float32,reshape_1
call_module,model.decoder.layers.0.final_layer_norm,{reshape_1: None},"(reshape_1,)",{},{model_decoder_layers_0_fc1: None},,reshape_1,model_decoder_layers_0_fc1,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.final_layer_norm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16384, 2048]]",[True],True,0.22118399739265443,0.22118399739265443,0,0,"(16384, 2048)",torch.float32,model_decoder_layers_0_final_layer_norm
call_module,model.decoder.layers.0.fc1,{model_decoder_layers_0_final_layer_norm: None},"(model_decoder_layers_0_final_layer_norm,)",{},{model_decoder_layers_0_activation_fn: None},,model_decoder_layers_0_final_layer_norm,model_decoder_layers_0_activation_fn,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.fc1', <class 'torch.nn.modules.linear.Linear'>)])}","[[16384, 2048]]",[True],True,32.20521011352539,32.20521011352539,0,0,"(16384, 8192)",torch.float32,model_decoder_layers_0_fc1
call_module,model.decoder.layers.0.activation_fn,{model_decoder_layers_0_fc1: None},"(model_decoder_layers_0_fc1,)",{},{model_decoder_layers_0_fc2: None},,model_decoder_layers_0_fc1,model_decoder_layers_0_fc2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.activation_fn', <class 'torch.nn.modules.activation.ReLU'>)])}","[[16384, 8192]]",[True],True,0.7823360085487365,0.7823360085487365,0,0,"(16384, 8192)",torch.float32,model_decoder_layers_0_activation_fn
call_module,model.decoder.layers.0.fc2,{model_decoder_layers_0_activation_fn: None},"(model_decoder_layers_0_activation_fn,)",{},{dropout_2: None},,model_decoder_layers_0_activation_fn,dropout_2,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>), ('model.decoder.layers.0.fc2', <class 'torch.nn.modules.linear.Linear'>)])}","[[16384, 8192]]",[True],True,32.1038330078125,32.1038330078125,0,0,"(16384, 2048)",torch.float32,model_decoder_layers_0_fc2
call_function,<function dropout at 0x1554949dcd30>,{model_decoder_layers_0_fc2: None},"(model_decoder_layers_0_fc2,)","{'p': 0.1, 'training': False, 'inplace': False}",{add_8: None},,model_decoder_layers_0_fc2,add_8,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[16384, 2048]]",[True],True,0.007987200003117322,0.007987200003117322,0,0,"(16384, 2048)",torch.float32,dropout_2
call_function,<built-in function add>,"{reshape_1: None, dropout_2: None}","(reshape_1, dropout_2)",{},{view_11: None},,dropout_2,view_11,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[16384, 2048], [16384, 2048]]","[True, True]",True,0.31375359892845156,0.31375359892845156,0,0,"(16384, 2048)",torch.float32,add_8
call_method,view,"{add_8: None, size_11: None}","(add_8, size_11)",{},{model_decoder_final_layer_norm: None},,add_8,model_decoder_final_layer_norm,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.layers.0', <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>)])}","[[16384, 2048], [1]]","[True, True]",True,0.008191999979317188,0.008191999979317188,0,0,"(8, 2048, 2048)",torch.float32,view_11
call_module,model.decoder.final_layer_norm,{view_11: None},"(view_11,)",{},{lm_head: None},,view_11,lm_head,False,,"{'nn_module_stack': OrderedDict([('model.decoder', <class 'transformers.models.opt.modeling_opt.OPTDecoder'>), ('model.decoder.final_layer_norm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 2048, 2048]]",[True],True,0.22159359455108643,0.22159359455108643,0,0,"(8, 2048, 2048)",torch.float32,model_decoder_final_layer_norm
call_module,lm_head,{model_decoder_final_layer_norm: None},"(model_decoder_final_layer_norm,)",{},{contiguous_3: None},,model_decoder_final_layer_norm,contiguous_3,False,,"{'nn_module_stack': OrderedDict([('lm_head', <class 'torch.nn.modules.linear.Linear'>)])}","[[8, 2048, 2048]]",[True],True,196.36346435546875,196.36346435546875,0,0,"(8, 2048, 50272)",torch.float32,lm_head
call_method,contiguous,{lm_head: None},"(lm_head,)",{},{output: None},,lm_head,output,False,,{},"[[8, 2048, 50272]]",[True],True,0.005939200147986412,0.005939200147986412,0,0,"(8, 2048, 50272)",torch.float32,contiguous_3
output,output,"{contiguous_3: None, contiguous: None, contiguous_1: None}","({'logits': contiguous_3, 'past_key_values': ((contiguous, contiguous_1),)},)",{},{},,contiguous_3,,False,,{},"[[8, 2048, 50272], [8, 32, 2048, 64], [8, 32, 2048, 64]]","[True, True, True]",True,0.0,0.0,0,0,"(8, 2048, 50272)",torch.float32,output
