op,target,_input_nodes,_args,_kwargs,users,type,_prev,_next,_erased,_repr_fn,meta,input_shapes,input_contiguous,contiguous,output_shape,dtype,Name
placeholder,input_ids,{},(),{},"{size: None, view: None}",<class 'torch.Tensor'>,,size,False,,{},[],[],True,"(8, 1024)",torch.int64,input_ids
call_method,size,{input_ids: None},"(input_ids,)",{},"{getitem: None, getitem_2: None, getitem_3: None}",,input_ids,getitem,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 1024]]",[True],True,"(1,)",,size
call_function,<built-in function getitem>,{size: None},"(size, -1)",{},{view: None},,size,view,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,"(1,)",,getitem
call_method,view,"{input_ids: None, getitem: None}","(input_ids, -1, getitem)",{},"{size_1: None, getattr_1: None, transformer_wte: None}",,getitem,size_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 1024], [1]]","[True, True]",True,"(8, 1024)",torch.int64,view
call_method,size,{view: None},"(view,)",{},{getitem_1: None},,view,getitem_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 1024]]",[True],True,"(1,)",,size_1
call_function,<built-in function getitem>,{size_1: None},"(size_1, 0)",{},{},,size_1,getitem_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,"(1,)",,getitem_1
call_function,<built-in function getitem>,{size: None},"(size, -1)",{},{add: None},,getitem_1,add,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,"(1,)",,getitem_2
call_function,<built-in function add>,{getitem_2: None},"(getitem_2, 0)",{},{arange: None},,getitem_2,getattr_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,"(1,)",,add
call_function,<built-in function getattr>,{view: None},"(view, 'device')",{},{arange: None},,add,arange,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 1024]]",[True],True,"(1,)",,getattr_1
call_function,<built-in method arange of type object at 0x7f703d574d60>,"{add: None, getattr_1: None}","(0, add)","{'dtype': torch.int64, 'device': getattr_1}",{unsqueeze: None},,getattr_1,unsqueeze,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[1], [1]]","[True, True]",True,"(1024,)",torch.int64,arange
call_method,unsqueeze,{arange: None},"(arange, 0)",{},{transformer_wpe: None},,arange,transformer_wte,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1024]],[True],True,"(1, 1024)",torch.int64,unsqueeze
call_module,transformer.wte,{view: None},"(view,)",{},{add_1: None},,unsqueeze,transformer_wpe,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.wte', <class 'torch.nn.modules.sparse.Embedding'>)])}","[[8, 1024]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_wte
call_module,transformer.wpe,{unsqueeze: None},"(unsqueeze,)",{},{add_1: None},,transformer_wte,add_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.wpe', <class 'torch.nn.modules.sparse.Embedding'>)])}","[[1, 1024]]",[True],True,"(1, 1024, 1280)",torch.float32,transformer_wpe
call_function,<built-in function add>,"{transformer_wte: None, transformer_wpe: None}","(transformer_wte, transformer_wpe)",{},{transformer_drop: None},,transformer_wpe,transformer_drop,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 1024, 1280], [1, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_1
call_module,transformer.drop,{add_1: None},"(add_1,)",{},"{size_2: None, transformer_h_0_ln_1: None, add_10: None}",,add_1,getitem_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.drop', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_drop
call_function,<built-in function getitem>,{size: None},"(size, slice(1, None, None))",{},{add_2: None},,transformer_drop,add_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,"(1,)",,getitem_3
call_function,<built-in function add>,{getitem_3: None},"((-1,), getitem_3)",{},{add_3: None},,getitem_3,size_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}",[[1]],[True],True,"(1,)",,add_2
call_method,size,{transformer_drop: None},"(transformer_drop, -1)",{},{add_3: None},,add_2,add_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_2
call_function,<built-in function add>,"{add_2: None, size_2: None}","(add_2, (size_2,))",{},{view_433: None},,size_2,transformer_h_0_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,add_3
call_module,transformer.h.0.ln_1,{transformer_drop: None},"(transformer_drop,)",{},"{size_3: None, size_4: None, view_1: None}",,add_3,size_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_0_ln_1
call_method,size,{transformer_h_0_ln_1: None},"(transformer_h_0_ln_1,)",{},{getitem_4: None},,transformer_h_0_ln_1,getitem_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_3
call_function,<built-in function getitem>,{size_3: None},"(size_3, slice(None, -1, None))",{},{add_4: None},,size_3,add_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_4
call_function,<built-in function add>,{getitem_4: None},"(getitem_4, (3840,))",{},{view_2: None},,getitem_4,transformer_h_0_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_4
get_attr,transformer.h.0.attn.c_attn.bias,{},(),{},{addmm: None},,add_4,size_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_0_attn_c_attn_bias
call_method,size,{transformer_h_0_ln_1: None},"(transformer_h_0_ln_1, -1)",{},{view_1: None},,transformer_h_0_attn_c_attn_bias,view_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_4
call_method,view,"{transformer_h_0_ln_1: None, size_4: None}","(transformer_h_0_ln_1, -1, size_4)",{},{addmm: None},,size_4,transformer_h_0_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_1
get_attr,transformer.h.0.attn.c_attn.weight,{},(),{},{addmm: None},,view_1,addmm,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_0_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_0_attn_c_attn_bias: None, view_1: None, transformer_h_0_attn_c_attn_weight: None}","(transformer_h_0_attn_c_attn_bias, view_1, transformer_h_0_attn_c_attn_weight)",{},{view_2: None},,transformer_h_0_attn_c_attn_weight,view_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm
call_method,view,"{addmm: None, add_4: None}","(addmm, add_4)",{},{split: None},,addmm,split,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_2
call_method,split,{view_2: None},"(view_2, 1280)",{'dim': 2},"{getitem_5: None, getitem_6: None, getitem_7: None}",,view_2,getitem_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split
call_function,<built-in function getitem>,{split: None},"(split, 0)",{},"{size_5: None, view_3: None}",,split,getitem_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_5
call_function,<built-in function getitem>,{split: None},"(split, 1)",{},"{size_6: None, view_4: None}",,getitem_5,getitem_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_6
call_function,<built-in function getitem>,{split: None},"(split, 2)",{},"{size_7: None, view_5: None}",,getitem_6,size_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_7
call_method,size,{getitem_5: None},"(getitem_5,)",{},{getitem_8: None},,getitem_7,getitem_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_5
call_function,<built-in function getitem>,{size_5: None},"(size_5, slice(None, -1, None))",{},{add_5: None},,size_5,add_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_8
call_function,<built-in function add>,{getitem_8: None},"(getitem_8, (20, 64))",{},{view_3: None},,getitem_8,view_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_5
call_method,view,"{getitem_5: None, add_5: None}","(getitem_5, add_5)",{},{permute: None},,add_5,permute,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_3
call_method,permute,{view_3: None},"(view_3, 0, 2, 1, 3)",{},"{matmul: None, size_9: None}",,view_3,size_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute
call_method,size,{getitem_6: None},"(getitem_6,)",{},{getitem_9: None},,permute,getitem_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_6
call_function,<built-in function getitem>,{size_6: None},"(size_6, slice(None, -1, None))",{},{add_6: None},,size_6,add_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_9
call_function,<built-in function add>,{getitem_9: None},"(getitem_9, (20, 64))",{},{view_4: None},,getitem_9,view_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_6
call_method,view,"{getitem_6: None, add_6: None}","(getitem_6, add_6)",{},{permute_1: None},,add_6,permute_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_4
call_method,permute,{view_4: None},"(view_4, 0, 2, 1, 3)",{},"{transpose: None, size_10: None, output: None}",,view_4,size_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_1
call_method,size,{getitem_7: None},"(getitem_7,)",{},{getitem_10: None},,permute_1,getitem_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_7
call_function,<built-in function getitem>,{size_7: None},"(size_7, slice(None, -1, None))",{},{add_7: None},,size_7,add_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_10
call_function,<built-in function add>,{getitem_10: None},"(getitem_10, (20, 64))",{},{view_5: None},,getitem_10,view_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_7
call_method,view,"{getitem_7: None, add_7: None}","(getitem_7, add_7)",{},{permute_2: None},,add_7,permute_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_5
call_method,permute,{view_5: None},"(view_5, 0, 2, 1, 3)",{},"{size_8: None, getattr_9: None, matmul_1: None, output: None}",,view_5,transpose,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_2
call_method,transpose,{permute_1: None},"(permute_1, -1, -2)",{},{matmul: None},,permute_2,matmul,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute: None, transpose: None}","(permute, transpose)",{},"{getattr_2: None, getattr_3: None, truediv: None}",,transpose,size_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul
call_method,size,{permute_2: None},"(permute_2, -1)",{},{pow_1: None},,matmul,pow_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_8
call_function,<built-in function pow>,{size_8: None},"(size_8, 0.5)",{},{full: None},,size_8,getattr_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_1
call_function,<built-in function getattr>,{matmul: None},"(matmul, 'dtype')",{},{full: None},,pow_1,getattr_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_2
call_function,<built-in function getattr>,{matmul: None},"(matmul, 'device')",{},{full: None},,getattr_2,full,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_3
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_1: None, getattr_2: None, getattr_3: None}","([], pow_1)","{'dtype': getattr_2, 'device': getattr_3}",{truediv: None},,getattr_3,truediv,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full
call_function,<built-in function truediv>,"{matmul: None, full: None}","(matmul, full)",{},"{getattr_4: None, getattr_6: None, getattr_7: None, getattr_8: None, to: None}",,full,size_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv
call_method,size,{permute: None},"(permute, -2)",{},{sub: None},,truediv,size_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_9
call_method,size,{permute_1: None},"(permute_1, -2)",{},"{sub: None, getitem_11: None}",,size_9,transformer_h_0_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_10
get_attr,transformer.h.0.attn.bias,{},(),{},{getitem_11: None},,size_10,sub,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_0_attn_bias
call_function,<built-in function sub>,"{size_10: None, size_9: None}","(size_10, size_9)",{},{getitem_11: None},,transformer_h_0_attn_bias,getitem_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub
call_function,<built-in function getitem>,"{transformer_h_0_attn_bias: None, sub: None, size_10: None}","(transformer_h_0_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub, size_10, None), slice(None, size_10, None)))",{},{where: None},,sub,getattr_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_11
call_function,<built-in function getattr>,{truediv: None},"(truediv, 'dtype')",{},{finfo: None},,getitem_11,finfo,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_4
call_function,<class 'torch.finfo'>,{getattr_4: None},"(getattr_4,)",{},{getattr_5: None},,getattr_4,getattr_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo
call_function,<built-in function getattr>,{finfo: None},"(finfo, 'min')",{},{full_1: None},,finfo,getattr_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_5
call_function,<built-in function getattr>,{truediv: None},"(truediv, 'dtype')",{},{full_1: None},,getattr_5,getattr_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_6
call_function,<built-in function getattr>,{truediv: None},"(truediv, 'device')",{},{full_1: None},,getattr_6,full_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_7
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_5: None, getattr_6: None, getattr_7: None}","([], getattr_5)","{'dtype': getattr_6, 'device': getattr_7}",{where: None},,getattr_7,getattr_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_1
call_function,<built-in function getattr>,{truediv: None},"(truediv, 'dtype')",{},{to: None},,full_1,to,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_8
call_method,to,"{truediv: None, getattr_8: None}","(truediv, getattr_8)",{},{where: None},,getattr_8,where,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_11: None, to: None, full_1: None}","(getitem_11, to, full_1)",{},{softmax: None},,to,softmax,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where
call_function,<function softmax at 0x7f6fd5135ca0>,{where: None},"(where,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_1: None},,where,getattr_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax
call_function,<built-in function getattr>,{permute_2: None},"(permute_2, 'dtype')",{},{type_1: None},,softmax,type_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_9
call_method,type,"{softmax: None, getattr_9: None}","(softmax, getattr_9)",{},{transformer_h_0_attn_attn_dropout: None},,getattr_9,transformer_h_0_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_1
call_module,transformer.h.0.attn.attn_dropout,{type_1: None},"(type_1,)",{},{matmul_1: None},,type_1,matmul_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_0_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_0_attn_attn_dropout: None, permute_2: None}","(transformer_h_0_attn_attn_dropout, permute_2)",{},{permute_3: None},,transformer_h_0_attn_attn_dropout,permute_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_1
call_method,permute,{matmul_1: None},"(matmul_1, 0, 2, 1, 3)",{},{contiguous: None},,matmul_1,contiguous,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_3
call_method,contiguous,{permute_3: None},"(permute_3,)",{},"{size_11: None, view_6: None}",,permute_3,size_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous
call_method,size,{contiguous: None},"(contiguous,)",{},{getitem_12: None},,contiguous,getitem_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_11
call_function,<built-in function getitem>,{size_11: None},"(size_11, slice(None, -2, None))",{},{add_8: None},,size_11,add_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_12
call_function,<built-in function add>,{getitem_12: None},"(getitem_12, (1280,))",{},{view_6: None},,getitem_12,view_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_8
call_method,view,"{contiguous: None, add_8: None}","(contiguous, add_8)",{},"{size_12: None, size_13: None, view_7: None}",,add_8,size_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_6
call_method,size,{view_6: None},"(view_6,)",{},{getitem_13: None},,view_6,getitem_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_12
call_function,<built-in function getitem>,{size_12: None},"(size_12, slice(None, -1, None))",{},{add_9: None},,size_12,add_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_13
call_function,<built-in function add>,{getitem_13: None},"(getitem_13, (1280,))",{},{view_8: None},,getitem_13,transformer_h_0_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_9
get_attr,transformer.h.0.attn.c_proj.bias,{},(),{},{addmm_1: None},,add_9,size_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_0_attn_c_proj_bias
call_method,size,{view_6: None},"(view_6, -1)",{},{view_7: None},,transformer_h_0_attn_c_proj_bias,view_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_13
call_method,view,"{view_6: None, size_13: None}","(view_6, -1, size_13)",{},{addmm_1: None},,size_13,transformer_h_0_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_7
get_attr,transformer.h.0.attn.c_proj.weight,{},(),{},{addmm_1: None},,view_7,addmm_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_0_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_0_attn_c_proj_bias: None, view_7: None, transformer_h_0_attn_c_proj_weight: None}","(transformer_h_0_attn_c_proj_bias, view_7, transformer_h_0_attn_c_proj_weight)",{},{view_8: None},,transformer_h_0_attn_c_proj_weight,view_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_1
call_method,view,"{addmm_1: None, add_9: None}","(addmm_1, add_9)",{},{transformer_h_0_attn_resid_dropout: None},,addmm_1,transformer_h_0_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_8
call_module,transformer.h.0.attn.resid_dropout,{view_8: None},"(view_8,)",{},{add_10: None},,view_8,add_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.0.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_0_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_0_attn_resid_dropout: None, transformer_drop: None}","(transformer_h_0_attn_resid_dropout, transformer_drop)",{},"{transformer_h_0_ln_2: None, add_15: None}",,transformer_h_0_attn_resid_dropout,transformer_h_0_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_10
call_module,transformer.h.0.ln_2,{add_10: None},"(add_10,)",{},"{size_14: None, size_15: None, view_9: None}",,add_10,size_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_0_ln_2
call_method,size,{transformer_h_0_ln_2: None},"(transformer_h_0_ln_2,)",{},{getitem_14: None},,transformer_h_0_ln_2,getitem_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_14
call_function,<built-in function getitem>,{size_14: None},"(size_14, slice(None, -1, None))",{},{add_11: None},,size_14,add_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_14
call_function,<built-in function add>,{getitem_14: None},"(getitem_14, (5120,))",{},{view_10: None},,getitem_14,transformer_h_0_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_11
get_attr,transformer.h.0.mlp.c_fc.bias,{},(),{},{addmm_2: None},,add_11,size_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_0_mlp_c_fc_bias
call_method,size,{transformer_h_0_ln_2: None},"(transformer_h_0_ln_2, -1)",{},{view_9: None},,transformer_h_0_mlp_c_fc_bias,view_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_15
call_method,view,"{transformer_h_0_ln_2: None, size_15: None}","(transformer_h_0_ln_2, -1, size_15)",{},{addmm_2: None},,size_15,transformer_h_0_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_9
get_attr,transformer.h.0.mlp.c_fc.weight,{},(),{},{addmm_2: None},,view_9,addmm_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_0_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_0_mlp_c_fc_bias: None, view_9: None, transformer_h_0_mlp_c_fc_weight: None}","(transformer_h_0_mlp_c_fc_bias, view_9, transformer_h_0_mlp_c_fc_weight)",{},{view_10: None},,transformer_h_0_mlp_c_fc_weight,view_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_2
call_method,view,"{addmm_2: None, add_11: None}","(addmm_2, add_11)",{},"{mul: None, pow_2: None, add_12: None}",,addmm_2,mul,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_10
call_function,<built-in function mul>,{view_10: None},"(0.5, view_10)",{},{mul_3: None},,view_10,pow_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_10: None},"(view_10, 3.0)",{},{mul_1: None},,mul,mul_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_2
call_function,<built-in function mul>,{pow_2: None},"(0.044715, pow_2)",{},{add_12: None},,pow_2,add_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_1
call_function,<built-in function add>,"{view_10: None, mul_1: None}","(view_10, mul_1)",{},{mul_2: None},,mul_1,mul_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_12
call_function,<built-in function mul>,{add_12: None},"(0.7978845608028654, add_12)",{},{tanh: None},,add_12,tanh,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_2
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_2: None},"(mul_2,)",{},{add_13: None},,mul_2,add_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh
call_function,<built-in function add>,{tanh: None},"(1.0, tanh)",{},{mul_3: None},,tanh,mul_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_13
call_function,<built-in function mul>,"{mul: None, add_13: None}","(mul, add_13)",{},"{size_16: None, size_17: None, view_11: None}",,add_13,size_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_3
call_method,size,{mul_3: None},"(mul_3,)",{},{getitem_15: None},,mul_3,getitem_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_16
call_function,<built-in function getitem>,{size_16: None},"(size_16, slice(None, -1, None))",{},{add_14: None},,size_16,add_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_15
call_function,<built-in function add>,{getitem_15: None},"(getitem_15, (1280,))",{},{view_12: None},,getitem_15,transformer_h_0_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_14
get_attr,transformer.h.0.mlp.c_proj.bias,{},(),{},{addmm_3: None},,add_14,size_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_0_mlp_c_proj_bias
call_method,size,{mul_3: None},"(mul_3, -1)",{},{view_11: None},,transformer_h_0_mlp_c_proj_bias,view_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_17
call_method,view,"{mul_3: None, size_17: None}","(mul_3, -1, size_17)",{},{addmm_3: None},,size_17,transformer_h_0_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_11
get_attr,transformer.h.0.mlp.c_proj.weight,{},(),{},{addmm_3: None},,view_11,addmm_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_0_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_0_mlp_c_proj_bias: None, view_11: None, transformer_h_0_mlp_c_proj_weight: None}","(transformer_h_0_mlp_c_proj_bias, view_11, transformer_h_0_mlp_c_proj_weight)",{},{view_12: None},,transformer_h_0_mlp_c_proj_weight,view_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_3
call_method,view,"{addmm_3: None, add_14: None}","(addmm_3, add_14)",{},{transformer_h_0_mlp_dropout: None},,addmm_3,transformer_h_0_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_12
call_module,transformer.h.0.mlp.dropout,{view_12: None},"(view_12,)",{},{add_15: None},,view_12,add_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.0.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_0_mlp_dropout
call_function,<built-in function add>,"{add_10: None, transformer_h_0_mlp_dropout: None}","(add_10, transformer_h_0_mlp_dropout)",{},"{transformer_h_1_ln_1: None, add_22: None}",,transformer_h_0_mlp_dropout,transformer_h_1_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_15
call_module,transformer.h.1.ln_1,{add_15: None},"(add_15,)",{},"{size_18: None, size_19: None, view_13: None}",,add_15,size_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_1_ln_1
call_method,size,{transformer_h_1_ln_1: None},"(transformer_h_1_ln_1,)",{},{getitem_16: None},,transformer_h_1_ln_1,getitem_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.1.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_18
call_function,<built-in function getitem>,{size_18: None},"(size_18, slice(None, -1, None))",{},{add_16: None},,size_18,add_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.1.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_16
call_function,<built-in function add>,{getitem_16: None},"(getitem_16, (3840,))",{},{view_14: None},,getitem_16,transformer_h_1_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.1.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_16
get_attr,transformer.h.1.attn.c_attn.bias,{},(),{},{addmm_4: None},,add_16,size_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.1.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_1_attn_c_attn_bias
call_method,size,{transformer_h_1_ln_1: None},"(transformer_h_1_ln_1, -1)",{},{view_13: None},,transformer_h_1_attn_c_attn_bias,view_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.1.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_19
call_method,view,"{transformer_h_1_ln_1: None, size_19: None}","(transformer_h_1_ln_1, -1, size_19)",{},{addmm_4: None},,size_19,transformer_h_1_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.1.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_13
get_attr,transformer.h.1.attn.c_attn.weight,{},(),{},{addmm_4: None},,view_13,addmm_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.1.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_1_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_1_attn_c_attn_bias: None, view_13: None, transformer_h_1_attn_c_attn_weight: None}","(transformer_h_1_attn_c_attn_bias, view_13, transformer_h_1_attn_c_attn_weight)",{},{view_14: None},,transformer_h_1_attn_c_attn_weight,view_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.1.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_4
call_method,view,"{addmm_4: None, add_16: None}","(addmm_4, add_16)",{},{split_1: None},,addmm_4,split_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.1.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_14
call_method,split,{view_14: None},"(view_14, 1280)",{'dim': 2},"{getitem_17: None, getitem_18: None, getitem_19: None}",,view_14,getitem_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_1
call_function,<built-in function getitem>,{split_1: None},"(split_1, 0)",{},"{size_20: None, view_15: None}",,split_1,getitem_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_17
call_function,<built-in function getitem>,{split_1: None},"(split_1, 1)",{},"{size_21: None, view_16: None}",,getitem_17,getitem_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_18
call_function,<built-in function getitem>,{split_1: None},"(split_1, 2)",{},"{size_22: None, view_17: None}",,getitem_18,size_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_19
call_method,size,{getitem_17: None},"(getitem_17,)",{},{getitem_20: None},,getitem_19,getitem_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_20
call_function,<built-in function getitem>,{size_20: None},"(size_20, slice(None, -1, None))",{},{add_17: None},,size_20,add_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_20
call_function,<built-in function add>,{getitem_20: None},"(getitem_20, (20, 64))",{},{view_15: None},,getitem_20,view_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_17
call_method,view,"{getitem_17: None, add_17: None}","(getitem_17, add_17)",{},{permute_4: None},,add_17,permute_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_15
call_method,permute,{view_15: None},"(view_15, 0, 2, 1, 3)",{},"{matmul_2: None, size_24: None}",,view_15,size_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_4
call_method,size,{getitem_18: None},"(getitem_18,)",{},{getitem_21: None},,permute_4,getitem_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_21
call_function,<built-in function getitem>,{size_21: None},"(size_21, slice(None, -1, None))",{},{add_18: None},,size_21,add_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_21
call_function,<built-in function add>,{getitem_21: None},"(getitem_21, (20, 64))",{},{view_16: None},,getitem_21,view_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_18
call_method,view,"{getitem_18: None, add_18: None}","(getitem_18, add_18)",{},{permute_5: None},,add_18,permute_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_16
call_method,permute,{view_16: None},"(view_16, 0, 2, 1, 3)",{},"{transpose_1: None, size_25: None, output: None}",,view_16,size_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_5
call_method,size,{getitem_19: None},"(getitem_19,)",{},{getitem_22: None},,permute_5,getitem_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_22
call_function,<built-in function getitem>,{size_22: None},"(size_22, slice(None, -1, None))",{},{add_19: None},,size_22,add_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_22
call_function,<built-in function add>,{getitem_22: None},"(getitem_22, (20, 64))",{},{view_17: None},,getitem_22,view_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_19
call_method,view,"{getitem_19: None, add_19: None}","(getitem_19, add_19)",{},{permute_6: None},,add_19,permute_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_17
call_method,permute,{view_17: None},"(view_17, 0, 2, 1, 3)",{},"{size_23: None, getattr_17: None, matmul_3: None, output: None}",,view_17,transpose_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_6
call_method,transpose,{permute_5: None},"(permute_5, -1, -2)",{},{matmul_2: None},,permute_6,matmul_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_1
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_4: None, transpose_1: None}","(permute_4, transpose_1)",{},"{getattr_10: None, getattr_11: None, truediv_1: None}",,transpose_1,size_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_2
call_method,size,{permute_6: None},"(permute_6, -1)",{},{pow_3: None},,matmul_2,pow_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_23
call_function,<built-in function pow>,{size_23: None},"(size_23, 0.5)",{},{full_2: None},,size_23,getattr_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_3
call_function,<built-in function getattr>,{matmul_2: None},"(matmul_2, 'dtype')",{},{full_2: None},,pow_3,getattr_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_10
call_function,<built-in function getattr>,{matmul_2: None},"(matmul_2, 'device')",{},{full_2: None},,getattr_10,full_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_11
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_3: None, getattr_10: None, getattr_11: None}","([], pow_3)","{'dtype': getattr_10, 'device': getattr_11}",{truediv_1: None},,getattr_11,truediv_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_2
call_function,<built-in function truediv>,"{matmul_2: None, full_2: None}","(matmul_2, full_2)",{},"{getattr_12: None, getattr_14: None, getattr_15: None, getattr_16: None, to_1: None}",,full_2,size_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_1
call_method,size,{permute_4: None},"(permute_4, -2)",{},{sub_1: None},,truediv_1,size_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_24
call_method,size,{permute_5: None},"(permute_5, -2)",{},"{sub_1: None, getitem_23: None}",,size_24,transformer_h_1_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_25
get_attr,transformer.h.1.attn.bias,{},(),{},{getitem_23: None},,size_25,sub_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_1_attn_bias
call_function,<built-in function sub>,"{size_25: None, size_24: None}","(size_25, size_24)",{},{getitem_23: None},,transformer_h_1_attn_bias,getitem_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_1
call_function,<built-in function getitem>,"{transformer_h_1_attn_bias: None, sub_1: None, size_25: None}","(transformer_h_1_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_1, size_25, None), slice(None, size_25, None)))",{},{where_1: None},,sub_1,getattr_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_23
call_function,<built-in function getattr>,{truediv_1: None},"(truediv_1, 'dtype')",{},{finfo_1: None},,getitem_23,finfo_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_12
call_function,<class 'torch.finfo'>,{getattr_12: None},"(getattr_12,)",{},{getattr_13: None},,getattr_12,getattr_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_1
call_function,<built-in function getattr>,{finfo_1: None},"(finfo_1, 'min')",{},{full_3: None},,finfo_1,getattr_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_13
call_function,<built-in function getattr>,{truediv_1: None},"(truediv_1, 'dtype')",{},{full_3: None},,getattr_13,getattr_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_14
call_function,<built-in function getattr>,{truediv_1: None},"(truediv_1, 'device')",{},{full_3: None},,getattr_14,full_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_15
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_13: None, getattr_14: None, getattr_15: None}","([], getattr_13)","{'dtype': getattr_14, 'device': getattr_15}",{where_1: None},,getattr_15,getattr_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_3
call_function,<built-in function getattr>,{truediv_1: None},"(truediv_1, 'dtype')",{},{to_1: None},,full_3,to_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_16
call_method,to,"{truediv_1: None, getattr_16: None}","(truediv_1, getattr_16)",{},{where_1: None},,getattr_16,where_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_1
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_23: None, to_1: None, full_3: None}","(getitem_23, to_1, full_3)",{},{softmax_1: None},,to_1,softmax_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_1
call_function,<function softmax at 0x7f6fd5135ca0>,{where_1: None},"(where_1,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_2: None},,where_1,getattr_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_1
call_function,<built-in function getattr>,{permute_6: None},"(permute_6, 'dtype')",{},{type_2: None},,softmax_1,type_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_17
call_method,type,"{softmax_1: None, getattr_17: None}","(softmax_1, getattr_17)",{},{transformer_h_1_attn_attn_dropout: None},,getattr_17,transformer_h_1_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_2
call_module,transformer.h.1.attn.attn_dropout,{type_2: None},"(type_2,)",{},{matmul_3: None},,type_2,matmul_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.1.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_1_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_1_attn_attn_dropout: None, permute_6: None}","(transformer_h_1_attn_attn_dropout, permute_6)",{},{permute_7: None},,transformer_h_1_attn_attn_dropout,permute_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_3
call_method,permute,{matmul_3: None},"(matmul_3, 0, 2, 1, 3)",{},{contiguous_1: None},,matmul_3,contiguous_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_7
call_method,contiguous,{permute_7: None},"(permute_7,)",{},"{size_26: None, view_18: None}",,permute_7,size_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_1
call_method,size,{contiguous_1: None},"(contiguous_1,)",{},{getitem_24: None},,contiguous_1,getitem_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_26
call_function,<built-in function getitem>,{size_26: None},"(size_26, slice(None, -2, None))",{},{add_20: None},,size_26,add_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_24
call_function,<built-in function add>,{getitem_24: None},"(getitem_24, (1280,))",{},{view_18: None},,getitem_24,view_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_20
call_method,view,"{contiguous_1: None, add_20: None}","(contiguous_1, add_20)",{},"{size_27: None, size_28: None, view_19: None}",,add_20,size_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_18
call_method,size,{view_18: None},"(view_18,)",{},{getitem_25: None},,view_18,getitem_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.1.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_27
call_function,<built-in function getitem>,{size_27: None},"(size_27, slice(None, -1, None))",{},{add_21: None},,size_27,add_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.1.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_25
call_function,<built-in function add>,{getitem_25: None},"(getitem_25, (1280,))",{},{view_20: None},,getitem_25,transformer_h_1_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.1.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_21
get_attr,transformer.h.1.attn.c_proj.bias,{},(),{},{addmm_5: None},,add_21,size_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.1.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_1_attn_c_proj_bias
call_method,size,{view_18: None},"(view_18, -1)",{},{view_19: None},,transformer_h_1_attn_c_proj_bias,view_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.1.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_28
call_method,view,"{view_18: None, size_28: None}","(view_18, -1, size_28)",{},{addmm_5: None},,size_28,transformer_h_1_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.1.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_19
get_attr,transformer.h.1.attn.c_proj.weight,{},(),{},{addmm_5: None},,view_19,addmm_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.1.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_1_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_1_attn_c_proj_bias: None, view_19: None, transformer_h_1_attn_c_proj_weight: None}","(transformer_h_1_attn_c_proj_bias, view_19, transformer_h_1_attn_c_proj_weight)",{},{view_20: None},,transformer_h_1_attn_c_proj_weight,view_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.1.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_5
call_method,view,"{addmm_5: None, add_21: None}","(addmm_5, add_21)",{},{transformer_h_1_attn_resid_dropout: None},,addmm_5,transformer_h_1_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.1.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_20
call_module,transformer.h.1.attn.resid_dropout,{view_20: None},"(view_20,)",{},{add_22: None},,view_20,add_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.1.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_1_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_1_attn_resid_dropout: None, add_15: None}","(transformer_h_1_attn_resid_dropout, add_15)",{},"{transformer_h_1_ln_2: None, add_27: None}",,transformer_h_1_attn_resid_dropout,transformer_h_1_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_22
call_module,transformer.h.1.ln_2,{add_22: None},"(add_22,)",{},"{size_29: None, size_30: None, view_21: None}",,add_22,size_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_1_ln_2
call_method,size,{transformer_h_1_ln_2: None},"(transformer_h_1_ln_2,)",{},{getitem_26: None},,transformer_h_1_ln_2,getitem_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_29
call_function,<built-in function getitem>,{size_29: None},"(size_29, slice(None, -1, None))",{},{add_23: None},,size_29,add_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_26
call_function,<built-in function add>,{getitem_26: None},"(getitem_26, (5120,))",{},{view_22: None},,getitem_26,transformer_h_1_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_23
get_attr,transformer.h.1.mlp.c_fc.bias,{},(),{},{addmm_6: None},,add_23,size_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_1_mlp_c_fc_bias
call_method,size,{transformer_h_1_ln_2: None},"(transformer_h_1_ln_2, -1)",{},{view_21: None},,transformer_h_1_mlp_c_fc_bias,view_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_30
call_method,view,"{transformer_h_1_ln_2: None, size_30: None}","(transformer_h_1_ln_2, -1, size_30)",{},{addmm_6: None},,size_30,transformer_h_1_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_21
get_attr,transformer.h.1.mlp.c_fc.weight,{},(),{},{addmm_6: None},,view_21,addmm_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_1_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_1_mlp_c_fc_bias: None, view_21: None, transformer_h_1_mlp_c_fc_weight: None}","(transformer_h_1_mlp_c_fc_bias, view_21, transformer_h_1_mlp_c_fc_weight)",{},{view_22: None},,transformer_h_1_mlp_c_fc_weight,view_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_6
call_method,view,"{addmm_6: None, add_23: None}","(addmm_6, add_23)",{},"{mul_4: None, pow_4: None, add_24: None}",,addmm_6,mul_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_22
call_function,<built-in function mul>,{view_22: None},"(0.5, view_22)",{},{mul_7: None},,view_22,pow_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_4
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_22: None},"(view_22, 3.0)",{},{mul_5: None},,mul_4,mul_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_4
call_function,<built-in function mul>,{pow_4: None},"(0.044715, pow_4)",{},{add_24: None},,pow_4,add_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_5
call_function,<built-in function add>,"{view_22: None, mul_5: None}","(view_22, mul_5)",{},{mul_6: None},,mul_5,mul_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_24
call_function,<built-in function mul>,{add_24: None},"(0.7978845608028654, add_24)",{},{tanh_1: None},,add_24,tanh_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_6
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_6: None},"(mul_6,)",{},{add_25: None},,mul_6,add_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_1
call_function,<built-in function add>,{tanh_1: None},"(1.0, tanh_1)",{},{mul_7: None},,tanh_1,mul_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_25
call_function,<built-in function mul>,"{mul_4: None, add_25: None}","(mul_4, add_25)",{},"{size_31: None, size_32: None, view_23: None}",,add_25,size_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_7
call_method,size,{mul_7: None},"(mul_7,)",{},{getitem_27: None},,mul_7,getitem_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_31
call_function,<built-in function getitem>,{size_31: None},"(size_31, slice(None, -1, None))",{},{add_26: None},,size_31,add_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_27
call_function,<built-in function add>,{getitem_27: None},"(getitem_27, (1280,))",{},{view_24: None},,getitem_27,transformer_h_1_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_26
get_attr,transformer.h.1.mlp.c_proj.bias,{},(),{},{addmm_7: None},,add_26,size_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_1_mlp_c_proj_bias
call_method,size,{mul_7: None},"(mul_7, -1)",{},{view_23: None},,transformer_h_1_mlp_c_proj_bias,view_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_32
call_method,view,"{mul_7: None, size_32: None}","(mul_7, -1, size_32)",{},{addmm_7: None},,size_32,transformer_h_1_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_23
get_attr,transformer.h.1.mlp.c_proj.weight,{},(),{},{addmm_7: None},,view_23,addmm_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_1_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_1_mlp_c_proj_bias: None, view_23: None, transformer_h_1_mlp_c_proj_weight: None}","(transformer_h_1_mlp_c_proj_bias, view_23, transformer_h_1_mlp_c_proj_weight)",{},{view_24: None},,transformer_h_1_mlp_c_proj_weight,view_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_7
call_method,view,"{addmm_7: None, add_26: None}","(addmm_7, add_26)",{},{transformer_h_1_mlp_dropout: None},,addmm_7,transformer_h_1_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_24
call_module,transformer.h.1.mlp.dropout,{view_24: None},"(view_24,)",{},{add_27: None},,view_24,add_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.1.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.1.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_1_mlp_dropout
call_function,<built-in function add>,"{add_22: None, transformer_h_1_mlp_dropout: None}","(add_22, transformer_h_1_mlp_dropout)",{},"{transformer_h_2_ln_1: None, add_34: None}",,transformer_h_1_mlp_dropout,transformer_h_2_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.1', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_27
call_module,transformer.h.2.ln_1,{add_27: None},"(add_27,)",{},"{size_33: None, size_34: None, view_25: None}",,add_27,size_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_2_ln_1
call_method,size,{transformer_h_2_ln_1: None},"(transformer_h_2_ln_1,)",{},{getitem_28: None},,transformer_h_2_ln_1,getitem_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.2.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_33
call_function,<built-in function getitem>,{size_33: None},"(size_33, slice(None, -1, None))",{},{add_28: None},,size_33,add_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.2.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_28
call_function,<built-in function add>,{getitem_28: None},"(getitem_28, (3840,))",{},{view_26: None},,getitem_28,transformer_h_2_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.2.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_28
get_attr,transformer.h.2.attn.c_attn.bias,{},(),{},{addmm_8: None},,add_28,size_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.2.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_2_attn_c_attn_bias
call_method,size,{transformer_h_2_ln_1: None},"(transformer_h_2_ln_1, -1)",{},{view_25: None},,transformer_h_2_attn_c_attn_bias,view_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.2.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_34
call_method,view,"{transformer_h_2_ln_1: None, size_34: None}","(transformer_h_2_ln_1, -1, size_34)",{},{addmm_8: None},,size_34,transformer_h_2_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.2.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_25
get_attr,transformer.h.2.attn.c_attn.weight,{},(),{},{addmm_8: None},,view_25,addmm_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.2.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_2_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_2_attn_c_attn_bias: None, view_25: None, transformer_h_2_attn_c_attn_weight: None}","(transformer_h_2_attn_c_attn_bias, view_25, transformer_h_2_attn_c_attn_weight)",{},{view_26: None},,transformer_h_2_attn_c_attn_weight,view_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.2.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_8
call_method,view,"{addmm_8: None, add_28: None}","(addmm_8, add_28)",{},{split_2: None},,addmm_8,split_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.2.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_26
call_method,split,{view_26: None},"(view_26, 1280)",{'dim': 2},"{getitem_29: None, getitem_30: None, getitem_31: None}",,view_26,getitem_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_2
call_function,<built-in function getitem>,{split_2: None},"(split_2, 0)",{},"{size_35: None, view_27: None}",,split_2,getitem_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_29
call_function,<built-in function getitem>,{split_2: None},"(split_2, 1)",{},"{size_36: None, view_28: None}",,getitem_29,getitem_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_30
call_function,<built-in function getitem>,{split_2: None},"(split_2, 2)",{},"{size_37: None, view_29: None}",,getitem_30,size_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_31
call_method,size,{getitem_29: None},"(getitem_29,)",{},{getitem_32: None},,getitem_31,getitem_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_35
call_function,<built-in function getitem>,{size_35: None},"(size_35, slice(None, -1, None))",{},{add_29: None},,size_35,add_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_32
call_function,<built-in function add>,{getitem_32: None},"(getitem_32, (20, 64))",{},{view_27: None},,getitem_32,view_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_29
call_method,view,"{getitem_29: None, add_29: None}","(getitem_29, add_29)",{},{permute_8: None},,add_29,permute_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_27
call_method,permute,{view_27: None},"(view_27, 0, 2, 1, 3)",{},"{matmul_4: None, size_39: None}",,view_27,size_36,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_8
call_method,size,{getitem_30: None},"(getitem_30,)",{},{getitem_33: None},,permute_8,getitem_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_36
call_function,<built-in function getitem>,{size_36: None},"(size_36, slice(None, -1, None))",{},{add_30: None},,size_36,add_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_33
call_function,<built-in function add>,{getitem_33: None},"(getitem_33, (20, 64))",{},{view_28: None},,getitem_33,view_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_30
call_method,view,"{getitem_30: None, add_30: None}","(getitem_30, add_30)",{},{permute_9: None},,add_30,permute_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_28
call_method,permute,{view_28: None},"(view_28, 0, 2, 1, 3)",{},"{transpose_2: None, size_40: None, output: None}",,view_28,size_37,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_9
call_method,size,{getitem_31: None},"(getitem_31,)",{},{getitem_34: None},,permute_9,getitem_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_37
call_function,<built-in function getitem>,{size_37: None},"(size_37, slice(None, -1, None))",{},{add_31: None},,size_37,add_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_34
call_function,<built-in function add>,{getitem_34: None},"(getitem_34, (20, 64))",{},{view_29: None},,getitem_34,view_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_31
call_method,view,"{getitem_31: None, add_31: None}","(getitem_31, add_31)",{},{permute_10: None},,add_31,permute_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_29
call_method,permute,{view_29: None},"(view_29, 0, 2, 1, 3)",{},"{size_38: None, getattr_25: None, matmul_5: None, output: None}",,view_29,transpose_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_10
call_method,transpose,{permute_9: None},"(permute_9, -1, -2)",{},{matmul_4: None},,permute_10,matmul_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_2
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_8: None, transpose_2: None}","(permute_8, transpose_2)",{},"{getattr_18: None, getattr_19: None, truediv_2: None}",,transpose_2,size_38,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_4
call_method,size,{permute_10: None},"(permute_10, -1)",{},{pow_5: None},,matmul_4,pow_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_38
call_function,<built-in function pow>,{size_38: None},"(size_38, 0.5)",{},{full_4: None},,size_38,getattr_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_5
call_function,<built-in function getattr>,{matmul_4: None},"(matmul_4, 'dtype')",{},{full_4: None},,pow_5,getattr_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_18
call_function,<built-in function getattr>,{matmul_4: None},"(matmul_4, 'device')",{},{full_4: None},,getattr_18,full_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_19
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_5: None, getattr_18: None, getattr_19: None}","([], pow_5)","{'dtype': getattr_18, 'device': getattr_19}",{truediv_2: None},,getattr_19,truediv_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_4
call_function,<built-in function truediv>,"{matmul_4: None, full_4: None}","(matmul_4, full_4)",{},"{getattr_20: None, getattr_22: None, getattr_23: None, getattr_24: None, to_2: None}",,full_4,size_39,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_2
call_method,size,{permute_8: None},"(permute_8, -2)",{},{sub_2: None},,truediv_2,size_40,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_39
call_method,size,{permute_9: None},"(permute_9, -2)",{},"{sub_2: None, getitem_35: None}",,size_39,transformer_h_2_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_40
get_attr,transformer.h.2.attn.bias,{},(),{},{getitem_35: None},,size_40,sub_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_2_attn_bias
call_function,<built-in function sub>,"{size_40: None, size_39: None}","(size_40, size_39)",{},{getitem_35: None},,transformer_h_2_attn_bias,getitem_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_2
call_function,<built-in function getitem>,"{transformer_h_2_attn_bias: None, sub_2: None, size_40: None}","(transformer_h_2_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_2, size_40, None), slice(None, size_40, None)))",{},{where_2: None},,sub_2,getattr_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_35
call_function,<built-in function getattr>,{truediv_2: None},"(truediv_2, 'dtype')",{},{finfo_2: None},,getitem_35,finfo_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_20
call_function,<class 'torch.finfo'>,{getattr_20: None},"(getattr_20,)",{},{getattr_21: None},,getattr_20,getattr_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_2
call_function,<built-in function getattr>,{finfo_2: None},"(finfo_2, 'min')",{},{full_5: None},,finfo_2,getattr_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_21
call_function,<built-in function getattr>,{truediv_2: None},"(truediv_2, 'dtype')",{},{full_5: None},,getattr_21,getattr_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_22
call_function,<built-in function getattr>,{truediv_2: None},"(truediv_2, 'device')",{},{full_5: None},,getattr_22,full_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_23
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_21: None, getattr_22: None, getattr_23: None}","([], getattr_21)","{'dtype': getattr_22, 'device': getattr_23}",{where_2: None},,getattr_23,getattr_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_5
call_function,<built-in function getattr>,{truediv_2: None},"(truediv_2, 'dtype')",{},{to_2: None},,full_5,to_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_24
call_method,to,"{truediv_2: None, getattr_24: None}","(truediv_2, getattr_24)",{},{where_2: None},,getattr_24,where_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_2
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_35: None, to_2: None, full_5: None}","(getitem_35, to_2, full_5)",{},{softmax_2: None},,to_2,softmax_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_2
call_function,<function softmax at 0x7f6fd5135ca0>,{where_2: None},"(where_2,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_3: None},,where_2,getattr_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_2
call_function,<built-in function getattr>,{permute_10: None},"(permute_10, 'dtype')",{},{type_3: None},,softmax_2,type_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_25
call_method,type,"{softmax_2: None, getattr_25: None}","(softmax_2, getattr_25)",{},{transformer_h_2_attn_attn_dropout: None},,getattr_25,transformer_h_2_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_3
call_module,transformer.h.2.attn.attn_dropout,{type_3: None},"(type_3,)",{},{matmul_5: None},,type_3,matmul_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.2.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_2_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_2_attn_attn_dropout: None, permute_10: None}","(transformer_h_2_attn_attn_dropout, permute_10)",{},{permute_11: None},,transformer_h_2_attn_attn_dropout,permute_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_5
call_method,permute,{matmul_5: None},"(matmul_5, 0, 2, 1, 3)",{},{contiguous_2: None},,matmul_5,contiguous_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_11
call_method,contiguous,{permute_11: None},"(permute_11,)",{},"{size_41: None, view_30: None}",,permute_11,size_41,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_2
call_method,size,{contiguous_2: None},"(contiguous_2,)",{},{getitem_36: None},,contiguous_2,getitem_36,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_41
call_function,<built-in function getitem>,{size_41: None},"(size_41, slice(None, -2, None))",{},{add_32: None},,size_41,add_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_36
call_function,<built-in function add>,{getitem_36: None},"(getitem_36, (1280,))",{},{view_30: None},,getitem_36,view_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_32
call_method,view,"{contiguous_2: None, add_32: None}","(contiguous_2, add_32)",{},"{size_42: None, size_43: None, view_31: None}",,add_32,size_42,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_30
call_method,size,{view_30: None},"(view_30,)",{},{getitem_37: None},,view_30,getitem_37,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.2.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_42
call_function,<built-in function getitem>,{size_42: None},"(size_42, slice(None, -1, None))",{},{add_33: None},,size_42,add_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.2.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_37
call_function,<built-in function add>,{getitem_37: None},"(getitem_37, (1280,))",{},{view_32: None},,getitem_37,transformer_h_2_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.2.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_33
get_attr,transformer.h.2.attn.c_proj.bias,{},(),{},{addmm_9: None},,add_33,size_43,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.2.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_2_attn_c_proj_bias
call_method,size,{view_30: None},"(view_30, -1)",{},{view_31: None},,transformer_h_2_attn_c_proj_bias,view_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.2.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_43
call_method,view,"{view_30: None, size_43: None}","(view_30, -1, size_43)",{},{addmm_9: None},,size_43,transformer_h_2_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.2.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_31
get_attr,transformer.h.2.attn.c_proj.weight,{},(),{},{addmm_9: None},,view_31,addmm_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.2.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_2_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_2_attn_c_proj_bias: None, view_31: None, transformer_h_2_attn_c_proj_weight: None}","(transformer_h_2_attn_c_proj_bias, view_31, transformer_h_2_attn_c_proj_weight)",{},{view_32: None},,transformer_h_2_attn_c_proj_weight,view_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.2.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_9
call_method,view,"{addmm_9: None, add_33: None}","(addmm_9, add_33)",{},{transformer_h_2_attn_resid_dropout: None},,addmm_9,transformer_h_2_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.2.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_32
call_module,transformer.h.2.attn.resid_dropout,{view_32: None},"(view_32,)",{},{add_34: None},,view_32,add_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.2.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_2_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_2_attn_resid_dropout: None, add_27: None}","(transformer_h_2_attn_resid_dropout, add_27)",{},"{transformer_h_2_ln_2: None, add_39: None}",,transformer_h_2_attn_resid_dropout,transformer_h_2_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_34
call_module,transformer.h.2.ln_2,{add_34: None},"(add_34,)",{},"{size_44: None, size_45: None, view_33: None}",,add_34,size_44,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_2_ln_2
call_method,size,{transformer_h_2_ln_2: None},"(transformer_h_2_ln_2,)",{},{getitem_38: None},,transformer_h_2_ln_2,getitem_38,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_44
call_function,<built-in function getitem>,{size_44: None},"(size_44, slice(None, -1, None))",{},{add_35: None},,size_44,add_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_38
call_function,<built-in function add>,{getitem_38: None},"(getitem_38, (5120,))",{},{view_34: None},,getitem_38,transformer_h_2_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_35
get_attr,transformer.h.2.mlp.c_fc.bias,{},(),{},{addmm_10: None},,add_35,size_45,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_2_mlp_c_fc_bias
call_method,size,{transformer_h_2_ln_2: None},"(transformer_h_2_ln_2, -1)",{},{view_33: None},,transformer_h_2_mlp_c_fc_bias,view_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_45
call_method,view,"{transformer_h_2_ln_2: None, size_45: None}","(transformer_h_2_ln_2, -1, size_45)",{},{addmm_10: None},,size_45,transformer_h_2_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_33
get_attr,transformer.h.2.mlp.c_fc.weight,{},(),{},{addmm_10: None},,view_33,addmm_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_2_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_2_mlp_c_fc_bias: None, view_33: None, transformer_h_2_mlp_c_fc_weight: None}","(transformer_h_2_mlp_c_fc_bias, view_33, transformer_h_2_mlp_c_fc_weight)",{},{view_34: None},,transformer_h_2_mlp_c_fc_weight,view_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_10
call_method,view,"{addmm_10: None, add_35: None}","(addmm_10, add_35)",{},"{mul_8: None, pow_6: None, add_36: None}",,addmm_10,mul_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_34
call_function,<built-in function mul>,{view_34: None},"(0.5, view_34)",{},{mul_11: None},,view_34,pow_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_8
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_34: None},"(view_34, 3.0)",{},{mul_9: None},,mul_8,mul_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_6
call_function,<built-in function mul>,{pow_6: None},"(0.044715, pow_6)",{},{add_36: None},,pow_6,add_36,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_9
call_function,<built-in function add>,"{view_34: None, mul_9: None}","(view_34, mul_9)",{},{mul_10: None},,mul_9,mul_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_36
call_function,<built-in function mul>,{add_36: None},"(0.7978845608028654, add_36)",{},{tanh_2: None},,add_36,tanh_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_10
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_10: None},"(mul_10,)",{},{add_37: None},,mul_10,add_37,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_2
call_function,<built-in function add>,{tanh_2: None},"(1.0, tanh_2)",{},{mul_11: None},,tanh_2,mul_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_37
call_function,<built-in function mul>,"{mul_8: None, add_37: None}","(mul_8, add_37)",{},"{size_46: None, size_47: None, view_35: None}",,add_37,size_46,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_11
call_method,size,{mul_11: None},"(mul_11,)",{},{getitem_39: None},,mul_11,getitem_39,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_46
call_function,<built-in function getitem>,{size_46: None},"(size_46, slice(None, -1, None))",{},{add_38: None},,size_46,add_38,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_39
call_function,<built-in function add>,{getitem_39: None},"(getitem_39, (1280,))",{},{view_36: None},,getitem_39,transformer_h_2_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_38
get_attr,transformer.h.2.mlp.c_proj.bias,{},(),{},{addmm_11: None},,add_38,size_47,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_2_mlp_c_proj_bias
call_method,size,{mul_11: None},"(mul_11, -1)",{},{view_35: None},,transformer_h_2_mlp_c_proj_bias,view_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_47
call_method,view,"{mul_11: None, size_47: None}","(mul_11, -1, size_47)",{},{addmm_11: None},,size_47,transformer_h_2_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_35
get_attr,transformer.h.2.mlp.c_proj.weight,{},(),{},{addmm_11: None},,view_35,addmm_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_2_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_2_mlp_c_proj_bias: None, view_35: None, transformer_h_2_mlp_c_proj_weight: None}","(transformer_h_2_mlp_c_proj_bias, view_35, transformer_h_2_mlp_c_proj_weight)",{},{view_36: None},,transformer_h_2_mlp_c_proj_weight,view_36,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_11
call_method,view,"{addmm_11: None, add_38: None}","(addmm_11, add_38)",{},{transformer_h_2_mlp_dropout: None},,addmm_11,transformer_h_2_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_36
call_module,transformer.h.2.mlp.dropout,{view_36: None},"(view_36,)",{},{add_39: None},,view_36,add_39,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.2.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.2.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_2_mlp_dropout
call_function,<built-in function add>,"{add_34: None, transformer_h_2_mlp_dropout: None}","(add_34, transformer_h_2_mlp_dropout)",{},"{transformer_h_3_ln_1: None, add_46: None}",,transformer_h_2_mlp_dropout,transformer_h_3_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.2', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_39
call_module,transformer.h.3.ln_1,{add_39: None},"(add_39,)",{},"{size_48: None, size_49: None, view_37: None}",,add_39,size_48,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_3_ln_1
call_method,size,{transformer_h_3_ln_1: None},"(transformer_h_3_ln_1,)",{},{getitem_40: None},,transformer_h_3_ln_1,getitem_40,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.3.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_48
call_function,<built-in function getitem>,{size_48: None},"(size_48, slice(None, -1, None))",{},{add_40: None},,size_48,add_40,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.3.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_40
call_function,<built-in function add>,{getitem_40: None},"(getitem_40, (3840,))",{},{view_38: None},,getitem_40,transformer_h_3_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.3.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_40
get_attr,transformer.h.3.attn.c_attn.bias,{},(),{},{addmm_12: None},,add_40,size_49,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.3.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_3_attn_c_attn_bias
call_method,size,{transformer_h_3_ln_1: None},"(transformer_h_3_ln_1, -1)",{},{view_37: None},,transformer_h_3_attn_c_attn_bias,view_37,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.3.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_49
call_method,view,"{transformer_h_3_ln_1: None, size_49: None}","(transformer_h_3_ln_1, -1, size_49)",{},{addmm_12: None},,size_49,transformer_h_3_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.3.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_37
get_attr,transformer.h.3.attn.c_attn.weight,{},(),{},{addmm_12: None},,view_37,addmm_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.3.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_3_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_3_attn_c_attn_bias: None, view_37: None, transformer_h_3_attn_c_attn_weight: None}","(transformer_h_3_attn_c_attn_bias, view_37, transformer_h_3_attn_c_attn_weight)",{},{view_38: None},,transformer_h_3_attn_c_attn_weight,view_38,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.3.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_12
call_method,view,"{addmm_12: None, add_40: None}","(addmm_12, add_40)",{},{split_3: None},,addmm_12,split_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.3.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_38
call_method,split,{view_38: None},"(view_38, 1280)",{'dim': 2},"{getitem_41: None, getitem_42: None, getitem_43: None}",,view_38,getitem_41,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_3
call_function,<built-in function getitem>,{split_3: None},"(split_3, 0)",{},"{size_50: None, view_39: None}",,split_3,getitem_42,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_41
call_function,<built-in function getitem>,{split_3: None},"(split_3, 1)",{},"{size_51: None, view_40: None}",,getitem_41,getitem_43,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_42
call_function,<built-in function getitem>,{split_3: None},"(split_3, 2)",{},"{size_52: None, view_41: None}",,getitem_42,size_50,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_43
call_method,size,{getitem_41: None},"(getitem_41,)",{},{getitem_44: None},,getitem_43,getitem_44,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_50
call_function,<built-in function getitem>,{size_50: None},"(size_50, slice(None, -1, None))",{},{add_41: None},,size_50,add_41,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_44
call_function,<built-in function add>,{getitem_44: None},"(getitem_44, (20, 64))",{},{view_39: None},,getitem_44,view_39,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_41
call_method,view,"{getitem_41: None, add_41: None}","(getitem_41, add_41)",{},{permute_12: None},,add_41,permute_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_39
call_method,permute,{view_39: None},"(view_39, 0, 2, 1, 3)",{},"{matmul_6: None, size_54: None}",,view_39,size_51,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_12
call_method,size,{getitem_42: None},"(getitem_42,)",{},{getitem_45: None},,permute_12,getitem_45,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_51
call_function,<built-in function getitem>,{size_51: None},"(size_51, slice(None, -1, None))",{},{add_42: None},,size_51,add_42,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_45
call_function,<built-in function add>,{getitem_45: None},"(getitem_45, (20, 64))",{},{view_40: None},,getitem_45,view_40,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_42
call_method,view,"{getitem_42: None, add_42: None}","(getitem_42, add_42)",{},{permute_13: None},,add_42,permute_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_40
call_method,permute,{view_40: None},"(view_40, 0, 2, 1, 3)",{},"{transpose_3: None, size_55: None, output: None}",,view_40,size_52,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_13
call_method,size,{getitem_43: None},"(getitem_43,)",{},{getitem_46: None},,permute_13,getitem_46,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_52
call_function,<built-in function getitem>,{size_52: None},"(size_52, slice(None, -1, None))",{},{add_43: None},,size_52,add_43,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_46
call_function,<built-in function add>,{getitem_46: None},"(getitem_46, (20, 64))",{},{view_41: None},,getitem_46,view_41,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_43
call_method,view,"{getitem_43: None, add_43: None}","(getitem_43, add_43)",{},{permute_14: None},,add_43,permute_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_41
call_method,permute,{view_41: None},"(view_41, 0, 2, 1, 3)",{},"{size_53: None, getattr_33: None, matmul_7: None, output: None}",,view_41,transpose_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_14
call_method,transpose,{permute_13: None},"(permute_13, -1, -2)",{},{matmul_6: None},,permute_14,matmul_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_3
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_12: None, transpose_3: None}","(permute_12, transpose_3)",{},"{getattr_26: None, getattr_27: None, truediv_3: None}",,transpose_3,size_53,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_6
call_method,size,{permute_14: None},"(permute_14, -1)",{},{pow_7: None},,matmul_6,pow_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_53
call_function,<built-in function pow>,{size_53: None},"(size_53, 0.5)",{},{full_6: None},,size_53,getattr_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_7
call_function,<built-in function getattr>,{matmul_6: None},"(matmul_6, 'dtype')",{},{full_6: None},,pow_7,getattr_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_26
call_function,<built-in function getattr>,{matmul_6: None},"(matmul_6, 'device')",{},{full_6: None},,getattr_26,full_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_27
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_7: None, getattr_26: None, getattr_27: None}","([], pow_7)","{'dtype': getattr_26, 'device': getattr_27}",{truediv_3: None},,getattr_27,truediv_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_6
call_function,<built-in function truediv>,"{matmul_6: None, full_6: None}","(matmul_6, full_6)",{},"{getattr_28: None, getattr_30: None, getattr_31: None, getattr_32: None, to_3: None}",,full_6,size_54,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_3
call_method,size,{permute_12: None},"(permute_12, -2)",{},{sub_3: None},,truediv_3,size_55,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_54
call_method,size,{permute_13: None},"(permute_13, -2)",{},"{sub_3: None, getitem_47: None}",,size_54,transformer_h_3_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_55
get_attr,transformer.h.3.attn.bias,{},(),{},{getitem_47: None},,size_55,sub_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_3_attn_bias
call_function,<built-in function sub>,"{size_55: None, size_54: None}","(size_55, size_54)",{},{getitem_47: None},,transformer_h_3_attn_bias,getitem_47,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_3
call_function,<built-in function getitem>,"{transformer_h_3_attn_bias: None, sub_3: None, size_55: None}","(transformer_h_3_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_3, size_55, None), slice(None, size_55, None)))",{},{where_3: None},,sub_3,getattr_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_47
call_function,<built-in function getattr>,{truediv_3: None},"(truediv_3, 'dtype')",{},{finfo_3: None},,getitem_47,finfo_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_28
call_function,<class 'torch.finfo'>,{getattr_28: None},"(getattr_28,)",{},{getattr_29: None},,getattr_28,getattr_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_3
call_function,<built-in function getattr>,{finfo_3: None},"(finfo_3, 'min')",{},{full_7: None},,finfo_3,getattr_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_29
call_function,<built-in function getattr>,{truediv_3: None},"(truediv_3, 'dtype')",{},{full_7: None},,getattr_29,getattr_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_30
call_function,<built-in function getattr>,{truediv_3: None},"(truediv_3, 'device')",{},{full_7: None},,getattr_30,full_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_31
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_29: None, getattr_30: None, getattr_31: None}","([], getattr_29)","{'dtype': getattr_30, 'device': getattr_31}",{where_3: None},,getattr_31,getattr_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_7
call_function,<built-in function getattr>,{truediv_3: None},"(truediv_3, 'dtype')",{},{to_3: None},,full_7,to_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_32
call_method,to,"{truediv_3: None, getattr_32: None}","(truediv_3, getattr_32)",{},{where_3: None},,getattr_32,where_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_3
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_47: None, to_3: None, full_7: None}","(getitem_47, to_3, full_7)",{},{softmax_3: None},,to_3,softmax_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_3
call_function,<function softmax at 0x7f6fd5135ca0>,{where_3: None},"(where_3,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_4: None},,where_3,getattr_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_3
call_function,<built-in function getattr>,{permute_14: None},"(permute_14, 'dtype')",{},{type_4: None},,softmax_3,type_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_33
call_method,type,"{softmax_3: None, getattr_33: None}","(softmax_3, getattr_33)",{},{transformer_h_3_attn_attn_dropout: None},,getattr_33,transformer_h_3_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_4
call_module,transformer.h.3.attn.attn_dropout,{type_4: None},"(type_4,)",{},{matmul_7: None},,type_4,matmul_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.3.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_3_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_3_attn_attn_dropout: None, permute_14: None}","(transformer_h_3_attn_attn_dropout, permute_14)",{},{permute_15: None},,transformer_h_3_attn_attn_dropout,permute_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_7
call_method,permute,{matmul_7: None},"(matmul_7, 0, 2, 1, 3)",{},{contiguous_3: None},,matmul_7,contiguous_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_15
call_method,contiguous,{permute_15: None},"(permute_15,)",{},"{size_56: None, view_42: None}",,permute_15,size_56,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_3
call_method,size,{contiguous_3: None},"(contiguous_3,)",{},{getitem_48: None},,contiguous_3,getitem_48,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_56
call_function,<built-in function getitem>,{size_56: None},"(size_56, slice(None, -2, None))",{},{add_44: None},,size_56,add_44,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_48
call_function,<built-in function add>,{getitem_48: None},"(getitem_48, (1280,))",{},{view_42: None},,getitem_48,view_42,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_44
call_method,view,"{contiguous_3: None, add_44: None}","(contiguous_3, add_44)",{},"{size_57: None, size_58: None, view_43: None}",,add_44,size_57,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_42
call_method,size,{view_42: None},"(view_42,)",{},{getitem_49: None},,view_42,getitem_49,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.3.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_57
call_function,<built-in function getitem>,{size_57: None},"(size_57, slice(None, -1, None))",{},{add_45: None},,size_57,add_45,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.3.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_49
call_function,<built-in function add>,{getitem_49: None},"(getitem_49, (1280,))",{},{view_44: None},,getitem_49,transformer_h_3_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.3.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_45
get_attr,transformer.h.3.attn.c_proj.bias,{},(),{},{addmm_13: None},,add_45,size_58,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.3.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_3_attn_c_proj_bias
call_method,size,{view_42: None},"(view_42, -1)",{},{view_43: None},,transformer_h_3_attn_c_proj_bias,view_43,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.3.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_58
call_method,view,"{view_42: None, size_58: None}","(view_42, -1, size_58)",{},{addmm_13: None},,size_58,transformer_h_3_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.3.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_43
get_attr,transformer.h.3.attn.c_proj.weight,{},(),{},{addmm_13: None},,view_43,addmm_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.3.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_3_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_3_attn_c_proj_bias: None, view_43: None, transformer_h_3_attn_c_proj_weight: None}","(transformer_h_3_attn_c_proj_bias, view_43, transformer_h_3_attn_c_proj_weight)",{},{view_44: None},,transformer_h_3_attn_c_proj_weight,view_44,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.3.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_13
call_method,view,"{addmm_13: None, add_45: None}","(addmm_13, add_45)",{},{transformer_h_3_attn_resid_dropout: None},,addmm_13,transformer_h_3_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.3.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_44
call_module,transformer.h.3.attn.resid_dropout,{view_44: None},"(view_44,)",{},{add_46: None},,view_44,add_46,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.3.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_3_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_3_attn_resid_dropout: None, add_39: None}","(transformer_h_3_attn_resid_dropout, add_39)",{},"{transformer_h_3_ln_2: None, add_51: None}",,transformer_h_3_attn_resid_dropout,transformer_h_3_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_46
call_module,transformer.h.3.ln_2,{add_46: None},"(add_46,)",{},"{size_59: None, size_60: None, view_45: None}",,add_46,size_59,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_3_ln_2
call_method,size,{transformer_h_3_ln_2: None},"(transformer_h_3_ln_2,)",{},{getitem_50: None},,transformer_h_3_ln_2,getitem_50,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_59
call_function,<built-in function getitem>,{size_59: None},"(size_59, slice(None, -1, None))",{},{add_47: None},,size_59,add_47,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_50
call_function,<built-in function add>,{getitem_50: None},"(getitem_50, (5120,))",{},{view_46: None},,getitem_50,transformer_h_3_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_47
get_attr,transformer.h.3.mlp.c_fc.bias,{},(),{},{addmm_14: None},,add_47,size_60,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_3_mlp_c_fc_bias
call_method,size,{transformer_h_3_ln_2: None},"(transformer_h_3_ln_2, -1)",{},{view_45: None},,transformer_h_3_mlp_c_fc_bias,view_45,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_60
call_method,view,"{transformer_h_3_ln_2: None, size_60: None}","(transformer_h_3_ln_2, -1, size_60)",{},{addmm_14: None},,size_60,transformer_h_3_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_45
get_attr,transformer.h.3.mlp.c_fc.weight,{},(),{},{addmm_14: None},,view_45,addmm_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_3_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_3_mlp_c_fc_bias: None, view_45: None, transformer_h_3_mlp_c_fc_weight: None}","(transformer_h_3_mlp_c_fc_bias, view_45, transformer_h_3_mlp_c_fc_weight)",{},{view_46: None},,transformer_h_3_mlp_c_fc_weight,view_46,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_14
call_method,view,"{addmm_14: None, add_47: None}","(addmm_14, add_47)",{},"{mul_12: None, pow_8: None, add_48: None}",,addmm_14,mul_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_46
call_function,<built-in function mul>,{view_46: None},"(0.5, view_46)",{},{mul_15: None},,view_46,pow_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_12
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_46: None},"(view_46, 3.0)",{},{mul_13: None},,mul_12,mul_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_8
call_function,<built-in function mul>,{pow_8: None},"(0.044715, pow_8)",{},{add_48: None},,pow_8,add_48,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_13
call_function,<built-in function add>,"{view_46: None, mul_13: None}","(view_46, mul_13)",{},{mul_14: None},,mul_13,mul_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_48
call_function,<built-in function mul>,{add_48: None},"(0.7978845608028654, add_48)",{},{tanh_3: None},,add_48,tanh_3,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_14
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_14: None},"(mul_14,)",{},{add_49: None},,mul_14,add_49,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_3
call_function,<built-in function add>,{tanh_3: None},"(1.0, tanh_3)",{},{mul_15: None},,tanh_3,mul_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_49
call_function,<built-in function mul>,"{mul_12: None, add_49: None}","(mul_12, add_49)",{},"{size_61: None, size_62: None, view_47: None}",,add_49,size_61,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_15
call_method,size,{mul_15: None},"(mul_15,)",{},{getitem_51: None},,mul_15,getitem_51,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_61
call_function,<built-in function getitem>,{size_61: None},"(size_61, slice(None, -1, None))",{},{add_50: None},,size_61,add_50,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_51
call_function,<built-in function add>,{getitem_51: None},"(getitem_51, (1280,))",{},{view_48: None},,getitem_51,transformer_h_3_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_50
get_attr,transformer.h.3.mlp.c_proj.bias,{},(),{},{addmm_15: None},,add_50,size_62,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_3_mlp_c_proj_bias
call_method,size,{mul_15: None},"(mul_15, -1)",{},{view_47: None},,transformer_h_3_mlp_c_proj_bias,view_47,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_62
call_method,view,"{mul_15: None, size_62: None}","(mul_15, -1, size_62)",{},{addmm_15: None},,size_62,transformer_h_3_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_47
get_attr,transformer.h.3.mlp.c_proj.weight,{},(),{},{addmm_15: None},,view_47,addmm_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_3_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_3_mlp_c_proj_bias: None, view_47: None, transformer_h_3_mlp_c_proj_weight: None}","(transformer_h_3_mlp_c_proj_bias, view_47, transformer_h_3_mlp_c_proj_weight)",{},{view_48: None},,transformer_h_3_mlp_c_proj_weight,view_48,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_15
call_method,view,"{addmm_15: None, add_50: None}","(addmm_15, add_50)",{},{transformer_h_3_mlp_dropout: None},,addmm_15,transformer_h_3_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_48
call_module,transformer.h.3.mlp.dropout,{view_48: None},"(view_48,)",{},{add_51: None},,view_48,add_51,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.3.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.3.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_3_mlp_dropout
call_function,<built-in function add>,"{add_46: None, transformer_h_3_mlp_dropout: None}","(add_46, transformer_h_3_mlp_dropout)",{},"{transformer_h_4_ln_1: None, add_58: None}",,transformer_h_3_mlp_dropout,transformer_h_4_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.3', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_51
call_module,transformer.h.4.ln_1,{add_51: None},"(add_51,)",{},"{size_63: None, size_64: None, view_49: None}",,add_51,size_63,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_4_ln_1
call_method,size,{transformer_h_4_ln_1: None},"(transformer_h_4_ln_1,)",{},{getitem_52: None},,transformer_h_4_ln_1,getitem_52,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.4.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_63
call_function,<built-in function getitem>,{size_63: None},"(size_63, slice(None, -1, None))",{},{add_52: None},,size_63,add_52,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.4.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_52
call_function,<built-in function add>,{getitem_52: None},"(getitem_52, (3840,))",{},{view_50: None},,getitem_52,transformer_h_4_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.4.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_52
get_attr,transformer.h.4.attn.c_attn.bias,{},(),{},{addmm_16: None},,add_52,size_64,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.4.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_4_attn_c_attn_bias
call_method,size,{transformer_h_4_ln_1: None},"(transformer_h_4_ln_1, -1)",{},{view_49: None},,transformer_h_4_attn_c_attn_bias,view_49,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.4.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_64
call_method,view,"{transformer_h_4_ln_1: None, size_64: None}","(transformer_h_4_ln_1, -1, size_64)",{},{addmm_16: None},,size_64,transformer_h_4_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.4.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_49
get_attr,transformer.h.4.attn.c_attn.weight,{},(),{},{addmm_16: None},,view_49,addmm_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.4.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_4_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_4_attn_c_attn_bias: None, view_49: None, transformer_h_4_attn_c_attn_weight: None}","(transformer_h_4_attn_c_attn_bias, view_49, transformer_h_4_attn_c_attn_weight)",{},{view_50: None},,transformer_h_4_attn_c_attn_weight,view_50,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.4.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_16
call_method,view,"{addmm_16: None, add_52: None}","(addmm_16, add_52)",{},{split_4: None},,addmm_16,split_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.4.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_50
call_method,split,{view_50: None},"(view_50, 1280)",{'dim': 2},"{getitem_53: None, getitem_54: None, getitem_55: None}",,view_50,getitem_53,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_4
call_function,<built-in function getitem>,{split_4: None},"(split_4, 0)",{},"{size_65: None, view_51: None}",,split_4,getitem_54,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_53
call_function,<built-in function getitem>,{split_4: None},"(split_4, 1)",{},"{size_66: None, view_52: None}",,getitem_53,getitem_55,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_54
call_function,<built-in function getitem>,{split_4: None},"(split_4, 2)",{},"{size_67: None, view_53: None}",,getitem_54,size_65,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_55
call_method,size,{getitem_53: None},"(getitem_53,)",{},{getitem_56: None},,getitem_55,getitem_56,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_65
call_function,<built-in function getitem>,{size_65: None},"(size_65, slice(None, -1, None))",{},{add_53: None},,size_65,add_53,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_56
call_function,<built-in function add>,{getitem_56: None},"(getitem_56, (20, 64))",{},{view_51: None},,getitem_56,view_51,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_53
call_method,view,"{getitem_53: None, add_53: None}","(getitem_53, add_53)",{},{permute_16: None},,add_53,permute_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_51
call_method,permute,{view_51: None},"(view_51, 0, 2, 1, 3)",{},"{matmul_8: None, size_69: None}",,view_51,size_66,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_16
call_method,size,{getitem_54: None},"(getitem_54,)",{},{getitem_57: None},,permute_16,getitem_57,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_66
call_function,<built-in function getitem>,{size_66: None},"(size_66, slice(None, -1, None))",{},{add_54: None},,size_66,add_54,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_57
call_function,<built-in function add>,{getitem_57: None},"(getitem_57, (20, 64))",{},{view_52: None},,getitem_57,view_52,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_54
call_method,view,"{getitem_54: None, add_54: None}","(getitem_54, add_54)",{},{permute_17: None},,add_54,permute_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_52
call_method,permute,{view_52: None},"(view_52, 0, 2, 1, 3)",{},"{transpose_4: None, size_70: None, output: None}",,view_52,size_67,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_17
call_method,size,{getitem_55: None},"(getitem_55,)",{},{getitem_58: None},,permute_17,getitem_58,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_67
call_function,<built-in function getitem>,{size_67: None},"(size_67, slice(None, -1, None))",{},{add_55: None},,size_67,add_55,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_58
call_function,<built-in function add>,{getitem_58: None},"(getitem_58, (20, 64))",{},{view_53: None},,getitem_58,view_53,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_55
call_method,view,"{getitem_55: None, add_55: None}","(getitem_55, add_55)",{},{permute_18: None},,add_55,permute_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_53
call_method,permute,{view_53: None},"(view_53, 0, 2, 1, 3)",{},"{size_68: None, getattr_41: None, matmul_9: None, output: None}",,view_53,transpose_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_18
call_method,transpose,{permute_17: None},"(permute_17, -1, -2)",{},{matmul_8: None},,permute_18,matmul_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_4
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_16: None, transpose_4: None}","(permute_16, transpose_4)",{},"{getattr_34: None, getattr_35: None, truediv_4: None}",,transpose_4,size_68,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_8
call_method,size,{permute_18: None},"(permute_18, -1)",{},{pow_9: None},,matmul_8,pow_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_68
call_function,<built-in function pow>,{size_68: None},"(size_68, 0.5)",{},{full_8: None},,size_68,getattr_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_9
call_function,<built-in function getattr>,{matmul_8: None},"(matmul_8, 'dtype')",{},{full_8: None},,pow_9,getattr_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_34
call_function,<built-in function getattr>,{matmul_8: None},"(matmul_8, 'device')",{},{full_8: None},,getattr_34,full_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_35
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_9: None, getattr_34: None, getattr_35: None}","([], pow_9)","{'dtype': getattr_34, 'device': getattr_35}",{truediv_4: None},,getattr_35,truediv_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_8
call_function,<built-in function truediv>,"{matmul_8: None, full_8: None}","(matmul_8, full_8)",{},"{getattr_36: None, getattr_38: None, getattr_39: None, getattr_40: None, to_4: None}",,full_8,size_69,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_4
call_method,size,{permute_16: None},"(permute_16, -2)",{},{sub_4: None},,truediv_4,size_70,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_69
call_method,size,{permute_17: None},"(permute_17, -2)",{},"{sub_4: None, getitem_59: None}",,size_69,transformer_h_4_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_70
get_attr,transformer.h.4.attn.bias,{},(),{},{getitem_59: None},,size_70,sub_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_4_attn_bias
call_function,<built-in function sub>,"{size_70: None, size_69: None}","(size_70, size_69)",{},{getitem_59: None},,transformer_h_4_attn_bias,getitem_59,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_4
call_function,<built-in function getitem>,"{transformer_h_4_attn_bias: None, sub_4: None, size_70: None}","(transformer_h_4_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_4, size_70, None), slice(None, size_70, None)))",{},{where_4: None},,sub_4,getattr_36,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_59
call_function,<built-in function getattr>,{truediv_4: None},"(truediv_4, 'dtype')",{},{finfo_4: None},,getitem_59,finfo_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_36
call_function,<class 'torch.finfo'>,{getattr_36: None},"(getattr_36,)",{},{getattr_37: None},,getattr_36,getattr_37,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_4
call_function,<built-in function getattr>,{finfo_4: None},"(finfo_4, 'min')",{},{full_9: None},,finfo_4,getattr_38,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_37
call_function,<built-in function getattr>,{truediv_4: None},"(truediv_4, 'dtype')",{},{full_9: None},,getattr_37,getattr_39,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_38
call_function,<built-in function getattr>,{truediv_4: None},"(truediv_4, 'device')",{},{full_9: None},,getattr_38,full_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_39
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_37: None, getattr_38: None, getattr_39: None}","([], getattr_37)","{'dtype': getattr_38, 'device': getattr_39}",{where_4: None},,getattr_39,getattr_40,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_9
call_function,<built-in function getattr>,{truediv_4: None},"(truediv_4, 'dtype')",{},{to_4: None},,full_9,to_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_40
call_method,to,"{truediv_4: None, getattr_40: None}","(truediv_4, getattr_40)",{},{where_4: None},,getattr_40,where_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_4
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_59: None, to_4: None, full_9: None}","(getitem_59, to_4, full_9)",{},{softmax_4: None},,to_4,softmax_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_4
call_function,<function softmax at 0x7f6fd5135ca0>,{where_4: None},"(where_4,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_5: None},,where_4,getattr_41,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_4
call_function,<built-in function getattr>,{permute_18: None},"(permute_18, 'dtype')",{},{type_5: None},,softmax_4,type_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_41
call_method,type,"{softmax_4: None, getattr_41: None}","(softmax_4, getattr_41)",{},{transformer_h_4_attn_attn_dropout: None},,getattr_41,transformer_h_4_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_5
call_module,transformer.h.4.attn.attn_dropout,{type_5: None},"(type_5,)",{},{matmul_9: None},,type_5,matmul_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.4.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_4_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_4_attn_attn_dropout: None, permute_18: None}","(transformer_h_4_attn_attn_dropout, permute_18)",{},{permute_19: None},,transformer_h_4_attn_attn_dropout,permute_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_9
call_method,permute,{matmul_9: None},"(matmul_9, 0, 2, 1, 3)",{},{contiguous_4: None},,matmul_9,contiguous_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_19
call_method,contiguous,{permute_19: None},"(permute_19,)",{},"{size_71: None, view_54: None}",,permute_19,size_71,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_4
call_method,size,{contiguous_4: None},"(contiguous_4,)",{},{getitem_60: None},,contiguous_4,getitem_60,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_71
call_function,<built-in function getitem>,{size_71: None},"(size_71, slice(None, -2, None))",{},{add_56: None},,size_71,add_56,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_60
call_function,<built-in function add>,{getitem_60: None},"(getitem_60, (1280,))",{},{view_54: None},,getitem_60,view_54,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_56
call_method,view,"{contiguous_4: None, add_56: None}","(contiguous_4, add_56)",{},"{size_72: None, size_73: None, view_55: None}",,add_56,size_72,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_54
call_method,size,{view_54: None},"(view_54,)",{},{getitem_61: None},,view_54,getitem_61,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.4.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_72
call_function,<built-in function getitem>,{size_72: None},"(size_72, slice(None, -1, None))",{},{add_57: None},,size_72,add_57,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.4.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_61
call_function,<built-in function add>,{getitem_61: None},"(getitem_61, (1280,))",{},{view_56: None},,getitem_61,transformer_h_4_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.4.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_57
get_attr,transformer.h.4.attn.c_proj.bias,{},(),{},{addmm_17: None},,add_57,size_73,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.4.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_4_attn_c_proj_bias
call_method,size,{view_54: None},"(view_54, -1)",{},{view_55: None},,transformer_h_4_attn_c_proj_bias,view_55,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.4.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_73
call_method,view,"{view_54: None, size_73: None}","(view_54, -1, size_73)",{},{addmm_17: None},,size_73,transformer_h_4_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.4.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_55
get_attr,transformer.h.4.attn.c_proj.weight,{},(),{},{addmm_17: None},,view_55,addmm_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.4.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_4_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_4_attn_c_proj_bias: None, view_55: None, transformer_h_4_attn_c_proj_weight: None}","(transformer_h_4_attn_c_proj_bias, view_55, transformer_h_4_attn_c_proj_weight)",{},{view_56: None},,transformer_h_4_attn_c_proj_weight,view_56,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.4.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_17
call_method,view,"{addmm_17: None, add_57: None}","(addmm_17, add_57)",{},{transformer_h_4_attn_resid_dropout: None},,addmm_17,transformer_h_4_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.4.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_56
call_module,transformer.h.4.attn.resid_dropout,{view_56: None},"(view_56,)",{},{add_58: None},,view_56,add_58,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.4.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_4_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_4_attn_resid_dropout: None, add_51: None}","(transformer_h_4_attn_resid_dropout, add_51)",{},"{transformer_h_4_ln_2: None, add_63: None}",,transformer_h_4_attn_resid_dropout,transformer_h_4_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_58
call_module,transformer.h.4.ln_2,{add_58: None},"(add_58,)",{},"{size_74: None, size_75: None, view_57: None}",,add_58,size_74,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_4_ln_2
call_method,size,{transformer_h_4_ln_2: None},"(transformer_h_4_ln_2,)",{},{getitem_62: None},,transformer_h_4_ln_2,getitem_62,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_74
call_function,<built-in function getitem>,{size_74: None},"(size_74, slice(None, -1, None))",{},{add_59: None},,size_74,add_59,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_62
call_function,<built-in function add>,{getitem_62: None},"(getitem_62, (5120,))",{},{view_58: None},,getitem_62,transformer_h_4_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_59
get_attr,transformer.h.4.mlp.c_fc.bias,{},(),{},{addmm_18: None},,add_59,size_75,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_4_mlp_c_fc_bias
call_method,size,{transformer_h_4_ln_2: None},"(transformer_h_4_ln_2, -1)",{},{view_57: None},,transformer_h_4_mlp_c_fc_bias,view_57,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_75
call_method,view,"{transformer_h_4_ln_2: None, size_75: None}","(transformer_h_4_ln_2, -1, size_75)",{},{addmm_18: None},,size_75,transformer_h_4_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_57
get_attr,transformer.h.4.mlp.c_fc.weight,{},(),{},{addmm_18: None},,view_57,addmm_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_4_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_4_mlp_c_fc_bias: None, view_57: None, transformer_h_4_mlp_c_fc_weight: None}","(transformer_h_4_mlp_c_fc_bias, view_57, transformer_h_4_mlp_c_fc_weight)",{},{view_58: None},,transformer_h_4_mlp_c_fc_weight,view_58,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_18
call_method,view,"{addmm_18: None, add_59: None}","(addmm_18, add_59)",{},"{mul_16: None, pow_10: None, add_60: None}",,addmm_18,mul_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_58
call_function,<built-in function mul>,{view_58: None},"(0.5, view_58)",{},{mul_19: None},,view_58,pow_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_16
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_58: None},"(view_58, 3.0)",{},{mul_17: None},,mul_16,mul_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_10
call_function,<built-in function mul>,{pow_10: None},"(0.044715, pow_10)",{},{add_60: None},,pow_10,add_60,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_17
call_function,<built-in function add>,"{view_58: None, mul_17: None}","(view_58, mul_17)",{},{mul_18: None},,mul_17,mul_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_60
call_function,<built-in function mul>,{add_60: None},"(0.7978845608028654, add_60)",{},{tanh_4: None},,add_60,tanh_4,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_18
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_18: None},"(mul_18,)",{},{add_61: None},,mul_18,add_61,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_4
call_function,<built-in function add>,{tanh_4: None},"(1.0, tanh_4)",{},{mul_19: None},,tanh_4,mul_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_61
call_function,<built-in function mul>,"{mul_16: None, add_61: None}","(mul_16, add_61)",{},"{size_76: None, size_77: None, view_59: None}",,add_61,size_76,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_19
call_method,size,{mul_19: None},"(mul_19,)",{},{getitem_63: None},,mul_19,getitem_63,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_76
call_function,<built-in function getitem>,{size_76: None},"(size_76, slice(None, -1, None))",{},{add_62: None},,size_76,add_62,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_63
call_function,<built-in function add>,{getitem_63: None},"(getitem_63, (1280,))",{},{view_60: None},,getitem_63,transformer_h_4_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_62
get_attr,transformer.h.4.mlp.c_proj.bias,{},(),{},{addmm_19: None},,add_62,size_77,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_4_mlp_c_proj_bias
call_method,size,{mul_19: None},"(mul_19, -1)",{},{view_59: None},,transformer_h_4_mlp_c_proj_bias,view_59,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_77
call_method,view,"{mul_19: None, size_77: None}","(mul_19, -1, size_77)",{},{addmm_19: None},,size_77,transformer_h_4_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_59
get_attr,transformer.h.4.mlp.c_proj.weight,{},(),{},{addmm_19: None},,view_59,addmm_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_4_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_4_mlp_c_proj_bias: None, view_59: None, transformer_h_4_mlp_c_proj_weight: None}","(transformer_h_4_mlp_c_proj_bias, view_59, transformer_h_4_mlp_c_proj_weight)",{},{view_60: None},,transformer_h_4_mlp_c_proj_weight,view_60,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_19
call_method,view,"{addmm_19: None, add_62: None}","(addmm_19, add_62)",{},{transformer_h_4_mlp_dropout: None},,addmm_19,transformer_h_4_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_60
call_module,transformer.h.4.mlp.dropout,{view_60: None},"(view_60,)",{},{add_63: None},,view_60,add_63,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.4.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.4.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_4_mlp_dropout
call_function,<built-in function add>,"{add_58: None, transformer_h_4_mlp_dropout: None}","(add_58, transformer_h_4_mlp_dropout)",{},"{transformer_h_5_ln_1: None, add_70: None}",,transformer_h_4_mlp_dropout,transformer_h_5_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.4', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_63
call_module,transformer.h.5.ln_1,{add_63: None},"(add_63,)",{},"{size_78: None, size_79: None, view_61: None}",,add_63,size_78,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_5_ln_1
call_method,size,{transformer_h_5_ln_1: None},"(transformer_h_5_ln_1,)",{},{getitem_64: None},,transformer_h_5_ln_1,getitem_64,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.5.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_78
call_function,<built-in function getitem>,{size_78: None},"(size_78, slice(None, -1, None))",{},{add_64: None},,size_78,add_64,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.5.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_64
call_function,<built-in function add>,{getitem_64: None},"(getitem_64, (3840,))",{},{view_62: None},,getitem_64,transformer_h_5_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.5.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_64
get_attr,transformer.h.5.attn.c_attn.bias,{},(),{},{addmm_20: None},,add_64,size_79,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.5.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_5_attn_c_attn_bias
call_method,size,{transformer_h_5_ln_1: None},"(transformer_h_5_ln_1, -1)",{},{view_61: None},,transformer_h_5_attn_c_attn_bias,view_61,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.5.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_79
call_method,view,"{transformer_h_5_ln_1: None, size_79: None}","(transformer_h_5_ln_1, -1, size_79)",{},{addmm_20: None},,size_79,transformer_h_5_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.5.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_61
get_attr,transformer.h.5.attn.c_attn.weight,{},(),{},{addmm_20: None},,view_61,addmm_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.5.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_5_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_5_attn_c_attn_bias: None, view_61: None, transformer_h_5_attn_c_attn_weight: None}","(transformer_h_5_attn_c_attn_bias, view_61, transformer_h_5_attn_c_attn_weight)",{},{view_62: None},,transformer_h_5_attn_c_attn_weight,view_62,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.5.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_20
call_method,view,"{addmm_20: None, add_64: None}","(addmm_20, add_64)",{},{split_5: None},,addmm_20,split_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.5.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_62
call_method,split,{view_62: None},"(view_62, 1280)",{'dim': 2},"{getitem_65: None, getitem_66: None, getitem_67: None}",,view_62,getitem_65,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_5
call_function,<built-in function getitem>,{split_5: None},"(split_5, 0)",{},"{size_80: None, view_63: None}",,split_5,getitem_66,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_65
call_function,<built-in function getitem>,{split_5: None},"(split_5, 1)",{},"{size_81: None, view_64: None}",,getitem_65,getitem_67,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_66
call_function,<built-in function getitem>,{split_5: None},"(split_5, 2)",{},"{size_82: None, view_65: None}",,getitem_66,size_80,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_67
call_method,size,{getitem_65: None},"(getitem_65,)",{},{getitem_68: None},,getitem_67,getitem_68,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_80
call_function,<built-in function getitem>,{size_80: None},"(size_80, slice(None, -1, None))",{},{add_65: None},,size_80,add_65,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_68
call_function,<built-in function add>,{getitem_68: None},"(getitem_68, (20, 64))",{},{view_63: None},,getitem_68,view_63,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_65
call_method,view,"{getitem_65: None, add_65: None}","(getitem_65, add_65)",{},{permute_20: None},,add_65,permute_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_63
call_method,permute,{view_63: None},"(view_63, 0, 2, 1, 3)",{},"{matmul_10: None, size_84: None}",,view_63,size_81,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_20
call_method,size,{getitem_66: None},"(getitem_66,)",{},{getitem_69: None},,permute_20,getitem_69,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_81
call_function,<built-in function getitem>,{size_81: None},"(size_81, slice(None, -1, None))",{},{add_66: None},,size_81,add_66,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_69
call_function,<built-in function add>,{getitem_69: None},"(getitem_69, (20, 64))",{},{view_64: None},,getitem_69,view_64,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_66
call_method,view,"{getitem_66: None, add_66: None}","(getitem_66, add_66)",{},{permute_21: None},,add_66,permute_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_64
call_method,permute,{view_64: None},"(view_64, 0, 2, 1, 3)",{},"{transpose_5: None, size_85: None, output: None}",,view_64,size_82,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_21
call_method,size,{getitem_67: None},"(getitem_67,)",{},{getitem_70: None},,permute_21,getitem_70,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_82
call_function,<built-in function getitem>,{size_82: None},"(size_82, slice(None, -1, None))",{},{add_67: None},,size_82,add_67,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_70
call_function,<built-in function add>,{getitem_70: None},"(getitem_70, (20, 64))",{},{view_65: None},,getitem_70,view_65,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_67
call_method,view,"{getitem_67: None, add_67: None}","(getitem_67, add_67)",{},{permute_22: None},,add_67,permute_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_65
call_method,permute,{view_65: None},"(view_65, 0, 2, 1, 3)",{},"{size_83: None, getattr_49: None, matmul_11: None, output: None}",,view_65,transpose_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_22
call_method,transpose,{permute_21: None},"(permute_21, -1, -2)",{},{matmul_10: None},,permute_22,matmul_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_5
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_20: None, transpose_5: None}","(permute_20, transpose_5)",{},"{getattr_42: None, getattr_43: None, truediv_5: None}",,transpose_5,size_83,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_10
call_method,size,{permute_22: None},"(permute_22, -1)",{},{pow_11: None},,matmul_10,pow_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_83
call_function,<built-in function pow>,{size_83: None},"(size_83, 0.5)",{},{full_10: None},,size_83,getattr_42,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_11
call_function,<built-in function getattr>,{matmul_10: None},"(matmul_10, 'dtype')",{},{full_10: None},,pow_11,getattr_43,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_42
call_function,<built-in function getattr>,{matmul_10: None},"(matmul_10, 'device')",{},{full_10: None},,getattr_42,full_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_43
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_11: None, getattr_42: None, getattr_43: None}","([], pow_11)","{'dtype': getattr_42, 'device': getattr_43}",{truediv_5: None},,getattr_43,truediv_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_10
call_function,<built-in function truediv>,"{matmul_10: None, full_10: None}","(matmul_10, full_10)",{},"{getattr_44: None, getattr_46: None, getattr_47: None, getattr_48: None, to_5: None}",,full_10,size_84,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_5
call_method,size,{permute_20: None},"(permute_20, -2)",{},{sub_5: None},,truediv_5,size_85,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_84
call_method,size,{permute_21: None},"(permute_21, -2)",{},"{sub_5: None, getitem_71: None}",,size_84,transformer_h_5_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_85
get_attr,transformer.h.5.attn.bias,{},(),{},{getitem_71: None},,size_85,sub_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_5_attn_bias
call_function,<built-in function sub>,"{size_85: None, size_84: None}","(size_85, size_84)",{},{getitem_71: None},,transformer_h_5_attn_bias,getitem_71,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_5
call_function,<built-in function getitem>,"{transformer_h_5_attn_bias: None, sub_5: None, size_85: None}","(transformer_h_5_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_5, size_85, None), slice(None, size_85, None)))",{},{where_5: None},,sub_5,getattr_44,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_71
call_function,<built-in function getattr>,{truediv_5: None},"(truediv_5, 'dtype')",{},{finfo_5: None},,getitem_71,finfo_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_44
call_function,<class 'torch.finfo'>,{getattr_44: None},"(getattr_44,)",{},{getattr_45: None},,getattr_44,getattr_45,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_5
call_function,<built-in function getattr>,{finfo_5: None},"(finfo_5, 'min')",{},{full_11: None},,finfo_5,getattr_46,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_45
call_function,<built-in function getattr>,{truediv_5: None},"(truediv_5, 'dtype')",{},{full_11: None},,getattr_45,getattr_47,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_46
call_function,<built-in function getattr>,{truediv_5: None},"(truediv_5, 'device')",{},{full_11: None},,getattr_46,full_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_47
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_45: None, getattr_46: None, getattr_47: None}","([], getattr_45)","{'dtype': getattr_46, 'device': getattr_47}",{where_5: None},,getattr_47,getattr_48,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_11
call_function,<built-in function getattr>,{truediv_5: None},"(truediv_5, 'dtype')",{},{to_5: None},,full_11,to_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_48
call_method,to,"{truediv_5: None, getattr_48: None}","(truediv_5, getattr_48)",{},{where_5: None},,getattr_48,where_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_5
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_71: None, to_5: None, full_11: None}","(getitem_71, to_5, full_11)",{},{softmax_5: None},,to_5,softmax_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_5
call_function,<function softmax at 0x7f6fd5135ca0>,{where_5: None},"(where_5,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_6: None},,where_5,getattr_49,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_5
call_function,<built-in function getattr>,{permute_22: None},"(permute_22, 'dtype')",{},{type_6: None},,softmax_5,type_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_49
call_method,type,"{softmax_5: None, getattr_49: None}","(softmax_5, getattr_49)",{},{transformer_h_5_attn_attn_dropout: None},,getattr_49,transformer_h_5_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_6
call_module,transformer.h.5.attn.attn_dropout,{type_6: None},"(type_6,)",{},{matmul_11: None},,type_6,matmul_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.5.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_5_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_5_attn_attn_dropout: None, permute_22: None}","(transformer_h_5_attn_attn_dropout, permute_22)",{},{permute_23: None},,transformer_h_5_attn_attn_dropout,permute_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_11
call_method,permute,{matmul_11: None},"(matmul_11, 0, 2, 1, 3)",{},{contiguous_5: None},,matmul_11,contiguous_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_23
call_method,contiguous,{permute_23: None},"(permute_23,)",{},"{size_86: None, view_66: None}",,permute_23,size_86,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_5
call_method,size,{contiguous_5: None},"(contiguous_5,)",{},{getitem_72: None},,contiguous_5,getitem_72,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_86
call_function,<built-in function getitem>,{size_86: None},"(size_86, slice(None, -2, None))",{},{add_68: None},,size_86,add_68,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_72
call_function,<built-in function add>,{getitem_72: None},"(getitem_72, (1280,))",{},{view_66: None},,getitem_72,view_66,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_68
call_method,view,"{contiguous_5: None, add_68: None}","(contiguous_5, add_68)",{},"{size_87: None, size_88: None, view_67: None}",,add_68,size_87,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_66
call_method,size,{view_66: None},"(view_66,)",{},{getitem_73: None},,view_66,getitem_73,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.5.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_87
call_function,<built-in function getitem>,{size_87: None},"(size_87, slice(None, -1, None))",{},{add_69: None},,size_87,add_69,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.5.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_73
call_function,<built-in function add>,{getitem_73: None},"(getitem_73, (1280,))",{},{view_68: None},,getitem_73,transformer_h_5_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.5.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_69
get_attr,transformer.h.5.attn.c_proj.bias,{},(),{},{addmm_21: None},,add_69,size_88,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.5.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_5_attn_c_proj_bias
call_method,size,{view_66: None},"(view_66, -1)",{},{view_67: None},,transformer_h_5_attn_c_proj_bias,view_67,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.5.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_88
call_method,view,"{view_66: None, size_88: None}","(view_66, -1, size_88)",{},{addmm_21: None},,size_88,transformer_h_5_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.5.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_67
get_attr,transformer.h.5.attn.c_proj.weight,{},(),{},{addmm_21: None},,view_67,addmm_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.5.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_5_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_5_attn_c_proj_bias: None, view_67: None, transformer_h_5_attn_c_proj_weight: None}","(transformer_h_5_attn_c_proj_bias, view_67, transformer_h_5_attn_c_proj_weight)",{},{view_68: None},,transformer_h_5_attn_c_proj_weight,view_68,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.5.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_21
call_method,view,"{addmm_21: None, add_69: None}","(addmm_21, add_69)",{},{transformer_h_5_attn_resid_dropout: None},,addmm_21,transformer_h_5_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.5.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_68
call_module,transformer.h.5.attn.resid_dropout,{view_68: None},"(view_68,)",{},{add_70: None},,view_68,add_70,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.5.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_5_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_5_attn_resid_dropout: None, add_63: None}","(transformer_h_5_attn_resid_dropout, add_63)",{},"{transformer_h_5_ln_2: None, add_75: None}",,transformer_h_5_attn_resid_dropout,transformer_h_5_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_70
call_module,transformer.h.5.ln_2,{add_70: None},"(add_70,)",{},"{size_89: None, size_90: None, view_69: None}",,add_70,size_89,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_5_ln_2
call_method,size,{transformer_h_5_ln_2: None},"(transformer_h_5_ln_2,)",{},{getitem_74: None},,transformer_h_5_ln_2,getitem_74,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_89
call_function,<built-in function getitem>,{size_89: None},"(size_89, slice(None, -1, None))",{},{add_71: None},,size_89,add_71,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_74
call_function,<built-in function add>,{getitem_74: None},"(getitem_74, (5120,))",{},{view_70: None},,getitem_74,transformer_h_5_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_71
get_attr,transformer.h.5.mlp.c_fc.bias,{},(),{},{addmm_22: None},,add_71,size_90,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_5_mlp_c_fc_bias
call_method,size,{transformer_h_5_ln_2: None},"(transformer_h_5_ln_2, -1)",{},{view_69: None},,transformer_h_5_mlp_c_fc_bias,view_69,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_90
call_method,view,"{transformer_h_5_ln_2: None, size_90: None}","(transformer_h_5_ln_2, -1, size_90)",{},{addmm_22: None},,size_90,transformer_h_5_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_69
get_attr,transformer.h.5.mlp.c_fc.weight,{},(),{},{addmm_22: None},,view_69,addmm_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_5_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_5_mlp_c_fc_bias: None, view_69: None, transformer_h_5_mlp_c_fc_weight: None}","(transformer_h_5_mlp_c_fc_bias, view_69, transformer_h_5_mlp_c_fc_weight)",{},{view_70: None},,transformer_h_5_mlp_c_fc_weight,view_70,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_22
call_method,view,"{addmm_22: None, add_71: None}","(addmm_22, add_71)",{},"{mul_20: None, pow_12: None, add_72: None}",,addmm_22,mul_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_70
call_function,<built-in function mul>,{view_70: None},"(0.5, view_70)",{},{mul_23: None},,view_70,pow_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_20
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_70: None},"(view_70, 3.0)",{},{mul_21: None},,mul_20,mul_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_12
call_function,<built-in function mul>,{pow_12: None},"(0.044715, pow_12)",{},{add_72: None},,pow_12,add_72,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_21
call_function,<built-in function add>,"{view_70: None, mul_21: None}","(view_70, mul_21)",{},{mul_22: None},,mul_21,mul_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_72
call_function,<built-in function mul>,{add_72: None},"(0.7978845608028654, add_72)",{},{tanh_5: None},,add_72,tanh_5,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_22
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_22: None},"(mul_22,)",{},{add_73: None},,mul_22,add_73,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_5
call_function,<built-in function add>,{tanh_5: None},"(1.0, tanh_5)",{},{mul_23: None},,tanh_5,mul_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_73
call_function,<built-in function mul>,"{mul_20: None, add_73: None}","(mul_20, add_73)",{},"{size_91: None, size_92: None, view_71: None}",,add_73,size_91,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_23
call_method,size,{mul_23: None},"(mul_23,)",{},{getitem_75: None},,mul_23,getitem_75,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_91
call_function,<built-in function getitem>,{size_91: None},"(size_91, slice(None, -1, None))",{},{add_74: None},,size_91,add_74,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_75
call_function,<built-in function add>,{getitem_75: None},"(getitem_75, (1280,))",{},{view_72: None},,getitem_75,transformer_h_5_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_74
get_attr,transformer.h.5.mlp.c_proj.bias,{},(),{},{addmm_23: None},,add_74,size_92,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_5_mlp_c_proj_bias
call_method,size,{mul_23: None},"(mul_23, -1)",{},{view_71: None},,transformer_h_5_mlp_c_proj_bias,view_71,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_92
call_method,view,"{mul_23: None, size_92: None}","(mul_23, -1, size_92)",{},{addmm_23: None},,size_92,transformer_h_5_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_71
get_attr,transformer.h.5.mlp.c_proj.weight,{},(),{},{addmm_23: None},,view_71,addmm_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_5_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_5_mlp_c_proj_bias: None, view_71: None, transformer_h_5_mlp_c_proj_weight: None}","(transformer_h_5_mlp_c_proj_bias, view_71, transformer_h_5_mlp_c_proj_weight)",{},{view_72: None},,transformer_h_5_mlp_c_proj_weight,view_72,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_23
call_method,view,"{addmm_23: None, add_74: None}","(addmm_23, add_74)",{},{transformer_h_5_mlp_dropout: None},,addmm_23,transformer_h_5_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_72
call_module,transformer.h.5.mlp.dropout,{view_72: None},"(view_72,)",{},{add_75: None},,view_72,add_75,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.5.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.5.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_5_mlp_dropout
call_function,<built-in function add>,"{add_70: None, transformer_h_5_mlp_dropout: None}","(add_70, transformer_h_5_mlp_dropout)",{},"{transformer_h_6_ln_1: None, add_82: None}",,transformer_h_5_mlp_dropout,transformer_h_6_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.5', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_75
call_module,transformer.h.6.ln_1,{add_75: None},"(add_75,)",{},"{size_93: None, size_94: None, view_73: None}",,add_75,size_93,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_6_ln_1
call_method,size,{transformer_h_6_ln_1: None},"(transformer_h_6_ln_1,)",{},{getitem_76: None},,transformer_h_6_ln_1,getitem_76,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.6.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_93
call_function,<built-in function getitem>,{size_93: None},"(size_93, slice(None, -1, None))",{},{add_76: None},,size_93,add_76,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.6.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_76
call_function,<built-in function add>,{getitem_76: None},"(getitem_76, (3840,))",{},{view_74: None},,getitem_76,transformer_h_6_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.6.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_76
get_attr,transformer.h.6.attn.c_attn.bias,{},(),{},{addmm_24: None},,add_76,size_94,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.6.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_6_attn_c_attn_bias
call_method,size,{transformer_h_6_ln_1: None},"(transformer_h_6_ln_1, -1)",{},{view_73: None},,transformer_h_6_attn_c_attn_bias,view_73,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.6.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_94
call_method,view,"{transformer_h_6_ln_1: None, size_94: None}","(transformer_h_6_ln_1, -1, size_94)",{},{addmm_24: None},,size_94,transformer_h_6_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.6.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_73
get_attr,transformer.h.6.attn.c_attn.weight,{},(),{},{addmm_24: None},,view_73,addmm_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.6.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_6_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_6_attn_c_attn_bias: None, view_73: None, transformer_h_6_attn_c_attn_weight: None}","(transformer_h_6_attn_c_attn_bias, view_73, transformer_h_6_attn_c_attn_weight)",{},{view_74: None},,transformer_h_6_attn_c_attn_weight,view_74,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.6.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_24
call_method,view,"{addmm_24: None, add_76: None}","(addmm_24, add_76)",{},{split_6: None},,addmm_24,split_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.6.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_74
call_method,split,{view_74: None},"(view_74, 1280)",{'dim': 2},"{getitem_77: None, getitem_78: None, getitem_79: None}",,view_74,getitem_77,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_6
call_function,<built-in function getitem>,{split_6: None},"(split_6, 0)",{},"{size_95: None, view_75: None}",,split_6,getitem_78,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_77
call_function,<built-in function getitem>,{split_6: None},"(split_6, 1)",{},"{size_96: None, view_76: None}",,getitem_77,getitem_79,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_78
call_function,<built-in function getitem>,{split_6: None},"(split_6, 2)",{},"{size_97: None, view_77: None}",,getitem_78,size_95,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_79
call_method,size,{getitem_77: None},"(getitem_77,)",{},{getitem_80: None},,getitem_79,getitem_80,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_95
call_function,<built-in function getitem>,{size_95: None},"(size_95, slice(None, -1, None))",{},{add_77: None},,size_95,add_77,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_80
call_function,<built-in function add>,{getitem_80: None},"(getitem_80, (20, 64))",{},{view_75: None},,getitem_80,view_75,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_77
call_method,view,"{getitem_77: None, add_77: None}","(getitem_77, add_77)",{},{permute_24: None},,add_77,permute_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_75
call_method,permute,{view_75: None},"(view_75, 0, 2, 1, 3)",{},"{matmul_12: None, size_99: None}",,view_75,size_96,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_24
call_method,size,{getitem_78: None},"(getitem_78,)",{},{getitem_81: None},,permute_24,getitem_81,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_96
call_function,<built-in function getitem>,{size_96: None},"(size_96, slice(None, -1, None))",{},{add_78: None},,size_96,add_78,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_81
call_function,<built-in function add>,{getitem_81: None},"(getitem_81, (20, 64))",{},{view_76: None},,getitem_81,view_76,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_78
call_method,view,"{getitem_78: None, add_78: None}","(getitem_78, add_78)",{},{permute_25: None},,add_78,permute_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_76
call_method,permute,{view_76: None},"(view_76, 0, 2, 1, 3)",{},"{transpose_6: None, size_100: None, output: None}",,view_76,size_97,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_25
call_method,size,{getitem_79: None},"(getitem_79,)",{},{getitem_82: None},,permute_25,getitem_82,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_97
call_function,<built-in function getitem>,{size_97: None},"(size_97, slice(None, -1, None))",{},{add_79: None},,size_97,add_79,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_82
call_function,<built-in function add>,{getitem_82: None},"(getitem_82, (20, 64))",{},{view_77: None},,getitem_82,view_77,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_79
call_method,view,"{getitem_79: None, add_79: None}","(getitem_79, add_79)",{},{permute_26: None},,add_79,permute_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_77
call_method,permute,{view_77: None},"(view_77, 0, 2, 1, 3)",{},"{size_98: None, getattr_57: None, matmul_13: None, output: None}",,view_77,transpose_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_26
call_method,transpose,{permute_25: None},"(permute_25, -1, -2)",{},{matmul_12: None},,permute_26,matmul_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_6
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_24: None, transpose_6: None}","(permute_24, transpose_6)",{},"{getattr_50: None, getattr_51: None, truediv_6: None}",,transpose_6,size_98,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_12
call_method,size,{permute_26: None},"(permute_26, -1)",{},{pow_13: None},,matmul_12,pow_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_98
call_function,<built-in function pow>,{size_98: None},"(size_98, 0.5)",{},{full_12: None},,size_98,getattr_50,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_13
call_function,<built-in function getattr>,{matmul_12: None},"(matmul_12, 'dtype')",{},{full_12: None},,pow_13,getattr_51,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_50
call_function,<built-in function getattr>,{matmul_12: None},"(matmul_12, 'device')",{},{full_12: None},,getattr_50,full_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_51
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_13: None, getattr_50: None, getattr_51: None}","([], pow_13)","{'dtype': getattr_50, 'device': getattr_51}",{truediv_6: None},,getattr_51,truediv_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_12
call_function,<built-in function truediv>,"{matmul_12: None, full_12: None}","(matmul_12, full_12)",{},"{getattr_52: None, getattr_54: None, getattr_55: None, getattr_56: None, to_6: None}",,full_12,size_99,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_6
call_method,size,{permute_24: None},"(permute_24, -2)",{},{sub_6: None},,truediv_6,size_100,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_99
call_method,size,{permute_25: None},"(permute_25, -2)",{},"{sub_6: None, getitem_83: None}",,size_99,transformer_h_6_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_100
get_attr,transformer.h.6.attn.bias,{},(),{},{getitem_83: None},,size_100,sub_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_6_attn_bias
call_function,<built-in function sub>,"{size_100: None, size_99: None}","(size_100, size_99)",{},{getitem_83: None},,transformer_h_6_attn_bias,getitem_83,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_6
call_function,<built-in function getitem>,"{transformer_h_6_attn_bias: None, sub_6: None, size_100: None}","(transformer_h_6_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_6, size_100, None), slice(None, size_100, None)))",{},{where_6: None},,sub_6,getattr_52,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_83
call_function,<built-in function getattr>,{truediv_6: None},"(truediv_6, 'dtype')",{},{finfo_6: None},,getitem_83,finfo_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_52
call_function,<class 'torch.finfo'>,{getattr_52: None},"(getattr_52,)",{},{getattr_53: None},,getattr_52,getattr_53,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_6
call_function,<built-in function getattr>,{finfo_6: None},"(finfo_6, 'min')",{},{full_13: None},,finfo_6,getattr_54,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_53
call_function,<built-in function getattr>,{truediv_6: None},"(truediv_6, 'dtype')",{},{full_13: None},,getattr_53,getattr_55,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_54
call_function,<built-in function getattr>,{truediv_6: None},"(truediv_6, 'device')",{},{full_13: None},,getattr_54,full_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_55
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_53: None, getattr_54: None, getattr_55: None}","([], getattr_53)","{'dtype': getattr_54, 'device': getattr_55}",{where_6: None},,getattr_55,getattr_56,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_13
call_function,<built-in function getattr>,{truediv_6: None},"(truediv_6, 'dtype')",{},{to_6: None},,full_13,to_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_56
call_method,to,"{truediv_6: None, getattr_56: None}","(truediv_6, getattr_56)",{},{where_6: None},,getattr_56,where_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_6
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_83: None, to_6: None, full_13: None}","(getitem_83, to_6, full_13)",{},{softmax_6: None},,to_6,softmax_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_6
call_function,<function softmax at 0x7f6fd5135ca0>,{where_6: None},"(where_6,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_7: None},,where_6,getattr_57,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_6
call_function,<built-in function getattr>,{permute_26: None},"(permute_26, 'dtype')",{},{type_7: None},,softmax_6,type_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_57
call_method,type,"{softmax_6: None, getattr_57: None}","(softmax_6, getattr_57)",{},{transformer_h_6_attn_attn_dropout: None},,getattr_57,transformer_h_6_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_7
call_module,transformer.h.6.attn.attn_dropout,{type_7: None},"(type_7,)",{},{matmul_13: None},,type_7,matmul_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.6.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_6_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_6_attn_attn_dropout: None, permute_26: None}","(transformer_h_6_attn_attn_dropout, permute_26)",{},{permute_27: None},,transformer_h_6_attn_attn_dropout,permute_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_13
call_method,permute,{matmul_13: None},"(matmul_13, 0, 2, 1, 3)",{},{contiguous_6: None},,matmul_13,contiguous_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_27
call_method,contiguous,{permute_27: None},"(permute_27,)",{},"{size_101: None, view_78: None}",,permute_27,size_101,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_6
call_method,size,{contiguous_6: None},"(contiguous_6,)",{},{getitem_84: None},,contiguous_6,getitem_84,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_101
call_function,<built-in function getitem>,{size_101: None},"(size_101, slice(None, -2, None))",{},{add_80: None},,size_101,add_80,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_84
call_function,<built-in function add>,{getitem_84: None},"(getitem_84, (1280,))",{},{view_78: None},,getitem_84,view_78,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_80
call_method,view,"{contiguous_6: None, add_80: None}","(contiguous_6, add_80)",{},"{size_102: None, size_103: None, view_79: None}",,add_80,size_102,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_78
call_method,size,{view_78: None},"(view_78,)",{},{getitem_85: None},,view_78,getitem_85,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.6.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_102
call_function,<built-in function getitem>,{size_102: None},"(size_102, slice(None, -1, None))",{},{add_81: None},,size_102,add_81,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.6.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_85
call_function,<built-in function add>,{getitem_85: None},"(getitem_85, (1280,))",{},{view_80: None},,getitem_85,transformer_h_6_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.6.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_81
get_attr,transformer.h.6.attn.c_proj.bias,{},(),{},{addmm_25: None},,add_81,size_103,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.6.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_6_attn_c_proj_bias
call_method,size,{view_78: None},"(view_78, -1)",{},{view_79: None},,transformer_h_6_attn_c_proj_bias,view_79,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.6.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_103
call_method,view,"{view_78: None, size_103: None}","(view_78, -1, size_103)",{},{addmm_25: None},,size_103,transformer_h_6_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.6.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_79
get_attr,transformer.h.6.attn.c_proj.weight,{},(),{},{addmm_25: None},,view_79,addmm_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.6.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_6_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_6_attn_c_proj_bias: None, view_79: None, transformer_h_6_attn_c_proj_weight: None}","(transformer_h_6_attn_c_proj_bias, view_79, transformer_h_6_attn_c_proj_weight)",{},{view_80: None},,transformer_h_6_attn_c_proj_weight,view_80,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.6.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_25
call_method,view,"{addmm_25: None, add_81: None}","(addmm_25, add_81)",{},{transformer_h_6_attn_resid_dropout: None},,addmm_25,transformer_h_6_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.6.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_80
call_module,transformer.h.6.attn.resid_dropout,{view_80: None},"(view_80,)",{},{add_82: None},,view_80,add_82,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.6.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_6_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_6_attn_resid_dropout: None, add_75: None}","(transformer_h_6_attn_resid_dropout, add_75)",{},"{transformer_h_6_ln_2: None, add_87: None}",,transformer_h_6_attn_resid_dropout,transformer_h_6_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_82
call_module,transformer.h.6.ln_2,{add_82: None},"(add_82,)",{},"{size_104: None, size_105: None, view_81: None}",,add_82,size_104,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_6_ln_2
call_method,size,{transformer_h_6_ln_2: None},"(transformer_h_6_ln_2,)",{},{getitem_86: None},,transformer_h_6_ln_2,getitem_86,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_104
call_function,<built-in function getitem>,{size_104: None},"(size_104, slice(None, -1, None))",{},{add_83: None},,size_104,add_83,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_86
call_function,<built-in function add>,{getitem_86: None},"(getitem_86, (5120,))",{},{view_82: None},,getitem_86,transformer_h_6_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_83
get_attr,transformer.h.6.mlp.c_fc.bias,{},(),{},{addmm_26: None},,add_83,size_105,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_6_mlp_c_fc_bias
call_method,size,{transformer_h_6_ln_2: None},"(transformer_h_6_ln_2, -1)",{},{view_81: None},,transformer_h_6_mlp_c_fc_bias,view_81,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_105
call_method,view,"{transformer_h_6_ln_2: None, size_105: None}","(transformer_h_6_ln_2, -1, size_105)",{},{addmm_26: None},,size_105,transformer_h_6_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_81
get_attr,transformer.h.6.mlp.c_fc.weight,{},(),{},{addmm_26: None},,view_81,addmm_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_6_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_6_mlp_c_fc_bias: None, view_81: None, transformer_h_6_mlp_c_fc_weight: None}","(transformer_h_6_mlp_c_fc_bias, view_81, transformer_h_6_mlp_c_fc_weight)",{},{view_82: None},,transformer_h_6_mlp_c_fc_weight,view_82,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_26
call_method,view,"{addmm_26: None, add_83: None}","(addmm_26, add_83)",{},"{mul_24: None, pow_14: None, add_84: None}",,addmm_26,mul_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_82
call_function,<built-in function mul>,{view_82: None},"(0.5, view_82)",{},{mul_27: None},,view_82,pow_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_24
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_82: None},"(view_82, 3.0)",{},{mul_25: None},,mul_24,mul_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_14
call_function,<built-in function mul>,{pow_14: None},"(0.044715, pow_14)",{},{add_84: None},,pow_14,add_84,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_25
call_function,<built-in function add>,"{view_82: None, mul_25: None}","(view_82, mul_25)",{},{mul_26: None},,mul_25,mul_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_84
call_function,<built-in function mul>,{add_84: None},"(0.7978845608028654, add_84)",{},{tanh_6: None},,add_84,tanh_6,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_26
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_26: None},"(mul_26,)",{},{add_85: None},,mul_26,add_85,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_6
call_function,<built-in function add>,{tanh_6: None},"(1.0, tanh_6)",{},{mul_27: None},,tanh_6,mul_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_85
call_function,<built-in function mul>,"{mul_24: None, add_85: None}","(mul_24, add_85)",{},"{size_106: None, size_107: None, view_83: None}",,add_85,size_106,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_27
call_method,size,{mul_27: None},"(mul_27,)",{},{getitem_87: None},,mul_27,getitem_87,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_106
call_function,<built-in function getitem>,{size_106: None},"(size_106, slice(None, -1, None))",{},{add_86: None},,size_106,add_86,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_87
call_function,<built-in function add>,{getitem_87: None},"(getitem_87, (1280,))",{},{view_84: None},,getitem_87,transformer_h_6_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_86
get_attr,transformer.h.6.mlp.c_proj.bias,{},(),{},{addmm_27: None},,add_86,size_107,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_6_mlp_c_proj_bias
call_method,size,{mul_27: None},"(mul_27, -1)",{},{view_83: None},,transformer_h_6_mlp_c_proj_bias,view_83,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_107
call_method,view,"{mul_27: None, size_107: None}","(mul_27, -1, size_107)",{},{addmm_27: None},,size_107,transformer_h_6_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_83
get_attr,transformer.h.6.mlp.c_proj.weight,{},(),{},{addmm_27: None},,view_83,addmm_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_6_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_6_mlp_c_proj_bias: None, view_83: None, transformer_h_6_mlp_c_proj_weight: None}","(transformer_h_6_mlp_c_proj_bias, view_83, transformer_h_6_mlp_c_proj_weight)",{},{view_84: None},,transformer_h_6_mlp_c_proj_weight,view_84,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_27
call_method,view,"{addmm_27: None, add_86: None}","(addmm_27, add_86)",{},{transformer_h_6_mlp_dropout: None},,addmm_27,transformer_h_6_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_84
call_module,transformer.h.6.mlp.dropout,{view_84: None},"(view_84,)",{},{add_87: None},,view_84,add_87,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.6.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.6.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_6_mlp_dropout
call_function,<built-in function add>,"{add_82: None, transformer_h_6_mlp_dropout: None}","(add_82, transformer_h_6_mlp_dropout)",{},"{transformer_h_7_ln_1: None, add_94: None}",,transformer_h_6_mlp_dropout,transformer_h_7_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.6', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_87
call_module,transformer.h.7.ln_1,{add_87: None},"(add_87,)",{},"{size_108: None, size_109: None, view_85: None}",,add_87,size_108,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_7_ln_1
call_method,size,{transformer_h_7_ln_1: None},"(transformer_h_7_ln_1,)",{},{getitem_88: None},,transformer_h_7_ln_1,getitem_88,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.7.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_108
call_function,<built-in function getitem>,{size_108: None},"(size_108, slice(None, -1, None))",{},{add_88: None},,size_108,add_88,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.7.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_88
call_function,<built-in function add>,{getitem_88: None},"(getitem_88, (3840,))",{},{view_86: None},,getitem_88,transformer_h_7_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.7.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_88
get_attr,transformer.h.7.attn.c_attn.bias,{},(),{},{addmm_28: None},,add_88,size_109,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.7.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_7_attn_c_attn_bias
call_method,size,{transformer_h_7_ln_1: None},"(transformer_h_7_ln_1, -1)",{},{view_85: None},,transformer_h_7_attn_c_attn_bias,view_85,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.7.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_109
call_method,view,"{transformer_h_7_ln_1: None, size_109: None}","(transformer_h_7_ln_1, -1, size_109)",{},{addmm_28: None},,size_109,transformer_h_7_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.7.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_85
get_attr,transformer.h.7.attn.c_attn.weight,{},(),{},{addmm_28: None},,view_85,addmm_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.7.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_7_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_7_attn_c_attn_bias: None, view_85: None, transformer_h_7_attn_c_attn_weight: None}","(transformer_h_7_attn_c_attn_bias, view_85, transformer_h_7_attn_c_attn_weight)",{},{view_86: None},,transformer_h_7_attn_c_attn_weight,view_86,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.7.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_28
call_method,view,"{addmm_28: None, add_88: None}","(addmm_28, add_88)",{},{split_7: None},,addmm_28,split_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.7.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_86
call_method,split,{view_86: None},"(view_86, 1280)",{'dim': 2},"{getitem_89: None, getitem_90: None, getitem_91: None}",,view_86,getitem_89,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_7
call_function,<built-in function getitem>,{split_7: None},"(split_7, 0)",{},"{size_110: None, view_87: None}",,split_7,getitem_90,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_89
call_function,<built-in function getitem>,{split_7: None},"(split_7, 1)",{},"{size_111: None, view_88: None}",,getitem_89,getitem_91,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_90
call_function,<built-in function getitem>,{split_7: None},"(split_7, 2)",{},"{size_112: None, view_89: None}",,getitem_90,size_110,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_91
call_method,size,{getitem_89: None},"(getitem_89,)",{},{getitem_92: None},,getitem_91,getitem_92,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_110
call_function,<built-in function getitem>,{size_110: None},"(size_110, slice(None, -1, None))",{},{add_89: None},,size_110,add_89,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_92
call_function,<built-in function add>,{getitem_92: None},"(getitem_92, (20, 64))",{},{view_87: None},,getitem_92,view_87,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_89
call_method,view,"{getitem_89: None, add_89: None}","(getitem_89, add_89)",{},{permute_28: None},,add_89,permute_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_87
call_method,permute,{view_87: None},"(view_87, 0, 2, 1, 3)",{},"{matmul_14: None, size_114: None}",,view_87,size_111,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_28
call_method,size,{getitem_90: None},"(getitem_90,)",{},{getitem_93: None},,permute_28,getitem_93,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_111
call_function,<built-in function getitem>,{size_111: None},"(size_111, slice(None, -1, None))",{},{add_90: None},,size_111,add_90,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_93
call_function,<built-in function add>,{getitem_93: None},"(getitem_93, (20, 64))",{},{view_88: None},,getitem_93,view_88,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_90
call_method,view,"{getitem_90: None, add_90: None}","(getitem_90, add_90)",{},{permute_29: None},,add_90,permute_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_88
call_method,permute,{view_88: None},"(view_88, 0, 2, 1, 3)",{},"{transpose_7: None, size_115: None, output: None}",,view_88,size_112,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_29
call_method,size,{getitem_91: None},"(getitem_91,)",{},{getitem_94: None},,permute_29,getitem_94,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_112
call_function,<built-in function getitem>,{size_112: None},"(size_112, slice(None, -1, None))",{},{add_91: None},,size_112,add_91,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_94
call_function,<built-in function add>,{getitem_94: None},"(getitem_94, (20, 64))",{},{view_89: None},,getitem_94,view_89,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_91
call_method,view,"{getitem_91: None, add_91: None}","(getitem_91, add_91)",{},{permute_30: None},,add_91,permute_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_89
call_method,permute,{view_89: None},"(view_89, 0, 2, 1, 3)",{},"{size_113: None, getattr_65: None, matmul_15: None, output: None}",,view_89,transpose_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_30
call_method,transpose,{permute_29: None},"(permute_29, -1, -2)",{},{matmul_14: None},,permute_30,matmul_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_7
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_28: None, transpose_7: None}","(permute_28, transpose_7)",{},"{getattr_58: None, getattr_59: None, truediv_7: None}",,transpose_7,size_113,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_14
call_method,size,{permute_30: None},"(permute_30, -1)",{},{pow_15: None},,matmul_14,pow_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_113
call_function,<built-in function pow>,{size_113: None},"(size_113, 0.5)",{},{full_14: None},,size_113,getattr_58,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_15
call_function,<built-in function getattr>,{matmul_14: None},"(matmul_14, 'dtype')",{},{full_14: None},,pow_15,getattr_59,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_58
call_function,<built-in function getattr>,{matmul_14: None},"(matmul_14, 'device')",{},{full_14: None},,getattr_58,full_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_59
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_15: None, getattr_58: None, getattr_59: None}","([], pow_15)","{'dtype': getattr_58, 'device': getattr_59}",{truediv_7: None},,getattr_59,truediv_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_14
call_function,<built-in function truediv>,"{matmul_14: None, full_14: None}","(matmul_14, full_14)",{},"{getattr_60: None, getattr_62: None, getattr_63: None, getattr_64: None, to_7: None}",,full_14,size_114,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_7
call_method,size,{permute_28: None},"(permute_28, -2)",{},{sub_7: None},,truediv_7,size_115,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_114
call_method,size,{permute_29: None},"(permute_29, -2)",{},"{sub_7: None, getitem_95: None}",,size_114,transformer_h_7_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_115
get_attr,transformer.h.7.attn.bias,{},(),{},{getitem_95: None},,size_115,sub_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_7_attn_bias
call_function,<built-in function sub>,"{size_115: None, size_114: None}","(size_115, size_114)",{},{getitem_95: None},,transformer_h_7_attn_bias,getitem_95,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_7
call_function,<built-in function getitem>,"{transformer_h_7_attn_bias: None, sub_7: None, size_115: None}","(transformer_h_7_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_7, size_115, None), slice(None, size_115, None)))",{},{where_7: None},,sub_7,getattr_60,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_95
call_function,<built-in function getattr>,{truediv_7: None},"(truediv_7, 'dtype')",{},{finfo_7: None},,getitem_95,finfo_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_60
call_function,<class 'torch.finfo'>,{getattr_60: None},"(getattr_60,)",{},{getattr_61: None},,getattr_60,getattr_61,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_7
call_function,<built-in function getattr>,{finfo_7: None},"(finfo_7, 'min')",{},{full_15: None},,finfo_7,getattr_62,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_61
call_function,<built-in function getattr>,{truediv_7: None},"(truediv_7, 'dtype')",{},{full_15: None},,getattr_61,getattr_63,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_62
call_function,<built-in function getattr>,{truediv_7: None},"(truediv_7, 'device')",{},{full_15: None},,getattr_62,full_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_63
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_61: None, getattr_62: None, getattr_63: None}","([], getattr_61)","{'dtype': getattr_62, 'device': getattr_63}",{where_7: None},,getattr_63,getattr_64,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_15
call_function,<built-in function getattr>,{truediv_7: None},"(truediv_7, 'dtype')",{},{to_7: None},,full_15,to_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_64
call_method,to,"{truediv_7: None, getattr_64: None}","(truediv_7, getattr_64)",{},{where_7: None},,getattr_64,where_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_7
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_95: None, to_7: None, full_15: None}","(getitem_95, to_7, full_15)",{},{softmax_7: None},,to_7,softmax_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_7
call_function,<function softmax at 0x7f6fd5135ca0>,{where_7: None},"(where_7,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_8: None},,where_7,getattr_65,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_7
call_function,<built-in function getattr>,{permute_30: None},"(permute_30, 'dtype')",{},{type_8: None},,softmax_7,type_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_65
call_method,type,"{softmax_7: None, getattr_65: None}","(softmax_7, getattr_65)",{},{transformer_h_7_attn_attn_dropout: None},,getattr_65,transformer_h_7_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_8
call_module,transformer.h.7.attn.attn_dropout,{type_8: None},"(type_8,)",{},{matmul_15: None},,type_8,matmul_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.7.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_7_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_7_attn_attn_dropout: None, permute_30: None}","(transformer_h_7_attn_attn_dropout, permute_30)",{},{permute_31: None},,transformer_h_7_attn_attn_dropout,permute_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_15
call_method,permute,{matmul_15: None},"(matmul_15, 0, 2, 1, 3)",{},{contiguous_7: None},,matmul_15,contiguous_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_31
call_method,contiguous,{permute_31: None},"(permute_31,)",{},"{size_116: None, view_90: None}",,permute_31,size_116,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_7
call_method,size,{contiguous_7: None},"(contiguous_7,)",{},{getitem_96: None},,contiguous_7,getitem_96,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_116
call_function,<built-in function getitem>,{size_116: None},"(size_116, slice(None, -2, None))",{},{add_92: None},,size_116,add_92,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_96
call_function,<built-in function add>,{getitem_96: None},"(getitem_96, (1280,))",{},{view_90: None},,getitem_96,view_90,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_92
call_method,view,"{contiguous_7: None, add_92: None}","(contiguous_7, add_92)",{},"{size_117: None, size_118: None, view_91: None}",,add_92,size_117,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_90
call_method,size,{view_90: None},"(view_90,)",{},{getitem_97: None},,view_90,getitem_97,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.7.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_117
call_function,<built-in function getitem>,{size_117: None},"(size_117, slice(None, -1, None))",{},{add_93: None},,size_117,add_93,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.7.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_97
call_function,<built-in function add>,{getitem_97: None},"(getitem_97, (1280,))",{},{view_92: None},,getitem_97,transformer_h_7_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.7.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_93
get_attr,transformer.h.7.attn.c_proj.bias,{},(),{},{addmm_29: None},,add_93,size_118,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.7.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_7_attn_c_proj_bias
call_method,size,{view_90: None},"(view_90, -1)",{},{view_91: None},,transformer_h_7_attn_c_proj_bias,view_91,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.7.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_118
call_method,view,"{view_90: None, size_118: None}","(view_90, -1, size_118)",{},{addmm_29: None},,size_118,transformer_h_7_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.7.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_91
get_attr,transformer.h.7.attn.c_proj.weight,{},(),{},{addmm_29: None},,view_91,addmm_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.7.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_7_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_7_attn_c_proj_bias: None, view_91: None, transformer_h_7_attn_c_proj_weight: None}","(transformer_h_7_attn_c_proj_bias, view_91, transformer_h_7_attn_c_proj_weight)",{},{view_92: None},,transformer_h_7_attn_c_proj_weight,view_92,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.7.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_29
call_method,view,"{addmm_29: None, add_93: None}","(addmm_29, add_93)",{},{transformer_h_7_attn_resid_dropout: None},,addmm_29,transformer_h_7_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.7.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_92
call_module,transformer.h.7.attn.resid_dropout,{view_92: None},"(view_92,)",{},{add_94: None},,view_92,add_94,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.7.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_7_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_7_attn_resid_dropout: None, add_87: None}","(transformer_h_7_attn_resid_dropout, add_87)",{},"{transformer_h_7_ln_2: None, add_99: None}",,transformer_h_7_attn_resid_dropout,transformer_h_7_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_94
call_module,transformer.h.7.ln_2,{add_94: None},"(add_94,)",{},"{size_119: None, size_120: None, view_93: None}",,add_94,size_119,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_7_ln_2
call_method,size,{transformer_h_7_ln_2: None},"(transformer_h_7_ln_2,)",{},{getitem_98: None},,transformer_h_7_ln_2,getitem_98,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_119
call_function,<built-in function getitem>,{size_119: None},"(size_119, slice(None, -1, None))",{},{add_95: None},,size_119,add_95,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_98
call_function,<built-in function add>,{getitem_98: None},"(getitem_98, (5120,))",{},{view_94: None},,getitem_98,transformer_h_7_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_95
get_attr,transformer.h.7.mlp.c_fc.bias,{},(),{},{addmm_30: None},,add_95,size_120,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_7_mlp_c_fc_bias
call_method,size,{transformer_h_7_ln_2: None},"(transformer_h_7_ln_2, -1)",{},{view_93: None},,transformer_h_7_mlp_c_fc_bias,view_93,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_120
call_method,view,"{transformer_h_7_ln_2: None, size_120: None}","(transformer_h_7_ln_2, -1, size_120)",{},{addmm_30: None},,size_120,transformer_h_7_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_93
get_attr,transformer.h.7.mlp.c_fc.weight,{},(),{},{addmm_30: None},,view_93,addmm_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_7_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_7_mlp_c_fc_bias: None, view_93: None, transformer_h_7_mlp_c_fc_weight: None}","(transformer_h_7_mlp_c_fc_bias, view_93, transformer_h_7_mlp_c_fc_weight)",{},{view_94: None},,transformer_h_7_mlp_c_fc_weight,view_94,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_30
call_method,view,"{addmm_30: None, add_95: None}","(addmm_30, add_95)",{},"{mul_28: None, pow_16: None, add_96: None}",,addmm_30,mul_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_94
call_function,<built-in function mul>,{view_94: None},"(0.5, view_94)",{},{mul_31: None},,view_94,pow_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_28
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_94: None},"(view_94, 3.0)",{},{mul_29: None},,mul_28,mul_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_16
call_function,<built-in function mul>,{pow_16: None},"(0.044715, pow_16)",{},{add_96: None},,pow_16,add_96,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_29
call_function,<built-in function add>,"{view_94: None, mul_29: None}","(view_94, mul_29)",{},{mul_30: None},,mul_29,mul_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_96
call_function,<built-in function mul>,{add_96: None},"(0.7978845608028654, add_96)",{},{tanh_7: None},,add_96,tanh_7,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_30
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_30: None},"(mul_30,)",{},{add_97: None},,mul_30,add_97,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_7
call_function,<built-in function add>,{tanh_7: None},"(1.0, tanh_7)",{},{mul_31: None},,tanh_7,mul_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_97
call_function,<built-in function mul>,"{mul_28: None, add_97: None}","(mul_28, add_97)",{},"{size_121: None, size_122: None, view_95: None}",,add_97,size_121,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_31
call_method,size,{mul_31: None},"(mul_31,)",{},{getitem_99: None},,mul_31,getitem_99,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_121
call_function,<built-in function getitem>,{size_121: None},"(size_121, slice(None, -1, None))",{},{add_98: None},,size_121,add_98,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_99
call_function,<built-in function add>,{getitem_99: None},"(getitem_99, (1280,))",{},{view_96: None},,getitem_99,transformer_h_7_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_98
get_attr,transformer.h.7.mlp.c_proj.bias,{},(),{},{addmm_31: None},,add_98,size_122,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_7_mlp_c_proj_bias
call_method,size,{mul_31: None},"(mul_31, -1)",{},{view_95: None},,transformer_h_7_mlp_c_proj_bias,view_95,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_122
call_method,view,"{mul_31: None, size_122: None}","(mul_31, -1, size_122)",{},{addmm_31: None},,size_122,transformer_h_7_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_95
get_attr,transformer.h.7.mlp.c_proj.weight,{},(),{},{addmm_31: None},,view_95,addmm_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_7_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_7_mlp_c_proj_bias: None, view_95: None, transformer_h_7_mlp_c_proj_weight: None}","(transformer_h_7_mlp_c_proj_bias, view_95, transformer_h_7_mlp_c_proj_weight)",{},{view_96: None},,transformer_h_7_mlp_c_proj_weight,view_96,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_31
call_method,view,"{addmm_31: None, add_98: None}","(addmm_31, add_98)",{},{transformer_h_7_mlp_dropout: None},,addmm_31,transformer_h_7_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_96
call_module,transformer.h.7.mlp.dropout,{view_96: None},"(view_96,)",{},{add_99: None},,view_96,add_99,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.7.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.7.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_7_mlp_dropout
call_function,<built-in function add>,"{add_94: None, transformer_h_7_mlp_dropout: None}","(add_94, transformer_h_7_mlp_dropout)",{},"{transformer_h_8_ln_1: None, add_106: None}",,transformer_h_7_mlp_dropout,transformer_h_8_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.7', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_99
call_module,transformer.h.8.ln_1,{add_99: None},"(add_99,)",{},"{size_123: None, size_124: None, view_97: None}",,add_99,size_123,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_8_ln_1
call_method,size,{transformer_h_8_ln_1: None},"(transformer_h_8_ln_1,)",{},{getitem_100: None},,transformer_h_8_ln_1,getitem_100,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.8.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_123
call_function,<built-in function getitem>,{size_123: None},"(size_123, slice(None, -1, None))",{},{add_100: None},,size_123,add_100,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.8.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_100
call_function,<built-in function add>,{getitem_100: None},"(getitem_100, (3840,))",{},{view_98: None},,getitem_100,transformer_h_8_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.8.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_100
get_attr,transformer.h.8.attn.c_attn.bias,{},(),{},{addmm_32: None},,add_100,size_124,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.8.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_8_attn_c_attn_bias
call_method,size,{transformer_h_8_ln_1: None},"(transformer_h_8_ln_1, -1)",{},{view_97: None},,transformer_h_8_attn_c_attn_bias,view_97,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.8.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_124
call_method,view,"{transformer_h_8_ln_1: None, size_124: None}","(transformer_h_8_ln_1, -1, size_124)",{},{addmm_32: None},,size_124,transformer_h_8_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.8.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_97
get_attr,transformer.h.8.attn.c_attn.weight,{},(),{},{addmm_32: None},,view_97,addmm_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.8.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_8_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_8_attn_c_attn_bias: None, view_97: None, transformer_h_8_attn_c_attn_weight: None}","(transformer_h_8_attn_c_attn_bias, view_97, transformer_h_8_attn_c_attn_weight)",{},{view_98: None},,transformer_h_8_attn_c_attn_weight,view_98,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.8.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_32
call_method,view,"{addmm_32: None, add_100: None}","(addmm_32, add_100)",{},{split_8: None},,addmm_32,split_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.8.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_98
call_method,split,{view_98: None},"(view_98, 1280)",{'dim': 2},"{getitem_101: None, getitem_102: None, getitem_103: None}",,view_98,getitem_101,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_8
call_function,<built-in function getitem>,{split_8: None},"(split_8, 0)",{},"{size_125: None, view_99: None}",,split_8,getitem_102,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_101
call_function,<built-in function getitem>,{split_8: None},"(split_8, 1)",{},"{size_126: None, view_100: None}",,getitem_101,getitem_103,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_102
call_function,<built-in function getitem>,{split_8: None},"(split_8, 2)",{},"{size_127: None, view_101: None}",,getitem_102,size_125,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_103
call_method,size,{getitem_101: None},"(getitem_101,)",{},{getitem_104: None},,getitem_103,getitem_104,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_125
call_function,<built-in function getitem>,{size_125: None},"(size_125, slice(None, -1, None))",{},{add_101: None},,size_125,add_101,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_104
call_function,<built-in function add>,{getitem_104: None},"(getitem_104, (20, 64))",{},{view_99: None},,getitem_104,view_99,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_101
call_method,view,"{getitem_101: None, add_101: None}","(getitem_101, add_101)",{},{permute_32: None},,add_101,permute_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_99
call_method,permute,{view_99: None},"(view_99, 0, 2, 1, 3)",{},"{matmul_16: None, size_129: None}",,view_99,size_126,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_32
call_method,size,{getitem_102: None},"(getitem_102,)",{},{getitem_105: None},,permute_32,getitem_105,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_126
call_function,<built-in function getitem>,{size_126: None},"(size_126, slice(None, -1, None))",{},{add_102: None},,size_126,add_102,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_105
call_function,<built-in function add>,{getitem_105: None},"(getitem_105, (20, 64))",{},{view_100: None},,getitem_105,view_100,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_102
call_method,view,"{getitem_102: None, add_102: None}","(getitem_102, add_102)",{},{permute_33: None},,add_102,permute_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_100
call_method,permute,{view_100: None},"(view_100, 0, 2, 1, 3)",{},"{transpose_8: None, size_130: None, output: None}",,view_100,size_127,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_33
call_method,size,{getitem_103: None},"(getitem_103,)",{},{getitem_106: None},,permute_33,getitem_106,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_127
call_function,<built-in function getitem>,{size_127: None},"(size_127, slice(None, -1, None))",{},{add_103: None},,size_127,add_103,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_106
call_function,<built-in function add>,{getitem_106: None},"(getitem_106, (20, 64))",{},{view_101: None},,getitem_106,view_101,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_103
call_method,view,"{getitem_103: None, add_103: None}","(getitem_103, add_103)",{},{permute_34: None},,add_103,permute_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_101
call_method,permute,{view_101: None},"(view_101, 0, 2, 1, 3)",{},"{size_128: None, getattr_73: None, matmul_17: None, output: None}",,view_101,transpose_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_34
call_method,transpose,{permute_33: None},"(permute_33, -1, -2)",{},{matmul_16: None},,permute_34,matmul_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_8
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_32: None, transpose_8: None}","(permute_32, transpose_8)",{},"{getattr_66: None, getattr_67: None, truediv_8: None}",,transpose_8,size_128,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_16
call_method,size,{permute_34: None},"(permute_34, -1)",{},{pow_17: None},,matmul_16,pow_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_128
call_function,<built-in function pow>,{size_128: None},"(size_128, 0.5)",{},{full_16: None},,size_128,getattr_66,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_17
call_function,<built-in function getattr>,{matmul_16: None},"(matmul_16, 'dtype')",{},{full_16: None},,pow_17,getattr_67,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_66
call_function,<built-in function getattr>,{matmul_16: None},"(matmul_16, 'device')",{},{full_16: None},,getattr_66,full_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_67
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_17: None, getattr_66: None, getattr_67: None}","([], pow_17)","{'dtype': getattr_66, 'device': getattr_67}",{truediv_8: None},,getattr_67,truediv_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_16
call_function,<built-in function truediv>,"{matmul_16: None, full_16: None}","(matmul_16, full_16)",{},"{getattr_68: None, getattr_70: None, getattr_71: None, getattr_72: None, to_8: None}",,full_16,size_129,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_8
call_method,size,{permute_32: None},"(permute_32, -2)",{},{sub_8: None},,truediv_8,size_130,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_129
call_method,size,{permute_33: None},"(permute_33, -2)",{},"{sub_8: None, getitem_107: None}",,size_129,transformer_h_8_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_130
get_attr,transformer.h.8.attn.bias,{},(),{},{getitem_107: None},,size_130,sub_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_8_attn_bias
call_function,<built-in function sub>,"{size_130: None, size_129: None}","(size_130, size_129)",{},{getitem_107: None},,transformer_h_8_attn_bias,getitem_107,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_8
call_function,<built-in function getitem>,"{transformer_h_8_attn_bias: None, sub_8: None, size_130: None}","(transformer_h_8_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_8, size_130, None), slice(None, size_130, None)))",{},{where_8: None},,sub_8,getattr_68,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_107
call_function,<built-in function getattr>,{truediv_8: None},"(truediv_8, 'dtype')",{},{finfo_8: None},,getitem_107,finfo_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_68
call_function,<class 'torch.finfo'>,{getattr_68: None},"(getattr_68,)",{},{getattr_69: None},,getattr_68,getattr_69,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_8
call_function,<built-in function getattr>,{finfo_8: None},"(finfo_8, 'min')",{},{full_17: None},,finfo_8,getattr_70,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_69
call_function,<built-in function getattr>,{truediv_8: None},"(truediv_8, 'dtype')",{},{full_17: None},,getattr_69,getattr_71,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_70
call_function,<built-in function getattr>,{truediv_8: None},"(truediv_8, 'device')",{},{full_17: None},,getattr_70,full_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_71
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_69: None, getattr_70: None, getattr_71: None}","([], getattr_69)","{'dtype': getattr_70, 'device': getattr_71}",{where_8: None},,getattr_71,getattr_72,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_17
call_function,<built-in function getattr>,{truediv_8: None},"(truediv_8, 'dtype')",{},{to_8: None},,full_17,to_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_72
call_method,to,"{truediv_8: None, getattr_72: None}","(truediv_8, getattr_72)",{},{where_8: None},,getattr_72,where_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_8
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_107: None, to_8: None, full_17: None}","(getitem_107, to_8, full_17)",{},{softmax_8: None},,to_8,softmax_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_8
call_function,<function softmax at 0x7f6fd5135ca0>,{where_8: None},"(where_8,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_9: None},,where_8,getattr_73,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_8
call_function,<built-in function getattr>,{permute_34: None},"(permute_34, 'dtype')",{},{type_9: None},,softmax_8,type_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_73
call_method,type,"{softmax_8: None, getattr_73: None}","(softmax_8, getattr_73)",{},{transformer_h_8_attn_attn_dropout: None},,getattr_73,transformer_h_8_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_9
call_module,transformer.h.8.attn.attn_dropout,{type_9: None},"(type_9,)",{},{matmul_17: None},,type_9,matmul_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.8.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_8_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_8_attn_attn_dropout: None, permute_34: None}","(transformer_h_8_attn_attn_dropout, permute_34)",{},{permute_35: None},,transformer_h_8_attn_attn_dropout,permute_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_17
call_method,permute,{matmul_17: None},"(matmul_17, 0, 2, 1, 3)",{},{contiguous_8: None},,matmul_17,contiguous_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_35
call_method,contiguous,{permute_35: None},"(permute_35,)",{},"{size_131: None, view_102: None}",,permute_35,size_131,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_8
call_method,size,{contiguous_8: None},"(contiguous_8,)",{},{getitem_108: None},,contiguous_8,getitem_108,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_131
call_function,<built-in function getitem>,{size_131: None},"(size_131, slice(None, -2, None))",{},{add_104: None},,size_131,add_104,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_108
call_function,<built-in function add>,{getitem_108: None},"(getitem_108, (1280,))",{},{view_102: None},,getitem_108,view_102,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_104
call_method,view,"{contiguous_8: None, add_104: None}","(contiguous_8, add_104)",{},"{size_132: None, size_133: None, view_103: None}",,add_104,size_132,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_102
call_method,size,{view_102: None},"(view_102,)",{},{getitem_109: None},,view_102,getitem_109,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.8.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_132
call_function,<built-in function getitem>,{size_132: None},"(size_132, slice(None, -1, None))",{},{add_105: None},,size_132,add_105,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.8.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_109
call_function,<built-in function add>,{getitem_109: None},"(getitem_109, (1280,))",{},{view_104: None},,getitem_109,transformer_h_8_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.8.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_105
get_attr,transformer.h.8.attn.c_proj.bias,{},(),{},{addmm_33: None},,add_105,size_133,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.8.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_8_attn_c_proj_bias
call_method,size,{view_102: None},"(view_102, -1)",{},{view_103: None},,transformer_h_8_attn_c_proj_bias,view_103,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.8.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_133
call_method,view,"{view_102: None, size_133: None}","(view_102, -1, size_133)",{},{addmm_33: None},,size_133,transformer_h_8_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.8.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_103
get_attr,transformer.h.8.attn.c_proj.weight,{},(),{},{addmm_33: None},,view_103,addmm_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.8.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_8_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_8_attn_c_proj_bias: None, view_103: None, transformer_h_8_attn_c_proj_weight: None}","(transformer_h_8_attn_c_proj_bias, view_103, transformer_h_8_attn_c_proj_weight)",{},{view_104: None},,transformer_h_8_attn_c_proj_weight,view_104,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.8.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_33
call_method,view,"{addmm_33: None, add_105: None}","(addmm_33, add_105)",{},{transformer_h_8_attn_resid_dropout: None},,addmm_33,transformer_h_8_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.8.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_104
call_module,transformer.h.8.attn.resid_dropout,{view_104: None},"(view_104,)",{},{add_106: None},,view_104,add_106,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.8.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_8_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_8_attn_resid_dropout: None, add_99: None}","(transformer_h_8_attn_resid_dropout, add_99)",{},"{transformer_h_8_ln_2: None, add_111: None}",,transformer_h_8_attn_resid_dropout,transformer_h_8_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_106
call_module,transformer.h.8.ln_2,{add_106: None},"(add_106,)",{},"{size_134: None, size_135: None, view_105: None}",,add_106,size_134,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_8_ln_2
call_method,size,{transformer_h_8_ln_2: None},"(transformer_h_8_ln_2,)",{},{getitem_110: None},,transformer_h_8_ln_2,getitem_110,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_134
call_function,<built-in function getitem>,{size_134: None},"(size_134, slice(None, -1, None))",{},{add_107: None},,size_134,add_107,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_110
call_function,<built-in function add>,{getitem_110: None},"(getitem_110, (5120,))",{},{view_106: None},,getitem_110,transformer_h_8_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_107
get_attr,transformer.h.8.mlp.c_fc.bias,{},(),{},{addmm_34: None},,add_107,size_135,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_8_mlp_c_fc_bias
call_method,size,{transformer_h_8_ln_2: None},"(transformer_h_8_ln_2, -1)",{},{view_105: None},,transformer_h_8_mlp_c_fc_bias,view_105,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_135
call_method,view,"{transformer_h_8_ln_2: None, size_135: None}","(transformer_h_8_ln_2, -1, size_135)",{},{addmm_34: None},,size_135,transformer_h_8_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_105
get_attr,transformer.h.8.mlp.c_fc.weight,{},(),{},{addmm_34: None},,view_105,addmm_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_8_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_8_mlp_c_fc_bias: None, view_105: None, transformer_h_8_mlp_c_fc_weight: None}","(transformer_h_8_mlp_c_fc_bias, view_105, transformer_h_8_mlp_c_fc_weight)",{},{view_106: None},,transformer_h_8_mlp_c_fc_weight,view_106,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_34
call_method,view,"{addmm_34: None, add_107: None}","(addmm_34, add_107)",{},"{mul_32: None, pow_18: None, add_108: None}",,addmm_34,mul_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_106
call_function,<built-in function mul>,{view_106: None},"(0.5, view_106)",{},{mul_35: None},,view_106,pow_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_32
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_106: None},"(view_106, 3.0)",{},{mul_33: None},,mul_32,mul_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_18
call_function,<built-in function mul>,{pow_18: None},"(0.044715, pow_18)",{},{add_108: None},,pow_18,add_108,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_33
call_function,<built-in function add>,"{view_106: None, mul_33: None}","(view_106, mul_33)",{},{mul_34: None},,mul_33,mul_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_108
call_function,<built-in function mul>,{add_108: None},"(0.7978845608028654, add_108)",{},{tanh_8: None},,add_108,tanh_8,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_34
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_34: None},"(mul_34,)",{},{add_109: None},,mul_34,add_109,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_8
call_function,<built-in function add>,{tanh_8: None},"(1.0, tanh_8)",{},{mul_35: None},,tanh_8,mul_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_109
call_function,<built-in function mul>,"{mul_32: None, add_109: None}","(mul_32, add_109)",{},"{size_136: None, size_137: None, view_107: None}",,add_109,size_136,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_35
call_method,size,{mul_35: None},"(mul_35,)",{},{getitem_111: None},,mul_35,getitem_111,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_136
call_function,<built-in function getitem>,{size_136: None},"(size_136, slice(None, -1, None))",{},{add_110: None},,size_136,add_110,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_111
call_function,<built-in function add>,{getitem_111: None},"(getitem_111, (1280,))",{},{view_108: None},,getitem_111,transformer_h_8_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_110
get_attr,transformer.h.8.mlp.c_proj.bias,{},(),{},{addmm_35: None},,add_110,size_137,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_8_mlp_c_proj_bias
call_method,size,{mul_35: None},"(mul_35, -1)",{},{view_107: None},,transformer_h_8_mlp_c_proj_bias,view_107,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_137
call_method,view,"{mul_35: None, size_137: None}","(mul_35, -1, size_137)",{},{addmm_35: None},,size_137,transformer_h_8_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_107
get_attr,transformer.h.8.mlp.c_proj.weight,{},(),{},{addmm_35: None},,view_107,addmm_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_8_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_8_mlp_c_proj_bias: None, view_107: None, transformer_h_8_mlp_c_proj_weight: None}","(transformer_h_8_mlp_c_proj_bias, view_107, transformer_h_8_mlp_c_proj_weight)",{},{view_108: None},,transformer_h_8_mlp_c_proj_weight,view_108,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_35
call_method,view,"{addmm_35: None, add_110: None}","(addmm_35, add_110)",{},{transformer_h_8_mlp_dropout: None},,addmm_35,transformer_h_8_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_108
call_module,transformer.h.8.mlp.dropout,{view_108: None},"(view_108,)",{},{add_111: None},,view_108,add_111,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.8.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.8.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_8_mlp_dropout
call_function,<built-in function add>,"{add_106: None, transformer_h_8_mlp_dropout: None}","(add_106, transformer_h_8_mlp_dropout)",{},"{transformer_h_9_ln_1: None, add_118: None}",,transformer_h_8_mlp_dropout,transformer_h_9_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.8', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_111
call_module,transformer.h.9.ln_1,{add_111: None},"(add_111,)",{},"{size_138: None, size_139: None, view_109: None}",,add_111,size_138,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_9_ln_1
call_method,size,{transformer_h_9_ln_1: None},"(transformer_h_9_ln_1,)",{},{getitem_112: None},,transformer_h_9_ln_1,getitem_112,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.9.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_138
call_function,<built-in function getitem>,{size_138: None},"(size_138, slice(None, -1, None))",{},{add_112: None},,size_138,add_112,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.9.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_112
call_function,<built-in function add>,{getitem_112: None},"(getitem_112, (3840,))",{},{view_110: None},,getitem_112,transformer_h_9_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.9.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_112
get_attr,transformer.h.9.attn.c_attn.bias,{},(),{},{addmm_36: None},,add_112,size_139,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.9.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_9_attn_c_attn_bias
call_method,size,{transformer_h_9_ln_1: None},"(transformer_h_9_ln_1, -1)",{},{view_109: None},,transformer_h_9_attn_c_attn_bias,view_109,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.9.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_139
call_method,view,"{transformer_h_9_ln_1: None, size_139: None}","(transformer_h_9_ln_1, -1, size_139)",{},{addmm_36: None},,size_139,transformer_h_9_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.9.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_109
get_attr,transformer.h.9.attn.c_attn.weight,{},(),{},{addmm_36: None},,view_109,addmm_36,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.9.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_9_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_9_attn_c_attn_bias: None, view_109: None, transformer_h_9_attn_c_attn_weight: None}","(transformer_h_9_attn_c_attn_bias, view_109, transformer_h_9_attn_c_attn_weight)",{},{view_110: None},,transformer_h_9_attn_c_attn_weight,view_110,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.9.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_36
call_method,view,"{addmm_36: None, add_112: None}","(addmm_36, add_112)",{},{split_9: None},,addmm_36,split_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.9.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_110
call_method,split,{view_110: None},"(view_110, 1280)",{'dim': 2},"{getitem_113: None, getitem_114: None, getitem_115: None}",,view_110,getitem_113,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_9
call_function,<built-in function getitem>,{split_9: None},"(split_9, 0)",{},"{size_140: None, view_111: None}",,split_9,getitem_114,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_113
call_function,<built-in function getitem>,{split_9: None},"(split_9, 1)",{},"{size_141: None, view_112: None}",,getitem_113,getitem_115,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_114
call_function,<built-in function getitem>,{split_9: None},"(split_9, 2)",{},"{size_142: None, view_113: None}",,getitem_114,size_140,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_115
call_method,size,{getitem_113: None},"(getitem_113,)",{},{getitem_116: None},,getitem_115,getitem_116,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_140
call_function,<built-in function getitem>,{size_140: None},"(size_140, slice(None, -1, None))",{},{add_113: None},,size_140,add_113,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_116
call_function,<built-in function add>,{getitem_116: None},"(getitem_116, (20, 64))",{},{view_111: None},,getitem_116,view_111,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_113
call_method,view,"{getitem_113: None, add_113: None}","(getitem_113, add_113)",{},{permute_36: None},,add_113,permute_36,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_111
call_method,permute,{view_111: None},"(view_111, 0, 2, 1, 3)",{},"{matmul_18: None, size_144: None}",,view_111,size_141,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_36
call_method,size,{getitem_114: None},"(getitem_114,)",{},{getitem_117: None},,permute_36,getitem_117,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_141
call_function,<built-in function getitem>,{size_141: None},"(size_141, slice(None, -1, None))",{},{add_114: None},,size_141,add_114,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_117
call_function,<built-in function add>,{getitem_117: None},"(getitem_117, (20, 64))",{},{view_112: None},,getitem_117,view_112,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_114
call_method,view,"{getitem_114: None, add_114: None}","(getitem_114, add_114)",{},{permute_37: None},,add_114,permute_37,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_112
call_method,permute,{view_112: None},"(view_112, 0, 2, 1, 3)",{},"{transpose_9: None, size_145: None, output: None}",,view_112,size_142,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_37
call_method,size,{getitem_115: None},"(getitem_115,)",{},{getitem_118: None},,permute_37,getitem_118,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_142
call_function,<built-in function getitem>,{size_142: None},"(size_142, slice(None, -1, None))",{},{add_115: None},,size_142,add_115,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_118
call_function,<built-in function add>,{getitem_118: None},"(getitem_118, (20, 64))",{},{view_113: None},,getitem_118,view_113,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_115
call_method,view,"{getitem_115: None, add_115: None}","(getitem_115, add_115)",{},{permute_38: None},,add_115,permute_38,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_113
call_method,permute,{view_113: None},"(view_113, 0, 2, 1, 3)",{},"{size_143: None, getattr_81: None, matmul_19: None, output: None}",,view_113,transpose_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_38
call_method,transpose,{permute_37: None},"(permute_37, -1, -2)",{},{matmul_18: None},,permute_38,matmul_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_9
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_36: None, transpose_9: None}","(permute_36, transpose_9)",{},"{getattr_74: None, getattr_75: None, truediv_9: None}",,transpose_9,size_143,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_18
call_method,size,{permute_38: None},"(permute_38, -1)",{},{pow_19: None},,matmul_18,pow_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_143
call_function,<built-in function pow>,{size_143: None},"(size_143, 0.5)",{},{full_18: None},,size_143,getattr_74,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_19
call_function,<built-in function getattr>,{matmul_18: None},"(matmul_18, 'dtype')",{},{full_18: None},,pow_19,getattr_75,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_74
call_function,<built-in function getattr>,{matmul_18: None},"(matmul_18, 'device')",{},{full_18: None},,getattr_74,full_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_75
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_19: None, getattr_74: None, getattr_75: None}","([], pow_19)","{'dtype': getattr_74, 'device': getattr_75}",{truediv_9: None},,getattr_75,truediv_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_18
call_function,<built-in function truediv>,"{matmul_18: None, full_18: None}","(matmul_18, full_18)",{},"{getattr_76: None, getattr_78: None, getattr_79: None, getattr_80: None, to_9: None}",,full_18,size_144,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_9
call_method,size,{permute_36: None},"(permute_36, -2)",{},{sub_9: None},,truediv_9,size_145,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_144
call_method,size,{permute_37: None},"(permute_37, -2)",{},"{sub_9: None, getitem_119: None}",,size_144,transformer_h_9_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_145
get_attr,transformer.h.9.attn.bias,{},(),{},{getitem_119: None},,size_145,sub_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_9_attn_bias
call_function,<built-in function sub>,"{size_145: None, size_144: None}","(size_145, size_144)",{},{getitem_119: None},,transformer_h_9_attn_bias,getitem_119,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_9
call_function,<built-in function getitem>,"{transformer_h_9_attn_bias: None, sub_9: None, size_145: None}","(transformer_h_9_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_9, size_145, None), slice(None, size_145, None)))",{},{where_9: None},,sub_9,getattr_76,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_119
call_function,<built-in function getattr>,{truediv_9: None},"(truediv_9, 'dtype')",{},{finfo_9: None},,getitem_119,finfo_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_76
call_function,<class 'torch.finfo'>,{getattr_76: None},"(getattr_76,)",{},{getattr_77: None},,getattr_76,getattr_77,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_9
call_function,<built-in function getattr>,{finfo_9: None},"(finfo_9, 'min')",{},{full_19: None},,finfo_9,getattr_78,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_77
call_function,<built-in function getattr>,{truediv_9: None},"(truediv_9, 'dtype')",{},{full_19: None},,getattr_77,getattr_79,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_78
call_function,<built-in function getattr>,{truediv_9: None},"(truediv_9, 'device')",{},{full_19: None},,getattr_78,full_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_79
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_77: None, getattr_78: None, getattr_79: None}","([], getattr_77)","{'dtype': getattr_78, 'device': getattr_79}",{where_9: None},,getattr_79,getattr_80,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_19
call_function,<built-in function getattr>,{truediv_9: None},"(truediv_9, 'dtype')",{},{to_9: None},,full_19,to_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_80
call_method,to,"{truediv_9: None, getattr_80: None}","(truediv_9, getattr_80)",{},{where_9: None},,getattr_80,where_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_9
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_119: None, to_9: None, full_19: None}","(getitem_119, to_9, full_19)",{},{softmax_9: None},,to_9,softmax_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_9
call_function,<function softmax at 0x7f6fd5135ca0>,{where_9: None},"(where_9,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_10: None},,where_9,getattr_81,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_9
call_function,<built-in function getattr>,{permute_38: None},"(permute_38, 'dtype')",{},{type_10: None},,softmax_9,type_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_81
call_method,type,"{softmax_9: None, getattr_81: None}","(softmax_9, getattr_81)",{},{transformer_h_9_attn_attn_dropout: None},,getattr_81,transformer_h_9_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_10
call_module,transformer.h.9.attn.attn_dropout,{type_10: None},"(type_10,)",{},{matmul_19: None},,type_10,matmul_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.9.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_9_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_9_attn_attn_dropout: None, permute_38: None}","(transformer_h_9_attn_attn_dropout, permute_38)",{},{permute_39: None},,transformer_h_9_attn_attn_dropout,permute_39,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_19
call_method,permute,{matmul_19: None},"(matmul_19, 0, 2, 1, 3)",{},{contiguous_9: None},,matmul_19,contiguous_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_39
call_method,contiguous,{permute_39: None},"(permute_39,)",{},"{size_146: None, view_114: None}",,permute_39,size_146,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_9
call_method,size,{contiguous_9: None},"(contiguous_9,)",{},{getitem_120: None},,contiguous_9,getitem_120,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_146
call_function,<built-in function getitem>,{size_146: None},"(size_146, slice(None, -2, None))",{},{add_116: None},,size_146,add_116,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_120
call_function,<built-in function add>,{getitem_120: None},"(getitem_120, (1280,))",{},{view_114: None},,getitem_120,view_114,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_116
call_method,view,"{contiguous_9: None, add_116: None}","(contiguous_9, add_116)",{},"{size_147: None, size_148: None, view_115: None}",,add_116,size_147,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_114
call_method,size,{view_114: None},"(view_114,)",{},{getitem_121: None},,view_114,getitem_121,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.9.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_147
call_function,<built-in function getitem>,{size_147: None},"(size_147, slice(None, -1, None))",{},{add_117: None},,size_147,add_117,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.9.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_121
call_function,<built-in function add>,{getitem_121: None},"(getitem_121, (1280,))",{},{view_116: None},,getitem_121,transformer_h_9_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.9.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_117
get_attr,transformer.h.9.attn.c_proj.bias,{},(),{},{addmm_37: None},,add_117,size_148,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.9.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_9_attn_c_proj_bias
call_method,size,{view_114: None},"(view_114, -1)",{},{view_115: None},,transformer_h_9_attn_c_proj_bias,view_115,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.9.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_148
call_method,view,"{view_114: None, size_148: None}","(view_114, -1, size_148)",{},{addmm_37: None},,size_148,transformer_h_9_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.9.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_115
get_attr,transformer.h.9.attn.c_proj.weight,{},(),{},{addmm_37: None},,view_115,addmm_37,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.9.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_9_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_9_attn_c_proj_bias: None, view_115: None, transformer_h_9_attn_c_proj_weight: None}","(transformer_h_9_attn_c_proj_bias, view_115, transformer_h_9_attn_c_proj_weight)",{},{view_116: None},,transformer_h_9_attn_c_proj_weight,view_116,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.9.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_37
call_method,view,"{addmm_37: None, add_117: None}","(addmm_37, add_117)",{},{transformer_h_9_attn_resid_dropout: None},,addmm_37,transformer_h_9_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.9.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_116
call_module,transformer.h.9.attn.resid_dropout,{view_116: None},"(view_116,)",{},{add_118: None},,view_116,add_118,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.9.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_9_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_9_attn_resid_dropout: None, add_111: None}","(transformer_h_9_attn_resid_dropout, add_111)",{},"{transformer_h_9_ln_2: None, add_123: None}",,transformer_h_9_attn_resid_dropout,transformer_h_9_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_118
call_module,transformer.h.9.ln_2,{add_118: None},"(add_118,)",{},"{size_149: None, size_150: None, view_117: None}",,add_118,size_149,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_9_ln_2
call_method,size,{transformer_h_9_ln_2: None},"(transformer_h_9_ln_2,)",{},{getitem_122: None},,transformer_h_9_ln_2,getitem_122,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_149
call_function,<built-in function getitem>,{size_149: None},"(size_149, slice(None, -1, None))",{},{add_119: None},,size_149,add_119,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_122
call_function,<built-in function add>,{getitem_122: None},"(getitem_122, (5120,))",{},{view_118: None},,getitem_122,transformer_h_9_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_119
get_attr,transformer.h.9.mlp.c_fc.bias,{},(),{},{addmm_38: None},,add_119,size_150,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_9_mlp_c_fc_bias
call_method,size,{transformer_h_9_ln_2: None},"(transformer_h_9_ln_2, -1)",{},{view_117: None},,transformer_h_9_mlp_c_fc_bias,view_117,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_150
call_method,view,"{transformer_h_9_ln_2: None, size_150: None}","(transformer_h_9_ln_2, -1, size_150)",{},{addmm_38: None},,size_150,transformer_h_9_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_117
get_attr,transformer.h.9.mlp.c_fc.weight,{},(),{},{addmm_38: None},,view_117,addmm_38,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_9_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_9_mlp_c_fc_bias: None, view_117: None, transformer_h_9_mlp_c_fc_weight: None}","(transformer_h_9_mlp_c_fc_bias, view_117, transformer_h_9_mlp_c_fc_weight)",{},{view_118: None},,transformer_h_9_mlp_c_fc_weight,view_118,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_38
call_method,view,"{addmm_38: None, add_119: None}","(addmm_38, add_119)",{},"{mul_36: None, pow_20: None, add_120: None}",,addmm_38,mul_36,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_118
call_function,<built-in function mul>,{view_118: None},"(0.5, view_118)",{},{mul_39: None},,view_118,pow_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_36
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_118: None},"(view_118, 3.0)",{},{mul_37: None},,mul_36,mul_37,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_20
call_function,<built-in function mul>,{pow_20: None},"(0.044715, pow_20)",{},{add_120: None},,pow_20,add_120,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_37
call_function,<built-in function add>,"{view_118: None, mul_37: None}","(view_118, mul_37)",{},{mul_38: None},,mul_37,mul_38,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_120
call_function,<built-in function mul>,{add_120: None},"(0.7978845608028654, add_120)",{},{tanh_9: None},,add_120,tanh_9,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_38
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_38: None},"(mul_38,)",{},{add_121: None},,mul_38,add_121,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_9
call_function,<built-in function add>,{tanh_9: None},"(1.0, tanh_9)",{},{mul_39: None},,tanh_9,mul_39,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_121
call_function,<built-in function mul>,"{mul_36: None, add_121: None}","(mul_36, add_121)",{},"{size_151: None, size_152: None, view_119: None}",,add_121,size_151,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_39
call_method,size,{mul_39: None},"(mul_39,)",{},{getitem_123: None},,mul_39,getitem_123,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_151
call_function,<built-in function getitem>,{size_151: None},"(size_151, slice(None, -1, None))",{},{add_122: None},,size_151,add_122,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_123
call_function,<built-in function add>,{getitem_123: None},"(getitem_123, (1280,))",{},{view_120: None},,getitem_123,transformer_h_9_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_122
get_attr,transformer.h.9.mlp.c_proj.bias,{},(),{},{addmm_39: None},,add_122,size_152,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_9_mlp_c_proj_bias
call_method,size,{mul_39: None},"(mul_39, -1)",{},{view_119: None},,transformer_h_9_mlp_c_proj_bias,view_119,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_152
call_method,view,"{mul_39: None, size_152: None}","(mul_39, -1, size_152)",{},{addmm_39: None},,size_152,transformer_h_9_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_119
get_attr,transformer.h.9.mlp.c_proj.weight,{},(),{},{addmm_39: None},,view_119,addmm_39,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_9_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_9_mlp_c_proj_bias: None, view_119: None, transformer_h_9_mlp_c_proj_weight: None}","(transformer_h_9_mlp_c_proj_bias, view_119, transformer_h_9_mlp_c_proj_weight)",{},{view_120: None},,transformer_h_9_mlp_c_proj_weight,view_120,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_39
call_method,view,"{addmm_39: None, add_122: None}","(addmm_39, add_122)",{},{transformer_h_9_mlp_dropout: None},,addmm_39,transformer_h_9_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_120
call_module,transformer.h.9.mlp.dropout,{view_120: None},"(view_120,)",{},{add_123: None},,view_120,add_123,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.9.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.9.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_9_mlp_dropout
call_function,<built-in function add>,"{add_118: None, transformer_h_9_mlp_dropout: None}","(add_118, transformer_h_9_mlp_dropout)",{},"{transformer_h_10_ln_1: None, add_130: None}",,transformer_h_9_mlp_dropout,transformer_h_10_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.9', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_123
call_module,transformer.h.10.ln_1,{add_123: None},"(add_123,)",{},"{size_153: None, size_154: None, view_121: None}",,add_123,size_153,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_10_ln_1
call_method,size,{transformer_h_10_ln_1: None},"(transformer_h_10_ln_1,)",{},{getitem_124: None},,transformer_h_10_ln_1,getitem_124,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.10.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_153
call_function,<built-in function getitem>,{size_153: None},"(size_153, slice(None, -1, None))",{},{add_124: None},,size_153,add_124,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.10.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_124
call_function,<built-in function add>,{getitem_124: None},"(getitem_124, (3840,))",{},{view_122: None},,getitem_124,transformer_h_10_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.10.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_124
get_attr,transformer.h.10.attn.c_attn.bias,{},(),{},{addmm_40: None},,add_124,size_154,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.10.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_10_attn_c_attn_bias
call_method,size,{transformer_h_10_ln_1: None},"(transformer_h_10_ln_1, -1)",{},{view_121: None},,transformer_h_10_attn_c_attn_bias,view_121,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.10.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_154
call_method,view,"{transformer_h_10_ln_1: None, size_154: None}","(transformer_h_10_ln_1, -1, size_154)",{},{addmm_40: None},,size_154,transformer_h_10_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.10.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_121
get_attr,transformer.h.10.attn.c_attn.weight,{},(),{},{addmm_40: None},,view_121,addmm_40,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.10.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_10_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_10_attn_c_attn_bias: None, view_121: None, transformer_h_10_attn_c_attn_weight: None}","(transformer_h_10_attn_c_attn_bias, view_121, transformer_h_10_attn_c_attn_weight)",{},{view_122: None},,transformer_h_10_attn_c_attn_weight,view_122,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.10.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_40
call_method,view,"{addmm_40: None, add_124: None}","(addmm_40, add_124)",{},{split_10: None},,addmm_40,split_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.10.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_122
call_method,split,{view_122: None},"(view_122, 1280)",{'dim': 2},"{getitem_125: None, getitem_126: None, getitem_127: None}",,view_122,getitem_125,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_10
call_function,<built-in function getitem>,{split_10: None},"(split_10, 0)",{},"{size_155: None, view_123: None}",,split_10,getitem_126,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_125
call_function,<built-in function getitem>,{split_10: None},"(split_10, 1)",{},"{size_156: None, view_124: None}",,getitem_125,getitem_127,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_126
call_function,<built-in function getitem>,{split_10: None},"(split_10, 2)",{},"{size_157: None, view_125: None}",,getitem_126,size_155,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_127
call_method,size,{getitem_125: None},"(getitem_125,)",{},{getitem_128: None},,getitem_127,getitem_128,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_155
call_function,<built-in function getitem>,{size_155: None},"(size_155, slice(None, -1, None))",{},{add_125: None},,size_155,add_125,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_128
call_function,<built-in function add>,{getitem_128: None},"(getitem_128, (20, 64))",{},{view_123: None},,getitem_128,view_123,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_125
call_method,view,"{getitem_125: None, add_125: None}","(getitem_125, add_125)",{},{permute_40: None},,add_125,permute_40,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_123
call_method,permute,{view_123: None},"(view_123, 0, 2, 1, 3)",{},"{matmul_20: None, size_159: None}",,view_123,size_156,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_40
call_method,size,{getitem_126: None},"(getitem_126,)",{},{getitem_129: None},,permute_40,getitem_129,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_156
call_function,<built-in function getitem>,{size_156: None},"(size_156, slice(None, -1, None))",{},{add_126: None},,size_156,add_126,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_129
call_function,<built-in function add>,{getitem_129: None},"(getitem_129, (20, 64))",{},{view_124: None},,getitem_129,view_124,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_126
call_method,view,"{getitem_126: None, add_126: None}","(getitem_126, add_126)",{},{permute_41: None},,add_126,permute_41,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_124
call_method,permute,{view_124: None},"(view_124, 0, 2, 1, 3)",{},"{transpose_10: None, size_160: None, output: None}",,view_124,size_157,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_41
call_method,size,{getitem_127: None},"(getitem_127,)",{},{getitem_130: None},,permute_41,getitem_130,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_157
call_function,<built-in function getitem>,{size_157: None},"(size_157, slice(None, -1, None))",{},{add_127: None},,size_157,add_127,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_130
call_function,<built-in function add>,{getitem_130: None},"(getitem_130, (20, 64))",{},{view_125: None},,getitem_130,view_125,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_127
call_method,view,"{getitem_127: None, add_127: None}","(getitem_127, add_127)",{},{permute_42: None},,add_127,permute_42,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_125
call_method,permute,{view_125: None},"(view_125, 0, 2, 1, 3)",{},"{size_158: None, getattr_89: None, matmul_21: None, output: None}",,view_125,transpose_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_42
call_method,transpose,{permute_41: None},"(permute_41, -1, -2)",{},{matmul_20: None},,permute_42,matmul_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_10
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_40: None, transpose_10: None}","(permute_40, transpose_10)",{},"{getattr_82: None, getattr_83: None, truediv_10: None}",,transpose_10,size_158,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_20
call_method,size,{permute_42: None},"(permute_42, -1)",{},{pow_21: None},,matmul_20,pow_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_158
call_function,<built-in function pow>,{size_158: None},"(size_158, 0.5)",{},{full_20: None},,size_158,getattr_82,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_21
call_function,<built-in function getattr>,{matmul_20: None},"(matmul_20, 'dtype')",{},{full_20: None},,pow_21,getattr_83,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_82
call_function,<built-in function getattr>,{matmul_20: None},"(matmul_20, 'device')",{},{full_20: None},,getattr_82,full_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_83
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_21: None, getattr_82: None, getattr_83: None}","([], pow_21)","{'dtype': getattr_82, 'device': getattr_83}",{truediv_10: None},,getattr_83,truediv_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_20
call_function,<built-in function truediv>,"{matmul_20: None, full_20: None}","(matmul_20, full_20)",{},"{getattr_84: None, getattr_86: None, getattr_87: None, getattr_88: None, to_10: None}",,full_20,size_159,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_10
call_method,size,{permute_40: None},"(permute_40, -2)",{},{sub_10: None},,truediv_10,size_160,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_159
call_method,size,{permute_41: None},"(permute_41, -2)",{},"{sub_10: None, getitem_131: None}",,size_159,transformer_h_10_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_160
get_attr,transformer.h.10.attn.bias,{},(),{},{getitem_131: None},,size_160,sub_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_10_attn_bias
call_function,<built-in function sub>,"{size_160: None, size_159: None}","(size_160, size_159)",{},{getitem_131: None},,transformer_h_10_attn_bias,getitem_131,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_10
call_function,<built-in function getitem>,"{transformer_h_10_attn_bias: None, sub_10: None, size_160: None}","(transformer_h_10_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_10, size_160, None), slice(None, size_160, None)))",{},{where_10: None},,sub_10,getattr_84,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_131
call_function,<built-in function getattr>,{truediv_10: None},"(truediv_10, 'dtype')",{},{finfo_10: None},,getitem_131,finfo_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_84
call_function,<class 'torch.finfo'>,{getattr_84: None},"(getattr_84,)",{},{getattr_85: None},,getattr_84,getattr_85,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_10
call_function,<built-in function getattr>,{finfo_10: None},"(finfo_10, 'min')",{},{full_21: None},,finfo_10,getattr_86,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_85
call_function,<built-in function getattr>,{truediv_10: None},"(truediv_10, 'dtype')",{},{full_21: None},,getattr_85,getattr_87,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_86
call_function,<built-in function getattr>,{truediv_10: None},"(truediv_10, 'device')",{},{full_21: None},,getattr_86,full_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_87
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_85: None, getattr_86: None, getattr_87: None}","([], getattr_85)","{'dtype': getattr_86, 'device': getattr_87}",{where_10: None},,getattr_87,getattr_88,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_21
call_function,<built-in function getattr>,{truediv_10: None},"(truediv_10, 'dtype')",{},{to_10: None},,full_21,to_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_88
call_method,to,"{truediv_10: None, getattr_88: None}","(truediv_10, getattr_88)",{},{where_10: None},,getattr_88,where_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_10
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_131: None, to_10: None, full_21: None}","(getitem_131, to_10, full_21)",{},{softmax_10: None},,to_10,softmax_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_10
call_function,<function softmax at 0x7f6fd5135ca0>,{where_10: None},"(where_10,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_11: None},,where_10,getattr_89,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_10
call_function,<built-in function getattr>,{permute_42: None},"(permute_42, 'dtype')",{},{type_11: None},,softmax_10,type_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_89
call_method,type,"{softmax_10: None, getattr_89: None}","(softmax_10, getattr_89)",{},{transformer_h_10_attn_attn_dropout: None},,getattr_89,transformer_h_10_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_11
call_module,transformer.h.10.attn.attn_dropout,{type_11: None},"(type_11,)",{},{matmul_21: None},,type_11,matmul_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.10.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_10_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_10_attn_attn_dropout: None, permute_42: None}","(transformer_h_10_attn_attn_dropout, permute_42)",{},{permute_43: None},,transformer_h_10_attn_attn_dropout,permute_43,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_21
call_method,permute,{matmul_21: None},"(matmul_21, 0, 2, 1, 3)",{},{contiguous_10: None},,matmul_21,contiguous_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_43
call_method,contiguous,{permute_43: None},"(permute_43,)",{},"{size_161: None, view_126: None}",,permute_43,size_161,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_10
call_method,size,{contiguous_10: None},"(contiguous_10,)",{},{getitem_132: None},,contiguous_10,getitem_132,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_161
call_function,<built-in function getitem>,{size_161: None},"(size_161, slice(None, -2, None))",{},{add_128: None},,size_161,add_128,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_132
call_function,<built-in function add>,{getitem_132: None},"(getitem_132, (1280,))",{},{view_126: None},,getitem_132,view_126,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_128
call_method,view,"{contiguous_10: None, add_128: None}","(contiguous_10, add_128)",{},"{size_162: None, size_163: None, view_127: None}",,add_128,size_162,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_126
call_method,size,{view_126: None},"(view_126,)",{},{getitem_133: None},,view_126,getitem_133,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.10.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_162
call_function,<built-in function getitem>,{size_162: None},"(size_162, slice(None, -1, None))",{},{add_129: None},,size_162,add_129,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.10.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_133
call_function,<built-in function add>,{getitem_133: None},"(getitem_133, (1280,))",{},{view_128: None},,getitem_133,transformer_h_10_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.10.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_129
get_attr,transformer.h.10.attn.c_proj.bias,{},(),{},{addmm_41: None},,add_129,size_163,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.10.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_10_attn_c_proj_bias
call_method,size,{view_126: None},"(view_126, -1)",{},{view_127: None},,transformer_h_10_attn_c_proj_bias,view_127,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.10.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_163
call_method,view,"{view_126: None, size_163: None}","(view_126, -1, size_163)",{},{addmm_41: None},,size_163,transformer_h_10_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.10.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_127
get_attr,transformer.h.10.attn.c_proj.weight,{},(),{},{addmm_41: None},,view_127,addmm_41,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.10.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_10_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_10_attn_c_proj_bias: None, view_127: None, transformer_h_10_attn_c_proj_weight: None}","(transformer_h_10_attn_c_proj_bias, view_127, transformer_h_10_attn_c_proj_weight)",{},{view_128: None},,transformer_h_10_attn_c_proj_weight,view_128,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.10.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_41
call_method,view,"{addmm_41: None, add_129: None}","(addmm_41, add_129)",{},{transformer_h_10_attn_resid_dropout: None},,addmm_41,transformer_h_10_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.10.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_128
call_module,transformer.h.10.attn.resid_dropout,{view_128: None},"(view_128,)",{},{add_130: None},,view_128,add_130,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.10.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_10_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_10_attn_resid_dropout: None, add_123: None}","(transformer_h_10_attn_resid_dropout, add_123)",{},"{transformer_h_10_ln_2: None, add_135: None}",,transformer_h_10_attn_resid_dropout,transformer_h_10_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_130
call_module,transformer.h.10.ln_2,{add_130: None},"(add_130,)",{},"{size_164: None, size_165: None, view_129: None}",,add_130,size_164,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_10_ln_2
call_method,size,{transformer_h_10_ln_2: None},"(transformer_h_10_ln_2,)",{},{getitem_134: None},,transformer_h_10_ln_2,getitem_134,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_164
call_function,<built-in function getitem>,{size_164: None},"(size_164, slice(None, -1, None))",{},{add_131: None},,size_164,add_131,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_134
call_function,<built-in function add>,{getitem_134: None},"(getitem_134, (5120,))",{},{view_130: None},,getitem_134,transformer_h_10_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_131
get_attr,transformer.h.10.mlp.c_fc.bias,{},(),{},{addmm_42: None},,add_131,size_165,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_10_mlp_c_fc_bias
call_method,size,{transformer_h_10_ln_2: None},"(transformer_h_10_ln_2, -1)",{},{view_129: None},,transformer_h_10_mlp_c_fc_bias,view_129,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_165
call_method,view,"{transformer_h_10_ln_2: None, size_165: None}","(transformer_h_10_ln_2, -1, size_165)",{},{addmm_42: None},,size_165,transformer_h_10_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_129
get_attr,transformer.h.10.mlp.c_fc.weight,{},(),{},{addmm_42: None},,view_129,addmm_42,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_10_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_10_mlp_c_fc_bias: None, view_129: None, transformer_h_10_mlp_c_fc_weight: None}","(transformer_h_10_mlp_c_fc_bias, view_129, transformer_h_10_mlp_c_fc_weight)",{},{view_130: None},,transformer_h_10_mlp_c_fc_weight,view_130,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_42
call_method,view,"{addmm_42: None, add_131: None}","(addmm_42, add_131)",{},"{mul_40: None, pow_22: None, add_132: None}",,addmm_42,mul_40,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_130
call_function,<built-in function mul>,{view_130: None},"(0.5, view_130)",{},{mul_43: None},,view_130,pow_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_40
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_130: None},"(view_130, 3.0)",{},{mul_41: None},,mul_40,mul_41,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_22
call_function,<built-in function mul>,{pow_22: None},"(0.044715, pow_22)",{},{add_132: None},,pow_22,add_132,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_41
call_function,<built-in function add>,"{view_130: None, mul_41: None}","(view_130, mul_41)",{},{mul_42: None},,mul_41,mul_42,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_132
call_function,<built-in function mul>,{add_132: None},"(0.7978845608028654, add_132)",{},{tanh_10: None},,add_132,tanh_10,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_42
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_42: None},"(mul_42,)",{},{add_133: None},,mul_42,add_133,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_10
call_function,<built-in function add>,{tanh_10: None},"(1.0, tanh_10)",{},{mul_43: None},,tanh_10,mul_43,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_133
call_function,<built-in function mul>,"{mul_40: None, add_133: None}","(mul_40, add_133)",{},"{size_166: None, size_167: None, view_131: None}",,add_133,size_166,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_43
call_method,size,{mul_43: None},"(mul_43,)",{},{getitem_135: None},,mul_43,getitem_135,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_166
call_function,<built-in function getitem>,{size_166: None},"(size_166, slice(None, -1, None))",{},{add_134: None},,size_166,add_134,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_135
call_function,<built-in function add>,{getitem_135: None},"(getitem_135, (1280,))",{},{view_132: None},,getitem_135,transformer_h_10_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_134
get_attr,transformer.h.10.mlp.c_proj.bias,{},(),{},{addmm_43: None},,add_134,size_167,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_10_mlp_c_proj_bias
call_method,size,{mul_43: None},"(mul_43, -1)",{},{view_131: None},,transformer_h_10_mlp_c_proj_bias,view_131,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_167
call_method,view,"{mul_43: None, size_167: None}","(mul_43, -1, size_167)",{},{addmm_43: None},,size_167,transformer_h_10_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_131
get_attr,transformer.h.10.mlp.c_proj.weight,{},(),{},{addmm_43: None},,view_131,addmm_43,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_10_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_10_mlp_c_proj_bias: None, view_131: None, transformer_h_10_mlp_c_proj_weight: None}","(transformer_h_10_mlp_c_proj_bias, view_131, transformer_h_10_mlp_c_proj_weight)",{},{view_132: None},,transformer_h_10_mlp_c_proj_weight,view_132,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_43
call_method,view,"{addmm_43: None, add_134: None}","(addmm_43, add_134)",{},{transformer_h_10_mlp_dropout: None},,addmm_43,transformer_h_10_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_132
call_module,transformer.h.10.mlp.dropout,{view_132: None},"(view_132,)",{},{add_135: None},,view_132,add_135,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.10.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.10.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_10_mlp_dropout
call_function,<built-in function add>,"{add_130: None, transformer_h_10_mlp_dropout: None}","(add_130, transformer_h_10_mlp_dropout)",{},"{transformer_h_11_ln_1: None, add_142: None}",,transformer_h_10_mlp_dropout,transformer_h_11_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.10', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_135
call_module,transformer.h.11.ln_1,{add_135: None},"(add_135,)",{},"{size_168: None, size_169: None, view_133: None}",,add_135,size_168,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_11_ln_1
call_method,size,{transformer_h_11_ln_1: None},"(transformer_h_11_ln_1,)",{},{getitem_136: None},,transformer_h_11_ln_1,getitem_136,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.11.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_168
call_function,<built-in function getitem>,{size_168: None},"(size_168, slice(None, -1, None))",{},{add_136: None},,size_168,add_136,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.11.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_136
call_function,<built-in function add>,{getitem_136: None},"(getitem_136, (3840,))",{},{view_134: None},,getitem_136,transformer_h_11_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.11.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_136
get_attr,transformer.h.11.attn.c_attn.bias,{},(),{},{addmm_44: None},,add_136,size_169,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.11.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_11_attn_c_attn_bias
call_method,size,{transformer_h_11_ln_1: None},"(transformer_h_11_ln_1, -1)",{},{view_133: None},,transformer_h_11_attn_c_attn_bias,view_133,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.11.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_169
call_method,view,"{transformer_h_11_ln_1: None, size_169: None}","(transformer_h_11_ln_1, -1, size_169)",{},{addmm_44: None},,size_169,transformer_h_11_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.11.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_133
get_attr,transformer.h.11.attn.c_attn.weight,{},(),{},{addmm_44: None},,view_133,addmm_44,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.11.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_11_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_11_attn_c_attn_bias: None, view_133: None, transformer_h_11_attn_c_attn_weight: None}","(transformer_h_11_attn_c_attn_bias, view_133, transformer_h_11_attn_c_attn_weight)",{},{view_134: None},,transformer_h_11_attn_c_attn_weight,view_134,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.11.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_44
call_method,view,"{addmm_44: None, add_136: None}","(addmm_44, add_136)",{},{split_11: None},,addmm_44,split_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.11.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_134
call_method,split,{view_134: None},"(view_134, 1280)",{'dim': 2},"{getitem_137: None, getitem_138: None, getitem_139: None}",,view_134,getitem_137,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_11
call_function,<built-in function getitem>,{split_11: None},"(split_11, 0)",{},"{size_170: None, view_135: None}",,split_11,getitem_138,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_137
call_function,<built-in function getitem>,{split_11: None},"(split_11, 1)",{},"{size_171: None, view_136: None}",,getitem_137,getitem_139,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_138
call_function,<built-in function getitem>,{split_11: None},"(split_11, 2)",{},"{size_172: None, view_137: None}",,getitem_138,size_170,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_139
call_method,size,{getitem_137: None},"(getitem_137,)",{},{getitem_140: None},,getitem_139,getitem_140,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_170
call_function,<built-in function getitem>,{size_170: None},"(size_170, slice(None, -1, None))",{},{add_137: None},,size_170,add_137,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_140
call_function,<built-in function add>,{getitem_140: None},"(getitem_140, (20, 64))",{},{view_135: None},,getitem_140,view_135,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_137
call_method,view,"{getitem_137: None, add_137: None}","(getitem_137, add_137)",{},{permute_44: None},,add_137,permute_44,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_135
call_method,permute,{view_135: None},"(view_135, 0, 2, 1, 3)",{},"{matmul_22: None, size_174: None}",,view_135,size_171,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_44
call_method,size,{getitem_138: None},"(getitem_138,)",{},{getitem_141: None},,permute_44,getitem_141,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_171
call_function,<built-in function getitem>,{size_171: None},"(size_171, slice(None, -1, None))",{},{add_138: None},,size_171,add_138,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_141
call_function,<built-in function add>,{getitem_141: None},"(getitem_141, (20, 64))",{},{view_136: None},,getitem_141,view_136,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_138
call_method,view,"{getitem_138: None, add_138: None}","(getitem_138, add_138)",{},{permute_45: None},,add_138,permute_45,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_136
call_method,permute,{view_136: None},"(view_136, 0, 2, 1, 3)",{},"{transpose_11: None, size_175: None, output: None}",,view_136,size_172,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_45
call_method,size,{getitem_139: None},"(getitem_139,)",{},{getitem_142: None},,permute_45,getitem_142,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_172
call_function,<built-in function getitem>,{size_172: None},"(size_172, slice(None, -1, None))",{},{add_139: None},,size_172,add_139,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_142
call_function,<built-in function add>,{getitem_142: None},"(getitem_142, (20, 64))",{},{view_137: None},,getitem_142,view_137,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_139
call_method,view,"{getitem_139: None, add_139: None}","(getitem_139, add_139)",{},{permute_46: None},,add_139,permute_46,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_137
call_method,permute,{view_137: None},"(view_137, 0, 2, 1, 3)",{},"{size_173: None, getattr_97: None, matmul_23: None, output: None}",,view_137,transpose_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_46
call_method,transpose,{permute_45: None},"(permute_45, -1, -2)",{},{matmul_22: None},,permute_46,matmul_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_11
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_44: None, transpose_11: None}","(permute_44, transpose_11)",{},"{getattr_90: None, getattr_91: None, truediv_11: None}",,transpose_11,size_173,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_22
call_method,size,{permute_46: None},"(permute_46, -1)",{},{pow_23: None},,matmul_22,pow_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_173
call_function,<built-in function pow>,{size_173: None},"(size_173, 0.5)",{},{full_22: None},,size_173,getattr_90,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_23
call_function,<built-in function getattr>,{matmul_22: None},"(matmul_22, 'dtype')",{},{full_22: None},,pow_23,getattr_91,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_90
call_function,<built-in function getattr>,{matmul_22: None},"(matmul_22, 'device')",{},{full_22: None},,getattr_90,full_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_91
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_23: None, getattr_90: None, getattr_91: None}","([], pow_23)","{'dtype': getattr_90, 'device': getattr_91}",{truediv_11: None},,getattr_91,truediv_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_22
call_function,<built-in function truediv>,"{matmul_22: None, full_22: None}","(matmul_22, full_22)",{},"{getattr_92: None, getattr_94: None, getattr_95: None, getattr_96: None, to_11: None}",,full_22,size_174,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_11
call_method,size,{permute_44: None},"(permute_44, -2)",{},{sub_11: None},,truediv_11,size_175,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_174
call_method,size,{permute_45: None},"(permute_45, -2)",{},"{sub_11: None, getitem_143: None}",,size_174,transformer_h_11_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_175
get_attr,transformer.h.11.attn.bias,{},(),{},{getitem_143: None},,size_175,sub_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_11_attn_bias
call_function,<built-in function sub>,"{size_175: None, size_174: None}","(size_175, size_174)",{},{getitem_143: None},,transformer_h_11_attn_bias,getitem_143,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_11
call_function,<built-in function getitem>,"{transformer_h_11_attn_bias: None, sub_11: None, size_175: None}","(transformer_h_11_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_11, size_175, None), slice(None, size_175, None)))",{},{where_11: None},,sub_11,getattr_92,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_143
call_function,<built-in function getattr>,{truediv_11: None},"(truediv_11, 'dtype')",{},{finfo_11: None},,getitem_143,finfo_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_92
call_function,<class 'torch.finfo'>,{getattr_92: None},"(getattr_92,)",{},{getattr_93: None},,getattr_92,getattr_93,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_11
call_function,<built-in function getattr>,{finfo_11: None},"(finfo_11, 'min')",{},{full_23: None},,finfo_11,getattr_94,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_93
call_function,<built-in function getattr>,{truediv_11: None},"(truediv_11, 'dtype')",{},{full_23: None},,getattr_93,getattr_95,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_94
call_function,<built-in function getattr>,{truediv_11: None},"(truediv_11, 'device')",{},{full_23: None},,getattr_94,full_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_95
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_93: None, getattr_94: None, getattr_95: None}","([], getattr_93)","{'dtype': getattr_94, 'device': getattr_95}",{where_11: None},,getattr_95,getattr_96,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_23
call_function,<built-in function getattr>,{truediv_11: None},"(truediv_11, 'dtype')",{},{to_11: None},,full_23,to_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_96
call_method,to,"{truediv_11: None, getattr_96: None}","(truediv_11, getattr_96)",{},{where_11: None},,getattr_96,where_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_11
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_143: None, to_11: None, full_23: None}","(getitem_143, to_11, full_23)",{},{softmax_11: None},,to_11,softmax_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_11
call_function,<function softmax at 0x7f6fd5135ca0>,{where_11: None},"(where_11,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_12: None},,where_11,getattr_97,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_11
call_function,<built-in function getattr>,{permute_46: None},"(permute_46, 'dtype')",{},{type_12: None},,softmax_11,type_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_97
call_method,type,"{softmax_11: None, getattr_97: None}","(softmax_11, getattr_97)",{},{transformer_h_11_attn_attn_dropout: None},,getattr_97,transformer_h_11_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_12
call_module,transformer.h.11.attn.attn_dropout,{type_12: None},"(type_12,)",{},{matmul_23: None},,type_12,matmul_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.11.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_11_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_11_attn_attn_dropout: None, permute_46: None}","(transformer_h_11_attn_attn_dropout, permute_46)",{},{permute_47: None},,transformer_h_11_attn_attn_dropout,permute_47,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_23
call_method,permute,{matmul_23: None},"(matmul_23, 0, 2, 1, 3)",{},{contiguous_11: None},,matmul_23,contiguous_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_47
call_method,contiguous,{permute_47: None},"(permute_47,)",{},"{size_176: None, view_138: None}",,permute_47,size_176,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_11
call_method,size,{contiguous_11: None},"(contiguous_11,)",{},{getitem_144: None},,contiguous_11,getitem_144,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_176
call_function,<built-in function getitem>,{size_176: None},"(size_176, slice(None, -2, None))",{},{add_140: None},,size_176,add_140,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_144
call_function,<built-in function add>,{getitem_144: None},"(getitem_144, (1280,))",{},{view_138: None},,getitem_144,view_138,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_140
call_method,view,"{contiguous_11: None, add_140: None}","(contiguous_11, add_140)",{},"{size_177: None, size_178: None, view_139: None}",,add_140,size_177,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_138
call_method,size,{view_138: None},"(view_138,)",{},{getitem_145: None},,view_138,getitem_145,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.11.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_177
call_function,<built-in function getitem>,{size_177: None},"(size_177, slice(None, -1, None))",{},{add_141: None},,size_177,add_141,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.11.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_145
call_function,<built-in function add>,{getitem_145: None},"(getitem_145, (1280,))",{},{view_140: None},,getitem_145,transformer_h_11_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.11.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_141
get_attr,transformer.h.11.attn.c_proj.bias,{},(),{},{addmm_45: None},,add_141,size_178,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.11.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_11_attn_c_proj_bias
call_method,size,{view_138: None},"(view_138, -1)",{},{view_139: None},,transformer_h_11_attn_c_proj_bias,view_139,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.11.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_178
call_method,view,"{view_138: None, size_178: None}","(view_138, -1, size_178)",{},{addmm_45: None},,size_178,transformer_h_11_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.11.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_139
get_attr,transformer.h.11.attn.c_proj.weight,{},(),{},{addmm_45: None},,view_139,addmm_45,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.11.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_11_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_11_attn_c_proj_bias: None, view_139: None, transformer_h_11_attn_c_proj_weight: None}","(transformer_h_11_attn_c_proj_bias, view_139, transformer_h_11_attn_c_proj_weight)",{},{view_140: None},,transformer_h_11_attn_c_proj_weight,view_140,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.11.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_45
call_method,view,"{addmm_45: None, add_141: None}","(addmm_45, add_141)",{},{transformer_h_11_attn_resid_dropout: None},,addmm_45,transformer_h_11_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.11.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_140
call_module,transformer.h.11.attn.resid_dropout,{view_140: None},"(view_140,)",{},{add_142: None},,view_140,add_142,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.11.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_11_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_11_attn_resid_dropout: None, add_135: None}","(transformer_h_11_attn_resid_dropout, add_135)",{},"{transformer_h_11_ln_2: None, add_147: None}",,transformer_h_11_attn_resid_dropout,transformer_h_11_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_142
call_module,transformer.h.11.ln_2,{add_142: None},"(add_142,)",{},"{size_179: None, size_180: None, view_141: None}",,add_142,size_179,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_11_ln_2
call_method,size,{transformer_h_11_ln_2: None},"(transformer_h_11_ln_2,)",{},{getitem_146: None},,transformer_h_11_ln_2,getitem_146,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_179
call_function,<built-in function getitem>,{size_179: None},"(size_179, slice(None, -1, None))",{},{add_143: None},,size_179,add_143,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_146
call_function,<built-in function add>,{getitem_146: None},"(getitem_146, (5120,))",{},{view_142: None},,getitem_146,transformer_h_11_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_143
get_attr,transformer.h.11.mlp.c_fc.bias,{},(),{},{addmm_46: None},,add_143,size_180,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_11_mlp_c_fc_bias
call_method,size,{transformer_h_11_ln_2: None},"(transformer_h_11_ln_2, -1)",{},{view_141: None},,transformer_h_11_mlp_c_fc_bias,view_141,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_180
call_method,view,"{transformer_h_11_ln_2: None, size_180: None}","(transformer_h_11_ln_2, -1, size_180)",{},{addmm_46: None},,size_180,transformer_h_11_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_141
get_attr,transformer.h.11.mlp.c_fc.weight,{},(),{},{addmm_46: None},,view_141,addmm_46,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_11_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_11_mlp_c_fc_bias: None, view_141: None, transformer_h_11_mlp_c_fc_weight: None}","(transformer_h_11_mlp_c_fc_bias, view_141, transformer_h_11_mlp_c_fc_weight)",{},{view_142: None},,transformer_h_11_mlp_c_fc_weight,view_142,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_46
call_method,view,"{addmm_46: None, add_143: None}","(addmm_46, add_143)",{},"{mul_44: None, pow_24: None, add_144: None}",,addmm_46,mul_44,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_142
call_function,<built-in function mul>,{view_142: None},"(0.5, view_142)",{},{mul_47: None},,view_142,pow_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_44
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_142: None},"(view_142, 3.0)",{},{mul_45: None},,mul_44,mul_45,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_24
call_function,<built-in function mul>,{pow_24: None},"(0.044715, pow_24)",{},{add_144: None},,pow_24,add_144,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_45
call_function,<built-in function add>,"{view_142: None, mul_45: None}","(view_142, mul_45)",{},{mul_46: None},,mul_45,mul_46,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_144
call_function,<built-in function mul>,{add_144: None},"(0.7978845608028654, add_144)",{},{tanh_11: None},,add_144,tanh_11,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_46
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_46: None},"(mul_46,)",{},{add_145: None},,mul_46,add_145,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_11
call_function,<built-in function add>,{tanh_11: None},"(1.0, tanh_11)",{},{mul_47: None},,tanh_11,mul_47,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_145
call_function,<built-in function mul>,"{mul_44: None, add_145: None}","(mul_44, add_145)",{},"{size_181: None, size_182: None, view_143: None}",,add_145,size_181,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_47
call_method,size,{mul_47: None},"(mul_47,)",{},{getitem_147: None},,mul_47,getitem_147,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_181
call_function,<built-in function getitem>,{size_181: None},"(size_181, slice(None, -1, None))",{},{add_146: None},,size_181,add_146,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_147
call_function,<built-in function add>,{getitem_147: None},"(getitem_147, (1280,))",{},{view_144: None},,getitem_147,transformer_h_11_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_146
get_attr,transformer.h.11.mlp.c_proj.bias,{},(),{},{addmm_47: None},,add_146,size_182,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_11_mlp_c_proj_bias
call_method,size,{mul_47: None},"(mul_47, -1)",{},{view_143: None},,transformer_h_11_mlp_c_proj_bias,view_143,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_182
call_method,view,"{mul_47: None, size_182: None}","(mul_47, -1, size_182)",{},{addmm_47: None},,size_182,transformer_h_11_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_143
get_attr,transformer.h.11.mlp.c_proj.weight,{},(),{},{addmm_47: None},,view_143,addmm_47,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_11_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_11_mlp_c_proj_bias: None, view_143: None, transformer_h_11_mlp_c_proj_weight: None}","(transformer_h_11_mlp_c_proj_bias, view_143, transformer_h_11_mlp_c_proj_weight)",{},{view_144: None},,transformer_h_11_mlp_c_proj_weight,view_144,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_47
call_method,view,"{addmm_47: None, add_146: None}","(addmm_47, add_146)",{},{transformer_h_11_mlp_dropout: None},,addmm_47,transformer_h_11_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_144
call_module,transformer.h.11.mlp.dropout,{view_144: None},"(view_144,)",{},{add_147: None},,view_144,add_147,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.11.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.11.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_11_mlp_dropout
call_function,<built-in function add>,"{add_142: None, transformer_h_11_mlp_dropout: None}","(add_142, transformer_h_11_mlp_dropout)",{},"{transformer_h_12_ln_1: None, add_154: None}",,transformer_h_11_mlp_dropout,transformer_h_12_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.11', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_147
call_module,transformer.h.12.ln_1,{add_147: None},"(add_147,)",{},"{size_183: None, size_184: None, view_145: None}",,add_147,size_183,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_12_ln_1
call_method,size,{transformer_h_12_ln_1: None},"(transformer_h_12_ln_1,)",{},{getitem_148: None},,transformer_h_12_ln_1,getitem_148,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.12.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_183
call_function,<built-in function getitem>,{size_183: None},"(size_183, slice(None, -1, None))",{},{add_148: None},,size_183,add_148,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.12.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_148
call_function,<built-in function add>,{getitem_148: None},"(getitem_148, (3840,))",{},{view_146: None},,getitem_148,transformer_h_12_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.12.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_148
get_attr,transformer.h.12.attn.c_attn.bias,{},(),{},{addmm_48: None},,add_148,size_184,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.12.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_12_attn_c_attn_bias
call_method,size,{transformer_h_12_ln_1: None},"(transformer_h_12_ln_1, -1)",{},{view_145: None},,transformer_h_12_attn_c_attn_bias,view_145,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.12.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_184
call_method,view,"{transformer_h_12_ln_1: None, size_184: None}","(transformer_h_12_ln_1, -1, size_184)",{},{addmm_48: None},,size_184,transformer_h_12_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.12.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_145
get_attr,transformer.h.12.attn.c_attn.weight,{},(),{},{addmm_48: None},,view_145,addmm_48,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.12.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_12_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_12_attn_c_attn_bias: None, view_145: None, transformer_h_12_attn_c_attn_weight: None}","(transformer_h_12_attn_c_attn_bias, view_145, transformer_h_12_attn_c_attn_weight)",{},{view_146: None},,transformer_h_12_attn_c_attn_weight,view_146,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.12.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_48
call_method,view,"{addmm_48: None, add_148: None}","(addmm_48, add_148)",{},{split_12: None},,addmm_48,split_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.12.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_146
call_method,split,{view_146: None},"(view_146, 1280)",{'dim': 2},"{getitem_149: None, getitem_150: None, getitem_151: None}",,view_146,getitem_149,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_12
call_function,<built-in function getitem>,{split_12: None},"(split_12, 0)",{},"{size_185: None, view_147: None}",,split_12,getitem_150,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_149
call_function,<built-in function getitem>,{split_12: None},"(split_12, 1)",{},"{size_186: None, view_148: None}",,getitem_149,getitem_151,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_150
call_function,<built-in function getitem>,{split_12: None},"(split_12, 2)",{},"{size_187: None, view_149: None}",,getitem_150,size_185,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_151
call_method,size,{getitem_149: None},"(getitem_149,)",{},{getitem_152: None},,getitem_151,getitem_152,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_185
call_function,<built-in function getitem>,{size_185: None},"(size_185, slice(None, -1, None))",{},{add_149: None},,size_185,add_149,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_152
call_function,<built-in function add>,{getitem_152: None},"(getitem_152, (20, 64))",{},{view_147: None},,getitem_152,view_147,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_149
call_method,view,"{getitem_149: None, add_149: None}","(getitem_149, add_149)",{},{permute_48: None},,add_149,permute_48,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_147
call_method,permute,{view_147: None},"(view_147, 0, 2, 1, 3)",{},"{matmul_24: None, size_189: None}",,view_147,size_186,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_48
call_method,size,{getitem_150: None},"(getitem_150,)",{},{getitem_153: None},,permute_48,getitem_153,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_186
call_function,<built-in function getitem>,{size_186: None},"(size_186, slice(None, -1, None))",{},{add_150: None},,size_186,add_150,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_153
call_function,<built-in function add>,{getitem_153: None},"(getitem_153, (20, 64))",{},{view_148: None},,getitem_153,view_148,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_150
call_method,view,"{getitem_150: None, add_150: None}","(getitem_150, add_150)",{},{permute_49: None},,add_150,permute_49,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_148
call_method,permute,{view_148: None},"(view_148, 0, 2, 1, 3)",{},"{transpose_12: None, size_190: None, output: None}",,view_148,size_187,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_49
call_method,size,{getitem_151: None},"(getitem_151,)",{},{getitem_154: None},,permute_49,getitem_154,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_187
call_function,<built-in function getitem>,{size_187: None},"(size_187, slice(None, -1, None))",{},{add_151: None},,size_187,add_151,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_154
call_function,<built-in function add>,{getitem_154: None},"(getitem_154, (20, 64))",{},{view_149: None},,getitem_154,view_149,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_151
call_method,view,"{getitem_151: None, add_151: None}","(getitem_151, add_151)",{},{permute_50: None},,add_151,permute_50,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_149
call_method,permute,{view_149: None},"(view_149, 0, 2, 1, 3)",{},"{size_188: None, getattr_105: None, matmul_25: None, output: None}",,view_149,transpose_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_50
call_method,transpose,{permute_49: None},"(permute_49, -1, -2)",{},{matmul_24: None},,permute_50,matmul_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_12
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_48: None, transpose_12: None}","(permute_48, transpose_12)",{},"{getattr_98: None, getattr_99: None, truediv_12: None}",,transpose_12,size_188,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_24
call_method,size,{permute_50: None},"(permute_50, -1)",{},{pow_25: None},,matmul_24,pow_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_188
call_function,<built-in function pow>,{size_188: None},"(size_188, 0.5)",{},{full_24: None},,size_188,getattr_98,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_25
call_function,<built-in function getattr>,{matmul_24: None},"(matmul_24, 'dtype')",{},{full_24: None},,pow_25,getattr_99,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_98
call_function,<built-in function getattr>,{matmul_24: None},"(matmul_24, 'device')",{},{full_24: None},,getattr_98,full_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_99
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_25: None, getattr_98: None, getattr_99: None}","([], pow_25)","{'dtype': getattr_98, 'device': getattr_99}",{truediv_12: None},,getattr_99,truediv_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_24
call_function,<built-in function truediv>,"{matmul_24: None, full_24: None}","(matmul_24, full_24)",{},"{getattr_100: None, getattr_102: None, getattr_103: None, getattr_104: None, to_12: None}",,full_24,size_189,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_12
call_method,size,{permute_48: None},"(permute_48, -2)",{},{sub_12: None},,truediv_12,size_190,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_189
call_method,size,{permute_49: None},"(permute_49, -2)",{},"{sub_12: None, getitem_155: None}",,size_189,transformer_h_12_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_190
get_attr,transformer.h.12.attn.bias,{},(),{},{getitem_155: None},,size_190,sub_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_12_attn_bias
call_function,<built-in function sub>,"{size_190: None, size_189: None}","(size_190, size_189)",{},{getitem_155: None},,transformer_h_12_attn_bias,getitem_155,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_12
call_function,<built-in function getitem>,"{transformer_h_12_attn_bias: None, sub_12: None, size_190: None}","(transformer_h_12_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_12, size_190, None), slice(None, size_190, None)))",{},{where_12: None},,sub_12,getattr_100,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_155
call_function,<built-in function getattr>,{truediv_12: None},"(truediv_12, 'dtype')",{},{finfo_12: None},,getitem_155,finfo_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_100
call_function,<class 'torch.finfo'>,{getattr_100: None},"(getattr_100,)",{},{getattr_101: None},,getattr_100,getattr_101,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_12
call_function,<built-in function getattr>,{finfo_12: None},"(finfo_12, 'min')",{},{full_25: None},,finfo_12,getattr_102,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_101
call_function,<built-in function getattr>,{truediv_12: None},"(truediv_12, 'dtype')",{},{full_25: None},,getattr_101,getattr_103,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_102
call_function,<built-in function getattr>,{truediv_12: None},"(truediv_12, 'device')",{},{full_25: None},,getattr_102,full_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_103
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_101: None, getattr_102: None, getattr_103: None}","([], getattr_101)","{'dtype': getattr_102, 'device': getattr_103}",{where_12: None},,getattr_103,getattr_104,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_25
call_function,<built-in function getattr>,{truediv_12: None},"(truediv_12, 'dtype')",{},{to_12: None},,full_25,to_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_104
call_method,to,"{truediv_12: None, getattr_104: None}","(truediv_12, getattr_104)",{},{where_12: None},,getattr_104,where_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_12
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_155: None, to_12: None, full_25: None}","(getitem_155, to_12, full_25)",{},{softmax_12: None},,to_12,softmax_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_12
call_function,<function softmax at 0x7f6fd5135ca0>,{where_12: None},"(where_12,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_13: None},,where_12,getattr_105,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_12
call_function,<built-in function getattr>,{permute_50: None},"(permute_50, 'dtype')",{},{type_13: None},,softmax_12,type_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_105
call_method,type,"{softmax_12: None, getattr_105: None}","(softmax_12, getattr_105)",{},{transformer_h_12_attn_attn_dropout: None},,getattr_105,transformer_h_12_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_13
call_module,transformer.h.12.attn.attn_dropout,{type_13: None},"(type_13,)",{},{matmul_25: None},,type_13,matmul_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.12.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_12_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_12_attn_attn_dropout: None, permute_50: None}","(transformer_h_12_attn_attn_dropout, permute_50)",{},{permute_51: None},,transformer_h_12_attn_attn_dropout,permute_51,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_25
call_method,permute,{matmul_25: None},"(matmul_25, 0, 2, 1, 3)",{},{contiguous_12: None},,matmul_25,contiguous_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_51
call_method,contiguous,{permute_51: None},"(permute_51,)",{},"{size_191: None, view_150: None}",,permute_51,size_191,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_12
call_method,size,{contiguous_12: None},"(contiguous_12,)",{},{getitem_156: None},,contiguous_12,getitem_156,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_191
call_function,<built-in function getitem>,{size_191: None},"(size_191, slice(None, -2, None))",{},{add_152: None},,size_191,add_152,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_156
call_function,<built-in function add>,{getitem_156: None},"(getitem_156, (1280,))",{},{view_150: None},,getitem_156,view_150,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_152
call_method,view,"{contiguous_12: None, add_152: None}","(contiguous_12, add_152)",{},"{size_192: None, size_193: None, view_151: None}",,add_152,size_192,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_150
call_method,size,{view_150: None},"(view_150,)",{},{getitem_157: None},,view_150,getitem_157,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.12.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_192
call_function,<built-in function getitem>,{size_192: None},"(size_192, slice(None, -1, None))",{},{add_153: None},,size_192,add_153,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.12.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_157
call_function,<built-in function add>,{getitem_157: None},"(getitem_157, (1280,))",{},{view_152: None},,getitem_157,transformer_h_12_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.12.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_153
get_attr,transformer.h.12.attn.c_proj.bias,{},(),{},{addmm_49: None},,add_153,size_193,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.12.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_12_attn_c_proj_bias
call_method,size,{view_150: None},"(view_150, -1)",{},{view_151: None},,transformer_h_12_attn_c_proj_bias,view_151,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.12.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_193
call_method,view,"{view_150: None, size_193: None}","(view_150, -1, size_193)",{},{addmm_49: None},,size_193,transformer_h_12_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.12.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_151
get_attr,transformer.h.12.attn.c_proj.weight,{},(),{},{addmm_49: None},,view_151,addmm_49,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.12.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_12_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_12_attn_c_proj_bias: None, view_151: None, transformer_h_12_attn_c_proj_weight: None}","(transformer_h_12_attn_c_proj_bias, view_151, transformer_h_12_attn_c_proj_weight)",{},{view_152: None},,transformer_h_12_attn_c_proj_weight,view_152,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.12.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_49
call_method,view,"{addmm_49: None, add_153: None}","(addmm_49, add_153)",{},{transformer_h_12_attn_resid_dropout: None},,addmm_49,transformer_h_12_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.12.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_152
call_module,transformer.h.12.attn.resid_dropout,{view_152: None},"(view_152,)",{},{add_154: None},,view_152,add_154,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.12.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_12_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_12_attn_resid_dropout: None, add_147: None}","(transformer_h_12_attn_resid_dropout, add_147)",{},"{transformer_h_12_ln_2: None, add_159: None}",,transformer_h_12_attn_resid_dropout,transformer_h_12_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_154
call_module,transformer.h.12.ln_2,{add_154: None},"(add_154,)",{},"{size_194: None, size_195: None, view_153: None}",,add_154,size_194,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_12_ln_2
call_method,size,{transformer_h_12_ln_2: None},"(transformer_h_12_ln_2,)",{},{getitem_158: None},,transformer_h_12_ln_2,getitem_158,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_194
call_function,<built-in function getitem>,{size_194: None},"(size_194, slice(None, -1, None))",{},{add_155: None},,size_194,add_155,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_158
call_function,<built-in function add>,{getitem_158: None},"(getitem_158, (5120,))",{},{view_154: None},,getitem_158,transformer_h_12_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_155
get_attr,transformer.h.12.mlp.c_fc.bias,{},(),{},{addmm_50: None},,add_155,size_195,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_12_mlp_c_fc_bias
call_method,size,{transformer_h_12_ln_2: None},"(transformer_h_12_ln_2, -1)",{},{view_153: None},,transformer_h_12_mlp_c_fc_bias,view_153,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_195
call_method,view,"{transformer_h_12_ln_2: None, size_195: None}","(transformer_h_12_ln_2, -1, size_195)",{},{addmm_50: None},,size_195,transformer_h_12_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_153
get_attr,transformer.h.12.mlp.c_fc.weight,{},(),{},{addmm_50: None},,view_153,addmm_50,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_12_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_12_mlp_c_fc_bias: None, view_153: None, transformer_h_12_mlp_c_fc_weight: None}","(transformer_h_12_mlp_c_fc_bias, view_153, transformer_h_12_mlp_c_fc_weight)",{},{view_154: None},,transformer_h_12_mlp_c_fc_weight,view_154,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_50
call_method,view,"{addmm_50: None, add_155: None}","(addmm_50, add_155)",{},"{mul_48: None, pow_26: None, add_156: None}",,addmm_50,mul_48,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_154
call_function,<built-in function mul>,{view_154: None},"(0.5, view_154)",{},{mul_51: None},,view_154,pow_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_48
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_154: None},"(view_154, 3.0)",{},{mul_49: None},,mul_48,mul_49,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_26
call_function,<built-in function mul>,{pow_26: None},"(0.044715, pow_26)",{},{add_156: None},,pow_26,add_156,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_49
call_function,<built-in function add>,"{view_154: None, mul_49: None}","(view_154, mul_49)",{},{mul_50: None},,mul_49,mul_50,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_156
call_function,<built-in function mul>,{add_156: None},"(0.7978845608028654, add_156)",{},{tanh_12: None},,add_156,tanh_12,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_50
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_50: None},"(mul_50,)",{},{add_157: None},,mul_50,add_157,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_12
call_function,<built-in function add>,{tanh_12: None},"(1.0, tanh_12)",{},{mul_51: None},,tanh_12,mul_51,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_157
call_function,<built-in function mul>,"{mul_48: None, add_157: None}","(mul_48, add_157)",{},"{size_196: None, size_197: None, view_155: None}",,add_157,size_196,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_51
call_method,size,{mul_51: None},"(mul_51,)",{},{getitem_159: None},,mul_51,getitem_159,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_196
call_function,<built-in function getitem>,{size_196: None},"(size_196, slice(None, -1, None))",{},{add_158: None},,size_196,add_158,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_159
call_function,<built-in function add>,{getitem_159: None},"(getitem_159, (1280,))",{},{view_156: None},,getitem_159,transformer_h_12_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_158
get_attr,transformer.h.12.mlp.c_proj.bias,{},(),{},{addmm_51: None},,add_158,size_197,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_12_mlp_c_proj_bias
call_method,size,{mul_51: None},"(mul_51, -1)",{},{view_155: None},,transformer_h_12_mlp_c_proj_bias,view_155,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_197
call_method,view,"{mul_51: None, size_197: None}","(mul_51, -1, size_197)",{},{addmm_51: None},,size_197,transformer_h_12_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_155
get_attr,transformer.h.12.mlp.c_proj.weight,{},(),{},{addmm_51: None},,view_155,addmm_51,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_12_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_12_mlp_c_proj_bias: None, view_155: None, transformer_h_12_mlp_c_proj_weight: None}","(transformer_h_12_mlp_c_proj_bias, view_155, transformer_h_12_mlp_c_proj_weight)",{},{view_156: None},,transformer_h_12_mlp_c_proj_weight,view_156,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_51
call_method,view,"{addmm_51: None, add_158: None}","(addmm_51, add_158)",{},{transformer_h_12_mlp_dropout: None},,addmm_51,transformer_h_12_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_156
call_module,transformer.h.12.mlp.dropout,{view_156: None},"(view_156,)",{},{add_159: None},,view_156,add_159,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.12.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.12.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_12_mlp_dropout
call_function,<built-in function add>,"{add_154: None, transformer_h_12_mlp_dropout: None}","(add_154, transformer_h_12_mlp_dropout)",{},"{transformer_h_13_ln_1: None, add_166: None}",,transformer_h_12_mlp_dropout,transformer_h_13_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.12', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_159
call_module,transformer.h.13.ln_1,{add_159: None},"(add_159,)",{},"{size_198: None, size_199: None, view_157: None}",,add_159,size_198,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_13_ln_1
call_method,size,{transformer_h_13_ln_1: None},"(transformer_h_13_ln_1,)",{},{getitem_160: None},,transformer_h_13_ln_1,getitem_160,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.13.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_198
call_function,<built-in function getitem>,{size_198: None},"(size_198, slice(None, -1, None))",{},{add_160: None},,size_198,add_160,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.13.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_160
call_function,<built-in function add>,{getitem_160: None},"(getitem_160, (3840,))",{},{view_158: None},,getitem_160,transformer_h_13_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.13.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_160
get_attr,transformer.h.13.attn.c_attn.bias,{},(),{},{addmm_52: None},,add_160,size_199,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.13.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_13_attn_c_attn_bias
call_method,size,{transformer_h_13_ln_1: None},"(transformer_h_13_ln_1, -1)",{},{view_157: None},,transformer_h_13_attn_c_attn_bias,view_157,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.13.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_199
call_method,view,"{transformer_h_13_ln_1: None, size_199: None}","(transformer_h_13_ln_1, -1, size_199)",{},{addmm_52: None},,size_199,transformer_h_13_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.13.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_157
get_attr,transformer.h.13.attn.c_attn.weight,{},(),{},{addmm_52: None},,view_157,addmm_52,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.13.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_13_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_13_attn_c_attn_bias: None, view_157: None, transformer_h_13_attn_c_attn_weight: None}","(transformer_h_13_attn_c_attn_bias, view_157, transformer_h_13_attn_c_attn_weight)",{},{view_158: None},,transformer_h_13_attn_c_attn_weight,view_158,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.13.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_52
call_method,view,"{addmm_52: None, add_160: None}","(addmm_52, add_160)",{},{split_13: None},,addmm_52,split_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.13.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_158
call_method,split,{view_158: None},"(view_158, 1280)",{'dim': 2},"{getitem_161: None, getitem_162: None, getitem_163: None}",,view_158,getitem_161,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_13
call_function,<built-in function getitem>,{split_13: None},"(split_13, 0)",{},"{size_200: None, view_159: None}",,split_13,getitem_162,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_161
call_function,<built-in function getitem>,{split_13: None},"(split_13, 1)",{},"{size_201: None, view_160: None}",,getitem_161,getitem_163,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_162
call_function,<built-in function getitem>,{split_13: None},"(split_13, 2)",{},"{size_202: None, view_161: None}",,getitem_162,size_200,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_163
call_method,size,{getitem_161: None},"(getitem_161,)",{},{getitem_164: None},,getitem_163,getitem_164,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_200
call_function,<built-in function getitem>,{size_200: None},"(size_200, slice(None, -1, None))",{},{add_161: None},,size_200,add_161,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_164
call_function,<built-in function add>,{getitem_164: None},"(getitem_164, (20, 64))",{},{view_159: None},,getitem_164,view_159,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_161
call_method,view,"{getitem_161: None, add_161: None}","(getitem_161, add_161)",{},{permute_52: None},,add_161,permute_52,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_159
call_method,permute,{view_159: None},"(view_159, 0, 2, 1, 3)",{},"{matmul_26: None, size_204: None}",,view_159,size_201,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_52
call_method,size,{getitem_162: None},"(getitem_162,)",{},{getitem_165: None},,permute_52,getitem_165,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_201
call_function,<built-in function getitem>,{size_201: None},"(size_201, slice(None, -1, None))",{},{add_162: None},,size_201,add_162,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_165
call_function,<built-in function add>,{getitem_165: None},"(getitem_165, (20, 64))",{},{view_160: None},,getitem_165,view_160,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_162
call_method,view,"{getitem_162: None, add_162: None}","(getitem_162, add_162)",{},{permute_53: None},,add_162,permute_53,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_160
call_method,permute,{view_160: None},"(view_160, 0, 2, 1, 3)",{},"{transpose_13: None, size_205: None, output: None}",,view_160,size_202,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_53
call_method,size,{getitem_163: None},"(getitem_163,)",{},{getitem_166: None},,permute_53,getitem_166,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_202
call_function,<built-in function getitem>,{size_202: None},"(size_202, slice(None, -1, None))",{},{add_163: None},,size_202,add_163,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_166
call_function,<built-in function add>,{getitem_166: None},"(getitem_166, (20, 64))",{},{view_161: None},,getitem_166,view_161,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_163
call_method,view,"{getitem_163: None, add_163: None}","(getitem_163, add_163)",{},{permute_54: None},,add_163,permute_54,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_161
call_method,permute,{view_161: None},"(view_161, 0, 2, 1, 3)",{},"{size_203: None, getattr_113: None, matmul_27: None, output: None}",,view_161,transpose_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_54
call_method,transpose,{permute_53: None},"(permute_53, -1, -2)",{},{matmul_26: None},,permute_54,matmul_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_13
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_52: None, transpose_13: None}","(permute_52, transpose_13)",{},"{getattr_106: None, getattr_107: None, truediv_13: None}",,transpose_13,size_203,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_26
call_method,size,{permute_54: None},"(permute_54, -1)",{},{pow_27: None},,matmul_26,pow_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_203
call_function,<built-in function pow>,{size_203: None},"(size_203, 0.5)",{},{full_26: None},,size_203,getattr_106,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_27
call_function,<built-in function getattr>,{matmul_26: None},"(matmul_26, 'dtype')",{},{full_26: None},,pow_27,getattr_107,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_106
call_function,<built-in function getattr>,{matmul_26: None},"(matmul_26, 'device')",{},{full_26: None},,getattr_106,full_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_107
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_27: None, getattr_106: None, getattr_107: None}","([], pow_27)","{'dtype': getattr_106, 'device': getattr_107}",{truediv_13: None},,getattr_107,truediv_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_26
call_function,<built-in function truediv>,"{matmul_26: None, full_26: None}","(matmul_26, full_26)",{},"{getattr_108: None, getattr_110: None, getattr_111: None, getattr_112: None, to_13: None}",,full_26,size_204,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_13
call_method,size,{permute_52: None},"(permute_52, -2)",{},{sub_13: None},,truediv_13,size_205,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_204
call_method,size,{permute_53: None},"(permute_53, -2)",{},"{sub_13: None, getitem_167: None}",,size_204,transformer_h_13_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_205
get_attr,transformer.h.13.attn.bias,{},(),{},{getitem_167: None},,size_205,sub_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_13_attn_bias
call_function,<built-in function sub>,"{size_205: None, size_204: None}","(size_205, size_204)",{},{getitem_167: None},,transformer_h_13_attn_bias,getitem_167,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_13
call_function,<built-in function getitem>,"{transformer_h_13_attn_bias: None, sub_13: None, size_205: None}","(transformer_h_13_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_13, size_205, None), slice(None, size_205, None)))",{},{where_13: None},,sub_13,getattr_108,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_167
call_function,<built-in function getattr>,{truediv_13: None},"(truediv_13, 'dtype')",{},{finfo_13: None},,getitem_167,finfo_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_108
call_function,<class 'torch.finfo'>,{getattr_108: None},"(getattr_108,)",{},{getattr_109: None},,getattr_108,getattr_109,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_13
call_function,<built-in function getattr>,{finfo_13: None},"(finfo_13, 'min')",{},{full_27: None},,finfo_13,getattr_110,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_109
call_function,<built-in function getattr>,{truediv_13: None},"(truediv_13, 'dtype')",{},{full_27: None},,getattr_109,getattr_111,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_110
call_function,<built-in function getattr>,{truediv_13: None},"(truediv_13, 'device')",{},{full_27: None},,getattr_110,full_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_111
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_109: None, getattr_110: None, getattr_111: None}","([], getattr_109)","{'dtype': getattr_110, 'device': getattr_111}",{where_13: None},,getattr_111,getattr_112,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_27
call_function,<built-in function getattr>,{truediv_13: None},"(truediv_13, 'dtype')",{},{to_13: None},,full_27,to_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_112
call_method,to,"{truediv_13: None, getattr_112: None}","(truediv_13, getattr_112)",{},{where_13: None},,getattr_112,where_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_13
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_167: None, to_13: None, full_27: None}","(getitem_167, to_13, full_27)",{},{softmax_13: None},,to_13,softmax_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_13
call_function,<function softmax at 0x7f6fd5135ca0>,{where_13: None},"(where_13,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_14: None},,where_13,getattr_113,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_13
call_function,<built-in function getattr>,{permute_54: None},"(permute_54, 'dtype')",{},{type_14: None},,softmax_13,type_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_113
call_method,type,"{softmax_13: None, getattr_113: None}","(softmax_13, getattr_113)",{},{transformer_h_13_attn_attn_dropout: None},,getattr_113,transformer_h_13_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_14
call_module,transformer.h.13.attn.attn_dropout,{type_14: None},"(type_14,)",{},{matmul_27: None},,type_14,matmul_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.13.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_13_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_13_attn_attn_dropout: None, permute_54: None}","(transformer_h_13_attn_attn_dropout, permute_54)",{},{permute_55: None},,transformer_h_13_attn_attn_dropout,permute_55,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_27
call_method,permute,{matmul_27: None},"(matmul_27, 0, 2, 1, 3)",{},{contiguous_13: None},,matmul_27,contiguous_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_55
call_method,contiguous,{permute_55: None},"(permute_55,)",{},"{size_206: None, view_162: None}",,permute_55,size_206,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_13
call_method,size,{contiguous_13: None},"(contiguous_13,)",{},{getitem_168: None},,contiguous_13,getitem_168,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_206
call_function,<built-in function getitem>,{size_206: None},"(size_206, slice(None, -2, None))",{},{add_164: None},,size_206,add_164,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_168
call_function,<built-in function add>,{getitem_168: None},"(getitem_168, (1280,))",{},{view_162: None},,getitem_168,view_162,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_164
call_method,view,"{contiguous_13: None, add_164: None}","(contiguous_13, add_164)",{},"{size_207: None, size_208: None, view_163: None}",,add_164,size_207,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_162
call_method,size,{view_162: None},"(view_162,)",{},{getitem_169: None},,view_162,getitem_169,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.13.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_207
call_function,<built-in function getitem>,{size_207: None},"(size_207, slice(None, -1, None))",{},{add_165: None},,size_207,add_165,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.13.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_169
call_function,<built-in function add>,{getitem_169: None},"(getitem_169, (1280,))",{},{view_164: None},,getitem_169,transformer_h_13_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.13.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_165
get_attr,transformer.h.13.attn.c_proj.bias,{},(),{},{addmm_53: None},,add_165,size_208,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.13.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_13_attn_c_proj_bias
call_method,size,{view_162: None},"(view_162, -1)",{},{view_163: None},,transformer_h_13_attn_c_proj_bias,view_163,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.13.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_208
call_method,view,"{view_162: None, size_208: None}","(view_162, -1, size_208)",{},{addmm_53: None},,size_208,transformer_h_13_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.13.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_163
get_attr,transformer.h.13.attn.c_proj.weight,{},(),{},{addmm_53: None},,view_163,addmm_53,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.13.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_13_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_13_attn_c_proj_bias: None, view_163: None, transformer_h_13_attn_c_proj_weight: None}","(transformer_h_13_attn_c_proj_bias, view_163, transformer_h_13_attn_c_proj_weight)",{},{view_164: None},,transformer_h_13_attn_c_proj_weight,view_164,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.13.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_53
call_method,view,"{addmm_53: None, add_165: None}","(addmm_53, add_165)",{},{transformer_h_13_attn_resid_dropout: None},,addmm_53,transformer_h_13_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.13.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_164
call_module,transformer.h.13.attn.resid_dropout,{view_164: None},"(view_164,)",{},{add_166: None},,view_164,add_166,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.13.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_13_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_13_attn_resid_dropout: None, add_159: None}","(transformer_h_13_attn_resid_dropout, add_159)",{},"{transformer_h_13_ln_2: None, add_171: None}",,transformer_h_13_attn_resid_dropout,transformer_h_13_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_166
call_module,transformer.h.13.ln_2,{add_166: None},"(add_166,)",{},"{size_209: None, size_210: None, view_165: None}",,add_166,size_209,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_13_ln_2
call_method,size,{transformer_h_13_ln_2: None},"(transformer_h_13_ln_2,)",{},{getitem_170: None},,transformer_h_13_ln_2,getitem_170,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_209
call_function,<built-in function getitem>,{size_209: None},"(size_209, slice(None, -1, None))",{},{add_167: None},,size_209,add_167,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_170
call_function,<built-in function add>,{getitem_170: None},"(getitem_170, (5120,))",{},{view_166: None},,getitem_170,transformer_h_13_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_167
get_attr,transformer.h.13.mlp.c_fc.bias,{},(),{},{addmm_54: None},,add_167,size_210,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_13_mlp_c_fc_bias
call_method,size,{transformer_h_13_ln_2: None},"(transformer_h_13_ln_2, -1)",{},{view_165: None},,transformer_h_13_mlp_c_fc_bias,view_165,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_210
call_method,view,"{transformer_h_13_ln_2: None, size_210: None}","(transformer_h_13_ln_2, -1, size_210)",{},{addmm_54: None},,size_210,transformer_h_13_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_165
get_attr,transformer.h.13.mlp.c_fc.weight,{},(),{},{addmm_54: None},,view_165,addmm_54,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_13_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_13_mlp_c_fc_bias: None, view_165: None, transformer_h_13_mlp_c_fc_weight: None}","(transformer_h_13_mlp_c_fc_bias, view_165, transformer_h_13_mlp_c_fc_weight)",{},{view_166: None},,transformer_h_13_mlp_c_fc_weight,view_166,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_54
call_method,view,"{addmm_54: None, add_167: None}","(addmm_54, add_167)",{},"{mul_52: None, pow_28: None, add_168: None}",,addmm_54,mul_52,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_166
call_function,<built-in function mul>,{view_166: None},"(0.5, view_166)",{},{mul_55: None},,view_166,pow_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_52
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_166: None},"(view_166, 3.0)",{},{mul_53: None},,mul_52,mul_53,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_28
call_function,<built-in function mul>,{pow_28: None},"(0.044715, pow_28)",{},{add_168: None},,pow_28,add_168,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_53
call_function,<built-in function add>,"{view_166: None, mul_53: None}","(view_166, mul_53)",{},{mul_54: None},,mul_53,mul_54,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_168
call_function,<built-in function mul>,{add_168: None},"(0.7978845608028654, add_168)",{},{tanh_13: None},,add_168,tanh_13,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_54
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_54: None},"(mul_54,)",{},{add_169: None},,mul_54,add_169,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_13
call_function,<built-in function add>,{tanh_13: None},"(1.0, tanh_13)",{},{mul_55: None},,tanh_13,mul_55,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_169
call_function,<built-in function mul>,"{mul_52: None, add_169: None}","(mul_52, add_169)",{},"{size_211: None, size_212: None, view_167: None}",,add_169,size_211,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_55
call_method,size,{mul_55: None},"(mul_55,)",{},{getitem_171: None},,mul_55,getitem_171,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_211
call_function,<built-in function getitem>,{size_211: None},"(size_211, slice(None, -1, None))",{},{add_170: None},,size_211,add_170,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_171
call_function,<built-in function add>,{getitem_171: None},"(getitem_171, (1280,))",{},{view_168: None},,getitem_171,transformer_h_13_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_170
get_attr,transformer.h.13.mlp.c_proj.bias,{},(),{},{addmm_55: None},,add_170,size_212,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_13_mlp_c_proj_bias
call_method,size,{mul_55: None},"(mul_55, -1)",{},{view_167: None},,transformer_h_13_mlp_c_proj_bias,view_167,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_212
call_method,view,"{mul_55: None, size_212: None}","(mul_55, -1, size_212)",{},{addmm_55: None},,size_212,transformer_h_13_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_167
get_attr,transformer.h.13.mlp.c_proj.weight,{},(),{},{addmm_55: None},,view_167,addmm_55,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_13_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_13_mlp_c_proj_bias: None, view_167: None, transformer_h_13_mlp_c_proj_weight: None}","(transformer_h_13_mlp_c_proj_bias, view_167, transformer_h_13_mlp_c_proj_weight)",{},{view_168: None},,transformer_h_13_mlp_c_proj_weight,view_168,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_55
call_method,view,"{addmm_55: None, add_170: None}","(addmm_55, add_170)",{},{transformer_h_13_mlp_dropout: None},,addmm_55,transformer_h_13_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_168
call_module,transformer.h.13.mlp.dropout,{view_168: None},"(view_168,)",{},{add_171: None},,view_168,add_171,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.13.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.13.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_13_mlp_dropout
call_function,<built-in function add>,"{add_166: None, transformer_h_13_mlp_dropout: None}","(add_166, transformer_h_13_mlp_dropout)",{},"{transformer_h_14_ln_1: None, add_178: None}",,transformer_h_13_mlp_dropout,transformer_h_14_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.13', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_171
call_module,transformer.h.14.ln_1,{add_171: None},"(add_171,)",{},"{size_213: None, size_214: None, view_169: None}",,add_171,size_213,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_14_ln_1
call_method,size,{transformer_h_14_ln_1: None},"(transformer_h_14_ln_1,)",{},{getitem_172: None},,transformer_h_14_ln_1,getitem_172,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.14.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_213
call_function,<built-in function getitem>,{size_213: None},"(size_213, slice(None, -1, None))",{},{add_172: None},,size_213,add_172,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.14.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_172
call_function,<built-in function add>,{getitem_172: None},"(getitem_172, (3840,))",{},{view_170: None},,getitem_172,transformer_h_14_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.14.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_172
get_attr,transformer.h.14.attn.c_attn.bias,{},(),{},{addmm_56: None},,add_172,size_214,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.14.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_14_attn_c_attn_bias
call_method,size,{transformer_h_14_ln_1: None},"(transformer_h_14_ln_1, -1)",{},{view_169: None},,transformer_h_14_attn_c_attn_bias,view_169,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.14.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_214
call_method,view,"{transformer_h_14_ln_1: None, size_214: None}","(transformer_h_14_ln_1, -1, size_214)",{},{addmm_56: None},,size_214,transformer_h_14_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.14.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_169
get_attr,transformer.h.14.attn.c_attn.weight,{},(),{},{addmm_56: None},,view_169,addmm_56,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.14.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_14_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_14_attn_c_attn_bias: None, view_169: None, transformer_h_14_attn_c_attn_weight: None}","(transformer_h_14_attn_c_attn_bias, view_169, transformer_h_14_attn_c_attn_weight)",{},{view_170: None},,transformer_h_14_attn_c_attn_weight,view_170,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.14.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_56
call_method,view,"{addmm_56: None, add_172: None}","(addmm_56, add_172)",{},{split_14: None},,addmm_56,split_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.14.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_170
call_method,split,{view_170: None},"(view_170, 1280)",{'dim': 2},"{getitem_173: None, getitem_174: None, getitem_175: None}",,view_170,getitem_173,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_14
call_function,<built-in function getitem>,{split_14: None},"(split_14, 0)",{},"{size_215: None, view_171: None}",,split_14,getitem_174,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_173
call_function,<built-in function getitem>,{split_14: None},"(split_14, 1)",{},"{size_216: None, view_172: None}",,getitem_173,getitem_175,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_174
call_function,<built-in function getitem>,{split_14: None},"(split_14, 2)",{},"{size_217: None, view_173: None}",,getitem_174,size_215,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_175
call_method,size,{getitem_173: None},"(getitem_173,)",{},{getitem_176: None},,getitem_175,getitem_176,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_215
call_function,<built-in function getitem>,{size_215: None},"(size_215, slice(None, -1, None))",{},{add_173: None},,size_215,add_173,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_176
call_function,<built-in function add>,{getitem_176: None},"(getitem_176, (20, 64))",{},{view_171: None},,getitem_176,view_171,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_173
call_method,view,"{getitem_173: None, add_173: None}","(getitem_173, add_173)",{},{permute_56: None},,add_173,permute_56,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_171
call_method,permute,{view_171: None},"(view_171, 0, 2, 1, 3)",{},"{matmul_28: None, size_219: None}",,view_171,size_216,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_56
call_method,size,{getitem_174: None},"(getitem_174,)",{},{getitem_177: None},,permute_56,getitem_177,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_216
call_function,<built-in function getitem>,{size_216: None},"(size_216, slice(None, -1, None))",{},{add_174: None},,size_216,add_174,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_177
call_function,<built-in function add>,{getitem_177: None},"(getitem_177, (20, 64))",{},{view_172: None},,getitem_177,view_172,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_174
call_method,view,"{getitem_174: None, add_174: None}","(getitem_174, add_174)",{},{permute_57: None},,add_174,permute_57,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_172
call_method,permute,{view_172: None},"(view_172, 0, 2, 1, 3)",{},"{transpose_14: None, size_220: None, output: None}",,view_172,size_217,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_57
call_method,size,{getitem_175: None},"(getitem_175,)",{},{getitem_178: None},,permute_57,getitem_178,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_217
call_function,<built-in function getitem>,{size_217: None},"(size_217, slice(None, -1, None))",{},{add_175: None},,size_217,add_175,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_178
call_function,<built-in function add>,{getitem_178: None},"(getitem_178, (20, 64))",{},{view_173: None},,getitem_178,view_173,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_175
call_method,view,"{getitem_175: None, add_175: None}","(getitem_175, add_175)",{},{permute_58: None},,add_175,permute_58,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_173
call_method,permute,{view_173: None},"(view_173, 0, 2, 1, 3)",{},"{size_218: None, getattr_121: None, matmul_29: None, output: None}",,view_173,transpose_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_58
call_method,transpose,{permute_57: None},"(permute_57, -1, -2)",{},{matmul_28: None},,permute_58,matmul_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_14
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_56: None, transpose_14: None}","(permute_56, transpose_14)",{},"{getattr_114: None, getattr_115: None, truediv_14: None}",,transpose_14,size_218,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_28
call_method,size,{permute_58: None},"(permute_58, -1)",{},{pow_29: None},,matmul_28,pow_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_218
call_function,<built-in function pow>,{size_218: None},"(size_218, 0.5)",{},{full_28: None},,size_218,getattr_114,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_29
call_function,<built-in function getattr>,{matmul_28: None},"(matmul_28, 'dtype')",{},{full_28: None},,pow_29,getattr_115,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_114
call_function,<built-in function getattr>,{matmul_28: None},"(matmul_28, 'device')",{},{full_28: None},,getattr_114,full_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_115
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_29: None, getattr_114: None, getattr_115: None}","([], pow_29)","{'dtype': getattr_114, 'device': getattr_115}",{truediv_14: None},,getattr_115,truediv_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_28
call_function,<built-in function truediv>,"{matmul_28: None, full_28: None}","(matmul_28, full_28)",{},"{getattr_116: None, getattr_118: None, getattr_119: None, getattr_120: None, to_14: None}",,full_28,size_219,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_14
call_method,size,{permute_56: None},"(permute_56, -2)",{},{sub_14: None},,truediv_14,size_220,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_219
call_method,size,{permute_57: None},"(permute_57, -2)",{},"{sub_14: None, getitem_179: None}",,size_219,transformer_h_14_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_220
get_attr,transformer.h.14.attn.bias,{},(),{},{getitem_179: None},,size_220,sub_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_14_attn_bias
call_function,<built-in function sub>,"{size_220: None, size_219: None}","(size_220, size_219)",{},{getitem_179: None},,transformer_h_14_attn_bias,getitem_179,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_14
call_function,<built-in function getitem>,"{transformer_h_14_attn_bias: None, sub_14: None, size_220: None}","(transformer_h_14_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_14, size_220, None), slice(None, size_220, None)))",{},{where_14: None},,sub_14,getattr_116,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_179
call_function,<built-in function getattr>,{truediv_14: None},"(truediv_14, 'dtype')",{},{finfo_14: None},,getitem_179,finfo_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_116
call_function,<class 'torch.finfo'>,{getattr_116: None},"(getattr_116,)",{},{getattr_117: None},,getattr_116,getattr_117,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_14
call_function,<built-in function getattr>,{finfo_14: None},"(finfo_14, 'min')",{},{full_29: None},,finfo_14,getattr_118,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_117
call_function,<built-in function getattr>,{truediv_14: None},"(truediv_14, 'dtype')",{},{full_29: None},,getattr_117,getattr_119,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_118
call_function,<built-in function getattr>,{truediv_14: None},"(truediv_14, 'device')",{},{full_29: None},,getattr_118,full_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_119
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_117: None, getattr_118: None, getattr_119: None}","([], getattr_117)","{'dtype': getattr_118, 'device': getattr_119}",{where_14: None},,getattr_119,getattr_120,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_29
call_function,<built-in function getattr>,{truediv_14: None},"(truediv_14, 'dtype')",{},{to_14: None},,full_29,to_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_120
call_method,to,"{truediv_14: None, getattr_120: None}","(truediv_14, getattr_120)",{},{where_14: None},,getattr_120,where_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_14
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_179: None, to_14: None, full_29: None}","(getitem_179, to_14, full_29)",{},{softmax_14: None},,to_14,softmax_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_14
call_function,<function softmax at 0x7f6fd5135ca0>,{where_14: None},"(where_14,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_15: None},,where_14,getattr_121,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_14
call_function,<built-in function getattr>,{permute_58: None},"(permute_58, 'dtype')",{},{type_15: None},,softmax_14,type_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_121
call_method,type,"{softmax_14: None, getattr_121: None}","(softmax_14, getattr_121)",{},{transformer_h_14_attn_attn_dropout: None},,getattr_121,transformer_h_14_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_15
call_module,transformer.h.14.attn.attn_dropout,{type_15: None},"(type_15,)",{},{matmul_29: None},,type_15,matmul_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.14.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_14_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_14_attn_attn_dropout: None, permute_58: None}","(transformer_h_14_attn_attn_dropout, permute_58)",{},{permute_59: None},,transformer_h_14_attn_attn_dropout,permute_59,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_29
call_method,permute,{matmul_29: None},"(matmul_29, 0, 2, 1, 3)",{},{contiguous_14: None},,matmul_29,contiguous_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_59
call_method,contiguous,{permute_59: None},"(permute_59,)",{},"{size_221: None, view_174: None}",,permute_59,size_221,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_14
call_method,size,{contiguous_14: None},"(contiguous_14,)",{},{getitem_180: None},,contiguous_14,getitem_180,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_221
call_function,<built-in function getitem>,{size_221: None},"(size_221, slice(None, -2, None))",{},{add_176: None},,size_221,add_176,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_180
call_function,<built-in function add>,{getitem_180: None},"(getitem_180, (1280,))",{},{view_174: None},,getitem_180,view_174,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_176
call_method,view,"{contiguous_14: None, add_176: None}","(contiguous_14, add_176)",{},"{size_222: None, size_223: None, view_175: None}",,add_176,size_222,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_174
call_method,size,{view_174: None},"(view_174,)",{},{getitem_181: None},,view_174,getitem_181,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.14.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_222
call_function,<built-in function getitem>,{size_222: None},"(size_222, slice(None, -1, None))",{},{add_177: None},,size_222,add_177,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.14.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_181
call_function,<built-in function add>,{getitem_181: None},"(getitem_181, (1280,))",{},{view_176: None},,getitem_181,transformer_h_14_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.14.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_177
get_attr,transformer.h.14.attn.c_proj.bias,{},(),{},{addmm_57: None},,add_177,size_223,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.14.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_14_attn_c_proj_bias
call_method,size,{view_174: None},"(view_174, -1)",{},{view_175: None},,transformer_h_14_attn_c_proj_bias,view_175,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.14.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_223
call_method,view,"{view_174: None, size_223: None}","(view_174, -1, size_223)",{},{addmm_57: None},,size_223,transformer_h_14_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.14.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_175
get_attr,transformer.h.14.attn.c_proj.weight,{},(),{},{addmm_57: None},,view_175,addmm_57,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.14.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_14_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_14_attn_c_proj_bias: None, view_175: None, transformer_h_14_attn_c_proj_weight: None}","(transformer_h_14_attn_c_proj_bias, view_175, transformer_h_14_attn_c_proj_weight)",{},{view_176: None},,transformer_h_14_attn_c_proj_weight,view_176,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.14.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_57
call_method,view,"{addmm_57: None, add_177: None}","(addmm_57, add_177)",{},{transformer_h_14_attn_resid_dropout: None},,addmm_57,transformer_h_14_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.14.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_176
call_module,transformer.h.14.attn.resid_dropout,{view_176: None},"(view_176,)",{},{add_178: None},,view_176,add_178,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.14.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_14_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_14_attn_resid_dropout: None, add_171: None}","(transformer_h_14_attn_resid_dropout, add_171)",{},"{transformer_h_14_ln_2: None, add_183: None}",,transformer_h_14_attn_resid_dropout,transformer_h_14_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_178
call_module,transformer.h.14.ln_2,{add_178: None},"(add_178,)",{},"{size_224: None, size_225: None, view_177: None}",,add_178,size_224,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_14_ln_2
call_method,size,{transformer_h_14_ln_2: None},"(transformer_h_14_ln_2,)",{},{getitem_182: None},,transformer_h_14_ln_2,getitem_182,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_224
call_function,<built-in function getitem>,{size_224: None},"(size_224, slice(None, -1, None))",{},{add_179: None},,size_224,add_179,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_182
call_function,<built-in function add>,{getitem_182: None},"(getitem_182, (5120,))",{},{view_178: None},,getitem_182,transformer_h_14_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_179
get_attr,transformer.h.14.mlp.c_fc.bias,{},(),{},{addmm_58: None},,add_179,size_225,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_14_mlp_c_fc_bias
call_method,size,{transformer_h_14_ln_2: None},"(transformer_h_14_ln_2, -1)",{},{view_177: None},,transformer_h_14_mlp_c_fc_bias,view_177,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_225
call_method,view,"{transformer_h_14_ln_2: None, size_225: None}","(transformer_h_14_ln_2, -1, size_225)",{},{addmm_58: None},,size_225,transformer_h_14_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_177
get_attr,transformer.h.14.mlp.c_fc.weight,{},(),{},{addmm_58: None},,view_177,addmm_58,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_14_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_14_mlp_c_fc_bias: None, view_177: None, transformer_h_14_mlp_c_fc_weight: None}","(transformer_h_14_mlp_c_fc_bias, view_177, transformer_h_14_mlp_c_fc_weight)",{},{view_178: None},,transformer_h_14_mlp_c_fc_weight,view_178,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_58
call_method,view,"{addmm_58: None, add_179: None}","(addmm_58, add_179)",{},"{mul_56: None, pow_30: None, add_180: None}",,addmm_58,mul_56,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_178
call_function,<built-in function mul>,{view_178: None},"(0.5, view_178)",{},{mul_59: None},,view_178,pow_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_56
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_178: None},"(view_178, 3.0)",{},{mul_57: None},,mul_56,mul_57,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_30
call_function,<built-in function mul>,{pow_30: None},"(0.044715, pow_30)",{},{add_180: None},,pow_30,add_180,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_57
call_function,<built-in function add>,"{view_178: None, mul_57: None}","(view_178, mul_57)",{},{mul_58: None},,mul_57,mul_58,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_180
call_function,<built-in function mul>,{add_180: None},"(0.7978845608028654, add_180)",{},{tanh_14: None},,add_180,tanh_14,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_58
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_58: None},"(mul_58,)",{},{add_181: None},,mul_58,add_181,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_14
call_function,<built-in function add>,{tanh_14: None},"(1.0, tanh_14)",{},{mul_59: None},,tanh_14,mul_59,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_181
call_function,<built-in function mul>,"{mul_56: None, add_181: None}","(mul_56, add_181)",{},"{size_226: None, size_227: None, view_179: None}",,add_181,size_226,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_59
call_method,size,{mul_59: None},"(mul_59,)",{},{getitem_183: None},,mul_59,getitem_183,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_226
call_function,<built-in function getitem>,{size_226: None},"(size_226, slice(None, -1, None))",{},{add_182: None},,size_226,add_182,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_183
call_function,<built-in function add>,{getitem_183: None},"(getitem_183, (1280,))",{},{view_180: None},,getitem_183,transformer_h_14_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_182
get_attr,transformer.h.14.mlp.c_proj.bias,{},(),{},{addmm_59: None},,add_182,size_227,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_14_mlp_c_proj_bias
call_method,size,{mul_59: None},"(mul_59, -1)",{},{view_179: None},,transformer_h_14_mlp_c_proj_bias,view_179,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_227
call_method,view,"{mul_59: None, size_227: None}","(mul_59, -1, size_227)",{},{addmm_59: None},,size_227,transformer_h_14_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_179
get_attr,transformer.h.14.mlp.c_proj.weight,{},(),{},{addmm_59: None},,view_179,addmm_59,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_14_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_14_mlp_c_proj_bias: None, view_179: None, transformer_h_14_mlp_c_proj_weight: None}","(transformer_h_14_mlp_c_proj_bias, view_179, transformer_h_14_mlp_c_proj_weight)",{},{view_180: None},,transformer_h_14_mlp_c_proj_weight,view_180,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_59
call_method,view,"{addmm_59: None, add_182: None}","(addmm_59, add_182)",{},{transformer_h_14_mlp_dropout: None},,addmm_59,transformer_h_14_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_180
call_module,transformer.h.14.mlp.dropout,{view_180: None},"(view_180,)",{},{add_183: None},,view_180,add_183,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.14.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.14.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_14_mlp_dropout
call_function,<built-in function add>,"{add_178: None, transformer_h_14_mlp_dropout: None}","(add_178, transformer_h_14_mlp_dropout)",{},"{transformer_h_15_ln_1: None, add_190: None}",,transformer_h_14_mlp_dropout,transformer_h_15_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.14', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_183
call_module,transformer.h.15.ln_1,{add_183: None},"(add_183,)",{},"{size_228: None, size_229: None, view_181: None}",,add_183,size_228,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_15_ln_1
call_method,size,{transformer_h_15_ln_1: None},"(transformer_h_15_ln_1,)",{},{getitem_184: None},,transformer_h_15_ln_1,getitem_184,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.15.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_228
call_function,<built-in function getitem>,{size_228: None},"(size_228, slice(None, -1, None))",{},{add_184: None},,size_228,add_184,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.15.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_184
call_function,<built-in function add>,{getitem_184: None},"(getitem_184, (3840,))",{},{view_182: None},,getitem_184,transformer_h_15_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.15.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_184
get_attr,transformer.h.15.attn.c_attn.bias,{},(),{},{addmm_60: None},,add_184,size_229,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.15.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_15_attn_c_attn_bias
call_method,size,{transformer_h_15_ln_1: None},"(transformer_h_15_ln_1, -1)",{},{view_181: None},,transformer_h_15_attn_c_attn_bias,view_181,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.15.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_229
call_method,view,"{transformer_h_15_ln_1: None, size_229: None}","(transformer_h_15_ln_1, -1, size_229)",{},{addmm_60: None},,size_229,transformer_h_15_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.15.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_181
get_attr,transformer.h.15.attn.c_attn.weight,{},(),{},{addmm_60: None},,view_181,addmm_60,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.15.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_15_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_15_attn_c_attn_bias: None, view_181: None, transformer_h_15_attn_c_attn_weight: None}","(transformer_h_15_attn_c_attn_bias, view_181, transformer_h_15_attn_c_attn_weight)",{},{view_182: None},,transformer_h_15_attn_c_attn_weight,view_182,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.15.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_60
call_method,view,"{addmm_60: None, add_184: None}","(addmm_60, add_184)",{},{split_15: None},,addmm_60,split_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.15.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_182
call_method,split,{view_182: None},"(view_182, 1280)",{'dim': 2},"{getitem_185: None, getitem_186: None, getitem_187: None}",,view_182,getitem_185,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_15
call_function,<built-in function getitem>,{split_15: None},"(split_15, 0)",{},"{size_230: None, view_183: None}",,split_15,getitem_186,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_185
call_function,<built-in function getitem>,{split_15: None},"(split_15, 1)",{},"{size_231: None, view_184: None}",,getitem_185,getitem_187,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_186
call_function,<built-in function getitem>,{split_15: None},"(split_15, 2)",{},"{size_232: None, view_185: None}",,getitem_186,size_230,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_187
call_method,size,{getitem_185: None},"(getitem_185,)",{},{getitem_188: None},,getitem_187,getitem_188,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_230
call_function,<built-in function getitem>,{size_230: None},"(size_230, slice(None, -1, None))",{},{add_185: None},,size_230,add_185,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_188
call_function,<built-in function add>,{getitem_188: None},"(getitem_188, (20, 64))",{},{view_183: None},,getitem_188,view_183,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_185
call_method,view,"{getitem_185: None, add_185: None}","(getitem_185, add_185)",{},{permute_60: None},,add_185,permute_60,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_183
call_method,permute,{view_183: None},"(view_183, 0, 2, 1, 3)",{},"{matmul_30: None, size_234: None}",,view_183,size_231,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_60
call_method,size,{getitem_186: None},"(getitem_186,)",{},{getitem_189: None},,permute_60,getitem_189,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_231
call_function,<built-in function getitem>,{size_231: None},"(size_231, slice(None, -1, None))",{},{add_186: None},,size_231,add_186,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_189
call_function,<built-in function add>,{getitem_189: None},"(getitem_189, (20, 64))",{},{view_184: None},,getitem_189,view_184,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_186
call_method,view,"{getitem_186: None, add_186: None}","(getitem_186, add_186)",{},{permute_61: None},,add_186,permute_61,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_184
call_method,permute,{view_184: None},"(view_184, 0, 2, 1, 3)",{},"{transpose_15: None, size_235: None, output: None}",,view_184,size_232,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_61
call_method,size,{getitem_187: None},"(getitem_187,)",{},{getitem_190: None},,permute_61,getitem_190,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_232
call_function,<built-in function getitem>,{size_232: None},"(size_232, slice(None, -1, None))",{},{add_187: None},,size_232,add_187,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_190
call_function,<built-in function add>,{getitem_190: None},"(getitem_190, (20, 64))",{},{view_185: None},,getitem_190,view_185,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_187
call_method,view,"{getitem_187: None, add_187: None}","(getitem_187, add_187)",{},{permute_62: None},,add_187,permute_62,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_185
call_method,permute,{view_185: None},"(view_185, 0, 2, 1, 3)",{},"{size_233: None, getattr_129: None, matmul_31: None, output: None}",,view_185,transpose_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_62
call_method,transpose,{permute_61: None},"(permute_61, -1, -2)",{},{matmul_30: None},,permute_62,matmul_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_15
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_60: None, transpose_15: None}","(permute_60, transpose_15)",{},"{getattr_122: None, getattr_123: None, truediv_15: None}",,transpose_15,size_233,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_30
call_method,size,{permute_62: None},"(permute_62, -1)",{},{pow_31: None},,matmul_30,pow_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_233
call_function,<built-in function pow>,{size_233: None},"(size_233, 0.5)",{},{full_30: None},,size_233,getattr_122,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_31
call_function,<built-in function getattr>,{matmul_30: None},"(matmul_30, 'dtype')",{},{full_30: None},,pow_31,getattr_123,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_122
call_function,<built-in function getattr>,{matmul_30: None},"(matmul_30, 'device')",{},{full_30: None},,getattr_122,full_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_123
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_31: None, getattr_122: None, getattr_123: None}","([], pow_31)","{'dtype': getattr_122, 'device': getattr_123}",{truediv_15: None},,getattr_123,truediv_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_30
call_function,<built-in function truediv>,"{matmul_30: None, full_30: None}","(matmul_30, full_30)",{},"{getattr_124: None, getattr_126: None, getattr_127: None, getattr_128: None, to_15: None}",,full_30,size_234,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_15
call_method,size,{permute_60: None},"(permute_60, -2)",{},{sub_15: None},,truediv_15,size_235,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_234
call_method,size,{permute_61: None},"(permute_61, -2)",{},"{sub_15: None, getitem_191: None}",,size_234,transformer_h_15_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_235
get_attr,transformer.h.15.attn.bias,{},(),{},{getitem_191: None},,size_235,sub_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_15_attn_bias
call_function,<built-in function sub>,"{size_235: None, size_234: None}","(size_235, size_234)",{},{getitem_191: None},,transformer_h_15_attn_bias,getitem_191,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_15
call_function,<built-in function getitem>,"{transformer_h_15_attn_bias: None, sub_15: None, size_235: None}","(transformer_h_15_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_15, size_235, None), slice(None, size_235, None)))",{},{where_15: None},,sub_15,getattr_124,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_191
call_function,<built-in function getattr>,{truediv_15: None},"(truediv_15, 'dtype')",{},{finfo_15: None},,getitem_191,finfo_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_124
call_function,<class 'torch.finfo'>,{getattr_124: None},"(getattr_124,)",{},{getattr_125: None},,getattr_124,getattr_125,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_15
call_function,<built-in function getattr>,{finfo_15: None},"(finfo_15, 'min')",{},{full_31: None},,finfo_15,getattr_126,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_125
call_function,<built-in function getattr>,{truediv_15: None},"(truediv_15, 'dtype')",{},{full_31: None},,getattr_125,getattr_127,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_126
call_function,<built-in function getattr>,{truediv_15: None},"(truediv_15, 'device')",{},{full_31: None},,getattr_126,full_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_127
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_125: None, getattr_126: None, getattr_127: None}","([], getattr_125)","{'dtype': getattr_126, 'device': getattr_127}",{where_15: None},,getattr_127,getattr_128,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_31
call_function,<built-in function getattr>,{truediv_15: None},"(truediv_15, 'dtype')",{},{to_15: None},,full_31,to_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_128
call_method,to,"{truediv_15: None, getattr_128: None}","(truediv_15, getattr_128)",{},{where_15: None},,getattr_128,where_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_15
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_191: None, to_15: None, full_31: None}","(getitem_191, to_15, full_31)",{},{softmax_15: None},,to_15,softmax_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_15
call_function,<function softmax at 0x7f6fd5135ca0>,{where_15: None},"(where_15,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_16: None},,where_15,getattr_129,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_15
call_function,<built-in function getattr>,{permute_62: None},"(permute_62, 'dtype')",{},{type_16: None},,softmax_15,type_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_129
call_method,type,"{softmax_15: None, getattr_129: None}","(softmax_15, getattr_129)",{},{transformer_h_15_attn_attn_dropout: None},,getattr_129,transformer_h_15_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_16
call_module,transformer.h.15.attn.attn_dropout,{type_16: None},"(type_16,)",{},{matmul_31: None},,type_16,matmul_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.15.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_15_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_15_attn_attn_dropout: None, permute_62: None}","(transformer_h_15_attn_attn_dropout, permute_62)",{},{permute_63: None},,transformer_h_15_attn_attn_dropout,permute_63,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_31
call_method,permute,{matmul_31: None},"(matmul_31, 0, 2, 1, 3)",{},{contiguous_15: None},,matmul_31,contiguous_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_63
call_method,contiguous,{permute_63: None},"(permute_63,)",{},"{size_236: None, view_186: None}",,permute_63,size_236,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_15
call_method,size,{contiguous_15: None},"(contiguous_15,)",{},{getitem_192: None},,contiguous_15,getitem_192,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_236
call_function,<built-in function getitem>,{size_236: None},"(size_236, slice(None, -2, None))",{},{add_188: None},,size_236,add_188,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_192
call_function,<built-in function add>,{getitem_192: None},"(getitem_192, (1280,))",{},{view_186: None},,getitem_192,view_186,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_188
call_method,view,"{contiguous_15: None, add_188: None}","(contiguous_15, add_188)",{},"{size_237: None, size_238: None, view_187: None}",,add_188,size_237,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_186
call_method,size,{view_186: None},"(view_186,)",{},{getitem_193: None},,view_186,getitem_193,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.15.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_237
call_function,<built-in function getitem>,{size_237: None},"(size_237, slice(None, -1, None))",{},{add_189: None},,size_237,add_189,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.15.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_193
call_function,<built-in function add>,{getitem_193: None},"(getitem_193, (1280,))",{},{view_188: None},,getitem_193,transformer_h_15_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.15.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_189
get_attr,transformer.h.15.attn.c_proj.bias,{},(),{},{addmm_61: None},,add_189,size_238,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.15.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_15_attn_c_proj_bias
call_method,size,{view_186: None},"(view_186, -1)",{},{view_187: None},,transformer_h_15_attn_c_proj_bias,view_187,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.15.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_238
call_method,view,"{view_186: None, size_238: None}","(view_186, -1, size_238)",{},{addmm_61: None},,size_238,transformer_h_15_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.15.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_187
get_attr,transformer.h.15.attn.c_proj.weight,{},(),{},{addmm_61: None},,view_187,addmm_61,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.15.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_15_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_15_attn_c_proj_bias: None, view_187: None, transformer_h_15_attn_c_proj_weight: None}","(transformer_h_15_attn_c_proj_bias, view_187, transformer_h_15_attn_c_proj_weight)",{},{view_188: None},,transformer_h_15_attn_c_proj_weight,view_188,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.15.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_61
call_method,view,"{addmm_61: None, add_189: None}","(addmm_61, add_189)",{},{transformer_h_15_attn_resid_dropout: None},,addmm_61,transformer_h_15_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.15.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_188
call_module,transformer.h.15.attn.resid_dropout,{view_188: None},"(view_188,)",{},{add_190: None},,view_188,add_190,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.15.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_15_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_15_attn_resid_dropout: None, add_183: None}","(transformer_h_15_attn_resid_dropout, add_183)",{},"{transformer_h_15_ln_2: None, add_195: None}",,transformer_h_15_attn_resid_dropout,transformer_h_15_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_190
call_module,transformer.h.15.ln_2,{add_190: None},"(add_190,)",{},"{size_239: None, size_240: None, view_189: None}",,add_190,size_239,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_15_ln_2
call_method,size,{transformer_h_15_ln_2: None},"(transformer_h_15_ln_2,)",{},{getitem_194: None},,transformer_h_15_ln_2,getitem_194,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_239
call_function,<built-in function getitem>,{size_239: None},"(size_239, slice(None, -1, None))",{},{add_191: None},,size_239,add_191,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_194
call_function,<built-in function add>,{getitem_194: None},"(getitem_194, (5120,))",{},{view_190: None},,getitem_194,transformer_h_15_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_191
get_attr,transformer.h.15.mlp.c_fc.bias,{},(),{},{addmm_62: None},,add_191,size_240,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_15_mlp_c_fc_bias
call_method,size,{transformer_h_15_ln_2: None},"(transformer_h_15_ln_2, -1)",{},{view_189: None},,transformer_h_15_mlp_c_fc_bias,view_189,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_240
call_method,view,"{transformer_h_15_ln_2: None, size_240: None}","(transformer_h_15_ln_2, -1, size_240)",{},{addmm_62: None},,size_240,transformer_h_15_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_189
get_attr,transformer.h.15.mlp.c_fc.weight,{},(),{},{addmm_62: None},,view_189,addmm_62,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_15_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_15_mlp_c_fc_bias: None, view_189: None, transformer_h_15_mlp_c_fc_weight: None}","(transformer_h_15_mlp_c_fc_bias, view_189, transformer_h_15_mlp_c_fc_weight)",{},{view_190: None},,transformer_h_15_mlp_c_fc_weight,view_190,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_62
call_method,view,"{addmm_62: None, add_191: None}","(addmm_62, add_191)",{},"{mul_60: None, pow_32: None, add_192: None}",,addmm_62,mul_60,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_190
call_function,<built-in function mul>,{view_190: None},"(0.5, view_190)",{},{mul_63: None},,view_190,pow_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_60
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_190: None},"(view_190, 3.0)",{},{mul_61: None},,mul_60,mul_61,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_32
call_function,<built-in function mul>,{pow_32: None},"(0.044715, pow_32)",{},{add_192: None},,pow_32,add_192,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_61
call_function,<built-in function add>,"{view_190: None, mul_61: None}","(view_190, mul_61)",{},{mul_62: None},,mul_61,mul_62,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_192
call_function,<built-in function mul>,{add_192: None},"(0.7978845608028654, add_192)",{},{tanh_15: None},,add_192,tanh_15,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_62
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_62: None},"(mul_62,)",{},{add_193: None},,mul_62,add_193,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_15
call_function,<built-in function add>,{tanh_15: None},"(1.0, tanh_15)",{},{mul_63: None},,tanh_15,mul_63,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_193
call_function,<built-in function mul>,"{mul_60: None, add_193: None}","(mul_60, add_193)",{},"{size_241: None, size_242: None, view_191: None}",,add_193,size_241,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_63
call_method,size,{mul_63: None},"(mul_63,)",{},{getitem_195: None},,mul_63,getitem_195,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_241
call_function,<built-in function getitem>,{size_241: None},"(size_241, slice(None, -1, None))",{},{add_194: None},,size_241,add_194,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_195
call_function,<built-in function add>,{getitem_195: None},"(getitem_195, (1280,))",{},{view_192: None},,getitem_195,transformer_h_15_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_194
get_attr,transformer.h.15.mlp.c_proj.bias,{},(),{},{addmm_63: None},,add_194,size_242,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_15_mlp_c_proj_bias
call_method,size,{mul_63: None},"(mul_63, -1)",{},{view_191: None},,transformer_h_15_mlp_c_proj_bias,view_191,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_242
call_method,view,"{mul_63: None, size_242: None}","(mul_63, -1, size_242)",{},{addmm_63: None},,size_242,transformer_h_15_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_191
get_attr,transformer.h.15.mlp.c_proj.weight,{},(),{},{addmm_63: None},,view_191,addmm_63,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_15_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_15_mlp_c_proj_bias: None, view_191: None, transformer_h_15_mlp_c_proj_weight: None}","(transformer_h_15_mlp_c_proj_bias, view_191, transformer_h_15_mlp_c_proj_weight)",{},{view_192: None},,transformer_h_15_mlp_c_proj_weight,view_192,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_63
call_method,view,"{addmm_63: None, add_194: None}","(addmm_63, add_194)",{},{transformer_h_15_mlp_dropout: None},,addmm_63,transformer_h_15_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_192
call_module,transformer.h.15.mlp.dropout,{view_192: None},"(view_192,)",{},{add_195: None},,view_192,add_195,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.15.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.15.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_15_mlp_dropout
call_function,<built-in function add>,"{add_190: None, transformer_h_15_mlp_dropout: None}","(add_190, transformer_h_15_mlp_dropout)",{},"{transformer_h_16_ln_1: None, add_202: None}",,transformer_h_15_mlp_dropout,transformer_h_16_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.15', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_195
call_module,transformer.h.16.ln_1,{add_195: None},"(add_195,)",{},"{size_243: None, size_244: None, view_193: None}",,add_195,size_243,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_16_ln_1
call_method,size,{transformer_h_16_ln_1: None},"(transformer_h_16_ln_1,)",{},{getitem_196: None},,transformer_h_16_ln_1,getitem_196,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.16.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_243
call_function,<built-in function getitem>,{size_243: None},"(size_243, slice(None, -1, None))",{},{add_196: None},,size_243,add_196,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.16.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_196
call_function,<built-in function add>,{getitem_196: None},"(getitem_196, (3840,))",{},{view_194: None},,getitem_196,transformer_h_16_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.16.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_196
get_attr,transformer.h.16.attn.c_attn.bias,{},(),{},{addmm_64: None},,add_196,size_244,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.16.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_16_attn_c_attn_bias
call_method,size,{transformer_h_16_ln_1: None},"(transformer_h_16_ln_1, -1)",{},{view_193: None},,transformer_h_16_attn_c_attn_bias,view_193,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.16.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_244
call_method,view,"{transformer_h_16_ln_1: None, size_244: None}","(transformer_h_16_ln_1, -1, size_244)",{},{addmm_64: None},,size_244,transformer_h_16_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.16.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_193
get_attr,transformer.h.16.attn.c_attn.weight,{},(),{},{addmm_64: None},,view_193,addmm_64,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.16.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_16_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_16_attn_c_attn_bias: None, view_193: None, transformer_h_16_attn_c_attn_weight: None}","(transformer_h_16_attn_c_attn_bias, view_193, transformer_h_16_attn_c_attn_weight)",{},{view_194: None},,transformer_h_16_attn_c_attn_weight,view_194,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.16.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_64
call_method,view,"{addmm_64: None, add_196: None}","(addmm_64, add_196)",{},{split_16: None},,addmm_64,split_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.16.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_194
call_method,split,{view_194: None},"(view_194, 1280)",{'dim': 2},"{getitem_197: None, getitem_198: None, getitem_199: None}",,view_194,getitem_197,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_16
call_function,<built-in function getitem>,{split_16: None},"(split_16, 0)",{},"{size_245: None, view_195: None}",,split_16,getitem_198,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_197
call_function,<built-in function getitem>,{split_16: None},"(split_16, 1)",{},"{size_246: None, view_196: None}",,getitem_197,getitem_199,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_198
call_function,<built-in function getitem>,{split_16: None},"(split_16, 2)",{},"{size_247: None, view_197: None}",,getitem_198,size_245,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_199
call_method,size,{getitem_197: None},"(getitem_197,)",{},{getitem_200: None},,getitem_199,getitem_200,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_245
call_function,<built-in function getitem>,{size_245: None},"(size_245, slice(None, -1, None))",{},{add_197: None},,size_245,add_197,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_200
call_function,<built-in function add>,{getitem_200: None},"(getitem_200, (20, 64))",{},{view_195: None},,getitem_200,view_195,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_197
call_method,view,"{getitem_197: None, add_197: None}","(getitem_197, add_197)",{},{permute_64: None},,add_197,permute_64,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_195
call_method,permute,{view_195: None},"(view_195, 0, 2, 1, 3)",{},"{matmul_32: None, size_249: None}",,view_195,size_246,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_64
call_method,size,{getitem_198: None},"(getitem_198,)",{},{getitem_201: None},,permute_64,getitem_201,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_246
call_function,<built-in function getitem>,{size_246: None},"(size_246, slice(None, -1, None))",{},{add_198: None},,size_246,add_198,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_201
call_function,<built-in function add>,{getitem_201: None},"(getitem_201, (20, 64))",{},{view_196: None},,getitem_201,view_196,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_198
call_method,view,"{getitem_198: None, add_198: None}","(getitem_198, add_198)",{},{permute_65: None},,add_198,permute_65,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_196
call_method,permute,{view_196: None},"(view_196, 0, 2, 1, 3)",{},"{transpose_16: None, size_250: None, output: None}",,view_196,size_247,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_65
call_method,size,{getitem_199: None},"(getitem_199,)",{},{getitem_202: None},,permute_65,getitem_202,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_247
call_function,<built-in function getitem>,{size_247: None},"(size_247, slice(None, -1, None))",{},{add_199: None},,size_247,add_199,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_202
call_function,<built-in function add>,{getitem_202: None},"(getitem_202, (20, 64))",{},{view_197: None},,getitem_202,view_197,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_199
call_method,view,"{getitem_199: None, add_199: None}","(getitem_199, add_199)",{},{permute_66: None},,add_199,permute_66,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_197
call_method,permute,{view_197: None},"(view_197, 0, 2, 1, 3)",{},"{size_248: None, getattr_137: None, matmul_33: None, output: None}",,view_197,transpose_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_66
call_method,transpose,{permute_65: None},"(permute_65, -1, -2)",{},{matmul_32: None},,permute_66,matmul_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_16
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_64: None, transpose_16: None}","(permute_64, transpose_16)",{},"{getattr_130: None, getattr_131: None, truediv_16: None}",,transpose_16,size_248,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_32
call_method,size,{permute_66: None},"(permute_66, -1)",{},{pow_33: None},,matmul_32,pow_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_248
call_function,<built-in function pow>,{size_248: None},"(size_248, 0.5)",{},{full_32: None},,size_248,getattr_130,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_33
call_function,<built-in function getattr>,{matmul_32: None},"(matmul_32, 'dtype')",{},{full_32: None},,pow_33,getattr_131,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_130
call_function,<built-in function getattr>,{matmul_32: None},"(matmul_32, 'device')",{},{full_32: None},,getattr_130,full_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_131
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_33: None, getattr_130: None, getattr_131: None}","([], pow_33)","{'dtype': getattr_130, 'device': getattr_131}",{truediv_16: None},,getattr_131,truediv_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_32
call_function,<built-in function truediv>,"{matmul_32: None, full_32: None}","(matmul_32, full_32)",{},"{getattr_132: None, getattr_134: None, getattr_135: None, getattr_136: None, to_16: None}",,full_32,size_249,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_16
call_method,size,{permute_64: None},"(permute_64, -2)",{},{sub_16: None},,truediv_16,size_250,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_249
call_method,size,{permute_65: None},"(permute_65, -2)",{},"{sub_16: None, getitem_203: None}",,size_249,transformer_h_16_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_250
get_attr,transformer.h.16.attn.bias,{},(),{},{getitem_203: None},,size_250,sub_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_16_attn_bias
call_function,<built-in function sub>,"{size_250: None, size_249: None}","(size_250, size_249)",{},{getitem_203: None},,transformer_h_16_attn_bias,getitem_203,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_16
call_function,<built-in function getitem>,"{transformer_h_16_attn_bias: None, sub_16: None, size_250: None}","(transformer_h_16_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_16, size_250, None), slice(None, size_250, None)))",{},{where_16: None},,sub_16,getattr_132,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_203
call_function,<built-in function getattr>,{truediv_16: None},"(truediv_16, 'dtype')",{},{finfo_16: None},,getitem_203,finfo_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_132
call_function,<class 'torch.finfo'>,{getattr_132: None},"(getattr_132,)",{},{getattr_133: None},,getattr_132,getattr_133,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_16
call_function,<built-in function getattr>,{finfo_16: None},"(finfo_16, 'min')",{},{full_33: None},,finfo_16,getattr_134,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_133
call_function,<built-in function getattr>,{truediv_16: None},"(truediv_16, 'dtype')",{},{full_33: None},,getattr_133,getattr_135,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_134
call_function,<built-in function getattr>,{truediv_16: None},"(truediv_16, 'device')",{},{full_33: None},,getattr_134,full_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_135
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_133: None, getattr_134: None, getattr_135: None}","([], getattr_133)","{'dtype': getattr_134, 'device': getattr_135}",{where_16: None},,getattr_135,getattr_136,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_33
call_function,<built-in function getattr>,{truediv_16: None},"(truediv_16, 'dtype')",{},{to_16: None},,full_33,to_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_136
call_method,to,"{truediv_16: None, getattr_136: None}","(truediv_16, getattr_136)",{},{where_16: None},,getattr_136,where_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_16
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_203: None, to_16: None, full_33: None}","(getitem_203, to_16, full_33)",{},{softmax_16: None},,to_16,softmax_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_16
call_function,<function softmax at 0x7f6fd5135ca0>,{where_16: None},"(where_16,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_17: None},,where_16,getattr_137,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_16
call_function,<built-in function getattr>,{permute_66: None},"(permute_66, 'dtype')",{},{type_17: None},,softmax_16,type_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_137
call_method,type,"{softmax_16: None, getattr_137: None}","(softmax_16, getattr_137)",{},{transformer_h_16_attn_attn_dropout: None},,getattr_137,transformer_h_16_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_17
call_module,transformer.h.16.attn.attn_dropout,{type_17: None},"(type_17,)",{},{matmul_33: None},,type_17,matmul_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.16.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_16_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_16_attn_attn_dropout: None, permute_66: None}","(transformer_h_16_attn_attn_dropout, permute_66)",{},{permute_67: None},,transformer_h_16_attn_attn_dropout,permute_67,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_33
call_method,permute,{matmul_33: None},"(matmul_33, 0, 2, 1, 3)",{},{contiguous_16: None},,matmul_33,contiguous_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_67
call_method,contiguous,{permute_67: None},"(permute_67,)",{},"{size_251: None, view_198: None}",,permute_67,size_251,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_16
call_method,size,{contiguous_16: None},"(contiguous_16,)",{},{getitem_204: None},,contiguous_16,getitem_204,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_251
call_function,<built-in function getitem>,{size_251: None},"(size_251, slice(None, -2, None))",{},{add_200: None},,size_251,add_200,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_204
call_function,<built-in function add>,{getitem_204: None},"(getitem_204, (1280,))",{},{view_198: None},,getitem_204,view_198,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_200
call_method,view,"{contiguous_16: None, add_200: None}","(contiguous_16, add_200)",{},"{size_252: None, size_253: None, view_199: None}",,add_200,size_252,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_198
call_method,size,{view_198: None},"(view_198,)",{},{getitem_205: None},,view_198,getitem_205,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.16.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_252
call_function,<built-in function getitem>,{size_252: None},"(size_252, slice(None, -1, None))",{},{add_201: None},,size_252,add_201,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.16.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_205
call_function,<built-in function add>,{getitem_205: None},"(getitem_205, (1280,))",{},{view_200: None},,getitem_205,transformer_h_16_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.16.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_201
get_attr,transformer.h.16.attn.c_proj.bias,{},(),{},{addmm_65: None},,add_201,size_253,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.16.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_16_attn_c_proj_bias
call_method,size,{view_198: None},"(view_198, -1)",{},{view_199: None},,transformer_h_16_attn_c_proj_bias,view_199,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.16.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_253
call_method,view,"{view_198: None, size_253: None}","(view_198, -1, size_253)",{},{addmm_65: None},,size_253,transformer_h_16_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.16.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_199
get_attr,transformer.h.16.attn.c_proj.weight,{},(),{},{addmm_65: None},,view_199,addmm_65,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.16.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_16_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_16_attn_c_proj_bias: None, view_199: None, transformer_h_16_attn_c_proj_weight: None}","(transformer_h_16_attn_c_proj_bias, view_199, transformer_h_16_attn_c_proj_weight)",{},{view_200: None},,transformer_h_16_attn_c_proj_weight,view_200,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.16.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_65
call_method,view,"{addmm_65: None, add_201: None}","(addmm_65, add_201)",{},{transformer_h_16_attn_resid_dropout: None},,addmm_65,transformer_h_16_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.16.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_200
call_module,transformer.h.16.attn.resid_dropout,{view_200: None},"(view_200,)",{},{add_202: None},,view_200,add_202,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.16.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_16_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_16_attn_resid_dropout: None, add_195: None}","(transformer_h_16_attn_resid_dropout, add_195)",{},"{transformer_h_16_ln_2: None, add_207: None}",,transformer_h_16_attn_resid_dropout,transformer_h_16_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_202
call_module,transformer.h.16.ln_2,{add_202: None},"(add_202,)",{},"{size_254: None, size_255: None, view_201: None}",,add_202,size_254,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_16_ln_2
call_method,size,{transformer_h_16_ln_2: None},"(transformer_h_16_ln_2,)",{},{getitem_206: None},,transformer_h_16_ln_2,getitem_206,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_254
call_function,<built-in function getitem>,{size_254: None},"(size_254, slice(None, -1, None))",{},{add_203: None},,size_254,add_203,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_206
call_function,<built-in function add>,{getitem_206: None},"(getitem_206, (5120,))",{},{view_202: None},,getitem_206,transformer_h_16_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_203
get_attr,transformer.h.16.mlp.c_fc.bias,{},(),{},{addmm_66: None},,add_203,size_255,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_16_mlp_c_fc_bias
call_method,size,{transformer_h_16_ln_2: None},"(transformer_h_16_ln_2, -1)",{},{view_201: None},,transformer_h_16_mlp_c_fc_bias,view_201,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_255
call_method,view,"{transformer_h_16_ln_2: None, size_255: None}","(transformer_h_16_ln_2, -1, size_255)",{},{addmm_66: None},,size_255,transformer_h_16_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_201
get_attr,transformer.h.16.mlp.c_fc.weight,{},(),{},{addmm_66: None},,view_201,addmm_66,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_16_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_16_mlp_c_fc_bias: None, view_201: None, transformer_h_16_mlp_c_fc_weight: None}","(transformer_h_16_mlp_c_fc_bias, view_201, transformer_h_16_mlp_c_fc_weight)",{},{view_202: None},,transformer_h_16_mlp_c_fc_weight,view_202,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_66
call_method,view,"{addmm_66: None, add_203: None}","(addmm_66, add_203)",{},"{mul_64: None, pow_34: None, add_204: None}",,addmm_66,mul_64,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_202
call_function,<built-in function mul>,{view_202: None},"(0.5, view_202)",{},{mul_67: None},,view_202,pow_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_64
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_202: None},"(view_202, 3.0)",{},{mul_65: None},,mul_64,mul_65,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_34
call_function,<built-in function mul>,{pow_34: None},"(0.044715, pow_34)",{},{add_204: None},,pow_34,add_204,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_65
call_function,<built-in function add>,"{view_202: None, mul_65: None}","(view_202, mul_65)",{},{mul_66: None},,mul_65,mul_66,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_204
call_function,<built-in function mul>,{add_204: None},"(0.7978845608028654, add_204)",{},{tanh_16: None},,add_204,tanh_16,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_66
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_66: None},"(mul_66,)",{},{add_205: None},,mul_66,add_205,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_16
call_function,<built-in function add>,{tanh_16: None},"(1.0, tanh_16)",{},{mul_67: None},,tanh_16,mul_67,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_205
call_function,<built-in function mul>,"{mul_64: None, add_205: None}","(mul_64, add_205)",{},"{size_256: None, size_257: None, view_203: None}",,add_205,size_256,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_67
call_method,size,{mul_67: None},"(mul_67,)",{},{getitem_207: None},,mul_67,getitem_207,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_256
call_function,<built-in function getitem>,{size_256: None},"(size_256, slice(None, -1, None))",{},{add_206: None},,size_256,add_206,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_207
call_function,<built-in function add>,{getitem_207: None},"(getitem_207, (1280,))",{},{view_204: None},,getitem_207,transformer_h_16_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_206
get_attr,transformer.h.16.mlp.c_proj.bias,{},(),{},{addmm_67: None},,add_206,size_257,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_16_mlp_c_proj_bias
call_method,size,{mul_67: None},"(mul_67, -1)",{},{view_203: None},,transformer_h_16_mlp_c_proj_bias,view_203,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_257
call_method,view,"{mul_67: None, size_257: None}","(mul_67, -1, size_257)",{},{addmm_67: None},,size_257,transformer_h_16_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_203
get_attr,transformer.h.16.mlp.c_proj.weight,{},(),{},{addmm_67: None},,view_203,addmm_67,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_16_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_16_mlp_c_proj_bias: None, view_203: None, transformer_h_16_mlp_c_proj_weight: None}","(transformer_h_16_mlp_c_proj_bias, view_203, transformer_h_16_mlp_c_proj_weight)",{},{view_204: None},,transformer_h_16_mlp_c_proj_weight,view_204,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_67
call_method,view,"{addmm_67: None, add_206: None}","(addmm_67, add_206)",{},{transformer_h_16_mlp_dropout: None},,addmm_67,transformer_h_16_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_204
call_module,transformer.h.16.mlp.dropout,{view_204: None},"(view_204,)",{},{add_207: None},,view_204,add_207,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.16.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.16.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_16_mlp_dropout
call_function,<built-in function add>,"{add_202: None, transformer_h_16_mlp_dropout: None}","(add_202, transformer_h_16_mlp_dropout)",{},"{transformer_h_17_ln_1: None, add_214: None}",,transformer_h_16_mlp_dropout,transformer_h_17_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.16', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_207
call_module,transformer.h.17.ln_1,{add_207: None},"(add_207,)",{},"{size_258: None, size_259: None, view_205: None}",,add_207,size_258,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_17_ln_1
call_method,size,{transformer_h_17_ln_1: None},"(transformer_h_17_ln_1,)",{},{getitem_208: None},,transformer_h_17_ln_1,getitem_208,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.17.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_258
call_function,<built-in function getitem>,{size_258: None},"(size_258, slice(None, -1, None))",{},{add_208: None},,size_258,add_208,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.17.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_208
call_function,<built-in function add>,{getitem_208: None},"(getitem_208, (3840,))",{},{view_206: None},,getitem_208,transformer_h_17_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.17.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_208
get_attr,transformer.h.17.attn.c_attn.bias,{},(),{},{addmm_68: None},,add_208,size_259,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.17.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_17_attn_c_attn_bias
call_method,size,{transformer_h_17_ln_1: None},"(transformer_h_17_ln_1, -1)",{},{view_205: None},,transformer_h_17_attn_c_attn_bias,view_205,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.17.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_259
call_method,view,"{transformer_h_17_ln_1: None, size_259: None}","(transformer_h_17_ln_1, -1, size_259)",{},{addmm_68: None},,size_259,transformer_h_17_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.17.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_205
get_attr,transformer.h.17.attn.c_attn.weight,{},(),{},{addmm_68: None},,view_205,addmm_68,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.17.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_17_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_17_attn_c_attn_bias: None, view_205: None, transformer_h_17_attn_c_attn_weight: None}","(transformer_h_17_attn_c_attn_bias, view_205, transformer_h_17_attn_c_attn_weight)",{},{view_206: None},,transformer_h_17_attn_c_attn_weight,view_206,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.17.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_68
call_method,view,"{addmm_68: None, add_208: None}","(addmm_68, add_208)",{},{split_17: None},,addmm_68,split_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.17.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_206
call_method,split,{view_206: None},"(view_206, 1280)",{'dim': 2},"{getitem_209: None, getitem_210: None, getitem_211: None}",,view_206,getitem_209,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_17
call_function,<built-in function getitem>,{split_17: None},"(split_17, 0)",{},"{size_260: None, view_207: None}",,split_17,getitem_210,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_209
call_function,<built-in function getitem>,{split_17: None},"(split_17, 1)",{},"{size_261: None, view_208: None}",,getitem_209,getitem_211,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_210
call_function,<built-in function getitem>,{split_17: None},"(split_17, 2)",{},"{size_262: None, view_209: None}",,getitem_210,size_260,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_211
call_method,size,{getitem_209: None},"(getitem_209,)",{},{getitem_212: None},,getitem_211,getitem_212,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_260
call_function,<built-in function getitem>,{size_260: None},"(size_260, slice(None, -1, None))",{},{add_209: None},,size_260,add_209,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_212
call_function,<built-in function add>,{getitem_212: None},"(getitem_212, (20, 64))",{},{view_207: None},,getitem_212,view_207,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_209
call_method,view,"{getitem_209: None, add_209: None}","(getitem_209, add_209)",{},{permute_68: None},,add_209,permute_68,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_207
call_method,permute,{view_207: None},"(view_207, 0, 2, 1, 3)",{},"{matmul_34: None, size_264: None}",,view_207,size_261,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_68
call_method,size,{getitem_210: None},"(getitem_210,)",{},{getitem_213: None},,permute_68,getitem_213,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_261
call_function,<built-in function getitem>,{size_261: None},"(size_261, slice(None, -1, None))",{},{add_210: None},,size_261,add_210,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_213
call_function,<built-in function add>,{getitem_213: None},"(getitem_213, (20, 64))",{},{view_208: None},,getitem_213,view_208,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_210
call_method,view,"{getitem_210: None, add_210: None}","(getitem_210, add_210)",{},{permute_69: None},,add_210,permute_69,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_208
call_method,permute,{view_208: None},"(view_208, 0, 2, 1, 3)",{},"{transpose_17: None, size_265: None, output: None}",,view_208,size_262,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_69
call_method,size,{getitem_211: None},"(getitem_211,)",{},{getitem_214: None},,permute_69,getitem_214,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_262
call_function,<built-in function getitem>,{size_262: None},"(size_262, slice(None, -1, None))",{},{add_211: None},,size_262,add_211,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_214
call_function,<built-in function add>,{getitem_214: None},"(getitem_214, (20, 64))",{},{view_209: None},,getitem_214,view_209,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_211
call_method,view,"{getitem_211: None, add_211: None}","(getitem_211, add_211)",{},{permute_70: None},,add_211,permute_70,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_209
call_method,permute,{view_209: None},"(view_209, 0, 2, 1, 3)",{},"{size_263: None, getattr_145: None, matmul_35: None, output: None}",,view_209,transpose_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_70
call_method,transpose,{permute_69: None},"(permute_69, -1, -2)",{},{matmul_34: None},,permute_70,matmul_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_17
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_68: None, transpose_17: None}","(permute_68, transpose_17)",{},"{getattr_138: None, getattr_139: None, truediv_17: None}",,transpose_17,size_263,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_34
call_method,size,{permute_70: None},"(permute_70, -1)",{},{pow_35: None},,matmul_34,pow_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_263
call_function,<built-in function pow>,{size_263: None},"(size_263, 0.5)",{},{full_34: None},,size_263,getattr_138,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_35
call_function,<built-in function getattr>,{matmul_34: None},"(matmul_34, 'dtype')",{},{full_34: None},,pow_35,getattr_139,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_138
call_function,<built-in function getattr>,{matmul_34: None},"(matmul_34, 'device')",{},{full_34: None},,getattr_138,full_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_139
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_35: None, getattr_138: None, getattr_139: None}","([], pow_35)","{'dtype': getattr_138, 'device': getattr_139}",{truediv_17: None},,getattr_139,truediv_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_34
call_function,<built-in function truediv>,"{matmul_34: None, full_34: None}","(matmul_34, full_34)",{},"{getattr_140: None, getattr_142: None, getattr_143: None, getattr_144: None, to_17: None}",,full_34,size_264,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_17
call_method,size,{permute_68: None},"(permute_68, -2)",{},{sub_17: None},,truediv_17,size_265,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_264
call_method,size,{permute_69: None},"(permute_69, -2)",{},"{sub_17: None, getitem_215: None}",,size_264,transformer_h_17_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_265
get_attr,transformer.h.17.attn.bias,{},(),{},{getitem_215: None},,size_265,sub_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_17_attn_bias
call_function,<built-in function sub>,"{size_265: None, size_264: None}","(size_265, size_264)",{},{getitem_215: None},,transformer_h_17_attn_bias,getitem_215,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_17
call_function,<built-in function getitem>,"{transformer_h_17_attn_bias: None, sub_17: None, size_265: None}","(transformer_h_17_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_17, size_265, None), slice(None, size_265, None)))",{},{where_17: None},,sub_17,getattr_140,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_215
call_function,<built-in function getattr>,{truediv_17: None},"(truediv_17, 'dtype')",{},{finfo_17: None},,getitem_215,finfo_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_140
call_function,<class 'torch.finfo'>,{getattr_140: None},"(getattr_140,)",{},{getattr_141: None},,getattr_140,getattr_141,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_17
call_function,<built-in function getattr>,{finfo_17: None},"(finfo_17, 'min')",{},{full_35: None},,finfo_17,getattr_142,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_141
call_function,<built-in function getattr>,{truediv_17: None},"(truediv_17, 'dtype')",{},{full_35: None},,getattr_141,getattr_143,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_142
call_function,<built-in function getattr>,{truediv_17: None},"(truediv_17, 'device')",{},{full_35: None},,getattr_142,full_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_143
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_141: None, getattr_142: None, getattr_143: None}","([], getattr_141)","{'dtype': getattr_142, 'device': getattr_143}",{where_17: None},,getattr_143,getattr_144,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_35
call_function,<built-in function getattr>,{truediv_17: None},"(truediv_17, 'dtype')",{},{to_17: None},,full_35,to_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_144
call_method,to,"{truediv_17: None, getattr_144: None}","(truediv_17, getattr_144)",{},{where_17: None},,getattr_144,where_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_17
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_215: None, to_17: None, full_35: None}","(getitem_215, to_17, full_35)",{},{softmax_17: None},,to_17,softmax_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_17
call_function,<function softmax at 0x7f6fd5135ca0>,{where_17: None},"(where_17,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_18: None},,where_17,getattr_145,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_17
call_function,<built-in function getattr>,{permute_70: None},"(permute_70, 'dtype')",{},{type_18: None},,softmax_17,type_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_145
call_method,type,"{softmax_17: None, getattr_145: None}","(softmax_17, getattr_145)",{},{transformer_h_17_attn_attn_dropout: None},,getattr_145,transformer_h_17_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_18
call_module,transformer.h.17.attn.attn_dropout,{type_18: None},"(type_18,)",{},{matmul_35: None},,type_18,matmul_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.17.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_17_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_17_attn_attn_dropout: None, permute_70: None}","(transformer_h_17_attn_attn_dropout, permute_70)",{},{permute_71: None},,transformer_h_17_attn_attn_dropout,permute_71,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_35
call_method,permute,{matmul_35: None},"(matmul_35, 0, 2, 1, 3)",{},{contiguous_17: None},,matmul_35,contiguous_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_71
call_method,contiguous,{permute_71: None},"(permute_71,)",{},"{size_266: None, view_210: None}",,permute_71,size_266,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_17
call_method,size,{contiguous_17: None},"(contiguous_17,)",{},{getitem_216: None},,contiguous_17,getitem_216,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_266
call_function,<built-in function getitem>,{size_266: None},"(size_266, slice(None, -2, None))",{},{add_212: None},,size_266,add_212,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_216
call_function,<built-in function add>,{getitem_216: None},"(getitem_216, (1280,))",{},{view_210: None},,getitem_216,view_210,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_212
call_method,view,"{contiguous_17: None, add_212: None}","(contiguous_17, add_212)",{},"{size_267: None, size_268: None, view_211: None}",,add_212,size_267,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_210
call_method,size,{view_210: None},"(view_210,)",{},{getitem_217: None},,view_210,getitem_217,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.17.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_267
call_function,<built-in function getitem>,{size_267: None},"(size_267, slice(None, -1, None))",{},{add_213: None},,size_267,add_213,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.17.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_217
call_function,<built-in function add>,{getitem_217: None},"(getitem_217, (1280,))",{},{view_212: None},,getitem_217,transformer_h_17_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.17.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_213
get_attr,transformer.h.17.attn.c_proj.bias,{},(),{},{addmm_69: None},,add_213,size_268,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.17.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_17_attn_c_proj_bias
call_method,size,{view_210: None},"(view_210, -1)",{},{view_211: None},,transformer_h_17_attn_c_proj_bias,view_211,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.17.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_268
call_method,view,"{view_210: None, size_268: None}","(view_210, -1, size_268)",{},{addmm_69: None},,size_268,transformer_h_17_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.17.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_211
get_attr,transformer.h.17.attn.c_proj.weight,{},(),{},{addmm_69: None},,view_211,addmm_69,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.17.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_17_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_17_attn_c_proj_bias: None, view_211: None, transformer_h_17_attn_c_proj_weight: None}","(transformer_h_17_attn_c_proj_bias, view_211, transformer_h_17_attn_c_proj_weight)",{},{view_212: None},,transformer_h_17_attn_c_proj_weight,view_212,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.17.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_69
call_method,view,"{addmm_69: None, add_213: None}","(addmm_69, add_213)",{},{transformer_h_17_attn_resid_dropout: None},,addmm_69,transformer_h_17_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.17.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_212
call_module,transformer.h.17.attn.resid_dropout,{view_212: None},"(view_212,)",{},{add_214: None},,view_212,add_214,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.17.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_17_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_17_attn_resid_dropout: None, add_207: None}","(transformer_h_17_attn_resid_dropout, add_207)",{},"{transformer_h_17_ln_2: None, add_219: None}",,transformer_h_17_attn_resid_dropout,transformer_h_17_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_214
call_module,transformer.h.17.ln_2,{add_214: None},"(add_214,)",{},"{size_269: None, size_270: None, view_213: None}",,add_214,size_269,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_17_ln_2
call_method,size,{transformer_h_17_ln_2: None},"(transformer_h_17_ln_2,)",{},{getitem_218: None},,transformer_h_17_ln_2,getitem_218,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_269
call_function,<built-in function getitem>,{size_269: None},"(size_269, slice(None, -1, None))",{},{add_215: None},,size_269,add_215,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_218
call_function,<built-in function add>,{getitem_218: None},"(getitem_218, (5120,))",{},{view_214: None},,getitem_218,transformer_h_17_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_215
get_attr,transformer.h.17.mlp.c_fc.bias,{},(),{},{addmm_70: None},,add_215,size_270,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_17_mlp_c_fc_bias
call_method,size,{transformer_h_17_ln_2: None},"(transformer_h_17_ln_2, -1)",{},{view_213: None},,transformer_h_17_mlp_c_fc_bias,view_213,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_270
call_method,view,"{transformer_h_17_ln_2: None, size_270: None}","(transformer_h_17_ln_2, -1, size_270)",{},{addmm_70: None},,size_270,transformer_h_17_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_213
get_attr,transformer.h.17.mlp.c_fc.weight,{},(),{},{addmm_70: None},,view_213,addmm_70,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_17_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_17_mlp_c_fc_bias: None, view_213: None, transformer_h_17_mlp_c_fc_weight: None}","(transformer_h_17_mlp_c_fc_bias, view_213, transformer_h_17_mlp_c_fc_weight)",{},{view_214: None},,transformer_h_17_mlp_c_fc_weight,view_214,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_70
call_method,view,"{addmm_70: None, add_215: None}","(addmm_70, add_215)",{},"{mul_68: None, pow_36: None, add_216: None}",,addmm_70,mul_68,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_214
call_function,<built-in function mul>,{view_214: None},"(0.5, view_214)",{},{mul_71: None},,view_214,pow_36,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_68
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_214: None},"(view_214, 3.0)",{},{mul_69: None},,mul_68,mul_69,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_36
call_function,<built-in function mul>,{pow_36: None},"(0.044715, pow_36)",{},{add_216: None},,pow_36,add_216,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_69
call_function,<built-in function add>,"{view_214: None, mul_69: None}","(view_214, mul_69)",{},{mul_70: None},,mul_69,mul_70,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_216
call_function,<built-in function mul>,{add_216: None},"(0.7978845608028654, add_216)",{},{tanh_17: None},,add_216,tanh_17,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_70
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_70: None},"(mul_70,)",{},{add_217: None},,mul_70,add_217,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_17
call_function,<built-in function add>,{tanh_17: None},"(1.0, tanh_17)",{},{mul_71: None},,tanh_17,mul_71,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_217
call_function,<built-in function mul>,"{mul_68: None, add_217: None}","(mul_68, add_217)",{},"{size_271: None, size_272: None, view_215: None}",,add_217,size_271,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_71
call_method,size,{mul_71: None},"(mul_71,)",{},{getitem_219: None},,mul_71,getitem_219,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_271
call_function,<built-in function getitem>,{size_271: None},"(size_271, slice(None, -1, None))",{},{add_218: None},,size_271,add_218,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_219
call_function,<built-in function add>,{getitem_219: None},"(getitem_219, (1280,))",{},{view_216: None},,getitem_219,transformer_h_17_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_218
get_attr,transformer.h.17.mlp.c_proj.bias,{},(),{},{addmm_71: None},,add_218,size_272,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_17_mlp_c_proj_bias
call_method,size,{mul_71: None},"(mul_71, -1)",{},{view_215: None},,transformer_h_17_mlp_c_proj_bias,view_215,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_272
call_method,view,"{mul_71: None, size_272: None}","(mul_71, -1, size_272)",{},{addmm_71: None},,size_272,transformer_h_17_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_215
get_attr,transformer.h.17.mlp.c_proj.weight,{},(),{},{addmm_71: None},,view_215,addmm_71,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_17_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_17_mlp_c_proj_bias: None, view_215: None, transformer_h_17_mlp_c_proj_weight: None}","(transformer_h_17_mlp_c_proj_bias, view_215, transformer_h_17_mlp_c_proj_weight)",{},{view_216: None},,transformer_h_17_mlp_c_proj_weight,view_216,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_71
call_method,view,"{addmm_71: None, add_218: None}","(addmm_71, add_218)",{},{transformer_h_17_mlp_dropout: None},,addmm_71,transformer_h_17_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_216
call_module,transformer.h.17.mlp.dropout,{view_216: None},"(view_216,)",{},{add_219: None},,view_216,add_219,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.17.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.17.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_17_mlp_dropout
call_function,<built-in function add>,"{add_214: None, transformer_h_17_mlp_dropout: None}","(add_214, transformer_h_17_mlp_dropout)",{},"{transformer_h_18_ln_1: None, add_226: None}",,transformer_h_17_mlp_dropout,transformer_h_18_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.17', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_219
call_module,transformer.h.18.ln_1,{add_219: None},"(add_219,)",{},"{size_273: None, size_274: None, view_217: None}",,add_219,size_273,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_18_ln_1
call_method,size,{transformer_h_18_ln_1: None},"(transformer_h_18_ln_1,)",{},{getitem_220: None},,transformer_h_18_ln_1,getitem_220,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.18.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_273
call_function,<built-in function getitem>,{size_273: None},"(size_273, slice(None, -1, None))",{},{add_220: None},,size_273,add_220,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.18.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_220
call_function,<built-in function add>,{getitem_220: None},"(getitem_220, (3840,))",{},{view_218: None},,getitem_220,transformer_h_18_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.18.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_220
get_attr,transformer.h.18.attn.c_attn.bias,{},(),{},{addmm_72: None},,add_220,size_274,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.18.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_18_attn_c_attn_bias
call_method,size,{transformer_h_18_ln_1: None},"(transformer_h_18_ln_1, -1)",{},{view_217: None},,transformer_h_18_attn_c_attn_bias,view_217,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.18.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_274
call_method,view,"{transformer_h_18_ln_1: None, size_274: None}","(transformer_h_18_ln_1, -1, size_274)",{},{addmm_72: None},,size_274,transformer_h_18_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.18.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_217
get_attr,transformer.h.18.attn.c_attn.weight,{},(),{},{addmm_72: None},,view_217,addmm_72,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.18.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_18_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_18_attn_c_attn_bias: None, view_217: None, transformer_h_18_attn_c_attn_weight: None}","(transformer_h_18_attn_c_attn_bias, view_217, transformer_h_18_attn_c_attn_weight)",{},{view_218: None},,transformer_h_18_attn_c_attn_weight,view_218,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.18.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_72
call_method,view,"{addmm_72: None, add_220: None}","(addmm_72, add_220)",{},{split_18: None},,addmm_72,split_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.18.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_218
call_method,split,{view_218: None},"(view_218, 1280)",{'dim': 2},"{getitem_221: None, getitem_222: None, getitem_223: None}",,view_218,getitem_221,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_18
call_function,<built-in function getitem>,{split_18: None},"(split_18, 0)",{},"{size_275: None, view_219: None}",,split_18,getitem_222,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_221
call_function,<built-in function getitem>,{split_18: None},"(split_18, 1)",{},"{size_276: None, view_220: None}",,getitem_221,getitem_223,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_222
call_function,<built-in function getitem>,{split_18: None},"(split_18, 2)",{},"{size_277: None, view_221: None}",,getitem_222,size_275,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_223
call_method,size,{getitem_221: None},"(getitem_221,)",{},{getitem_224: None},,getitem_223,getitem_224,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_275
call_function,<built-in function getitem>,{size_275: None},"(size_275, slice(None, -1, None))",{},{add_221: None},,size_275,add_221,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_224
call_function,<built-in function add>,{getitem_224: None},"(getitem_224, (20, 64))",{},{view_219: None},,getitem_224,view_219,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_221
call_method,view,"{getitem_221: None, add_221: None}","(getitem_221, add_221)",{},{permute_72: None},,add_221,permute_72,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_219
call_method,permute,{view_219: None},"(view_219, 0, 2, 1, 3)",{},"{matmul_36: None, size_279: None}",,view_219,size_276,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_72
call_method,size,{getitem_222: None},"(getitem_222,)",{},{getitem_225: None},,permute_72,getitem_225,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_276
call_function,<built-in function getitem>,{size_276: None},"(size_276, slice(None, -1, None))",{},{add_222: None},,size_276,add_222,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_225
call_function,<built-in function add>,{getitem_225: None},"(getitem_225, (20, 64))",{},{view_220: None},,getitem_225,view_220,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_222
call_method,view,"{getitem_222: None, add_222: None}","(getitem_222, add_222)",{},{permute_73: None},,add_222,permute_73,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_220
call_method,permute,{view_220: None},"(view_220, 0, 2, 1, 3)",{},"{transpose_18: None, size_280: None, output: None}",,view_220,size_277,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_73
call_method,size,{getitem_223: None},"(getitem_223,)",{},{getitem_226: None},,permute_73,getitem_226,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_277
call_function,<built-in function getitem>,{size_277: None},"(size_277, slice(None, -1, None))",{},{add_223: None},,size_277,add_223,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_226
call_function,<built-in function add>,{getitem_226: None},"(getitem_226, (20, 64))",{},{view_221: None},,getitem_226,view_221,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_223
call_method,view,"{getitem_223: None, add_223: None}","(getitem_223, add_223)",{},{permute_74: None},,add_223,permute_74,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_221
call_method,permute,{view_221: None},"(view_221, 0, 2, 1, 3)",{},"{size_278: None, getattr_153: None, matmul_37: None, output: None}",,view_221,transpose_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_74
call_method,transpose,{permute_73: None},"(permute_73, -1, -2)",{},{matmul_36: None},,permute_74,matmul_36,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_18
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_72: None, transpose_18: None}","(permute_72, transpose_18)",{},"{getattr_146: None, getattr_147: None, truediv_18: None}",,transpose_18,size_278,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_36
call_method,size,{permute_74: None},"(permute_74, -1)",{},{pow_37: None},,matmul_36,pow_37,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_278
call_function,<built-in function pow>,{size_278: None},"(size_278, 0.5)",{},{full_36: None},,size_278,getattr_146,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_37
call_function,<built-in function getattr>,{matmul_36: None},"(matmul_36, 'dtype')",{},{full_36: None},,pow_37,getattr_147,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_146
call_function,<built-in function getattr>,{matmul_36: None},"(matmul_36, 'device')",{},{full_36: None},,getattr_146,full_36,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_147
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_37: None, getattr_146: None, getattr_147: None}","([], pow_37)","{'dtype': getattr_146, 'device': getattr_147}",{truediv_18: None},,getattr_147,truediv_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_36
call_function,<built-in function truediv>,"{matmul_36: None, full_36: None}","(matmul_36, full_36)",{},"{getattr_148: None, getattr_150: None, getattr_151: None, getattr_152: None, to_18: None}",,full_36,size_279,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_18
call_method,size,{permute_72: None},"(permute_72, -2)",{},{sub_18: None},,truediv_18,size_280,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_279
call_method,size,{permute_73: None},"(permute_73, -2)",{},"{sub_18: None, getitem_227: None}",,size_279,transformer_h_18_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_280
get_attr,transformer.h.18.attn.bias,{},(),{},{getitem_227: None},,size_280,sub_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_18_attn_bias
call_function,<built-in function sub>,"{size_280: None, size_279: None}","(size_280, size_279)",{},{getitem_227: None},,transformer_h_18_attn_bias,getitem_227,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_18
call_function,<built-in function getitem>,"{transformer_h_18_attn_bias: None, sub_18: None, size_280: None}","(transformer_h_18_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_18, size_280, None), slice(None, size_280, None)))",{},{where_18: None},,sub_18,getattr_148,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_227
call_function,<built-in function getattr>,{truediv_18: None},"(truediv_18, 'dtype')",{},{finfo_18: None},,getitem_227,finfo_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_148
call_function,<class 'torch.finfo'>,{getattr_148: None},"(getattr_148,)",{},{getattr_149: None},,getattr_148,getattr_149,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_18
call_function,<built-in function getattr>,{finfo_18: None},"(finfo_18, 'min')",{},{full_37: None},,finfo_18,getattr_150,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_149
call_function,<built-in function getattr>,{truediv_18: None},"(truediv_18, 'dtype')",{},{full_37: None},,getattr_149,getattr_151,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_150
call_function,<built-in function getattr>,{truediv_18: None},"(truediv_18, 'device')",{},{full_37: None},,getattr_150,full_37,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_151
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_149: None, getattr_150: None, getattr_151: None}","([], getattr_149)","{'dtype': getattr_150, 'device': getattr_151}",{where_18: None},,getattr_151,getattr_152,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_37
call_function,<built-in function getattr>,{truediv_18: None},"(truediv_18, 'dtype')",{},{to_18: None},,full_37,to_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_152
call_method,to,"{truediv_18: None, getattr_152: None}","(truediv_18, getattr_152)",{},{where_18: None},,getattr_152,where_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_18
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_227: None, to_18: None, full_37: None}","(getitem_227, to_18, full_37)",{},{softmax_18: None},,to_18,softmax_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_18
call_function,<function softmax at 0x7f6fd5135ca0>,{where_18: None},"(where_18,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_19: None},,where_18,getattr_153,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_18
call_function,<built-in function getattr>,{permute_74: None},"(permute_74, 'dtype')",{},{type_19: None},,softmax_18,type_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_153
call_method,type,"{softmax_18: None, getattr_153: None}","(softmax_18, getattr_153)",{},{transformer_h_18_attn_attn_dropout: None},,getattr_153,transformer_h_18_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_19
call_module,transformer.h.18.attn.attn_dropout,{type_19: None},"(type_19,)",{},{matmul_37: None},,type_19,matmul_37,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.18.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_18_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_18_attn_attn_dropout: None, permute_74: None}","(transformer_h_18_attn_attn_dropout, permute_74)",{},{permute_75: None},,transformer_h_18_attn_attn_dropout,permute_75,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_37
call_method,permute,{matmul_37: None},"(matmul_37, 0, 2, 1, 3)",{},{contiguous_18: None},,matmul_37,contiguous_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_75
call_method,contiguous,{permute_75: None},"(permute_75,)",{},"{size_281: None, view_222: None}",,permute_75,size_281,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_18
call_method,size,{contiguous_18: None},"(contiguous_18,)",{},{getitem_228: None},,contiguous_18,getitem_228,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_281
call_function,<built-in function getitem>,{size_281: None},"(size_281, slice(None, -2, None))",{},{add_224: None},,size_281,add_224,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_228
call_function,<built-in function add>,{getitem_228: None},"(getitem_228, (1280,))",{},{view_222: None},,getitem_228,view_222,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_224
call_method,view,"{contiguous_18: None, add_224: None}","(contiguous_18, add_224)",{},"{size_282: None, size_283: None, view_223: None}",,add_224,size_282,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_222
call_method,size,{view_222: None},"(view_222,)",{},{getitem_229: None},,view_222,getitem_229,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.18.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_282
call_function,<built-in function getitem>,{size_282: None},"(size_282, slice(None, -1, None))",{},{add_225: None},,size_282,add_225,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.18.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_229
call_function,<built-in function add>,{getitem_229: None},"(getitem_229, (1280,))",{},{view_224: None},,getitem_229,transformer_h_18_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.18.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_225
get_attr,transformer.h.18.attn.c_proj.bias,{},(),{},{addmm_73: None},,add_225,size_283,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.18.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_18_attn_c_proj_bias
call_method,size,{view_222: None},"(view_222, -1)",{},{view_223: None},,transformer_h_18_attn_c_proj_bias,view_223,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.18.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_283
call_method,view,"{view_222: None, size_283: None}","(view_222, -1, size_283)",{},{addmm_73: None},,size_283,transformer_h_18_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.18.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_223
get_attr,transformer.h.18.attn.c_proj.weight,{},(),{},{addmm_73: None},,view_223,addmm_73,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.18.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_18_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_18_attn_c_proj_bias: None, view_223: None, transformer_h_18_attn_c_proj_weight: None}","(transformer_h_18_attn_c_proj_bias, view_223, transformer_h_18_attn_c_proj_weight)",{},{view_224: None},,transformer_h_18_attn_c_proj_weight,view_224,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.18.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_73
call_method,view,"{addmm_73: None, add_225: None}","(addmm_73, add_225)",{},{transformer_h_18_attn_resid_dropout: None},,addmm_73,transformer_h_18_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.18.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_224
call_module,transformer.h.18.attn.resid_dropout,{view_224: None},"(view_224,)",{},{add_226: None},,view_224,add_226,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.18.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_18_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_18_attn_resid_dropout: None, add_219: None}","(transformer_h_18_attn_resid_dropout, add_219)",{},"{transformer_h_18_ln_2: None, add_231: None}",,transformer_h_18_attn_resid_dropout,transformer_h_18_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_226
call_module,transformer.h.18.ln_2,{add_226: None},"(add_226,)",{},"{size_284: None, size_285: None, view_225: None}",,add_226,size_284,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_18_ln_2
call_method,size,{transformer_h_18_ln_2: None},"(transformer_h_18_ln_2,)",{},{getitem_230: None},,transformer_h_18_ln_2,getitem_230,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_284
call_function,<built-in function getitem>,{size_284: None},"(size_284, slice(None, -1, None))",{},{add_227: None},,size_284,add_227,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_230
call_function,<built-in function add>,{getitem_230: None},"(getitem_230, (5120,))",{},{view_226: None},,getitem_230,transformer_h_18_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_227
get_attr,transformer.h.18.mlp.c_fc.bias,{},(),{},{addmm_74: None},,add_227,size_285,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_18_mlp_c_fc_bias
call_method,size,{transformer_h_18_ln_2: None},"(transformer_h_18_ln_2, -1)",{},{view_225: None},,transformer_h_18_mlp_c_fc_bias,view_225,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_285
call_method,view,"{transformer_h_18_ln_2: None, size_285: None}","(transformer_h_18_ln_2, -1, size_285)",{},{addmm_74: None},,size_285,transformer_h_18_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_225
get_attr,transformer.h.18.mlp.c_fc.weight,{},(),{},{addmm_74: None},,view_225,addmm_74,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_18_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_18_mlp_c_fc_bias: None, view_225: None, transformer_h_18_mlp_c_fc_weight: None}","(transformer_h_18_mlp_c_fc_bias, view_225, transformer_h_18_mlp_c_fc_weight)",{},{view_226: None},,transformer_h_18_mlp_c_fc_weight,view_226,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_74
call_method,view,"{addmm_74: None, add_227: None}","(addmm_74, add_227)",{},"{mul_72: None, pow_38: None, add_228: None}",,addmm_74,mul_72,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_226
call_function,<built-in function mul>,{view_226: None},"(0.5, view_226)",{},{mul_75: None},,view_226,pow_38,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_72
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_226: None},"(view_226, 3.0)",{},{mul_73: None},,mul_72,mul_73,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_38
call_function,<built-in function mul>,{pow_38: None},"(0.044715, pow_38)",{},{add_228: None},,pow_38,add_228,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_73
call_function,<built-in function add>,"{view_226: None, mul_73: None}","(view_226, mul_73)",{},{mul_74: None},,mul_73,mul_74,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_228
call_function,<built-in function mul>,{add_228: None},"(0.7978845608028654, add_228)",{},{tanh_18: None},,add_228,tanh_18,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_74
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_74: None},"(mul_74,)",{},{add_229: None},,mul_74,add_229,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_18
call_function,<built-in function add>,{tanh_18: None},"(1.0, tanh_18)",{},{mul_75: None},,tanh_18,mul_75,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_229
call_function,<built-in function mul>,"{mul_72: None, add_229: None}","(mul_72, add_229)",{},"{size_286: None, size_287: None, view_227: None}",,add_229,size_286,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_75
call_method,size,{mul_75: None},"(mul_75,)",{},{getitem_231: None},,mul_75,getitem_231,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_286
call_function,<built-in function getitem>,{size_286: None},"(size_286, slice(None, -1, None))",{},{add_230: None},,size_286,add_230,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_231
call_function,<built-in function add>,{getitem_231: None},"(getitem_231, (1280,))",{},{view_228: None},,getitem_231,transformer_h_18_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_230
get_attr,transformer.h.18.mlp.c_proj.bias,{},(),{},{addmm_75: None},,add_230,size_287,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_18_mlp_c_proj_bias
call_method,size,{mul_75: None},"(mul_75, -1)",{},{view_227: None},,transformer_h_18_mlp_c_proj_bias,view_227,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_287
call_method,view,"{mul_75: None, size_287: None}","(mul_75, -1, size_287)",{},{addmm_75: None},,size_287,transformer_h_18_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_227
get_attr,transformer.h.18.mlp.c_proj.weight,{},(),{},{addmm_75: None},,view_227,addmm_75,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_18_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_18_mlp_c_proj_bias: None, view_227: None, transformer_h_18_mlp_c_proj_weight: None}","(transformer_h_18_mlp_c_proj_bias, view_227, transformer_h_18_mlp_c_proj_weight)",{},{view_228: None},,transformer_h_18_mlp_c_proj_weight,view_228,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_75
call_method,view,"{addmm_75: None, add_230: None}","(addmm_75, add_230)",{},{transformer_h_18_mlp_dropout: None},,addmm_75,transformer_h_18_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_228
call_module,transformer.h.18.mlp.dropout,{view_228: None},"(view_228,)",{},{add_231: None},,view_228,add_231,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.18.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.18.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_18_mlp_dropout
call_function,<built-in function add>,"{add_226: None, transformer_h_18_mlp_dropout: None}","(add_226, transformer_h_18_mlp_dropout)",{},"{transformer_h_19_ln_1: None, add_238: None}",,transformer_h_18_mlp_dropout,transformer_h_19_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.18', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_231
call_module,transformer.h.19.ln_1,{add_231: None},"(add_231,)",{},"{size_288: None, size_289: None, view_229: None}",,add_231,size_288,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_19_ln_1
call_method,size,{transformer_h_19_ln_1: None},"(transformer_h_19_ln_1,)",{},{getitem_232: None},,transformer_h_19_ln_1,getitem_232,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.19.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_288
call_function,<built-in function getitem>,{size_288: None},"(size_288, slice(None, -1, None))",{},{add_232: None},,size_288,add_232,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.19.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_232
call_function,<built-in function add>,{getitem_232: None},"(getitem_232, (3840,))",{},{view_230: None},,getitem_232,transformer_h_19_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.19.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_232
get_attr,transformer.h.19.attn.c_attn.bias,{},(),{},{addmm_76: None},,add_232,size_289,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.19.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_19_attn_c_attn_bias
call_method,size,{transformer_h_19_ln_1: None},"(transformer_h_19_ln_1, -1)",{},{view_229: None},,transformer_h_19_attn_c_attn_bias,view_229,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.19.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_289
call_method,view,"{transformer_h_19_ln_1: None, size_289: None}","(transformer_h_19_ln_1, -1, size_289)",{},{addmm_76: None},,size_289,transformer_h_19_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.19.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_229
get_attr,transformer.h.19.attn.c_attn.weight,{},(),{},{addmm_76: None},,view_229,addmm_76,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.19.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_19_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_19_attn_c_attn_bias: None, view_229: None, transformer_h_19_attn_c_attn_weight: None}","(transformer_h_19_attn_c_attn_bias, view_229, transformer_h_19_attn_c_attn_weight)",{},{view_230: None},,transformer_h_19_attn_c_attn_weight,view_230,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.19.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_76
call_method,view,"{addmm_76: None, add_232: None}","(addmm_76, add_232)",{},{split_19: None},,addmm_76,split_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.19.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_230
call_method,split,{view_230: None},"(view_230, 1280)",{'dim': 2},"{getitem_233: None, getitem_234: None, getitem_235: None}",,view_230,getitem_233,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_19
call_function,<built-in function getitem>,{split_19: None},"(split_19, 0)",{},"{size_290: None, view_231: None}",,split_19,getitem_234,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_233
call_function,<built-in function getitem>,{split_19: None},"(split_19, 1)",{},"{size_291: None, view_232: None}",,getitem_233,getitem_235,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_234
call_function,<built-in function getitem>,{split_19: None},"(split_19, 2)",{},"{size_292: None, view_233: None}",,getitem_234,size_290,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_235
call_method,size,{getitem_233: None},"(getitem_233,)",{},{getitem_236: None},,getitem_235,getitem_236,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_290
call_function,<built-in function getitem>,{size_290: None},"(size_290, slice(None, -1, None))",{},{add_233: None},,size_290,add_233,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_236
call_function,<built-in function add>,{getitem_236: None},"(getitem_236, (20, 64))",{},{view_231: None},,getitem_236,view_231,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_233
call_method,view,"{getitem_233: None, add_233: None}","(getitem_233, add_233)",{},{permute_76: None},,add_233,permute_76,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_231
call_method,permute,{view_231: None},"(view_231, 0, 2, 1, 3)",{},"{matmul_38: None, size_294: None}",,view_231,size_291,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_76
call_method,size,{getitem_234: None},"(getitem_234,)",{},{getitem_237: None},,permute_76,getitem_237,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_291
call_function,<built-in function getitem>,{size_291: None},"(size_291, slice(None, -1, None))",{},{add_234: None},,size_291,add_234,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_237
call_function,<built-in function add>,{getitem_237: None},"(getitem_237, (20, 64))",{},{view_232: None},,getitem_237,view_232,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_234
call_method,view,"{getitem_234: None, add_234: None}","(getitem_234, add_234)",{},{permute_77: None},,add_234,permute_77,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_232
call_method,permute,{view_232: None},"(view_232, 0, 2, 1, 3)",{},"{transpose_19: None, size_295: None, output: None}",,view_232,size_292,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_77
call_method,size,{getitem_235: None},"(getitem_235,)",{},{getitem_238: None},,permute_77,getitem_238,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_292
call_function,<built-in function getitem>,{size_292: None},"(size_292, slice(None, -1, None))",{},{add_235: None},,size_292,add_235,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_238
call_function,<built-in function add>,{getitem_238: None},"(getitem_238, (20, 64))",{},{view_233: None},,getitem_238,view_233,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_235
call_method,view,"{getitem_235: None, add_235: None}","(getitem_235, add_235)",{},{permute_78: None},,add_235,permute_78,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_233
call_method,permute,{view_233: None},"(view_233, 0, 2, 1, 3)",{},"{size_293: None, getattr_161: None, matmul_39: None, output: None}",,view_233,transpose_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_78
call_method,transpose,{permute_77: None},"(permute_77, -1, -2)",{},{matmul_38: None},,permute_78,matmul_38,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_19
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_76: None, transpose_19: None}","(permute_76, transpose_19)",{},"{getattr_154: None, getattr_155: None, truediv_19: None}",,transpose_19,size_293,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_38
call_method,size,{permute_78: None},"(permute_78, -1)",{},{pow_39: None},,matmul_38,pow_39,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_293
call_function,<built-in function pow>,{size_293: None},"(size_293, 0.5)",{},{full_38: None},,size_293,getattr_154,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_39
call_function,<built-in function getattr>,{matmul_38: None},"(matmul_38, 'dtype')",{},{full_38: None},,pow_39,getattr_155,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_154
call_function,<built-in function getattr>,{matmul_38: None},"(matmul_38, 'device')",{},{full_38: None},,getattr_154,full_38,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_155
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_39: None, getattr_154: None, getattr_155: None}","([], pow_39)","{'dtype': getattr_154, 'device': getattr_155}",{truediv_19: None},,getattr_155,truediv_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_38
call_function,<built-in function truediv>,"{matmul_38: None, full_38: None}","(matmul_38, full_38)",{},"{getattr_156: None, getattr_158: None, getattr_159: None, getattr_160: None, to_19: None}",,full_38,size_294,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_19
call_method,size,{permute_76: None},"(permute_76, -2)",{},{sub_19: None},,truediv_19,size_295,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_294
call_method,size,{permute_77: None},"(permute_77, -2)",{},"{sub_19: None, getitem_239: None}",,size_294,transformer_h_19_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_295
get_attr,transformer.h.19.attn.bias,{},(),{},{getitem_239: None},,size_295,sub_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_19_attn_bias
call_function,<built-in function sub>,"{size_295: None, size_294: None}","(size_295, size_294)",{},{getitem_239: None},,transformer_h_19_attn_bias,getitem_239,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_19
call_function,<built-in function getitem>,"{transformer_h_19_attn_bias: None, sub_19: None, size_295: None}","(transformer_h_19_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_19, size_295, None), slice(None, size_295, None)))",{},{where_19: None},,sub_19,getattr_156,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_239
call_function,<built-in function getattr>,{truediv_19: None},"(truediv_19, 'dtype')",{},{finfo_19: None},,getitem_239,finfo_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_156
call_function,<class 'torch.finfo'>,{getattr_156: None},"(getattr_156,)",{},{getattr_157: None},,getattr_156,getattr_157,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_19
call_function,<built-in function getattr>,{finfo_19: None},"(finfo_19, 'min')",{},{full_39: None},,finfo_19,getattr_158,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_157
call_function,<built-in function getattr>,{truediv_19: None},"(truediv_19, 'dtype')",{},{full_39: None},,getattr_157,getattr_159,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_158
call_function,<built-in function getattr>,{truediv_19: None},"(truediv_19, 'device')",{},{full_39: None},,getattr_158,full_39,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_159
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_157: None, getattr_158: None, getattr_159: None}","([], getattr_157)","{'dtype': getattr_158, 'device': getattr_159}",{where_19: None},,getattr_159,getattr_160,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_39
call_function,<built-in function getattr>,{truediv_19: None},"(truediv_19, 'dtype')",{},{to_19: None},,full_39,to_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_160
call_method,to,"{truediv_19: None, getattr_160: None}","(truediv_19, getattr_160)",{},{where_19: None},,getattr_160,where_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_19
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_239: None, to_19: None, full_39: None}","(getitem_239, to_19, full_39)",{},{softmax_19: None},,to_19,softmax_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_19
call_function,<function softmax at 0x7f6fd5135ca0>,{where_19: None},"(where_19,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_20: None},,where_19,getattr_161,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_19
call_function,<built-in function getattr>,{permute_78: None},"(permute_78, 'dtype')",{},{type_20: None},,softmax_19,type_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_161
call_method,type,"{softmax_19: None, getattr_161: None}","(softmax_19, getattr_161)",{},{transformer_h_19_attn_attn_dropout: None},,getattr_161,transformer_h_19_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_20
call_module,transformer.h.19.attn.attn_dropout,{type_20: None},"(type_20,)",{},{matmul_39: None},,type_20,matmul_39,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.19.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_19_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_19_attn_attn_dropout: None, permute_78: None}","(transformer_h_19_attn_attn_dropout, permute_78)",{},{permute_79: None},,transformer_h_19_attn_attn_dropout,permute_79,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_39
call_method,permute,{matmul_39: None},"(matmul_39, 0, 2, 1, 3)",{},{contiguous_19: None},,matmul_39,contiguous_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_79
call_method,contiguous,{permute_79: None},"(permute_79,)",{},"{size_296: None, view_234: None}",,permute_79,size_296,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_19
call_method,size,{contiguous_19: None},"(contiguous_19,)",{},{getitem_240: None},,contiguous_19,getitem_240,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_296
call_function,<built-in function getitem>,{size_296: None},"(size_296, slice(None, -2, None))",{},{add_236: None},,size_296,add_236,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_240
call_function,<built-in function add>,{getitem_240: None},"(getitem_240, (1280,))",{},{view_234: None},,getitem_240,view_234,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_236
call_method,view,"{contiguous_19: None, add_236: None}","(contiguous_19, add_236)",{},"{size_297: None, size_298: None, view_235: None}",,add_236,size_297,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_234
call_method,size,{view_234: None},"(view_234,)",{},{getitem_241: None},,view_234,getitem_241,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.19.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_297
call_function,<built-in function getitem>,{size_297: None},"(size_297, slice(None, -1, None))",{},{add_237: None},,size_297,add_237,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.19.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_241
call_function,<built-in function add>,{getitem_241: None},"(getitem_241, (1280,))",{},{view_236: None},,getitem_241,transformer_h_19_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.19.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_237
get_attr,transformer.h.19.attn.c_proj.bias,{},(),{},{addmm_77: None},,add_237,size_298,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.19.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_19_attn_c_proj_bias
call_method,size,{view_234: None},"(view_234, -1)",{},{view_235: None},,transformer_h_19_attn_c_proj_bias,view_235,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.19.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_298
call_method,view,"{view_234: None, size_298: None}","(view_234, -1, size_298)",{},{addmm_77: None},,size_298,transformer_h_19_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.19.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_235
get_attr,transformer.h.19.attn.c_proj.weight,{},(),{},{addmm_77: None},,view_235,addmm_77,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.19.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_19_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_19_attn_c_proj_bias: None, view_235: None, transformer_h_19_attn_c_proj_weight: None}","(transformer_h_19_attn_c_proj_bias, view_235, transformer_h_19_attn_c_proj_weight)",{},{view_236: None},,transformer_h_19_attn_c_proj_weight,view_236,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.19.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_77
call_method,view,"{addmm_77: None, add_237: None}","(addmm_77, add_237)",{},{transformer_h_19_attn_resid_dropout: None},,addmm_77,transformer_h_19_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.19.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_236
call_module,transformer.h.19.attn.resid_dropout,{view_236: None},"(view_236,)",{},{add_238: None},,view_236,add_238,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.19.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_19_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_19_attn_resid_dropout: None, add_231: None}","(transformer_h_19_attn_resid_dropout, add_231)",{},"{transformer_h_19_ln_2: None, add_243: None}",,transformer_h_19_attn_resid_dropout,transformer_h_19_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_238
call_module,transformer.h.19.ln_2,{add_238: None},"(add_238,)",{},"{size_299: None, size_300: None, view_237: None}",,add_238,size_299,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_19_ln_2
call_method,size,{transformer_h_19_ln_2: None},"(transformer_h_19_ln_2,)",{},{getitem_242: None},,transformer_h_19_ln_2,getitem_242,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_299
call_function,<built-in function getitem>,{size_299: None},"(size_299, slice(None, -1, None))",{},{add_239: None},,size_299,add_239,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_242
call_function,<built-in function add>,{getitem_242: None},"(getitem_242, (5120,))",{},{view_238: None},,getitem_242,transformer_h_19_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_239
get_attr,transformer.h.19.mlp.c_fc.bias,{},(),{},{addmm_78: None},,add_239,size_300,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_19_mlp_c_fc_bias
call_method,size,{transformer_h_19_ln_2: None},"(transformer_h_19_ln_2, -1)",{},{view_237: None},,transformer_h_19_mlp_c_fc_bias,view_237,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_300
call_method,view,"{transformer_h_19_ln_2: None, size_300: None}","(transformer_h_19_ln_2, -1, size_300)",{},{addmm_78: None},,size_300,transformer_h_19_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_237
get_attr,transformer.h.19.mlp.c_fc.weight,{},(),{},{addmm_78: None},,view_237,addmm_78,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_19_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_19_mlp_c_fc_bias: None, view_237: None, transformer_h_19_mlp_c_fc_weight: None}","(transformer_h_19_mlp_c_fc_bias, view_237, transformer_h_19_mlp_c_fc_weight)",{},{view_238: None},,transformer_h_19_mlp_c_fc_weight,view_238,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_78
call_method,view,"{addmm_78: None, add_239: None}","(addmm_78, add_239)",{},"{mul_76: None, pow_40: None, add_240: None}",,addmm_78,mul_76,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_238
call_function,<built-in function mul>,{view_238: None},"(0.5, view_238)",{},{mul_79: None},,view_238,pow_40,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_76
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_238: None},"(view_238, 3.0)",{},{mul_77: None},,mul_76,mul_77,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_40
call_function,<built-in function mul>,{pow_40: None},"(0.044715, pow_40)",{},{add_240: None},,pow_40,add_240,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_77
call_function,<built-in function add>,"{view_238: None, mul_77: None}","(view_238, mul_77)",{},{mul_78: None},,mul_77,mul_78,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_240
call_function,<built-in function mul>,{add_240: None},"(0.7978845608028654, add_240)",{},{tanh_19: None},,add_240,tanh_19,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_78
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_78: None},"(mul_78,)",{},{add_241: None},,mul_78,add_241,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_19
call_function,<built-in function add>,{tanh_19: None},"(1.0, tanh_19)",{},{mul_79: None},,tanh_19,mul_79,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_241
call_function,<built-in function mul>,"{mul_76: None, add_241: None}","(mul_76, add_241)",{},"{size_301: None, size_302: None, view_239: None}",,add_241,size_301,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_79
call_method,size,{mul_79: None},"(mul_79,)",{},{getitem_243: None},,mul_79,getitem_243,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_301
call_function,<built-in function getitem>,{size_301: None},"(size_301, slice(None, -1, None))",{},{add_242: None},,size_301,add_242,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_243
call_function,<built-in function add>,{getitem_243: None},"(getitem_243, (1280,))",{},{view_240: None},,getitem_243,transformer_h_19_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_242
get_attr,transformer.h.19.mlp.c_proj.bias,{},(),{},{addmm_79: None},,add_242,size_302,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_19_mlp_c_proj_bias
call_method,size,{mul_79: None},"(mul_79, -1)",{},{view_239: None},,transformer_h_19_mlp_c_proj_bias,view_239,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_302
call_method,view,"{mul_79: None, size_302: None}","(mul_79, -1, size_302)",{},{addmm_79: None},,size_302,transformer_h_19_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_239
get_attr,transformer.h.19.mlp.c_proj.weight,{},(),{},{addmm_79: None},,view_239,addmm_79,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_19_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_19_mlp_c_proj_bias: None, view_239: None, transformer_h_19_mlp_c_proj_weight: None}","(transformer_h_19_mlp_c_proj_bias, view_239, transformer_h_19_mlp_c_proj_weight)",{},{view_240: None},,transformer_h_19_mlp_c_proj_weight,view_240,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_79
call_method,view,"{addmm_79: None, add_242: None}","(addmm_79, add_242)",{},{transformer_h_19_mlp_dropout: None},,addmm_79,transformer_h_19_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_240
call_module,transformer.h.19.mlp.dropout,{view_240: None},"(view_240,)",{},{add_243: None},,view_240,add_243,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.19.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.19.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_19_mlp_dropout
call_function,<built-in function add>,"{add_238: None, transformer_h_19_mlp_dropout: None}","(add_238, transformer_h_19_mlp_dropout)",{},"{transformer_h_20_ln_1: None, add_250: None}",,transformer_h_19_mlp_dropout,transformer_h_20_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.19', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_243
call_module,transformer.h.20.ln_1,{add_243: None},"(add_243,)",{},"{size_303: None, size_304: None, view_241: None}",,add_243,size_303,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_20_ln_1
call_method,size,{transformer_h_20_ln_1: None},"(transformer_h_20_ln_1,)",{},{getitem_244: None},,transformer_h_20_ln_1,getitem_244,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.20.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_303
call_function,<built-in function getitem>,{size_303: None},"(size_303, slice(None, -1, None))",{},{add_244: None},,size_303,add_244,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.20.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_244
call_function,<built-in function add>,{getitem_244: None},"(getitem_244, (3840,))",{},{view_242: None},,getitem_244,transformer_h_20_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.20.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_244
get_attr,transformer.h.20.attn.c_attn.bias,{},(),{},{addmm_80: None},,add_244,size_304,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.20.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_20_attn_c_attn_bias
call_method,size,{transformer_h_20_ln_1: None},"(transformer_h_20_ln_1, -1)",{},{view_241: None},,transformer_h_20_attn_c_attn_bias,view_241,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.20.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_304
call_method,view,"{transformer_h_20_ln_1: None, size_304: None}","(transformer_h_20_ln_1, -1, size_304)",{},{addmm_80: None},,size_304,transformer_h_20_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.20.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_241
get_attr,transformer.h.20.attn.c_attn.weight,{},(),{},{addmm_80: None},,view_241,addmm_80,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.20.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_20_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_20_attn_c_attn_bias: None, view_241: None, transformer_h_20_attn_c_attn_weight: None}","(transformer_h_20_attn_c_attn_bias, view_241, transformer_h_20_attn_c_attn_weight)",{},{view_242: None},,transformer_h_20_attn_c_attn_weight,view_242,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.20.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_80
call_method,view,"{addmm_80: None, add_244: None}","(addmm_80, add_244)",{},{split_20: None},,addmm_80,split_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.20.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_242
call_method,split,{view_242: None},"(view_242, 1280)",{'dim': 2},"{getitem_245: None, getitem_246: None, getitem_247: None}",,view_242,getitem_245,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_20
call_function,<built-in function getitem>,{split_20: None},"(split_20, 0)",{},"{size_305: None, view_243: None}",,split_20,getitem_246,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_245
call_function,<built-in function getitem>,{split_20: None},"(split_20, 1)",{},"{size_306: None, view_244: None}",,getitem_245,getitem_247,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_246
call_function,<built-in function getitem>,{split_20: None},"(split_20, 2)",{},"{size_307: None, view_245: None}",,getitem_246,size_305,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_247
call_method,size,{getitem_245: None},"(getitem_245,)",{},{getitem_248: None},,getitem_247,getitem_248,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_305
call_function,<built-in function getitem>,{size_305: None},"(size_305, slice(None, -1, None))",{},{add_245: None},,size_305,add_245,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_248
call_function,<built-in function add>,{getitem_248: None},"(getitem_248, (20, 64))",{},{view_243: None},,getitem_248,view_243,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_245
call_method,view,"{getitem_245: None, add_245: None}","(getitem_245, add_245)",{},{permute_80: None},,add_245,permute_80,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_243
call_method,permute,{view_243: None},"(view_243, 0, 2, 1, 3)",{},"{matmul_40: None, size_309: None}",,view_243,size_306,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_80
call_method,size,{getitem_246: None},"(getitem_246,)",{},{getitem_249: None},,permute_80,getitem_249,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_306
call_function,<built-in function getitem>,{size_306: None},"(size_306, slice(None, -1, None))",{},{add_246: None},,size_306,add_246,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_249
call_function,<built-in function add>,{getitem_249: None},"(getitem_249, (20, 64))",{},{view_244: None},,getitem_249,view_244,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_246
call_method,view,"{getitem_246: None, add_246: None}","(getitem_246, add_246)",{},{permute_81: None},,add_246,permute_81,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_244
call_method,permute,{view_244: None},"(view_244, 0, 2, 1, 3)",{},"{transpose_20: None, size_310: None, output: None}",,view_244,size_307,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_81
call_method,size,{getitem_247: None},"(getitem_247,)",{},{getitem_250: None},,permute_81,getitem_250,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_307
call_function,<built-in function getitem>,{size_307: None},"(size_307, slice(None, -1, None))",{},{add_247: None},,size_307,add_247,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_250
call_function,<built-in function add>,{getitem_250: None},"(getitem_250, (20, 64))",{},{view_245: None},,getitem_250,view_245,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_247
call_method,view,"{getitem_247: None, add_247: None}","(getitem_247, add_247)",{},{permute_82: None},,add_247,permute_82,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_245
call_method,permute,{view_245: None},"(view_245, 0, 2, 1, 3)",{},"{size_308: None, getattr_169: None, matmul_41: None, output: None}",,view_245,transpose_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_82
call_method,transpose,{permute_81: None},"(permute_81, -1, -2)",{},{matmul_40: None},,permute_82,matmul_40,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_20
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_80: None, transpose_20: None}","(permute_80, transpose_20)",{},"{getattr_162: None, getattr_163: None, truediv_20: None}",,transpose_20,size_308,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_40
call_method,size,{permute_82: None},"(permute_82, -1)",{},{pow_41: None},,matmul_40,pow_41,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_308
call_function,<built-in function pow>,{size_308: None},"(size_308, 0.5)",{},{full_40: None},,size_308,getattr_162,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_41
call_function,<built-in function getattr>,{matmul_40: None},"(matmul_40, 'dtype')",{},{full_40: None},,pow_41,getattr_163,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_162
call_function,<built-in function getattr>,{matmul_40: None},"(matmul_40, 'device')",{},{full_40: None},,getattr_162,full_40,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_163
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_41: None, getattr_162: None, getattr_163: None}","([], pow_41)","{'dtype': getattr_162, 'device': getattr_163}",{truediv_20: None},,getattr_163,truediv_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_40
call_function,<built-in function truediv>,"{matmul_40: None, full_40: None}","(matmul_40, full_40)",{},"{getattr_164: None, getattr_166: None, getattr_167: None, getattr_168: None, to_20: None}",,full_40,size_309,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_20
call_method,size,{permute_80: None},"(permute_80, -2)",{},{sub_20: None},,truediv_20,size_310,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_309
call_method,size,{permute_81: None},"(permute_81, -2)",{},"{sub_20: None, getitem_251: None}",,size_309,transformer_h_20_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_310
get_attr,transformer.h.20.attn.bias,{},(),{},{getitem_251: None},,size_310,sub_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_20_attn_bias
call_function,<built-in function sub>,"{size_310: None, size_309: None}","(size_310, size_309)",{},{getitem_251: None},,transformer_h_20_attn_bias,getitem_251,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_20
call_function,<built-in function getitem>,"{transformer_h_20_attn_bias: None, sub_20: None, size_310: None}","(transformer_h_20_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_20, size_310, None), slice(None, size_310, None)))",{},{where_20: None},,sub_20,getattr_164,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_251
call_function,<built-in function getattr>,{truediv_20: None},"(truediv_20, 'dtype')",{},{finfo_20: None},,getitem_251,finfo_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_164
call_function,<class 'torch.finfo'>,{getattr_164: None},"(getattr_164,)",{},{getattr_165: None},,getattr_164,getattr_165,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_20
call_function,<built-in function getattr>,{finfo_20: None},"(finfo_20, 'min')",{},{full_41: None},,finfo_20,getattr_166,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_165
call_function,<built-in function getattr>,{truediv_20: None},"(truediv_20, 'dtype')",{},{full_41: None},,getattr_165,getattr_167,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_166
call_function,<built-in function getattr>,{truediv_20: None},"(truediv_20, 'device')",{},{full_41: None},,getattr_166,full_41,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_167
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_165: None, getattr_166: None, getattr_167: None}","([], getattr_165)","{'dtype': getattr_166, 'device': getattr_167}",{where_20: None},,getattr_167,getattr_168,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_41
call_function,<built-in function getattr>,{truediv_20: None},"(truediv_20, 'dtype')",{},{to_20: None},,full_41,to_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_168
call_method,to,"{truediv_20: None, getattr_168: None}","(truediv_20, getattr_168)",{},{where_20: None},,getattr_168,where_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_20
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_251: None, to_20: None, full_41: None}","(getitem_251, to_20, full_41)",{},{softmax_20: None},,to_20,softmax_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_20
call_function,<function softmax at 0x7f6fd5135ca0>,{where_20: None},"(where_20,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_21: None},,where_20,getattr_169,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_20
call_function,<built-in function getattr>,{permute_82: None},"(permute_82, 'dtype')",{},{type_21: None},,softmax_20,type_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_169
call_method,type,"{softmax_20: None, getattr_169: None}","(softmax_20, getattr_169)",{},{transformer_h_20_attn_attn_dropout: None},,getattr_169,transformer_h_20_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_21
call_module,transformer.h.20.attn.attn_dropout,{type_21: None},"(type_21,)",{},{matmul_41: None},,type_21,matmul_41,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.20.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_20_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_20_attn_attn_dropout: None, permute_82: None}","(transformer_h_20_attn_attn_dropout, permute_82)",{},{permute_83: None},,transformer_h_20_attn_attn_dropout,permute_83,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_41
call_method,permute,{matmul_41: None},"(matmul_41, 0, 2, 1, 3)",{},{contiguous_20: None},,matmul_41,contiguous_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_83
call_method,contiguous,{permute_83: None},"(permute_83,)",{},"{size_311: None, view_246: None}",,permute_83,size_311,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_20
call_method,size,{contiguous_20: None},"(contiguous_20,)",{},{getitem_252: None},,contiguous_20,getitem_252,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_311
call_function,<built-in function getitem>,{size_311: None},"(size_311, slice(None, -2, None))",{},{add_248: None},,size_311,add_248,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_252
call_function,<built-in function add>,{getitem_252: None},"(getitem_252, (1280,))",{},{view_246: None},,getitem_252,view_246,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_248
call_method,view,"{contiguous_20: None, add_248: None}","(contiguous_20, add_248)",{},"{size_312: None, size_313: None, view_247: None}",,add_248,size_312,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_246
call_method,size,{view_246: None},"(view_246,)",{},{getitem_253: None},,view_246,getitem_253,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.20.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_312
call_function,<built-in function getitem>,{size_312: None},"(size_312, slice(None, -1, None))",{},{add_249: None},,size_312,add_249,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.20.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_253
call_function,<built-in function add>,{getitem_253: None},"(getitem_253, (1280,))",{},{view_248: None},,getitem_253,transformer_h_20_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.20.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_249
get_attr,transformer.h.20.attn.c_proj.bias,{},(),{},{addmm_81: None},,add_249,size_313,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.20.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_20_attn_c_proj_bias
call_method,size,{view_246: None},"(view_246, -1)",{},{view_247: None},,transformer_h_20_attn_c_proj_bias,view_247,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.20.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_313
call_method,view,"{view_246: None, size_313: None}","(view_246, -1, size_313)",{},{addmm_81: None},,size_313,transformer_h_20_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.20.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_247
get_attr,transformer.h.20.attn.c_proj.weight,{},(),{},{addmm_81: None},,view_247,addmm_81,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.20.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_20_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_20_attn_c_proj_bias: None, view_247: None, transformer_h_20_attn_c_proj_weight: None}","(transformer_h_20_attn_c_proj_bias, view_247, transformer_h_20_attn_c_proj_weight)",{},{view_248: None},,transformer_h_20_attn_c_proj_weight,view_248,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.20.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_81
call_method,view,"{addmm_81: None, add_249: None}","(addmm_81, add_249)",{},{transformer_h_20_attn_resid_dropout: None},,addmm_81,transformer_h_20_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.20.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_248
call_module,transformer.h.20.attn.resid_dropout,{view_248: None},"(view_248,)",{},{add_250: None},,view_248,add_250,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.20.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_20_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_20_attn_resid_dropout: None, add_243: None}","(transformer_h_20_attn_resid_dropout, add_243)",{},"{transformer_h_20_ln_2: None, add_255: None}",,transformer_h_20_attn_resid_dropout,transformer_h_20_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_250
call_module,transformer.h.20.ln_2,{add_250: None},"(add_250,)",{},"{size_314: None, size_315: None, view_249: None}",,add_250,size_314,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_20_ln_2
call_method,size,{transformer_h_20_ln_2: None},"(transformer_h_20_ln_2,)",{},{getitem_254: None},,transformer_h_20_ln_2,getitem_254,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_314
call_function,<built-in function getitem>,{size_314: None},"(size_314, slice(None, -1, None))",{},{add_251: None},,size_314,add_251,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_254
call_function,<built-in function add>,{getitem_254: None},"(getitem_254, (5120,))",{},{view_250: None},,getitem_254,transformer_h_20_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_251
get_attr,transformer.h.20.mlp.c_fc.bias,{},(),{},{addmm_82: None},,add_251,size_315,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_20_mlp_c_fc_bias
call_method,size,{transformer_h_20_ln_2: None},"(transformer_h_20_ln_2, -1)",{},{view_249: None},,transformer_h_20_mlp_c_fc_bias,view_249,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_315
call_method,view,"{transformer_h_20_ln_2: None, size_315: None}","(transformer_h_20_ln_2, -1, size_315)",{},{addmm_82: None},,size_315,transformer_h_20_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_249
get_attr,transformer.h.20.mlp.c_fc.weight,{},(),{},{addmm_82: None},,view_249,addmm_82,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_20_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_20_mlp_c_fc_bias: None, view_249: None, transformer_h_20_mlp_c_fc_weight: None}","(transformer_h_20_mlp_c_fc_bias, view_249, transformer_h_20_mlp_c_fc_weight)",{},{view_250: None},,transformer_h_20_mlp_c_fc_weight,view_250,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_82
call_method,view,"{addmm_82: None, add_251: None}","(addmm_82, add_251)",{},"{mul_80: None, pow_42: None, add_252: None}",,addmm_82,mul_80,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_250
call_function,<built-in function mul>,{view_250: None},"(0.5, view_250)",{},{mul_83: None},,view_250,pow_42,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_80
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_250: None},"(view_250, 3.0)",{},{mul_81: None},,mul_80,mul_81,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_42
call_function,<built-in function mul>,{pow_42: None},"(0.044715, pow_42)",{},{add_252: None},,pow_42,add_252,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_81
call_function,<built-in function add>,"{view_250: None, mul_81: None}","(view_250, mul_81)",{},{mul_82: None},,mul_81,mul_82,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_252
call_function,<built-in function mul>,{add_252: None},"(0.7978845608028654, add_252)",{},{tanh_20: None},,add_252,tanh_20,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_82
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_82: None},"(mul_82,)",{},{add_253: None},,mul_82,add_253,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_20
call_function,<built-in function add>,{tanh_20: None},"(1.0, tanh_20)",{},{mul_83: None},,tanh_20,mul_83,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_253
call_function,<built-in function mul>,"{mul_80: None, add_253: None}","(mul_80, add_253)",{},"{size_316: None, size_317: None, view_251: None}",,add_253,size_316,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_83
call_method,size,{mul_83: None},"(mul_83,)",{},{getitem_255: None},,mul_83,getitem_255,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_316
call_function,<built-in function getitem>,{size_316: None},"(size_316, slice(None, -1, None))",{},{add_254: None},,size_316,add_254,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_255
call_function,<built-in function add>,{getitem_255: None},"(getitem_255, (1280,))",{},{view_252: None},,getitem_255,transformer_h_20_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_254
get_attr,transformer.h.20.mlp.c_proj.bias,{},(),{},{addmm_83: None},,add_254,size_317,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_20_mlp_c_proj_bias
call_method,size,{mul_83: None},"(mul_83, -1)",{},{view_251: None},,transformer_h_20_mlp_c_proj_bias,view_251,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_317
call_method,view,"{mul_83: None, size_317: None}","(mul_83, -1, size_317)",{},{addmm_83: None},,size_317,transformer_h_20_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_251
get_attr,transformer.h.20.mlp.c_proj.weight,{},(),{},{addmm_83: None},,view_251,addmm_83,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_20_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_20_mlp_c_proj_bias: None, view_251: None, transformer_h_20_mlp_c_proj_weight: None}","(transformer_h_20_mlp_c_proj_bias, view_251, transformer_h_20_mlp_c_proj_weight)",{},{view_252: None},,transformer_h_20_mlp_c_proj_weight,view_252,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_83
call_method,view,"{addmm_83: None, add_254: None}","(addmm_83, add_254)",{},{transformer_h_20_mlp_dropout: None},,addmm_83,transformer_h_20_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_252
call_module,transformer.h.20.mlp.dropout,{view_252: None},"(view_252,)",{},{add_255: None},,view_252,add_255,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.20.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.20.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_20_mlp_dropout
call_function,<built-in function add>,"{add_250: None, transformer_h_20_mlp_dropout: None}","(add_250, transformer_h_20_mlp_dropout)",{},"{transformer_h_21_ln_1: None, add_262: None}",,transformer_h_20_mlp_dropout,transformer_h_21_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.20', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_255
call_module,transformer.h.21.ln_1,{add_255: None},"(add_255,)",{},"{size_318: None, size_319: None, view_253: None}",,add_255,size_318,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_21_ln_1
call_method,size,{transformer_h_21_ln_1: None},"(transformer_h_21_ln_1,)",{},{getitem_256: None},,transformer_h_21_ln_1,getitem_256,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.21.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_318
call_function,<built-in function getitem>,{size_318: None},"(size_318, slice(None, -1, None))",{},{add_256: None},,size_318,add_256,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.21.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_256
call_function,<built-in function add>,{getitem_256: None},"(getitem_256, (3840,))",{},{view_254: None},,getitem_256,transformer_h_21_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.21.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_256
get_attr,transformer.h.21.attn.c_attn.bias,{},(),{},{addmm_84: None},,add_256,size_319,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.21.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_21_attn_c_attn_bias
call_method,size,{transformer_h_21_ln_1: None},"(transformer_h_21_ln_1, -1)",{},{view_253: None},,transformer_h_21_attn_c_attn_bias,view_253,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.21.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_319
call_method,view,"{transformer_h_21_ln_1: None, size_319: None}","(transformer_h_21_ln_1, -1, size_319)",{},{addmm_84: None},,size_319,transformer_h_21_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.21.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_253
get_attr,transformer.h.21.attn.c_attn.weight,{},(),{},{addmm_84: None},,view_253,addmm_84,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.21.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_21_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_21_attn_c_attn_bias: None, view_253: None, transformer_h_21_attn_c_attn_weight: None}","(transformer_h_21_attn_c_attn_bias, view_253, transformer_h_21_attn_c_attn_weight)",{},{view_254: None},,transformer_h_21_attn_c_attn_weight,view_254,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.21.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_84
call_method,view,"{addmm_84: None, add_256: None}","(addmm_84, add_256)",{},{split_21: None},,addmm_84,split_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.21.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_254
call_method,split,{view_254: None},"(view_254, 1280)",{'dim': 2},"{getitem_257: None, getitem_258: None, getitem_259: None}",,view_254,getitem_257,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_21
call_function,<built-in function getitem>,{split_21: None},"(split_21, 0)",{},"{size_320: None, view_255: None}",,split_21,getitem_258,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_257
call_function,<built-in function getitem>,{split_21: None},"(split_21, 1)",{},"{size_321: None, view_256: None}",,getitem_257,getitem_259,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_258
call_function,<built-in function getitem>,{split_21: None},"(split_21, 2)",{},"{size_322: None, view_257: None}",,getitem_258,size_320,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_259
call_method,size,{getitem_257: None},"(getitem_257,)",{},{getitem_260: None},,getitem_259,getitem_260,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_320
call_function,<built-in function getitem>,{size_320: None},"(size_320, slice(None, -1, None))",{},{add_257: None},,size_320,add_257,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_260
call_function,<built-in function add>,{getitem_260: None},"(getitem_260, (20, 64))",{},{view_255: None},,getitem_260,view_255,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_257
call_method,view,"{getitem_257: None, add_257: None}","(getitem_257, add_257)",{},{permute_84: None},,add_257,permute_84,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_255
call_method,permute,{view_255: None},"(view_255, 0, 2, 1, 3)",{},"{matmul_42: None, size_324: None}",,view_255,size_321,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_84
call_method,size,{getitem_258: None},"(getitem_258,)",{},{getitem_261: None},,permute_84,getitem_261,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_321
call_function,<built-in function getitem>,{size_321: None},"(size_321, slice(None, -1, None))",{},{add_258: None},,size_321,add_258,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_261
call_function,<built-in function add>,{getitem_261: None},"(getitem_261, (20, 64))",{},{view_256: None},,getitem_261,view_256,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_258
call_method,view,"{getitem_258: None, add_258: None}","(getitem_258, add_258)",{},{permute_85: None},,add_258,permute_85,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_256
call_method,permute,{view_256: None},"(view_256, 0, 2, 1, 3)",{},"{transpose_21: None, size_325: None, output: None}",,view_256,size_322,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_85
call_method,size,{getitem_259: None},"(getitem_259,)",{},{getitem_262: None},,permute_85,getitem_262,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_322
call_function,<built-in function getitem>,{size_322: None},"(size_322, slice(None, -1, None))",{},{add_259: None},,size_322,add_259,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_262
call_function,<built-in function add>,{getitem_262: None},"(getitem_262, (20, 64))",{},{view_257: None},,getitem_262,view_257,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_259
call_method,view,"{getitem_259: None, add_259: None}","(getitem_259, add_259)",{},{permute_86: None},,add_259,permute_86,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_257
call_method,permute,{view_257: None},"(view_257, 0, 2, 1, 3)",{},"{size_323: None, getattr_177: None, matmul_43: None, output: None}",,view_257,transpose_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_86
call_method,transpose,{permute_85: None},"(permute_85, -1, -2)",{},{matmul_42: None},,permute_86,matmul_42,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_21
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_84: None, transpose_21: None}","(permute_84, transpose_21)",{},"{getattr_170: None, getattr_171: None, truediv_21: None}",,transpose_21,size_323,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_42
call_method,size,{permute_86: None},"(permute_86, -1)",{},{pow_43: None},,matmul_42,pow_43,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_323
call_function,<built-in function pow>,{size_323: None},"(size_323, 0.5)",{},{full_42: None},,size_323,getattr_170,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_43
call_function,<built-in function getattr>,{matmul_42: None},"(matmul_42, 'dtype')",{},{full_42: None},,pow_43,getattr_171,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_170
call_function,<built-in function getattr>,{matmul_42: None},"(matmul_42, 'device')",{},{full_42: None},,getattr_170,full_42,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_171
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_43: None, getattr_170: None, getattr_171: None}","([], pow_43)","{'dtype': getattr_170, 'device': getattr_171}",{truediv_21: None},,getattr_171,truediv_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_42
call_function,<built-in function truediv>,"{matmul_42: None, full_42: None}","(matmul_42, full_42)",{},"{getattr_172: None, getattr_174: None, getattr_175: None, getattr_176: None, to_21: None}",,full_42,size_324,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_21
call_method,size,{permute_84: None},"(permute_84, -2)",{},{sub_21: None},,truediv_21,size_325,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_324
call_method,size,{permute_85: None},"(permute_85, -2)",{},"{sub_21: None, getitem_263: None}",,size_324,transformer_h_21_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_325
get_attr,transformer.h.21.attn.bias,{},(),{},{getitem_263: None},,size_325,sub_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_21_attn_bias
call_function,<built-in function sub>,"{size_325: None, size_324: None}","(size_325, size_324)",{},{getitem_263: None},,transformer_h_21_attn_bias,getitem_263,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_21
call_function,<built-in function getitem>,"{transformer_h_21_attn_bias: None, sub_21: None, size_325: None}","(transformer_h_21_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_21, size_325, None), slice(None, size_325, None)))",{},{where_21: None},,sub_21,getattr_172,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_263
call_function,<built-in function getattr>,{truediv_21: None},"(truediv_21, 'dtype')",{},{finfo_21: None},,getitem_263,finfo_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_172
call_function,<class 'torch.finfo'>,{getattr_172: None},"(getattr_172,)",{},{getattr_173: None},,getattr_172,getattr_173,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_21
call_function,<built-in function getattr>,{finfo_21: None},"(finfo_21, 'min')",{},{full_43: None},,finfo_21,getattr_174,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_173
call_function,<built-in function getattr>,{truediv_21: None},"(truediv_21, 'dtype')",{},{full_43: None},,getattr_173,getattr_175,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_174
call_function,<built-in function getattr>,{truediv_21: None},"(truediv_21, 'device')",{},{full_43: None},,getattr_174,full_43,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_175
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_173: None, getattr_174: None, getattr_175: None}","([], getattr_173)","{'dtype': getattr_174, 'device': getattr_175}",{where_21: None},,getattr_175,getattr_176,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_43
call_function,<built-in function getattr>,{truediv_21: None},"(truediv_21, 'dtype')",{},{to_21: None},,full_43,to_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_176
call_method,to,"{truediv_21: None, getattr_176: None}","(truediv_21, getattr_176)",{},{where_21: None},,getattr_176,where_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_21
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_263: None, to_21: None, full_43: None}","(getitem_263, to_21, full_43)",{},{softmax_21: None},,to_21,softmax_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_21
call_function,<function softmax at 0x7f6fd5135ca0>,{where_21: None},"(where_21,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_22: None},,where_21,getattr_177,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_21
call_function,<built-in function getattr>,{permute_86: None},"(permute_86, 'dtype')",{},{type_22: None},,softmax_21,type_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_177
call_method,type,"{softmax_21: None, getattr_177: None}","(softmax_21, getattr_177)",{},{transformer_h_21_attn_attn_dropout: None},,getattr_177,transformer_h_21_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_22
call_module,transformer.h.21.attn.attn_dropout,{type_22: None},"(type_22,)",{},{matmul_43: None},,type_22,matmul_43,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.21.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_21_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_21_attn_attn_dropout: None, permute_86: None}","(transformer_h_21_attn_attn_dropout, permute_86)",{},{permute_87: None},,transformer_h_21_attn_attn_dropout,permute_87,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_43
call_method,permute,{matmul_43: None},"(matmul_43, 0, 2, 1, 3)",{},{contiguous_21: None},,matmul_43,contiguous_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_87
call_method,contiguous,{permute_87: None},"(permute_87,)",{},"{size_326: None, view_258: None}",,permute_87,size_326,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_21
call_method,size,{contiguous_21: None},"(contiguous_21,)",{},{getitem_264: None},,contiguous_21,getitem_264,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_326
call_function,<built-in function getitem>,{size_326: None},"(size_326, slice(None, -2, None))",{},{add_260: None},,size_326,add_260,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_264
call_function,<built-in function add>,{getitem_264: None},"(getitem_264, (1280,))",{},{view_258: None},,getitem_264,view_258,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_260
call_method,view,"{contiguous_21: None, add_260: None}","(contiguous_21, add_260)",{},"{size_327: None, size_328: None, view_259: None}",,add_260,size_327,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_258
call_method,size,{view_258: None},"(view_258,)",{},{getitem_265: None},,view_258,getitem_265,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.21.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_327
call_function,<built-in function getitem>,{size_327: None},"(size_327, slice(None, -1, None))",{},{add_261: None},,size_327,add_261,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.21.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_265
call_function,<built-in function add>,{getitem_265: None},"(getitem_265, (1280,))",{},{view_260: None},,getitem_265,transformer_h_21_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.21.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_261
get_attr,transformer.h.21.attn.c_proj.bias,{},(),{},{addmm_85: None},,add_261,size_328,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.21.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_21_attn_c_proj_bias
call_method,size,{view_258: None},"(view_258, -1)",{},{view_259: None},,transformer_h_21_attn_c_proj_bias,view_259,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.21.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_328
call_method,view,"{view_258: None, size_328: None}","(view_258, -1, size_328)",{},{addmm_85: None},,size_328,transformer_h_21_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.21.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_259
get_attr,transformer.h.21.attn.c_proj.weight,{},(),{},{addmm_85: None},,view_259,addmm_85,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.21.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_21_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_21_attn_c_proj_bias: None, view_259: None, transformer_h_21_attn_c_proj_weight: None}","(transformer_h_21_attn_c_proj_bias, view_259, transformer_h_21_attn_c_proj_weight)",{},{view_260: None},,transformer_h_21_attn_c_proj_weight,view_260,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.21.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_85
call_method,view,"{addmm_85: None, add_261: None}","(addmm_85, add_261)",{},{transformer_h_21_attn_resid_dropout: None},,addmm_85,transformer_h_21_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.21.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_260
call_module,transformer.h.21.attn.resid_dropout,{view_260: None},"(view_260,)",{},{add_262: None},,view_260,add_262,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.21.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_21_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_21_attn_resid_dropout: None, add_255: None}","(transformer_h_21_attn_resid_dropout, add_255)",{},"{transformer_h_21_ln_2: None, add_267: None}",,transformer_h_21_attn_resid_dropout,transformer_h_21_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_262
call_module,transformer.h.21.ln_2,{add_262: None},"(add_262,)",{},"{size_329: None, size_330: None, view_261: None}",,add_262,size_329,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_21_ln_2
call_method,size,{transformer_h_21_ln_2: None},"(transformer_h_21_ln_2,)",{},{getitem_266: None},,transformer_h_21_ln_2,getitem_266,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_329
call_function,<built-in function getitem>,{size_329: None},"(size_329, slice(None, -1, None))",{},{add_263: None},,size_329,add_263,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_266
call_function,<built-in function add>,{getitem_266: None},"(getitem_266, (5120,))",{},{view_262: None},,getitem_266,transformer_h_21_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_263
get_attr,transformer.h.21.mlp.c_fc.bias,{},(),{},{addmm_86: None},,add_263,size_330,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_21_mlp_c_fc_bias
call_method,size,{transformer_h_21_ln_2: None},"(transformer_h_21_ln_2, -1)",{},{view_261: None},,transformer_h_21_mlp_c_fc_bias,view_261,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_330
call_method,view,"{transformer_h_21_ln_2: None, size_330: None}","(transformer_h_21_ln_2, -1, size_330)",{},{addmm_86: None},,size_330,transformer_h_21_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_261
get_attr,transformer.h.21.mlp.c_fc.weight,{},(),{},{addmm_86: None},,view_261,addmm_86,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_21_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_21_mlp_c_fc_bias: None, view_261: None, transformer_h_21_mlp_c_fc_weight: None}","(transformer_h_21_mlp_c_fc_bias, view_261, transformer_h_21_mlp_c_fc_weight)",{},{view_262: None},,transformer_h_21_mlp_c_fc_weight,view_262,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_86
call_method,view,"{addmm_86: None, add_263: None}","(addmm_86, add_263)",{},"{mul_84: None, pow_44: None, add_264: None}",,addmm_86,mul_84,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_262
call_function,<built-in function mul>,{view_262: None},"(0.5, view_262)",{},{mul_87: None},,view_262,pow_44,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_84
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_262: None},"(view_262, 3.0)",{},{mul_85: None},,mul_84,mul_85,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_44
call_function,<built-in function mul>,{pow_44: None},"(0.044715, pow_44)",{},{add_264: None},,pow_44,add_264,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_85
call_function,<built-in function add>,"{view_262: None, mul_85: None}","(view_262, mul_85)",{},{mul_86: None},,mul_85,mul_86,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_264
call_function,<built-in function mul>,{add_264: None},"(0.7978845608028654, add_264)",{},{tanh_21: None},,add_264,tanh_21,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_86
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_86: None},"(mul_86,)",{},{add_265: None},,mul_86,add_265,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_21
call_function,<built-in function add>,{tanh_21: None},"(1.0, tanh_21)",{},{mul_87: None},,tanh_21,mul_87,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_265
call_function,<built-in function mul>,"{mul_84: None, add_265: None}","(mul_84, add_265)",{},"{size_331: None, size_332: None, view_263: None}",,add_265,size_331,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_87
call_method,size,{mul_87: None},"(mul_87,)",{},{getitem_267: None},,mul_87,getitem_267,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_331
call_function,<built-in function getitem>,{size_331: None},"(size_331, slice(None, -1, None))",{},{add_266: None},,size_331,add_266,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_267
call_function,<built-in function add>,{getitem_267: None},"(getitem_267, (1280,))",{},{view_264: None},,getitem_267,transformer_h_21_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_266
get_attr,transformer.h.21.mlp.c_proj.bias,{},(),{},{addmm_87: None},,add_266,size_332,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_21_mlp_c_proj_bias
call_method,size,{mul_87: None},"(mul_87, -1)",{},{view_263: None},,transformer_h_21_mlp_c_proj_bias,view_263,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_332
call_method,view,"{mul_87: None, size_332: None}","(mul_87, -1, size_332)",{},{addmm_87: None},,size_332,transformer_h_21_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_263
get_attr,transformer.h.21.mlp.c_proj.weight,{},(),{},{addmm_87: None},,view_263,addmm_87,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_21_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_21_mlp_c_proj_bias: None, view_263: None, transformer_h_21_mlp_c_proj_weight: None}","(transformer_h_21_mlp_c_proj_bias, view_263, transformer_h_21_mlp_c_proj_weight)",{},{view_264: None},,transformer_h_21_mlp_c_proj_weight,view_264,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_87
call_method,view,"{addmm_87: None, add_266: None}","(addmm_87, add_266)",{},{transformer_h_21_mlp_dropout: None},,addmm_87,transformer_h_21_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_264
call_module,transformer.h.21.mlp.dropout,{view_264: None},"(view_264,)",{},{add_267: None},,view_264,add_267,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.21.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.21.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_21_mlp_dropout
call_function,<built-in function add>,"{add_262: None, transformer_h_21_mlp_dropout: None}","(add_262, transformer_h_21_mlp_dropout)",{},"{transformer_h_22_ln_1: None, add_274: None}",,transformer_h_21_mlp_dropout,transformer_h_22_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.21', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_267
call_module,transformer.h.22.ln_1,{add_267: None},"(add_267,)",{},"{size_333: None, size_334: None, view_265: None}",,add_267,size_333,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_22_ln_1
call_method,size,{transformer_h_22_ln_1: None},"(transformer_h_22_ln_1,)",{},{getitem_268: None},,transformer_h_22_ln_1,getitem_268,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.22.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_333
call_function,<built-in function getitem>,{size_333: None},"(size_333, slice(None, -1, None))",{},{add_268: None},,size_333,add_268,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.22.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_268
call_function,<built-in function add>,{getitem_268: None},"(getitem_268, (3840,))",{},{view_266: None},,getitem_268,transformer_h_22_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.22.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_268
get_attr,transformer.h.22.attn.c_attn.bias,{},(),{},{addmm_88: None},,add_268,size_334,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.22.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_22_attn_c_attn_bias
call_method,size,{transformer_h_22_ln_1: None},"(transformer_h_22_ln_1, -1)",{},{view_265: None},,transformer_h_22_attn_c_attn_bias,view_265,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.22.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_334
call_method,view,"{transformer_h_22_ln_1: None, size_334: None}","(transformer_h_22_ln_1, -1, size_334)",{},{addmm_88: None},,size_334,transformer_h_22_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.22.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_265
get_attr,transformer.h.22.attn.c_attn.weight,{},(),{},{addmm_88: None},,view_265,addmm_88,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.22.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_22_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_22_attn_c_attn_bias: None, view_265: None, transformer_h_22_attn_c_attn_weight: None}","(transformer_h_22_attn_c_attn_bias, view_265, transformer_h_22_attn_c_attn_weight)",{},{view_266: None},,transformer_h_22_attn_c_attn_weight,view_266,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.22.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_88
call_method,view,"{addmm_88: None, add_268: None}","(addmm_88, add_268)",{},{split_22: None},,addmm_88,split_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.22.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_266
call_method,split,{view_266: None},"(view_266, 1280)",{'dim': 2},"{getitem_269: None, getitem_270: None, getitem_271: None}",,view_266,getitem_269,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_22
call_function,<built-in function getitem>,{split_22: None},"(split_22, 0)",{},"{size_335: None, view_267: None}",,split_22,getitem_270,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_269
call_function,<built-in function getitem>,{split_22: None},"(split_22, 1)",{},"{size_336: None, view_268: None}",,getitem_269,getitem_271,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_270
call_function,<built-in function getitem>,{split_22: None},"(split_22, 2)",{},"{size_337: None, view_269: None}",,getitem_270,size_335,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_271
call_method,size,{getitem_269: None},"(getitem_269,)",{},{getitem_272: None},,getitem_271,getitem_272,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_335
call_function,<built-in function getitem>,{size_335: None},"(size_335, slice(None, -1, None))",{},{add_269: None},,size_335,add_269,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_272
call_function,<built-in function add>,{getitem_272: None},"(getitem_272, (20, 64))",{},{view_267: None},,getitem_272,view_267,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_269
call_method,view,"{getitem_269: None, add_269: None}","(getitem_269, add_269)",{},{permute_88: None},,add_269,permute_88,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_267
call_method,permute,{view_267: None},"(view_267, 0, 2, 1, 3)",{},"{matmul_44: None, size_339: None}",,view_267,size_336,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_88
call_method,size,{getitem_270: None},"(getitem_270,)",{},{getitem_273: None},,permute_88,getitem_273,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_336
call_function,<built-in function getitem>,{size_336: None},"(size_336, slice(None, -1, None))",{},{add_270: None},,size_336,add_270,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_273
call_function,<built-in function add>,{getitem_273: None},"(getitem_273, (20, 64))",{},{view_268: None},,getitem_273,view_268,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_270
call_method,view,"{getitem_270: None, add_270: None}","(getitem_270, add_270)",{},{permute_89: None},,add_270,permute_89,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_268
call_method,permute,{view_268: None},"(view_268, 0, 2, 1, 3)",{},"{transpose_22: None, size_340: None, output: None}",,view_268,size_337,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_89
call_method,size,{getitem_271: None},"(getitem_271,)",{},{getitem_274: None},,permute_89,getitem_274,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_337
call_function,<built-in function getitem>,{size_337: None},"(size_337, slice(None, -1, None))",{},{add_271: None},,size_337,add_271,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_274
call_function,<built-in function add>,{getitem_274: None},"(getitem_274, (20, 64))",{},{view_269: None},,getitem_274,view_269,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_271
call_method,view,"{getitem_271: None, add_271: None}","(getitem_271, add_271)",{},{permute_90: None},,add_271,permute_90,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_269
call_method,permute,{view_269: None},"(view_269, 0, 2, 1, 3)",{},"{size_338: None, getattr_185: None, matmul_45: None, output: None}",,view_269,transpose_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_90
call_method,transpose,{permute_89: None},"(permute_89, -1, -2)",{},{matmul_44: None},,permute_90,matmul_44,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_22
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_88: None, transpose_22: None}","(permute_88, transpose_22)",{},"{getattr_178: None, getattr_179: None, truediv_22: None}",,transpose_22,size_338,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_44
call_method,size,{permute_90: None},"(permute_90, -1)",{},{pow_45: None},,matmul_44,pow_45,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_338
call_function,<built-in function pow>,{size_338: None},"(size_338, 0.5)",{},{full_44: None},,size_338,getattr_178,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_45
call_function,<built-in function getattr>,{matmul_44: None},"(matmul_44, 'dtype')",{},{full_44: None},,pow_45,getattr_179,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_178
call_function,<built-in function getattr>,{matmul_44: None},"(matmul_44, 'device')",{},{full_44: None},,getattr_178,full_44,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_179
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_45: None, getattr_178: None, getattr_179: None}","([], pow_45)","{'dtype': getattr_178, 'device': getattr_179}",{truediv_22: None},,getattr_179,truediv_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_44
call_function,<built-in function truediv>,"{matmul_44: None, full_44: None}","(matmul_44, full_44)",{},"{getattr_180: None, getattr_182: None, getattr_183: None, getattr_184: None, to_22: None}",,full_44,size_339,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_22
call_method,size,{permute_88: None},"(permute_88, -2)",{},{sub_22: None},,truediv_22,size_340,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_339
call_method,size,{permute_89: None},"(permute_89, -2)",{},"{sub_22: None, getitem_275: None}",,size_339,transformer_h_22_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_340
get_attr,transformer.h.22.attn.bias,{},(),{},{getitem_275: None},,size_340,sub_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_22_attn_bias
call_function,<built-in function sub>,"{size_340: None, size_339: None}","(size_340, size_339)",{},{getitem_275: None},,transformer_h_22_attn_bias,getitem_275,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_22
call_function,<built-in function getitem>,"{transformer_h_22_attn_bias: None, sub_22: None, size_340: None}","(transformer_h_22_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_22, size_340, None), slice(None, size_340, None)))",{},{where_22: None},,sub_22,getattr_180,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_275
call_function,<built-in function getattr>,{truediv_22: None},"(truediv_22, 'dtype')",{},{finfo_22: None},,getitem_275,finfo_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_180
call_function,<class 'torch.finfo'>,{getattr_180: None},"(getattr_180,)",{},{getattr_181: None},,getattr_180,getattr_181,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_22
call_function,<built-in function getattr>,{finfo_22: None},"(finfo_22, 'min')",{},{full_45: None},,finfo_22,getattr_182,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_181
call_function,<built-in function getattr>,{truediv_22: None},"(truediv_22, 'dtype')",{},{full_45: None},,getattr_181,getattr_183,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_182
call_function,<built-in function getattr>,{truediv_22: None},"(truediv_22, 'device')",{},{full_45: None},,getattr_182,full_45,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_183
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_181: None, getattr_182: None, getattr_183: None}","([], getattr_181)","{'dtype': getattr_182, 'device': getattr_183}",{where_22: None},,getattr_183,getattr_184,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_45
call_function,<built-in function getattr>,{truediv_22: None},"(truediv_22, 'dtype')",{},{to_22: None},,full_45,to_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_184
call_method,to,"{truediv_22: None, getattr_184: None}","(truediv_22, getattr_184)",{},{where_22: None},,getattr_184,where_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_22
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_275: None, to_22: None, full_45: None}","(getitem_275, to_22, full_45)",{},{softmax_22: None},,to_22,softmax_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_22
call_function,<function softmax at 0x7f6fd5135ca0>,{where_22: None},"(where_22,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_23: None},,where_22,getattr_185,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_22
call_function,<built-in function getattr>,{permute_90: None},"(permute_90, 'dtype')",{},{type_23: None},,softmax_22,type_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_185
call_method,type,"{softmax_22: None, getattr_185: None}","(softmax_22, getattr_185)",{},{transformer_h_22_attn_attn_dropout: None},,getattr_185,transformer_h_22_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_23
call_module,transformer.h.22.attn.attn_dropout,{type_23: None},"(type_23,)",{},{matmul_45: None},,type_23,matmul_45,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.22.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_22_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_22_attn_attn_dropout: None, permute_90: None}","(transformer_h_22_attn_attn_dropout, permute_90)",{},{permute_91: None},,transformer_h_22_attn_attn_dropout,permute_91,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_45
call_method,permute,{matmul_45: None},"(matmul_45, 0, 2, 1, 3)",{},{contiguous_22: None},,matmul_45,contiguous_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_91
call_method,contiguous,{permute_91: None},"(permute_91,)",{},"{size_341: None, view_270: None}",,permute_91,size_341,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_22
call_method,size,{contiguous_22: None},"(contiguous_22,)",{},{getitem_276: None},,contiguous_22,getitem_276,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_341
call_function,<built-in function getitem>,{size_341: None},"(size_341, slice(None, -2, None))",{},{add_272: None},,size_341,add_272,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_276
call_function,<built-in function add>,{getitem_276: None},"(getitem_276, (1280,))",{},{view_270: None},,getitem_276,view_270,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_272
call_method,view,"{contiguous_22: None, add_272: None}","(contiguous_22, add_272)",{},"{size_342: None, size_343: None, view_271: None}",,add_272,size_342,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_270
call_method,size,{view_270: None},"(view_270,)",{},{getitem_277: None},,view_270,getitem_277,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.22.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_342
call_function,<built-in function getitem>,{size_342: None},"(size_342, slice(None, -1, None))",{},{add_273: None},,size_342,add_273,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.22.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_277
call_function,<built-in function add>,{getitem_277: None},"(getitem_277, (1280,))",{},{view_272: None},,getitem_277,transformer_h_22_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.22.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_273
get_attr,transformer.h.22.attn.c_proj.bias,{},(),{},{addmm_89: None},,add_273,size_343,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.22.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_22_attn_c_proj_bias
call_method,size,{view_270: None},"(view_270, -1)",{},{view_271: None},,transformer_h_22_attn_c_proj_bias,view_271,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.22.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_343
call_method,view,"{view_270: None, size_343: None}","(view_270, -1, size_343)",{},{addmm_89: None},,size_343,transformer_h_22_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.22.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_271
get_attr,transformer.h.22.attn.c_proj.weight,{},(),{},{addmm_89: None},,view_271,addmm_89,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.22.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_22_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_22_attn_c_proj_bias: None, view_271: None, transformer_h_22_attn_c_proj_weight: None}","(transformer_h_22_attn_c_proj_bias, view_271, transformer_h_22_attn_c_proj_weight)",{},{view_272: None},,transformer_h_22_attn_c_proj_weight,view_272,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.22.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_89
call_method,view,"{addmm_89: None, add_273: None}","(addmm_89, add_273)",{},{transformer_h_22_attn_resid_dropout: None},,addmm_89,transformer_h_22_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.22.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_272
call_module,transformer.h.22.attn.resid_dropout,{view_272: None},"(view_272,)",{},{add_274: None},,view_272,add_274,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.22.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_22_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_22_attn_resid_dropout: None, add_267: None}","(transformer_h_22_attn_resid_dropout, add_267)",{},"{transformer_h_22_ln_2: None, add_279: None}",,transformer_h_22_attn_resid_dropout,transformer_h_22_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_274
call_module,transformer.h.22.ln_2,{add_274: None},"(add_274,)",{},"{size_344: None, size_345: None, view_273: None}",,add_274,size_344,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_22_ln_2
call_method,size,{transformer_h_22_ln_2: None},"(transformer_h_22_ln_2,)",{},{getitem_278: None},,transformer_h_22_ln_2,getitem_278,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_344
call_function,<built-in function getitem>,{size_344: None},"(size_344, slice(None, -1, None))",{},{add_275: None},,size_344,add_275,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_278
call_function,<built-in function add>,{getitem_278: None},"(getitem_278, (5120,))",{},{view_274: None},,getitem_278,transformer_h_22_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_275
get_attr,transformer.h.22.mlp.c_fc.bias,{},(),{},{addmm_90: None},,add_275,size_345,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_22_mlp_c_fc_bias
call_method,size,{transformer_h_22_ln_2: None},"(transformer_h_22_ln_2, -1)",{},{view_273: None},,transformer_h_22_mlp_c_fc_bias,view_273,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_345
call_method,view,"{transformer_h_22_ln_2: None, size_345: None}","(transformer_h_22_ln_2, -1, size_345)",{},{addmm_90: None},,size_345,transformer_h_22_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_273
get_attr,transformer.h.22.mlp.c_fc.weight,{},(),{},{addmm_90: None},,view_273,addmm_90,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_22_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_22_mlp_c_fc_bias: None, view_273: None, transformer_h_22_mlp_c_fc_weight: None}","(transformer_h_22_mlp_c_fc_bias, view_273, transformer_h_22_mlp_c_fc_weight)",{},{view_274: None},,transformer_h_22_mlp_c_fc_weight,view_274,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_90
call_method,view,"{addmm_90: None, add_275: None}","(addmm_90, add_275)",{},"{mul_88: None, pow_46: None, add_276: None}",,addmm_90,mul_88,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_274
call_function,<built-in function mul>,{view_274: None},"(0.5, view_274)",{},{mul_91: None},,view_274,pow_46,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_88
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_274: None},"(view_274, 3.0)",{},{mul_89: None},,mul_88,mul_89,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_46
call_function,<built-in function mul>,{pow_46: None},"(0.044715, pow_46)",{},{add_276: None},,pow_46,add_276,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_89
call_function,<built-in function add>,"{view_274: None, mul_89: None}","(view_274, mul_89)",{},{mul_90: None},,mul_89,mul_90,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_276
call_function,<built-in function mul>,{add_276: None},"(0.7978845608028654, add_276)",{},{tanh_22: None},,add_276,tanh_22,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_90
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_90: None},"(mul_90,)",{},{add_277: None},,mul_90,add_277,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_22
call_function,<built-in function add>,{tanh_22: None},"(1.0, tanh_22)",{},{mul_91: None},,tanh_22,mul_91,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_277
call_function,<built-in function mul>,"{mul_88: None, add_277: None}","(mul_88, add_277)",{},"{size_346: None, size_347: None, view_275: None}",,add_277,size_346,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_91
call_method,size,{mul_91: None},"(mul_91,)",{},{getitem_279: None},,mul_91,getitem_279,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_346
call_function,<built-in function getitem>,{size_346: None},"(size_346, slice(None, -1, None))",{},{add_278: None},,size_346,add_278,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_279
call_function,<built-in function add>,{getitem_279: None},"(getitem_279, (1280,))",{},{view_276: None},,getitem_279,transformer_h_22_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_278
get_attr,transformer.h.22.mlp.c_proj.bias,{},(),{},{addmm_91: None},,add_278,size_347,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_22_mlp_c_proj_bias
call_method,size,{mul_91: None},"(mul_91, -1)",{},{view_275: None},,transformer_h_22_mlp_c_proj_bias,view_275,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_347
call_method,view,"{mul_91: None, size_347: None}","(mul_91, -1, size_347)",{},{addmm_91: None},,size_347,transformer_h_22_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_275
get_attr,transformer.h.22.mlp.c_proj.weight,{},(),{},{addmm_91: None},,view_275,addmm_91,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_22_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_22_mlp_c_proj_bias: None, view_275: None, transformer_h_22_mlp_c_proj_weight: None}","(transformer_h_22_mlp_c_proj_bias, view_275, transformer_h_22_mlp_c_proj_weight)",{},{view_276: None},,transformer_h_22_mlp_c_proj_weight,view_276,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_91
call_method,view,"{addmm_91: None, add_278: None}","(addmm_91, add_278)",{},{transformer_h_22_mlp_dropout: None},,addmm_91,transformer_h_22_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_276
call_module,transformer.h.22.mlp.dropout,{view_276: None},"(view_276,)",{},{add_279: None},,view_276,add_279,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.22.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.22.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_22_mlp_dropout
call_function,<built-in function add>,"{add_274: None, transformer_h_22_mlp_dropout: None}","(add_274, transformer_h_22_mlp_dropout)",{},"{transformer_h_23_ln_1: None, add_286: None}",,transformer_h_22_mlp_dropout,transformer_h_23_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.22', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_279
call_module,transformer.h.23.ln_1,{add_279: None},"(add_279,)",{},"{size_348: None, size_349: None, view_277: None}",,add_279,size_348,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_23_ln_1
call_method,size,{transformer_h_23_ln_1: None},"(transformer_h_23_ln_1,)",{},{getitem_280: None},,transformer_h_23_ln_1,getitem_280,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.23.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_348
call_function,<built-in function getitem>,{size_348: None},"(size_348, slice(None, -1, None))",{},{add_280: None},,size_348,add_280,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.23.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_280
call_function,<built-in function add>,{getitem_280: None},"(getitem_280, (3840,))",{},{view_278: None},,getitem_280,transformer_h_23_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.23.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_280
get_attr,transformer.h.23.attn.c_attn.bias,{},(),{},{addmm_92: None},,add_280,size_349,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.23.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_23_attn_c_attn_bias
call_method,size,{transformer_h_23_ln_1: None},"(transformer_h_23_ln_1, -1)",{},{view_277: None},,transformer_h_23_attn_c_attn_bias,view_277,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.23.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_349
call_method,view,"{transformer_h_23_ln_1: None, size_349: None}","(transformer_h_23_ln_1, -1, size_349)",{},{addmm_92: None},,size_349,transformer_h_23_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.23.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_277
get_attr,transformer.h.23.attn.c_attn.weight,{},(),{},{addmm_92: None},,view_277,addmm_92,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.23.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_23_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_23_attn_c_attn_bias: None, view_277: None, transformer_h_23_attn_c_attn_weight: None}","(transformer_h_23_attn_c_attn_bias, view_277, transformer_h_23_attn_c_attn_weight)",{},{view_278: None},,transformer_h_23_attn_c_attn_weight,view_278,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.23.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_92
call_method,view,"{addmm_92: None, add_280: None}","(addmm_92, add_280)",{},{split_23: None},,addmm_92,split_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.23.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_278
call_method,split,{view_278: None},"(view_278, 1280)",{'dim': 2},"{getitem_281: None, getitem_282: None, getitem_283: None}",,view_278,getitem_281,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_23
call_function,<built-in function getitem>,{split_23: None},"(split_23, 0)",{},"{size_350: None, view_279: None}",,split_23,getitem_282,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_281
call_function,<built-in function getitem>,{split_23: None},"(split_23, 1)",{},"{size_351: None, view_280: None}",,getitem_281,getitem_283,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_282
call_function,<built-in function getitem>,{split_23: None},"(split_23, 2)",{},"{size_352: None, view_281: None}",,getitem_282,size_350,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_283
call_method,size,{getitem_281: None},"(getitem_281,)",{},{getitem_284: None},,getitem_283,getitem_284,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_350
call_function,<built-in function getitem>,{size_350: None},"(size_350, slice(None, -1, None))",{},{add_281: None},,size_350,add_281,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_284
call_function,<built-in function add>,{getitem_284: None},"(getitem_284, (20, 64))",{},{view_279: None},,getitem_284,view_279,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_281
call_method,view,"{getitem_281: None, add_281: None}","(getitem_281, add_281)",{},{permute_92: None},,add_281,permute_92,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_279
call_method,permute,{view_279: None},"(view_279, 0, 2, 1, 3)",{},"{matmul_46: None, size_354: None}",,view_279,size_351,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_92
call_method,size,{getitem_282: None},"(getitem_282,)",{},{getitem_285: None},,permute_92,getitem_285,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_351
call_function,<built-in function getitem>,{size_351: None},"(size_351, slice(None, -1, None))",{},{add_282: None},,size_351,add_282,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_285
call_function,<built-in function add>,{getitem_285: None},"(getitem_285, (20, 64))",{},{view_280: None},,getitem_285,view_280,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_282
call_method,view,"{getitem_282: None, add_282: None}","(getitem_282, add_282)",{},{permute_93: None},,add_282,permute_93,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_280
call_method,permute,{view_280: None},"(view_280, 0, 2, 1, 3)",{},"{transpose_23: None, size_355: None, output: None}",,view_280,size_352,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_93
call_method,size,{getitem_283: None},"(getitem_283,)",{},{getitem_286: None},,permute_93,getitem_286,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_352
call_function,<built-in function getitem>,{size_352: None},"(size_352, slice(None, -1, None))",{},{add_283: None},,size_352,add_283,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_286
call_function,<built-in function add>,{getitem_286: None},"(getitem_286, (20, 64))",{},{view_281: None},,getitem_286,view_281,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_283
call_method,view,"{getitem_283: None, add_283: None}","(getitem_283, add_283)",{},{permute_94: None},,add_283,permute_94,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_281
call_method,permute,{view_281: None},"(view_281, 0, 2, 1, 3)",{},"{size_353: None, getattr_193: None, matmul_47: None, output: None}",,view_281,transpose_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_94
call_method,transpose,{permute_93: None},"(permute_93, -1, -2)",{},{matmul_46: None},,permute_94,matmul_46,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_23
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_92: None, transpose_23: None}","(permute_92, transpose_23)",{},"{getattr_186: None, getattr_187: None, truediv_23: None}",,transpose_23,size_353,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_46
call_method,size,{permute_94: None},"(permute_94, -1)",{},{pow_47: None},,matmul_46,pow_47,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_353
call_function,<built-in function pow>,{size_353: None},"(size_353, 0.5)",{},{full_46: None},,size_353,getattr_186,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_47
call_function,<built-in function getattr>,{matmul_46: None},"(matmul_46, 'dtype')",{},{full_46: None},,pow_47,getattr_187,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_186
call_function,<built-in function getattr>,{matmul_46: None},"(matmul_46, 'device')",{},{full_46: None},,getattr_186,full_46,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_187
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_47: None, getattr_186: None, getattr_187: None}","([], pow_47)","{'dtype': getattr_186, 'device': getattr_187}",{truediv_23: None},,getattr_187,truediv_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_46
call_function,<built-in function truediv>,"{matmul_46: None, full_46: None}","(matmul_46, full_46)",{},"{getattr_188: None, getattr_190: None, getattr_191: None, getattr_192: None, to_23: None}",,full_46,size_354,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_23
call_method,size,{permute_92: None},"(permute_92, -2)",{},{sub_23: None},,truediv_23,size_355,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_354
call_method,size,{permute_93: None},"(permute_93, -2)",{},"{sub_23: None, getitem_287: None}",,size_354,transformer_h_23_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_355
get_attr,transformer.h.23.attn.bias,{},(),{},{getitem_287: None},,size_355,sub_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_23_attn_bias
call_function,<built-in function sub>,"{size_355: None, size_354: None}","(size_355, size_354)",{},{getitem_287: None},,transformer_h_23_attn_bias,getitem_287,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_23
call_function,<built-in function getitem>,"{transformer_h_23_attn_bias: None, sub_23: None, size_355: None}","(transformer_h_23_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_23, size_355, None), slice(None, size_355, None)))",{},{where_23: None},,sub_23,getattr_188,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_287
call_function,<built-in function getattr>,{truediv_23: None},"(truediv_23, 'dtype')",{},{finfo_23: None},,getitem_287,finfo_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_188
call_function,<class 'torch.finfo'>,{getattr_188: None},"(getattr_188,)",{},{getattr_189: None},,getattr_188,getattr_189,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_23
call_function,<built-in function getattr>,{finfo_23: None},"(finfo_23, 'min')",{},{full_47: None},,finfo_23,getattr_190,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_189
call_function,<built-in function getattr>,{truediv_23: None},"(truediv_23, 'dtype')",{},{full_47: None},,getattr_189,getattr_191,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_190
call_function,<built-in function getattr>,{truediv_23: None},"(truediv_23, 'device')",{},{full_47: None},,getattr_190,full_47,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_191
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_189: None, getattr_190: None, getattr_191: None}","([], getattr_189)","{'dtype': getattr_190, 'device': getattr_191}",{where_23: None},,getattr_191,getattr_192,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_47
call_function,<built-in function getattr>,{truediv_23: None},"(truediv_23, 'dtype')",{},{to_23: None},,full_47,to_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_192
call_method,to,"{truediv_23: None, getattr_192: None}","(truediv_23, getattr_192)",{},{where_23: None},,getattr_192,where_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_23
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_287: None, to_23: None, full_47: None}","(getitem_287, to_23, full_47)",{},{softmax_23: None},,to_23,softmax_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_23
call_function,<function softmax at 0x7f6fd5135ca0>,{where_23: None},"(where_23,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_24: None},,where_23,getattr_193,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_23
call_function,<built-in function getattr>,{permute_94: None},"(permute_94, 'dtype')",{},{type_24: None},,softmax_23,type_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_193
call_method,type,"{softmax_23: None, getattr_193: None}","(softmax_23, getattr_193)",{},{transformer_h_23_attn_attn_dropout: None},,getattr_193,transformer_h_23_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_24
call_module,transformer.h.23.attn.attn_dropout,{type_24: None},"(type_24,)",{},{matmul_47: None},,type_24,matmul_47,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.23.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_23_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_23_attn_attn_dropout: None, permute_94: None}","(transformer_h_23_attn_attn_dropout, permute_94)",{},{permute_95: None},,transformer_h_23_attn_attn_dropout,permute_95,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_47
call_method,permute,{matmul_47: None},"(matmul_47, 0, 2, 1, 3)",{},{contiguous_23: None},,matmul_47,contiguous_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_95
call_method,contiguous,{permute_95: None},"(permute_95,)",{},"{size_356: None, view_282: None}",,permute_95,size_356,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_23
call_method,size,{contiguous_23: None},"(contiguous_23,)",{},{getitem_288: None},,contiguous_23,getitem_288,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_356
call_function,<built-in function getitem>,{size_356: None},"(size_356, slice(None, -2, None))",{},{add_284: None},,size_356,add_284,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_288
call_function,<built-in function add>,{getitem_288: None},"(getitem_288, (1280,))",{},{view_282: None},,getitem_288,view_282,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_284
call_method,view,"{contiguous_23: None, add_284: None}","(contiguous_23, add_284)",{},"{size_357: None, size_358: None, view_283: None}",,add_284,size_357,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_282
call_method,size,{view_282: None},"(view_282,)",{},{getitem_289: None},,view_282,getitem_289,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.23.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_357
call_function,<built-in function getitem>,{size_357: None},"(size_357, slice(None, -1, None))",{},{add_285: None},,size_357,add_285,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.23.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_289
call_function,<built-in function add>,{getitem_289: None},"(getitem_289, (1280,))",{},{view_284: None},,getitem_289,transformer_h_23_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.23.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_285
get_attr,transformer.h.23.attn.c_proj.bias,{},(),{},{addmm_93: None},,add_285,size_358,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.23.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_23_attn_c_proj_bias
call_method,size,{view_282: None},"(view_282, -1)",{},{view_283: None},,transformer_h_23_attn_c_proj_bias,view_283,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.23.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_358
call_method,view,"{view_282: None, size_358: None}","(view_282, -1, size_358)",{},{addmm_93: None},,size_358,transformer_h_23_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.23.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_283
get_attr,transformer.h.23.attn.c_proj.weight,{},(),{},{addmm_93: None},,view_283,addmm_93,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.23.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_23_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_23_attn_c_proj_bias: None, view_283: None, transformer_h_23_attn_c_proj_weight: None}","(transformer_h_23_attn_c_proj_bias, view_283, transformer_h_23_attn_c_proj_weight)",{},{view_284: None},,transformer_h_23_attn_c_proj_weight,view_284,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.23.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_93
call_method,view,"{addmm_93: None, add_285: None}","(addmm_93, add_285)",{},{transformer_h_23_attn_resid_dropout: None},,addmm_93,transformer_h_23_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.23.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_284
call_module,transformer.h.23.attn.resid_dropout,{view_284: None},"(view_284,)",{},{add_286: None},,view_284,add_286,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.23.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_23_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_23_attn_resid_dropout: None, add_279: None}","(transformer_h_23_attn_resid_dropout, add_279)",{},"{transformer_h_23_ln_2: None, add_291: None}",,transformer_h_23_attn_resid_dropout,transformer_h_23_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_286
call_module,transformer.h.23.ln_2,{add_286: None},"(add_286,)",{},"{size_359: None, size_360: None, view_285: None}",,add_286,size_359,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_23_ln_2
call_method,size,{transformer_h_23_ln_2: None},"(transformer_h_23_ln_2,)",{},{getitem_290: None},,transformer_h_23_ln_2,getitem_290,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_359
call_function,<built-in function getitem>,{size_359: None},"(size_359, slice(None, -1, None))",{},{add_287: None},,size_359,add_287,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_290
call_function,<built-in function add>,{getitem_290: None},"(getitem_290, (5120,))",{},{view_286: None},,getitem_290,transformer_h_23_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_287
get_attr,transformer.h.23.mlp.c_fc.bias,{},(),{},{addmm_94: None},,add_287,size_360,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_23_mlp_c_fc_bias
call_method,size,{transformer_h_23_ln_2: None},"(transformer_h_23_ln_2, -1)",{},{view_285: None},,transformer_h_23_mlp_c_fc_bias,view_285,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_360
call_method,view,"{transformer_h_23_ln_2: None, size_360: None}","(transformer_h_23_ln_2, -1, size_360)",{},{addmm_94: None},,size_360,transformer_h_23_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_285
get_attr,transformer.h.23.mlp.c_fc.weight,{},(),{},{addmm_94: None},,view_285,addmm_94,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_23_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_23_mlp_c_fc_bias: None, view_285: None, transformer_h_23_mlp_c_fc_weight: None}","(transformer_h_23_mlp_c_fc_bias, view_285, transformer_h_23_mlp_c_fc_weight)",{},{view_286: None},,transformer_h_23_mlp_c_fc_weight,view_286,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_94
call_method,view,"{addmm_94: None, add_287: None}","(addmm_94, add_287)",{},"{mul_92: None, pow_48: None, add_288: None}",,addmm_94,mul_92,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_286
call_function,<built-in function mul>,{view_286: None},"(0.5, view_286)",{},{mul_95: None},,view_286,pow_48,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_92
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_286: None},"(view_286, 3.0)",{},{mul_93: None},,mul_92,mul_93,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_48
call_function,<built-in function mul>,{pow_48: None},"(0.044715, pow_48)",{},{add_288: None},,pow_48,add_288,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_93
call_function,<built-in function add>,"{view_286: None, mul_93: None}","(view_286, mul_93)",{},{mul_94: None},,mul_93,mul_94,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_288
call_function,<built-in function mul>,{add_288: None},"(0.7978845608028654, add_288)",{},{tanh_23: None},,add_288,tanh_23,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_94
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_94: None},"(mul_94,)",{},{add_289: None},,mul_94,add_289,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_23
call_function,<built-in function add>,{tanh_23: None},"(1.0, tanh_23)",{},{mul_95: None},,tanh_23,mul_95,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_289
call_function,<built-in function mul>,"{mul_92: None, add_289: None}","(mul_92, add_289)",{},"{size_361: None, size_362: None, view_287: None}",,add_289,size_361,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_95
call_method,size,{mul_95: None},"(mul_95,)",{},{getitem_291: None},,mul_95,getitem_291,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_361
call_function,<built-in function getitem>,{size_361: None},"(size_361, slice(None, -1, None))",{},{add_290: None},,size_361,add_290,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_291
call_function,<built-in function add>,{getitem_291: None},"(getitem_291, (1280,))",{},{view_288: None},,getitem_291,transformer_h_23_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_290
get_attr,transformer.h.23.mlp.c_proj.bias,{},(),{},{addmm_95: None},,add_290,size_362,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_23_mlp_c_proj_bias
call_method,size,{mul_95: None},"(mul_95, -1)",{},{view_287: None},,transformer_h_23_mlp_c_proj_bias,view_287,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_362
call_method,view,"{mul_95: None, size_362: None}","(mul_95, -1, size_362)",{},{addmm_95: None},,size_362,transformer_h_23_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_287
get_attr,transformer.h.23.mlp.c_proj.weight,{},(),{},{addmm_95: None},,view_287,addmm_95,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_23_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_23_mlp_c_proj_bias: None, view_287: None, transformer_h_23_mlp_c_proj_weight: None}","(transformer_h_23_mlp_c_proj_bias, view_287, transformer_h_23_mlp_c_proj_weight)",{},{view_288: None},,transformer_h_23_mlp_c_proj_weight,view_288,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_95
call_method,view,"{addmm_95: None, add_290: None}","(addmm_95, add_290)",{},{transformer_h_23_mlp_dropout: None},,addmm_95,transformer_h_23_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_288
call_module,transformer.h.23.mlp.dropout,{view_288: None},"(view_288,)",{},{add_291: None},,view_288,add_291,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.23.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.23.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_23_mlp_dropout
call_function,<built-in function add>,"{add_286: None, transformer_h_23_mlp_dropout: None}","(add_286, transformer_h_23_mlp_dropout)",{},"{transformer_h_24_ln_1: None, add_298: None}",,transformer_h_23_mlp_dropout,transformer_h_24_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.23', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_291
call_module,transformer.h.24.ln_1,{add_291: None},"(add_291,)",{},"{size_363: None, size_364: None, view_289: None}",,add_291,size_363,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_24_ln_1
call_method,size,{transformer_h_24_ln_1: None},"(transformer_h_24_ln_1,)",{},{getitem_292: None},,transformer_h_24_ln_1,getitem_292,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.24.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_363
call_function,<built-in function getitem>,{size_363: None},"(size_363, slice(None, -1, None))",{},{add_292: None},,size_363,add_292,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.24.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_292
call_function,<built-in function add>,{getitem_292: None},"(getitem_292, (3840,))",{},{view_290: None},,getitem_292,transformer_h_24_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.24.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_292
get_attr,transformer.h.24.attn.c_attn.bias,{},(),{},{addmm_96: None},,add_292,size_364,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.24.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_24_attn_c_attn_bias
call_method,size,{transformer_h_24_ln_1: None},"(transformer_h_24_ln_1, -1)",{},{view_289: None},,transformer_h_24_attn_c_attn_bias,view_289,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.24.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_364
call_method,view,"{transformer_h_24_ln_1: None, size_364: None}","(transformer_h_24_ln_1, -1, size_364)",{},{addmm_96: None},,size_364,transformer_h_24_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.24.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_289
get_attr,transformer.h.24.attn.c_attn.weight,{},(),{},{addmm_96: None},,view_289,addmm_96,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.24.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_24_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_24_attn_c_attn_bias: None, view_289: None, transformer_h_24_attn_c_attn_weight: None}","(transformer_h_24_attn_c_attn_bias, view_289, transformer_h_24_attn_c_attn_weight)",{},{view_290: None},,transformer_h_24_attn_c_attn_weight,view_290,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.24.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_96
call_method,view,"{addmm_96: None, add_292: None}","(addmm_96, add_292)",{},{split_24: None},,addmm_96,split_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.24.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_290
call_method,split,{view_290: None},"(view_290, 1280)",{'dim': 2},"{getitem_293: None, getitem_294: None, getitem_295: None}",,view_290,getitem_293,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_24
call_function,<built-in function getitem>,{split_24: None},"(split_24, 0)",{},"{size_365: None, view_291: None}",,split_24,getitem_294,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_293
call_function,<built-in function getitem>,{split_24: None},"(split_24, 1)",{},"{size_366: None, view_292: None}",,getitem_293,getitem_295,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_294
call_function,<built-in function getitem>,{split_24: None},"(split_24, 2)",{},"{size_367: None, view_293: None}",,getitem_294,size_365,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_295
call_method,size,{getitem_293: None},"(getitem_293,)",{},{getitem_296: None},,getitem_295,getitem_296,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_365
call_function,<built-in function getitem>,{size_365: None},"(size_365, slice(None, -1, None))",{},{add_293: None},,size_365,add_293,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_296
call_function,<built-in function add>,{getitem_296: None},"(getitem_296, (20, 64))",{},{view_291: None},,getitem_296,view_291,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_293
call_method,view,"{getitem_293: None, add_293: None}","(getitem_293, add_293)",{},{permute_96: None},,add_293,permute_96,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_291
call_method,permute,{view_291: None},"(view_291, 0, 2, 1, 3)",{},"{matmul_48: None, size_369: None}",,view_291,size_366,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_96
call_method,size,{getitem_294: None},"(getitem_294,)",{},{getitem_297: None},,permute_96,getitem_297,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_366
call_function,<built-in function getitem>,{size_366: None},"(size_366, slice(None, -1, None))",{},{add_294: None},,size_366,add_294,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_297
call_function,<built-in function add>,{getitem_297: None},"(getitem_297, (20, 64))",{},{view_292: None},,getitem_297,view_292,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_294
call_method,view,"{getitem_294: None, add_294: None}","(getitem_294, add_294)",{},{permute_97: None},,add_294,permute_97,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_292
call_method,permute,{view_292: None},"(view_292, 0, 2, 1, 3)",{},"{transpose_24: None, size_370: None, output: None}",,view_292,size_367,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_97
call_method,size,{getitem_295: None},"(getitem_295,)",{},{getitem_298: None},,permute_97,getitem_298,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_367
call_function,<built-in function getitem>,{size_367: None},"(size_367, slice(None, -1, None))",{},{add_295: None},,size_367,add_295,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_298
call_function,<built-in function add>,{getitem_298: None},"(getitem_298, (20, 64))",{},{view_293: None},,getitem_298,view_293,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_295
call_method,view,"{getitem_295: None, add_295: None}","(getitem_295, add_295)",{},{permute_98: None},,add_295,permute_98,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_293
call_method,permute,{view_293: None},"(view_293, 0, 2, 1, 3)",{},"{size_368: None, getattr_201: None, matmul_49: None, output: None}",,view_293,transpose_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_98
call_method,transpose,{permute_97: None},"(permute_97, -1, -2)",{},{matmul_48: None},,permute_98,matmul_48,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_24
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_96: None, transpose_24: None}","(permute_96, transpose_24)",{},"{getattr_194: None, getattr_195: None, truediv_24: None}",,transpose_24,size_368,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_48
call_method,size,{permute_98: None},"(permute_98, -1)",{},{pow_49: None},,matmul_48,pow_49,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_368
call_function,<built-in function pow>,{size_368: None},"(size_368, 0.5)",{},{full_48: None},,size_368,getattr_194,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_49
call_function,<built-in function getattr>,{matmul_48: None},"(matmul_48, 'dtype')",{},{full_48: None},,pow_49,getattr_195,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_194
call_function,<built-in function getattr>,{matmul_48: None},"(matmul_48, 'device')",{},{full_48: None},,getattr_194,full_48,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_195
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_49: None, getattr_194: None, getattr_195: None}","([], pow_49)","{'dtype': getattr_194, 'device': getattr_195}",{truediv_24: None},,getattr_195,truediv_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_48
call_function,<built-in function truediv>,"{matmul_48: None, full_48: None}","(matmul_48, full_48)",{},"{getattr_196: None, getattr_198: None, getattr_199: None, getattr_200: None, to_24: None}",,full_48,size_369,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_24
call_method,size,{permute_96: None},"(permute_96, -2)",{},{sub_24: None},,truediv_24,size_370,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_369
call_method,size,{permute_97: None},"(permute_97, -2)",{},"{sub_24: None, getitem_299: None}",,size_369,transformer_h_24_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_370
get_attr,transformer.h.24.attn.bias,{},(),{},{getitem_299: None},,size_370,sub_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_24_attn_bias
call_function,<built-in function sub>,"{size_370: None, size_369: None}","(size_370, size_369)",{},{getitem_299: None},,transformer_h_24_attn_bias,getitem_299,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_24
call_function,<built-in function getitem>,"{transformer_h_24_attn_bias: None, sub_24: None, size_370: None}","(transformer_h_24_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_24, size_370, None), slice(None, size_370, None)))",{},{where_24: None},,sub_24,getattr_196,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_299
call_function,<built-in function getattr>,{truediv_24: None},"(truediv_24, 'dtype')",{},{finfo_24: None},,getitem_299,finfo_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_196
call_function,<class 'torch.finfo'>,{getattr_196: None},"(getattr_196,)",{},{getattr_197: None},,getattr_196,getattr_197,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_24
call_function,<built-in function getattr>,{finfo_24: None},"(finfo_24, 'min')",{},{full_49: None},,finfo_24,getattr_198,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_197
call_function,<built-in function getattr>,{truediv_24: None},"(truediv_24, 'dtype')",{},{full_49: None},,getattr_197,getattr_199,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_198
call_function,<built-in function getattr>,{truediv_24: None},"(truediv_24, 'device')",{},{full_49: None},,getattr_198,full_49,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_199
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_197: None, getattr_198: None, getattr_199: None}","([], getattr_197)","{'dtype': getattr_198, 'device': getattr_199}",{where_24: None},,getattr_199,getattr_200,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_49
call_function,<built-in function getattr>,{truediv_24: None},"(truediv_24, 'dtype')",{},{to_24: None},,full_49,to_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_200
call_method,to,"{truediv_24: None, getattr_200: None}","(truediv_24, getattr_200)",{},{where_24: None},,getattr_200,where_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_24
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_299: None, to_24: None, full_49: None}","(getitem_299, to_24, full_49)",{},{softmax_24: None},,to_24,softmax_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_24
call_function,<function softmax at 0x7f6fd5135ca0>,{where_24: None},"(where_24,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_25: None},,where_24,getattr_201,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_24
call_function,<built-in function getattr>,{permute_98: None},"(permute_98, 'dtype')",{},{type_25: None},,softmax_24,type_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_201
call_method,type,"{softmax_24: None, getattr_201: None}","(softmax_24, getattr_201)",{},{transformer_h_24_attn_attn_dropout: None},,getattr_201,transformer_h_24_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_25
call_module,transformer.h.24.attn.attn_dropout,{type_25: None},"(type_25,)",{},{matmul_49: None},,type_25,matmul_49,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.24.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_24_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_24_attn_attn_dropout: None, permute_98: None}","(transformer_h_24_attn_attn_dropout, permute_98)",{},{permute_99: None},,transformer_h_24_attn_attn_dropout,permute_99,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_49
call_method,permute,{matmul_49: None},"(matmul_49, 0, 2, 1, 3)",{},{contiguous_24: None},,matmul_49,contiguous_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_99
call_method,contiguous,{permute_99: None},"(permute_99,)",{},"{size_371: None, view_294: None}",,permute_99,size_371,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_24
call_method,size,{contiguous_24: None},"(contiguous_24,)",{},{getitem_300: None},,contiguous_24,getitem_300,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_371
call_function,<built-in function getitem>,{size_371: None},"(size_371, slice(None, -2, None))",{},{add_296: None},,size_371,add_296,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_300
call_function,<built-in function add>,{getitem_300: None},"(getitem_300, (1280,))",{},{view_294: None},,getitem_300,view_294,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_296
call_method,view,"{contiguous_24: None, add_296: None}","(contiguous_24, add_296)",{},"{size_372: None, size_373: None, view_295: None}",,add_296,size_372,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_294
call_method,size,{view_294: None},"(view_294,)",{},{getitem_301: None},,view_294,getitem_301,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.24.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_372
call_function,<built-in function getitem>,{size_372: None},"(size_372, slice(None, -1, None))",{},{add_297: None},,size_372,add_297,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.24.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_301
call_function,<built-in function add>,{getitem_301: None},"(getitem_301, (1280,))",{},{view_296: None},,getitem_301,transformer_h_24_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.24.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_297
get_attr,transformer.h.24.attn.c_proj.bias,{},(),{},{addmm_97: None},,add_297,size_373,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.24.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_24_attn_c_proj_bias
call_method,size,{view_294: None},"(view_294, -1)",{},{view_295: None},,transformer_h_24_attn_c_proj_bias,view_295,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.24.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_373
call_method,view,"{view_294: None, size_373: None}","(view_294, -1, size_373)",{},{addmm_97: None},,size_373,transformer_h_24_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.24.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_295
get_attr,transformer.h.24.attn.c_proj.weight,{},(),{},{addmm_97: None},,view_295,addmm_97,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.24.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_24_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_24_attn_c_proj_bias: None, view_295: None, transformer_h_24_attn_c_proj_weight: None}","(transformer_h_24_attn_c_proj_bias, view_295, transformer_h_24_attn_c_proj_weight)",{},{view_296: None},,transformer_h_24_attn_c_proj_weight,view_296,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.24.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_97
call_method,view,"{addmm_97: None, add_297: None}","(addmm_97, add_297)",{},{transformer_h_24_attn_resid_dropout: None},,addmm_97,transformer_h_24_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.24.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_296
call_module,transformer.h.24.attn.resid_dropout,{view_296: None},"(view_296,)",{},{add_298: None},,view_296,add_298,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.24.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_24_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_24_attn_resid_dropout: None, add_291: None}","(transformer_h_24_attn_resid_dropout, add_291)",{},"{transformer_h_24_ln_2: None, add_303: None}",,transformer_h_24_attn_resid_dropout,transformer_h_24_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_298
call_module,transformer.h.24.ln_2,{add_298: None},"(add_298,)",{},"{size_374: None, size_375: None, view_297: None}",,add_298,size_374,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_24_ln_2
call_method,size,{transformer_h_24_ln_2: None},"(transformer_h_24_ln_2,)",{},{getitem_302: None},,transformer_h_24_ln_2,getitem_302,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_374
call_function,<built-in function getitem>,{size_374: None},"(size_374, slice(None, -1, None))",{},{add_299: None},,size_374,add_299,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_302
call_function,<built-in function add>,{getitem_302: None},"(getitem_302, (5120,))",{},{view_298: None},,getitem_302,transformer_h_24_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_299
get_attr,transformer.h.24.mlp.c_fc.bias,{},(),{},{addmm_98: None},,add_299,size_375,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_24_mlp_c_fc_bias
call_method,size,{transformer_h_24_ln_2: None},"(transformer_h_24_ln_2, -1)",{},{view_297: None},,transformer_h_24_mlp_c_fc_bias,view_297,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_375
call_method,view,"{transformer_h_24_ln_2: None, size_375: None}","(transformer_h_24_ln_2, -1, size_375)",{},{addmm_98: None},,size_375,transformer_h_24_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_297
get_attr,transformer.h.24.mlp.c_fc.weight,{},(),{},{addmm_98: None},,view_297,addmm_98,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_24_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_24_mlp_c_fc_bias: None, view_297: None, transformer_h_24_mlp_c_fc_weight: None}","(transformer_h_24_mlp_c_fc_bias, view_297, transformer_h_24_mlp_c_fc_weight)",{},{view_298: None},,transformer_h_24_mlp_c_fc_weight,view_298,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_98
call_method,view,"{addmm_98: None, add_299: None}","(addmm_98, add_299)",{},"{mul_96: None, pow_50: None, add_300: None}",,addmm_98,mul_96,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_298
call_function,<built-in function mul>,{view_298: None},"(0.5, view_298)",{},{mul_99: None},,view_298,pow_50,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_96
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_298: None},"(view_298, 3.0)",{},{mul_97: None},,mul_96,mul_97,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_50
call_function,<built-in function mul>,{pow_50: None},"(0.044715, pow_50)",{},{add_300: None},,pow_50,add_300,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_97
call_function,<built-in function add>,"{view_298: None, mul_97: None}","(view_298, mul_97)",{},{mul_98: None},,mul_97,mul_98,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_300
call_function,<built-in function mul>,{add_300: None},"(0.7978845608028654, add_300)",{},{tanh_24: None},,add_300,tanh_24,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_98
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_98: None},"(mul_98,)",{},{add_301: None},,mul_98,add_301,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_24
call_function,<built-in function add>,{tanh_24: None},"(1.0, tanh_24)",{},{mul_99: None},,tanh_24,mul_99,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_301
call_function,<built-in function mul>,"{mul_96: None, add_301: None}","(mul_96, add_301)",{},"{size_376: None, size_377: None, view_299: None}",,add_301,size_376,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_99
call_method,size,{mul_99: None},"(mul_99,)",{},{getitem_303: None},,mul_99,getitem_303,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_376
call_function,<built-in function getitem>,{size_376: None},"(size_376, slice(None, -1, None))",{},{add_302: None},,size_376,add_302,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_303
call_function,<built-in function add>,{getitem_303: None},"(getitem_303, (1280,))",{},{view_300: None},,getitem_303,transformer_h_24_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_302
get_attr,transformer.h.24.mlp.c_proj.bias,{},(),{},{addmm_99: None},,add_302,size_377,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_24_mlp_c_proj_bias
call_method,size,{mul_99: None},"(mul_99, -1)",{},{view_299: None},,transformer_h_24_mlp_c_proj_bias,view_299,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_377
call_method,view,"{mul_99: None, size_377: None}","(mul_99, -1, size_377)",{},{addmm_99: None},,size_377,transformer_h_24_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_299
get_attr,transformer.h.24.mlp.c_proj.weight,{},(),{},{addmm_99: None},,view_299,addmm_99,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_24_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_24_mlp_c_proj_bias: None, view_299: None, transformer_h_24_mlp_c_proj_weight: None}","(transformer_h_24_mlp_c_proj_bias, view_299, transformer_h_24_mlp_c_proj_weight)",{},{view_300: None},,transformer_h_24_mlp_c_proj_weight,view_300,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_99
call_method,view,"{addmm_99: None, add_302: None}","(addmm_99, add_302)",{},{transformer_h_24_mlp_dropout: None},,addmm_99,transformer_h_24_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_300
call_module,transformer.h.24.mlp.dropout,{view_300: None},"(view_300,)",{},{add_303: None},,view_300,add_303,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.24.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.24.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_24_mlp_dropout
call_function,<built-in function add>,"{add_298: None, transformer_h_24_mlp_dropout: None}","(add_298, transformer_h_24_mlp_dropout)",{},"{transformer_h_25_ln_1: None, add_310: None}",,transformer_h_24_mlp_dropout,transformer_h_25_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.24', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_303
call_module,transformer.h.25.ln_1,{add_303: None},"(add_303,)",{},"{size_378: None, size_379: None, view_301: None}",,add_303,size_378,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_25_ln_1
call_method,size,{transformer_h_25_ln_1: None},"(transformer_h_25_ln_1,)",{},{getitem_304: None},,transformer_h_25_ln_1,getitem_304,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.25.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_378
call_function,<built-in function getitem>,{size_378: None},"(size_378, slice(None, -1, None))",{},{add_304: None},,size_378,add_304,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.25.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_304
call_function,<built-in function add>,{getitem_304: None},"(getitem_304, (3840,))",{},{view_302: None},,getitem_304,transformer_h_25_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.25.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_304
get_attr,transformer.h.25.attn.c_attn.bias,{},(),{},{addmm_100: None},,add_304,size_379,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.25.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_25_attn_c_attn_bias
call_method,size,{transformer_h_25_ln_1: None},"(transformer_h_25_ln_1, -1)",{},{view_301: None},,transformer_h_25_attn_c_attn_bias,view_301,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.25.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_379
call_method,view,"{transformer_h_25_ln_1: None, size_379: None}","(transformer_h_25_ln_1, -1, size_379)",{},{addmm_100: None},,size_379,transformer_h_25_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.25.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_301
get_attr,transformer.h.25.attn.c_attn.weight,{},(),{},{addmm_100: None},,view_301,addmm_100,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.25.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_25_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_25_attn_c_attn_bias: None, view_301: None, transformer_h_25_attn_c_attn_weight: None}","(transformer_h_25_attn_c_attn_bias, view_301, transformer_h_25_attn_c_attn_weight)",{},{view_302: None},,transformer_h_25_attn_c_attn_weight,view_302,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.25.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_100
call_method,view,"{addmm_100: None, add_304: None}","(addmm_100, add_304)",{},{split_25: None},,addmm_100,split_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.25.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_302
call_method,split,{view_302: None},"(view_302, 1280)",{'dim': 2},"{getitem_305: None, getitem_306: None, getitem_307: None}",,view_302,getitem_305,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_25
call_function,<built-in function getitem>,{split_25: None},"(split_25, 0)",{},"{size_380: None, view_303: None}",,split_25,getitem_306,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_305
call_function,<built-in function getitem>,{split_25: None},"(split_25, 1)",{},"{size_381: None, view_304: None}",,getitem_305,getitem_307,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_306
call_function,<built-in function getitem>,{split_25: None},"(split_25, 2)",{},"{size_382: None, view_305: None}",,getitem_306,size_380,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_307
call_method,size,{getitem_305: None},"(getitem_305,)",{},{getitem_308: None},,getitem_307,getitem_308,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_380
call_function,<built-in function getitem>,{size_380: None},"(size_380, slice(None, -1, None))",{},{add_305: None},,size_380,add_305,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_308
call_function,<built-in function add>,{getitem_308: None},"(getitem_308, (20, 64))",{},{view_303: None},,getitem_308,view_303,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_305
call_method,view,"{getitem_305: None, add_305: None}","(getitem_305, add_305)",{},{permute_100: None},,add_305,permute_100,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_303
call_method,permute,{view_303: None},"(view_303, 0, 2, 1, 3)",{},"{matmul_50: None, size_384: None}",,view_303,size_381,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_100
call_method,size,{getitem_306: None},"(getitem_306,)",{},{getitem_309: None},,permute_100,getitem_309,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_381
call_function,<built-in function getitem>,{size_381: None},"(size_381, slice(None, -1, None))",{},{add_306: None},,size_381,add_306,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_309
call_function,<built-in function add>,{getitem_309: None},"(getitem_309, (20, 64))",{},{view_304: None},,getitem_309,view_304,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_306
call_method,view,"{getitem_306: None, add_306: None}","(getitem_306, add_306)",{},{permute_101: None},,add_306,permute_101,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_304
call_method,permute,{view_304: None},"(view_304, 0, 2, 1, 3)",{},"{transpose_25: None, size_385: None, output: None}",,view_304,size_382,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_101
call_method,size,{getitem_307: None},"(getitem_307,)",{},{getitem_310: None},,permute_101,getitem_310,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_382
call_function,<built-in function getitem>,{size_382: None},"(size_382, slice(None, -1, None))",{},{add_307: None},,size_382,add_307,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_310
call_function,<built-in function add>,{getitem_310: None},"(getitem_310, (20, 64))",{},{view_305: None},,getitem_310,view_305,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_307
call_method,view,"{getitem_307: None, add_307: None}","(getitem_307, add_307)",{},{permute_102: None},,add_307,permute_102,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_305
call_method,permute,{view_305: None},"(view_305, 0, 2, 1, 3)",{},"{size_383: None, getattr_209: None, matmul_51: None, output: None}",,view_305,transpose_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_102
call_method,transpose,{permute_101: None},"(permute_101, -1, -2)",{},{matmul_50: None},,permute_102,matmul_50,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_25
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_100: None, transpose_25: None}","(permute_100, transpose_25)",{},"{getattr_202: None, getattr_203: None, truediv_25: None}",,transpose_25,size_383,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_50
call_method,size,{permute_102: None},"(permute_102, -1)",{},{pow_51: None},,matmul_50,pow_51,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_383
call_function,<built-in function pow>,{size_383: None},"(size_383, 0.5)",{},{full_50: None},,size_383,getattr_202,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_51
call_function,<built-in function getattr>,{matmul_50: None},"(matmul_50, 'dtype')",{},{full_50: None},,pow_51,getattr_203,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_202
call_function,<built-in function getattr>,{matmul_50: None},"(matmul_50, 'device')",{},{full_50: None},,getattr_202,full_50,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_203
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_51: None, getattr_202: None, getattr_203: None}","([], pow_51)","{'dtype': getattr_202, 'device': getattr_203}",{truediv_25: None},,getattr_203,truediv_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_50
call_function,<built-in function truediv>,"{matmul_50: None, full_50: None}","(matmul_50, full_50)",{},"{getattr_204: None, getattr_206: None, getattr_207: None, getattr_208: None, to_25: None}",,full_50,size_384,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_25
call_method,size,{permute_100: None},"(permute_100, -2)",{},{sub_25: None},,truediv_25,size_385,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_384
call_method,size,{permute_101: None},"(permute_101, -2)",{},"{sub_25: None, getitem_311: None}",,size_384,transformer_h_25_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_385
get_attr,transformer.h.25.attn.bias,{},(),{},{getitem_311: None},,size_385,sub_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_25_attn_bias
call_function,<built-in function sub>,"{size_385: None, size_384: None}","(size_385, size_384)",{},{getitem_311: None},,transformer_h_25_attn_bias,getitem_311,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_25
call_function,<built-in function getitem>,"{transformer_h_25_attn_bias: None, sub_25: None, size_385: None}","(transformer_h_25_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_25, size_385, None), slice(None, size_385, None)))",{},{where_25: None},,sub_25,getattr_204,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_311
call_function,<built-in function getattr>,{truediv_25: None},"(truediv_25, 'dtype')",{},{finfo_25: None},,getitem_311,finfo_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_204
call_function,<class 'torch.finfo'>,{getattr_204: None},"(getattr_204,)",{},{getattr_205: None},,getattr_204,getattr_205,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_25
call_function,<built-in function getattr>,{finfo_25: None},"(finfo_25, 'min')",{},{full_51: None},,finfo_25,getattr_206,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_205
call_function,<built-in function getattr>,{truediv_25: None},"(truediv_25, 'dtype')",{},{full_51: None},,getattr_205,getattr_207,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_206
call_function,<built-in function getattr>,{truediv_25: None},"(truediv_25, 'device')",{},{full_51: None},,getattr_206,full_51,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_207
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_205: None, getattr_206: None, getattr_207: None}","([], getattr_205)","{'dtype': getattr_206, 'device': getattr_207}",{where_25: None},,getattr_207,getattr_208,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_51
call_function,<built-in function getattr>,{truediv_25: None},"(truediv_25, 'dtype')",{},{to_25: None},,full_51,to_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_208
call_method,to,"{truediv_25: None, getattr_208: None}","(truediv_25, getattr_208)",{},{where_25: None},,getattr_208,where_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_25
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_311: None, to_25: None, full_51: None}","(getitem_311, to_25, full_51)",{},{softmax_25: None},,to_25,softmax_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_25
call_function,<function softmax at 0x7f6fd5135ca0>,{where_25: None},"(where_25,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_26: None},,where_25,getattr_209,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_25
call_function,<built-in function getattr>,{permute_102: None},"(permute_102, 'dtype')",{},{type_26: None},,softmax_25,type_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_209
call_method,type,"{softmax_25: None, getattr_209: None}","(softmax_25, getattr_209)",{},{transformer_h_25_attn_attn_dropout: None},,getattr_209,transformer_h_25_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_26
call_module,transformer.h.25.attn.attn_dropout,{type_26: None},"(type_26,)",{},{matmul_51: None},,type_26,matmul_51,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.25.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_25_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_25_attn_attn_dropout: None, permute_102: None}","(transformer_h_25_attn_attn_dropout, permute_102)",{},{permute_103: None},,transformer_h_25_attn_attn_dropout,permute_103,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_51
call_method,permute,{matmul_51: None},"(matmul_51, 0, 2, 1, 3)",{},{contiguous_25: None},,matmul_51,contiguous_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_103
call_method,contiguous,{permute_103: None},"(permute_103,)",{},"{size_386: None, view_306: None}",,permute_103,size_386,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_25
call_method,size,{contiguous_25: None},"(contiguous_25,)",{},{getitem_312: None},,contiguous_25,getitem_312,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_386
call_function,<built-in function getitem>,{size_386: None},"(size_386, slice(None, -2, None))",{},{add_308: None},,size_386,add_308,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_312
call_function,<built-in function add>,{getitem_312: None},"(getitem_312, (1280,))",{},{view_306: None},,getitem_312,view_306,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_308
call_method,view,"{contiguous_25: None, add_308: None}","(contiguous_25, add_308)",{},"{size_387: None, size_388: None, view_307: None}",,add_308,size_387,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_306
call_method,size,{view_306: None},"(view_306,)",{},{getitem_313: None},,view_306,getitem_313,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.25.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_387
call_function,<built-in function getitem>,{size_387: None},"(size_387, slice(None, -1, None))",{},{add_309: None},,size_387,add_309,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.25.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_313
call_function,<built-in function add>,{getitem_313: None},"(getitem_313, (1280,))",{},{view_308: None},,getitem_313,transformer_h_25_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.25.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_309
get_attr,transformer.h.25.attn.c_proj.bias,{},(),{},{addmm_101: None},,add_309,size_388,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.25.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_25_attn_c_proj_bias
call_method,size,{view_306: None},"(view_306, -1)",{},{view_307: None},,transformer_h_25_attn_c_proj_bias,view_307,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.25.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_388
call_method,view,"{view_306: None, size_388: None}","(view_306, -1, size_388)",{},{addmm_101: None},,size_388,transformer_h_25_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.25.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_307
get_attr,transformer.h.25.attn.c_proj.weight,{},(),{},{addmm_101: None},,view_307,addmm_101,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.25.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_25_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_25_attn_c_proj_bias: None, view_307: None, transformer_h_25_attn_c_proj_weight: None}","(transformer_h_25_attn_c_proj_bias, view_307, transformer_h_25_attn_c_proj_weight)",{},{view_308: None},,transformer_h_25_attn_c_proj_weight,view_308,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.25.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_101
call_method,view,"{addmm_101: None, add_309: None}","(addmm_101, add_309)",{},{transformer_h_25_attn_resid_dropout: None},,addmm_101,transformer_h_25_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.25.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_308
call_module,transformer.h.25.attn.resid_dropout,{view_308: None},"(view_308,)",{},{add_310: None},,view_308,add_310,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.25.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_25_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_25_attn_resid_dropout: None, add_303: None}","(transformer_h_25_attn_resid_dropout, add_303)",{},"{transformer_h_25_ln_2: None, add_315: None}",,transformer_h_25_attn_resid_dropout,transformer_h_25_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_310
call_module,transformer.h.25.ln_2,{add_310: None},"(add_310,)",{},"{size_389: None, size_390: None, view_309: None}",,add_310,size_389,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_25_ln_2
call_method,size,{transformer_h_25_ln_2: None},"(transformer_h_25_ln_2,)",{},{getitem_314: None},,transformer_h_25_ln_2,getitem_314,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_389
call_function,<built-in function getitem>,{size_389: None},"(size_389, slice(None, -1, None))",{},{add_311: None},,size_389,add_311,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_314
call_function,<built-in function add>,{getitem_314: None},"(getitem_314, (5120,))",{},{view_310: None},,getitem_314,transformer_h_25_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_311
get_attr,transformer.h.25.mlp.c_fc.bias,{},(),{},{addmm_102: None},,add_311,size_390,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_25_mlp_c_fc_bias
call_method,size,{transformer_h_25_ln_2: None},"(transformer_h_25_ln_2, -1)",{},{view_309: None},,transformer_h_25_mlp_c_fc_bias,view_309,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_390
call_method,view,"{transformer_h_25_ln_2: None, size_390: None}","(transformer_h_25_ln_2, -1, size_390)",{},{addmm_102: None},,size_390,transformer_h_25_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_309
get_attr,transformer.h.25.mlp.c_fc.weight,{},(),{},{addmm_102: None},,view_309,addmm_102,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_25_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_25_mlp_c_fc_bias: None, view_309: None, transformer_h_25_mlp_c_fc_weight: None}","(transformer_h_25_mlp_c_fc_bias, view_309, transformer_h_25_mlp_c_fc_weight)",{},{view_310: None},,transformer_h_25_mlp_c_fc_weight,view_310,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_102
call_method,view,"{addmm_102: None, add_311: None}","(addmm_102, add_311)",{},"{mul_100: None, pow_52: None, add_312: None}",,addmm_102,mul_100,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_310
call_function,<built-in function mul>,{view_310: None},"(0.5, view_310)",{},{mul_103: None},,view_310,pow_52,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_100
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_310: None},"(view_310, 3.0)",{},{mul_101: None},,mul_100,mul_101,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_52
call_function,<built-in function mul>,{pow_52: None},"(0.044715, pow_52)",{},{add_312: None},,pow_52,add_312,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_101
call_function,<built-in function add>,"{view_310: None, mul_101: None}","(view_310, mul_101)",{},{mul_102: None},,mul_101,mul_102,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_312
call_function,<built-in function mul>,{add_312: None},"(0.7978845608028654, add_312)",{},{tanh_25: None},,add_312,tanh_25,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_102
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_102: None},"(mul_102,)",{},{add_313: None},,mul_102,add_313,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_25
call_function,<built-in function add>,{tanh_25: None},"(1.0, tanh_25)",{},{mul_103: None},,tanh_25,mul_103,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_313
call_function,<built-in function mul>,"{mul_100: None, add_313: None}","(mul_100, add_313)",{},"{size_391: None, size_392: None, view_311: None}",,add_313,size_391,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_103
call_method,size,{mul_103: None},"(mul_103,)",{},{getitem_315: None},,mul_103,getitem_315,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_391
call_function,<built-in function getitem>,{size_391: None},"(size_391, slice(None, -1, None))",{},{add_314: None},,size_391,add_314,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_315
call_function,<built-in function add>,{getitem_315: None},"(getitem_315, (1280,))",{},{view_312: None},,getitem_315,transformer_h_25_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_314
get_attr,transformer.h.25.mlp.c_proj.bias,{},(),{},{addmm_103: None},,add_314,size_392,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_25_mlp_c_proj_bias
call_method,size,{mul_103: None},"(mul_103, -1)",{},{view_311: None},,transformer_h_25_mlp_c_proj_bias,view_311,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_392
call_method,view,"{mul_103: None, size_392: None}","(mul_103, -1, size_392)",{},{addmm_103: None},,size_392,transformer_h_25_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_311
get_attr,transformer.h.25.mlp.c_proj.weight,{},(),{},{addmm_103: None},,view_311,addmm_103,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_25_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_25_mlp_c_proj_bias: None, view_311: None, transformer_h_25_mlp_c_proj_weight: None}","(transformer_h_25_mlp_c_proj_bias, view_311, transformer_h_25_mlp_c_proj_weight)",{},{view_312: None},,transformer_h_25_mlp_c_proj_weight,view_312,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_103
call_method,view,"{addmm_103: None, add_314: None}","(addmm_103, add_314)",{},{transformer_h_25_mlp_dropout: None},,addmm_103,transformer_h_25_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_312
call_module,transformer.h.25.mlp.dropout,{view_312: None},"(view_312,)",{},{add_315: None},,view_312,add_315,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.25.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.25.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_25_mlp_dropout
call_function,<built-in function add>,"{add_310: None, transformer_h_25_mlp_dropout: None}","(add_310, transformer_h_25_mlp_dropout)",{},"{transformer_h_26_ln_1: None, add_322: None}",,transformer_h_25_mlp_dropout,transformer_h_26_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.25', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_315
call_module,transformer.h.26.ln_1,{add_315: None},"(add_315,)",{},"{size_393: None, size_394: None, view_313: None}",,add_315,size_393,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_26_ln_1
call_method,size,{transformer_h_26_ln_1: None},"(transformer_h_26_ln_1,)",{},{getitem_316: None},,transformer_h_26_ln_1,getitem_316,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.26.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_393
call_function,<built-in function getitem>,{size_393: None},"(size_393, slice(None, -1, None))",{},{add_316: None},,size_393,add_316,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.26.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_316
call_function,<built-in function add>,{getitem_316: None},"(getitem_316, (3840,))",{},{view_314: None},,getitem_316,transformer_h_26_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.26.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_316
get_attr,transformer.h.26.attn.c_attn.bias,{},(),{},{addmm_104: None},,add_316,size_394,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.26.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_26_attn_c_attn_bias
call_method,size,{transformer_h_26_ln_1: None},"(transformer_h_26_ln_1, -1)",{},{view_313: None},,transformer_h_26_attn_c_attn_bias,view_313,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.26.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_394
call_method,view,"{transformer_h_26_ln_1: None, size_394: None}","(transformer_h_26_ln_1, -1, size_394)",{},{addmm_104: None},,size_394,transformer_h_26_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.26.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_313
get_attr,transformer.h.26.attn.c_attn.weight,{},(),{},{addmm_104: None},,view_313,addmm_104,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.26.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_26_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_26_attn_c_attn_bias: None, view_313: None, transformer_h_26_attn_c_attn_weight: None}","(transformer_h_26_attn_c_attn_bias, view_313, transformer_h_26_attn_c_attn_weight)",{},{view_314: None},,transformer_h_26_attn_c_attn_weight,view_314,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.26.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_104
call_method,view,"{addmm_104: None, add_316: None}","(addmm_104, add_316)",{},{split_26: None},,addmm_104,split_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.26.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_314
call_method,split,{view_314: None},"(view_314, 1280)",{'dim': 2},"{getitem_317: None, getitem_318: None, getitem_319: None}",,view_314,getitem_317,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_26
call_function,<built-in function getitem>,{split_26: None},"(split_26, 0)",{},"{size_395: None, view_315: None}",,split_26,getitem_318,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_317
call_function,<built-in function getitem>,{split_26: None},"(split_26, 1)",{},"{size_396: None, view_316: None}",,getitem_317,getitem_319,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_318
call_function,<built-in function getitem>,{split_26: None},"(split_26, 2)",{},"{size_397: None, view_317: None}",,getitem_318,size_395,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_319
call_method,size,{getitem_317: None},"(getitem_317,)",{},{getitem_320: None},,getitem_319,getitem_320,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_395
call_function,<built-in function getitem>,{size_395: None},"(size_395, slice(None, -1, None))",{},{add_317: None},,size_395,add_317,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_320
call_function,<built-in function add>,{getitem_320: None},"(getitem_320, (20, 64))",{},{view_315: None},,getitem_320,view_315,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_317
call_method,view,"{getitem_317: None, add_317: None}","(getitem_317, add_317)",{},{permute_104: None},,add_317,permute_104,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_315
call_method,permute,{view_315: None},"(view_315, 0, 2, 1, 3)",{},"{matmul_52: None, size_399: None}",,view_315,size_396,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_104
call_method,size,{getitem_318: None},"(getitem_318,)",{},{getitem_321: None},,permute_104,getitem_321,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_396
call_function,<built-in function getitem>,{size_396: None},"(size_396, slice(None, -1, None))",{},{add_318: None},,size_396,add_318,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_321
call_function,<built-in function add>,{getitem_321: None},"(getitem_321, (20, 64))",{},{view_316: None},,getitem_321,view_316,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_318
call_method,view,"{getitem_318: None, add_318: None}","(getitem_318, add_318)",{},{permute_105: None},,add_318,permute_105,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_316
call_method,permute,{view_316: None},"(view_316, 0, 2, 1, 3)",{},"{transpose_26: None, size_400: None, output: None}",,view_316,size_397,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_105
call_method,size,{getitem_319: None},"(getitem_319,)",{},{getitem_322: None},,permute_105,getitem_322,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_397
call_function,<built-in function getitem>,{size_397: None},"(size_397, slice(None, -1, None))",{},{add_319: None},,size_397,add_319,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_322
call_function,<built-in function add>,{getitem_322: None},"(getitem_322, (20, 64))",{},{view_317: None},,getitem_322,view_317,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_319
call_method,view,"{getitem_319: None, add_319: None}","(getitem_319, add_319)",{},{permute_106: None},,add_319,permute_106,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_317
call_method,permute,{view_317: None},"(view_317, 0, 2, 1, 3)",{},"{size_398: None, getattr_217: None, matmul_53: None, output: None}",,view_317,transpose_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_106
call_method,transpose,{permute_105: None},"(permute_105, -1, -2)",{},{matmul_52: None},,permute_106,matmul_52,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_26
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_104: None, transpose_26: None}","(permute_104, transpose_26)",{},"{getattr_210: None, getattr_211: None, truediv_26: None}",,transpose_26,size_398,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_52
call_method,size,{permute_106: None},"(permute_106, -1)",{},{pow_53: None},,matmul_52,pow_53,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_398
call_function,<built-in function pow>,{size_398: None},"(size_398, 0.5)",{},{full_52: None},,size_398,getattr_210,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_53
call_function,<built-in function getattr>,{matmul_52: None},"(matmul_52, 'dtype')",{},{full_52: None},,pow_53,getattr_211,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_210
call_function,<built-in function getattr>,{matmul_52: None},"(matmul_52, 'device')",{},{full_52: None},,getattr_210,full_52,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_211
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_53: None, getattr_210: None, getattr_211: None}","([], pow_53)","{'dtype': getattr_210, 'device': getattr_211}",{truediv_26: None},,getattr_211,truediv_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_52
call_function,<built-in function truediv>,"{matmul_52: None, full_52: None}","(matmul_52, full_52)",{},"{getattr_212: None, getattr_214: None, getattr_215: None, getattr_216: None, to_26: None}",,full_52,size_399,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_26
call_method,size,{permute_104: None},"(permute_104, -2)",{},{sub_26: None},,truediv_26,size_400,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_399
call_method,size,{permute_105: None},"(permute_105, -2)",{},"{sub_26: None, getitem_323: None}",,size_399,transformer_h_26_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_400
get_attr,transformer.h.26.attn.bias,{},(),{},{getitem_323: None},,size_400,sub_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_26_attn_bias
call_function,<built-in function sub>,"{size_400: None, size_399: None}","(size_400, size_399)",{},{getitem_323: None},,transformer_h_26_attn_bias,getitem_323,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_26
call_function,<built-in function getitem>,"{transformer_h_26_attn_bias: None, sub_26: None, size_400: None}","(transformer_h_26_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_26, size_400, None), slice(None, size_400, None)))",{},{where_26: None},,sub_26,getattr_212,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_323
call_function,<built-in function getattr>,{truediv_26: None},"(truediv_26, 'dtype')",{},{finfo_26: None},,getitem_323,finfo_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_212
call_function,<class 'torch.finfo'>,{getattr_212: None},"(getattr_212,)",{},{getattr_213: None},,getattr_212,getattr_213,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_26
call_function,<built-in function getattr>,{finfo_26: None},"(finfo_26, 'min')",{},{full_53: None},,finfo_26,getattr_214,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_213
call_function,<built-in function getattr>,{truediv_26: None},"(truediv_26, 'dtype')",{},{full_53: None},,getattr_213,getattr_215,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_214
call_function,<built-in function getattr>,{truediv_26: None},"(truediv_26, 'device')",{},{full_53: None},,getattr_214,full_53,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_215
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_213: None, getattr_214: None, getattr_215: None}","([], getattr_213)","{'dtype': getattr_214, 'device': getattr_215}",{where_26: None},,getattr_215,getattr_216,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_53
call_function,<built-in function getattr>,{truediv_26: None},"(truediv_26, 'dtype')",{},{to_26: None},,full_53,to_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_216
call_method,to,"{truediv_26: None, getattr_216: None}","(truediv_26, getattr_216)",{},{where_26: None},,getattr_216,where_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_26
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_323: None, to_26: None, full_53: None}","(getitem_323, to_26, full_53)",{},{softmax_26: None},,to_26,softmax_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_26
call_function,<function softmax at 0x7f6fd5135ca0>,{where_26: None},"(where_26,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_27: None},,where_26,getattr_217,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_26
call_function,<built-in function getattr>,{permute_106: None},"(permute_106, 'dtype')",{},{type_27: None},,softmax_26,type_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_217
call_method,type,"{softmax_26: None, getattr_217: None}","(softmax_26, getattr_217)",{},{transformer_h_26_attn_attn_dropout: None},,getattr_217,transformer_h_26_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_27
call_module,transformer.h.26.attn.attn_dropout,{type_27: None},"(type_27,)",{},{matmul_53: None},,type_27,matmul_53,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.26.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_26_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_26_attn_attn_dropout: None, permute_106: None}","(transformer_h_26_attn_attn_dropout, permute_106)",{},{permute_107: None},,transformer_h_26_attn_attn_dropout,permute_107,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_53
call_method,permute,{matmul_53: None},"(matmul_53, 0, 2, 1, 3)",{},{contiguous_26: None},,matmul_53,contiguous_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_107
call_method,contiguous,{permute_107: None},"(permute_107,)",{},"{size_401: None, view_318: None}",,permute_107,size_401,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_26
call_method,size,{contiguous_26: None},"(contiguous_26,)",{},{getitem_324: None},,contiguous_26,getitem_324,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_401
call_function,<built-in function getitem>,{size_401: None},"(size_401, slice(None, -2, None))",{},{add_320: None},,size_401,add_320,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_324
call_function,<built-in function add>,{getitem_324: None},"(getitem_324, (1280,))",{},{view_318: None},,getitem_324,view_318,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_320
call_method,view,"{contiguous_26: None, add_320: None}","(contiguous_26, add_320)",{},"{size_402: None, size_403: None, view_319: None}",,add_320,size_402,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_318
call_method,size,{view_318: None},"(view_318,)",{},{getitem_325: None},,view_318,getitem_325,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.26.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_402
call_function,<built-in function getitem>,{size_402: None},"(size_402, slice(None, -1, None))",{},{add_321: None},,size_402,add_321,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.26.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_325
call_function,<built-in function add>,{getitem_325: None},"(getitem_325, (1280,))",{},{view_320: None},,getitem_325,transformer_h_26_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.26.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_321
get_attr,transformer.h.26.attn.c_proj.bias,{},(),{},{addmm_105: None},,add_321,size_403,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.26.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_26_attn_c_proj_bias
call_method,size,{view_318: None},"(view_318, -1)",{},{view_319: None},,transformer_h_26_attn_c_proj_bias,view_319,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.26.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_403
call_method,view,"{view_318: None, size_403: None}","(view_318, -1, size_403)",{},{addmm_105: None},,size_403,transformer_h_26_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.26.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_319
get_attr,transformer.h.26.attn.c_proj.weight,{},(),{},{addmm_105: None},,view_319,addmm_105,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.26.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_26_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_26_attn_c_proj_bias: None, view_319: None, transformer_h_26_attn_c_proj_weight: None}","(transformer_h_26_attn_c_proj_bias, view_319, transformer_h_26_attn_c_proj_weight)",{},{view_320: None},,transformer_h_26_attn_c_proj_weight,view_320,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.26.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_105
call_method,view,"{addmm_105: None, add_321: None}","(addmm_105, add_321)",{},{transformer_h_26_attn_resid_dropout: None},,addmm_105,transformer_h_26_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.26.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_320
call_module,transformer.h.26.attn.resid_dropout,{view_320: None},"(view_320,)",{},{add_322: None},,view_320,add_322,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.26.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_26_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_26_attn_resid_dropout: None, add_315: None}","(transformer_h_26_attn_resid_dropout, add_315)",{},"{transformer_h_26_ln_2: None, add_327: None}",,transformer_h_26_attn_resid_dropout,transformer_h_26_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_322
call_module,transformer.h.26.ln_2,{add_322: None},"(add_322,)",{},"{size_404: None, size_405: None, view_321: None}",,add_322,size_404,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_26_ln_2
call_method,size,{transformer_h_26_ln_2: None},"(transformer_h_26_ln_2,)",{},{getitem_326: None},,transformer_h_26_ln_2,getitem_326,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_404
call_function,<built-in function getitem>,{size_404: None},"(size_404, slice(None, -1, None))",{},{add_323: None},,size_404,add_323,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_326
call_function,<built-in function add>,{getitem_326: None},"(getitem_326, (5120,))",{},{view_322: None},,getitem_326,transformer_h_26_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_323
get_attr,transformer.h.26.mlp.c_fc.bias,{},(),{},{addmm_106: None},,add_323,size_405,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_26_mlp_c_fc_bias
call_method,size,{transformer_h_26_ln_2: None},"(transformer_h_26_ln_2, -1)",{},{view_321: None},,transformer_h_26_mlp_c_fc_bias,view_321,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_405
call_method,view,"{transformer_h_26_ln_2: None, size_405: None}","(transformer_h_26_ln_2, -1, size_405)",{},{addmm_106: None},,size_405,transformer_h_26_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_321
get_attr,transformer.h.26.mlp.c_fc.weight,{},(),{},{addmm_106: None},,view_321,addmm_106,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_26_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_26_mlp_c_fc_bias: None, view_321: None, transformer_h_26_mlp_c_fc_weight: None}","(transformer_h_26_mlp_c_fc_bias, view_321, transformer_h_26_mlp_c_fc_weight)",{},{view_322: None},,transformer_h_26_mlp_c_fc_weight,view_322,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_106
call_method,view,"{addmm_106: None, add_323: None}","(addmm_106, add_323)",{},"{mul_104: None, pow_54: None, add_324: None}",,addmm_106,mul_104,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_322
call_function,<built-in function mul>,{view_322: None},"(0.5, view_322)",{},{mul_107: None},,view_322,pow_54,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_104
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_322: None},"(view_322, 3.0)",{},{mul_105: None},,mul_104,mul_105,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_54
call_function,<built-in function mul>,{pow_54: None},"(0.044715, pow_54)",{},{add_324: None},,pow_54,add_324,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_105
call_function,<built-in function add>,"{view_322: None, mul_105: None}","(view_322, mul_105)",{},{mul_106: None},,mul_105,mul_106,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_324
call_function,<built-in function mul>,{add_324: None},"(0.7978845608028654, add_324)",{},{tanh_26: None},,add_324,tanh_26,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_106
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_106: None},"(mul_106,)",{},{add_325: None},,mul_106,add_325,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_26
call_function,<built-in function add>,{tanh_26: None},"(1.0, tanh_26)",{},{mul_107: None},,tanh_26,mul_107,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_325
call_function,<built-in function mul>,"{mul_104: None, add_325: None}","(mul_104, add_325)",{},"{size_406: None, size_407: None, view_323: None}",,add_325,size_406,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_107
call_method,size,{mul_107: None},"(mul_107,)",{},{getitem_327: None},,mul_107,getitem_327,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_406
call_function,<built-in function getitem>,{size_406: None},"(size_406, slice(None, -1, None))",{},{add_326: None},,size_406,add_326,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_327
call_function,<built-in function add>,{getitem_327: None},"(getitem_327, (1280,))",{},{view_324: None},,getitem_327,transformer_h_26_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_326
get_attr,transformer.h.26.mlp.c_proj.bias,{},(),{},{addmm_107: None},,add_326,size_407,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_26_mlp_c_proj_bias
call_method,size,{mul_107: None},"(mul_107, -1)",{},{view_323: None},,transformer_h_26_mlp_c_proj_bias,view_323,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_407
call_method,view,"{mul_107: None, size_407: None}","(mul_107, -1, size_407)",{},{addmm_107: None},,size_407,transformer_h_26_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_323
get_attr,transformer.h.26.mlp.c_proj.weight,{},(),{},{addmm_107: None},,view_323,addmm_107,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_26_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_26_mlp_c_proj_bias: None, view_323: None, transformer_h_26_mlp_c_proj_weight: None}","(transformer_h_26_mlp_c_proj_bias, view_323, transformer_h_26_mlp_c_proj_weight)",{},{view_324: None},,transformer_h_26_mlp_c_proj_weight,view_324,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_107
call_method,view,"{addmm_107: None, add_326: None}","(addmm_107, add_326)",{},{transformer_h_26_mlp_dropout: None},,addmm_107,transformer_h_26_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_324
call_module,transformer.h.26.mlp.dropout,{view_324: None},"(view_324,)",{},{add_327: None},,view_324,add_327,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.26.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.26.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_26_mlp_dropout
call_function,<built-in function add>,"{add_322: None, transformer_h_26_mlp_dropout: None}","(add_322, transformer_h_26_mlp_dropout)",{},"{transformer_h_27_ln_1: None, add_334: None}",,transformer_h_26_mlp_dropout,transformer_h_27_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.26', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_327
call_module,transformer.h.27.ln_1,{add_327: None},"(add_327,)",{},"{size_408: None, size_409: None, view_325: None}",,add_327,size_408,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_27_ln_1
call_method,size,{transformer_h_27_ln_1: None},"(transformer_h_27_ln_1,)",{},{getitem_328: None},,transformer_h_27_ln_1,getitem_328,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.27.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_408
call_function,<built-in function getitem>,{size_408: None},"(size_408, slice(None, -1, None))",{},{add_328: None},,size_408,add_328,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.27.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_328
call_function,<built-in function add>,{getitem_328: None},"(getitem_328, (3840,))",{},{view_326: None},,getitem_328,transformer_h_27_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.27.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_328
get_attr,transformer.h.27.attn.c_attn.bias,{},(),{},{addmm_108: None},,add_328,size_409,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.27.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_27_attn_c_attn_bias
call_method,size,{transformer_h_27_ln_1: None},"(transformer_h_27_ln_1, -1)",{},{view_325: None},,transformer_h_27_attn_c_attn_bias,view_325,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.27.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_409
call_method,view,"{transformer_h_27_ln_1: None, size_409: None}","(transformer_h_27_ln_1, -1, size_409)",{},{addmm_108: None},,size_409,transformer_h_27_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.27.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_325
get_attr,transformer.h.27.attn.c_attn.weight,{},(),{},{addmm_108: None},,view_325,addmm_108,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.27.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_27_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_27_attn_c_attn_bias: None, view_325: None, transformer_h_27_attn_c_attn_weight: None}","(transformer_h_27_attn_c_attn_bias, view_325, transformer_h_27_attn_c_attn_weight)",{},{view_326: None},,transformer_h_27_attn_c_attn_weight,view_326,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.27.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_108
call_method,view,"{addmm_108: None, add_328: None}","(addmm_108, add_328)",{},{split_27: None},,addmm_108,split_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.27.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_326
call_method,split,{view_326: None},"(view_326, 1280)",{'dim': 2},"{getitem_329: None, getitem_330: None, getitem_331: None}",,view_326,getitem_329,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_27
call_function,<built-in function getitem>,{split_27: None},"(split_27, 0)",{},"{size_410: None, view_327: None}",,split_27,getitem_330,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_329
call_function,<built-in function getitem>,{split_27: None},"(split_27, 1)",{},"{size_411: None, view_328: None}",,getitem_329,getitem_331,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_330
call_function,<built-in function getitem>,{split_27: None},"(split_27, 2)",{},"{size_412: None, view_329: None}",,getitem_330,size_410,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_331
call_method,size,{getitem_329: None},"(getitem_329,)",{},{getitem_332: None},,getitem_331,getitem_332,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_410
call_function,<built-in function getitem>,{size_410: None},"(size_410, slice(None, -1, None))",{},{add_329: None},,size_410,add_329,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_332
call_function,<built-in function add>,{getitem_332: None},"(getitem_332, (20, 64))",{},{view_327: None},,getitem_332,view_327,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_329
call_method,view,"{getitem_329: None, add_329: None}","(getitem_329, add_329)",{},{permute_108: None},,add_329,permute_108,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_327
call_method,permute,{view_327: None},"(view_327, 0, 2, 1, 3)",{},"{matmul_54: None, size_414: None}",,view_327,size_411,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_108
call_method,size,{getitem_330: None},"(getitem_330,)",{},{getitem_333: None},,permute_108,getitem_333,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_411
call_function,<built-in function getitem>,{size_411: None},"(size_411, slice(None, -1, None))",{},{add_330: None},,size_411,add_330,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_333
call_function,<built-in function add>,{getitem_333: None},"(getitem_333, (20, 64))",{},{view_328: None},,getitem_333,view_328,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_330
call_method,view,"{getitem_330: None, add_330: None}","(getitem_330, add_330)",{},{permute_109: None},,add_330,permute_109,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_328
call_method,permute,{view_328: None},"(view_328, 0, 2, 1, 3)",{},"{transpose_27: None, size_415: None, output: None}",,view_328,size_412,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_109
call_method,size,{getitem_331: None},"(getitem_331,)",{},{getitem_334: None},,permute_109,getitem_334,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_412
call_function,<built-in function getitem>,{size_412: None},"(size_412, slice(None, -1, None))",{},{add_331: None},,size_412,add_331,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_334
call_function,<built-in function add>,{getitem_334: None},"(getitem_334, (20, 64))",{},{view_329: None},,getitem_334,view_329,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_331
call_method,view,"{getitem_331: None, add_331: None}","(getitem_331, add_331)",{},{permute_110: None},,add_331,permute_110,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_329
call_method,permute,{view_329: None},"(view_329, 0, 2, 1, 3)",{},"{size_413: None, getattr_225: None, matmul_55: None, output: None}",,view_329,transpose_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_110
call_method,transpose,{permute_109: None},"(permute_109, -1, -2)",{},{matmul_54: None},,permute_110,matmul_54,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_27
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_108: None, transpose_27: None}","(permute_108, transpose_27)",{},"{getattr_218: None, getattr_219: None, truediv_27: None}",,transpose_27,size_413,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_54
call_method,size,{permute_110: None},"(permute_110, -1)",{},{pow_55: None},,matmul_54,pow_55,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_413
call_function,<built-in function pow>,{size_413: None},"(size_413, 0.5)",{},{full_54: None},,size_413,getattr_218,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_55
call_function,<built-in function getattr>,{matmul_54: None},"(matmul_54, 'dtype')",{},{full_54: None},,pow_55,getattr_219,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_218
call_function,<built-in function getattr>,{matmul_54: None},"(matmul_54, 'device')",{},{full_54: None},,getattr_218,full_54,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_219
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_55: None, getattr_218: None, getattr_219: None}","([], pow_55)","{'dtype': getattr_218, 'device': getattr_219}",{truediv_27: None},,getattr_219,truediv_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_54
call_function,<built-in function truediv>,"{matmul_54: None, full_54: None}","(matmul_54, full_54)",{},"{getattr_220: None, getattr_222: None, getattr_223: None, getattr_224: None, to_27: None}",,full_54,size_414,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_27
call_method,size,{permute_108: None},"(permute_108, -2)",{},{sub_27: None},,truediv_27,size_415,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_414
call_method,size,{permute_109: None},"(permute_109, -2)",{},"{sub_27: None, getitem_335: None}",,size_414,transformer_h_27_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_415
get_attr,transformer.h.27.attn.bias,{},(),{},{getitem_335: None},,size_415,sub_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_27_attn_bias
call_function,<built-in function sub>,"{size_415: None, size_414: None}","(size_415, size_414)",{},{getitem_335: None},,transformer_h_27_attn_bias,getitem_335,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_27
call_function,<built-in function getitem>,"{transformer_h_27_attn_bias: None, sub_27: None, size_415: None}","(transformer_h_27_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_27, size_415, None), slice(None, size_415, None)))",{},{where_27: None},,sub_27,getattr_220,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_335
call_function,<built-in function getattr>,{truediv_27: None},"(truediv_27, 'dtype')",{},{finfo_27: None},,getitem_335,finfo_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_220
call_function,<class 'torch.finfo'>,{getattr_220: None},"(getattr_220,)",{},{getattr_221: None},,getattr_220,getattr_221,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_27
call_function,<built-in function getattr>,{finfo_27: None},"(finfo_27, 'min')",{},{full_55: None},,finfo_27,getattr_222,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_221
call_function,<built-in function getattr>,{truediv_27: None},"(truediv_27, 'dtype')",{},{full_55: None},,getattr_221,getattr_223,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_222
call_function,<built-in function getattr>,{truediv_27: None},"(truediv_27, 'device')",{},{full_55: None},,getattr_222,full_55,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_223
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_221: None, getattr_222: None, getattr_223: None}","([], getattr_221)","{'dtype': getattr_222, 'device': getattr_223}",{where_27: None},,getattr_223,getattr_224,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_55
call_function,<built-in function getattr>,{truediv_27: None},"(truediv_27, 'dtype')",{},{to_27: None},,full_55,to_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_224
call_method,to,"{truediv_27: None, getattr_224: None}","(truediv_27, getattr_224)",{},{where_27: None},,getattr_224,where_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_27
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_335: None, to_27: None, full_55: None}","(getitem_335, to_27, full_55)",{},{softmax_27: None},,to_27,softmax_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_27
call_function,<function softmax at 0x7f6fd5135ca0>,{where_27: None},"(where_27,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_28: None},,where_27,getattr_225,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_27
call_function,<built-in function getattr>,{permute_110: None},"(permute_110, 'dtype')",{},{type_28: None},,softmax_27,type_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_225
call_method,type,"{softmax_27: None, getattr_225: None}","(softmax_27, getattr_225)",{},{transformer_h_27_attn_attn_dropout: None},,getattr_225,transformer_h_27_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_28
call_module,transformer.h.27.attn.attn_dropout,{type_28: None},"(type_28,)",{},{matmul_55: None},,type_28,matmul_55,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.27.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_27_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_27_attn_attn_dropout: None, permute_110: None}","(transformer_h_27_attn_attn_dropout, permute_110)",{},{permute_111: None},,transformer_h_27_attn_attn_dropout,permute_111,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_55
call_method,permute,{matmul_55: None},"(matmul_55, 0, 2, 1, 3)",{},{contiguous_27: None},,matmul_55,contiguous_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_111
call_method,contiguous,{permute_111: None},"(permute_111,)",{},"{size_416: None, view_330: None}",,permute_111,size_416,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_27
call_method,size,{contiguous_27: None},"(contiguous_27,)",{},{getitem_336: None},,contiguous_27,getitem_336,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_416
call_function,<built-in function getitem>,{size_416: None},"(size_416, slice(None, -2, None))",{},{add_332: None},,size_416,add_332,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_336
call_function,<built-in function add>,{getitem_336: None},"(getitem_336, (1280,))",{},{view_330: None},,getitem_336,view_330,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_332
call_method,view,"{contiguous_27: None, add_332: None}","(contiguous_27, add_332)",{},"{size_417: None, size_418: None, view_331: None}",,add_332,size_417,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_330
call_method,size,{view_330: None},"(view_330,)",{},{getitem_337: None},,view_330,getitem_337,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.27.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_417
call_function,<built-in function getitem>,{size_417: None},"(size_417, slice(None, -1, None))",{},{add_333: None},,size_417,add_333,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.27.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_337
call_function,<built-in function add>,{getitem_337: None},"(getitem_337, (1280,))",{},{view_332: None},,getitem_337,transformer_h_27_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.27.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_333
get_attr,transformer.h.27.attn.c_proj.bias,{},(),{},{addmm_109: None},,add_333,size_418,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.27.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_27_attn_c_proj_bias
call_method,size,{view_330: None},"(view_330, -1)",{},{view_331: None},,transformer_h_27_attn_c_proj_bias,view_331,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.27.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_418
call_method,view,"{view_330: None, size_418: None}","(view_330, -1, size_418)",{},{addmm_109: None},,size_418,transformer_h_27_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.27.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_331
get_attr,transformer.h.27.attn.c_proj.weight,{},(),{},{addmm_109: None},,view_331,addmm_109,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.27.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_27_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_27_attn_c_proj_bias: None, view_331: None, transformer_h_27_attn_c_proj_weight: None}","(transformer_h_27_attn_c_proj_bias, view_331, transformer_h_27_attn_c_proj_weight)",{},{view_332: None},,transformer_h_27_attn_c_proj_weight,view_332,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.27.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_109
call_method,view,"{addmm_109: None, add_333: None}","(addmm_109, add_333)",{},{transformer_h_27_attn_resid_dropout: None},,addmm_109,transformer_h_27_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.27.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_332
call_module,transformer.h.27.attn.resid_dropout,{view_332: None},"(view_332,)",{},{add_334: None},,view_332,add_334,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.27.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_27_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_27_attn_resid_dropout: None, add_327: None}","(transformer_h_27_attn_resid_dropout, add_327)",{},"{transformer_h_27_ln_2: None, add_339: None}",,transformer_h_27_attn_resid_dropout,transformer_h_27_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_334
call_module,transformer.h.27.ln_2,{add_334: None},"(add_334,)",{},"{size_419: None, size_420: None, view_333: None}",,add_334,size_419,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_27_ln_2
call_method,size,{transformer_h_27_ln_2: None},"(transformer_h_27_ln_2,)",{},{getitem_338: None},,transformer_h_27_ln_2,getitem_338,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_419
call_function,<built-in function getitem>,{size_419: None},"(size_419, slice(None, -1, None))",{},{add_335: None},,size_419,add_335,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_338
call_function,<built-in function add>,{getitem_338: None},"(getitem_338, (5120,))",{},{view_334: None},,getitem_338,transformer_h_27_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_335
get_attr,transformer.h.27.mlp.c_fc.bias,{},(),{},{addmm_110: None},,add_335,size_420,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_27_mlp_c_fc_bias
call_method,size,{transformer_h_27_ln_2: None},"(transformer_h_27_ln_2, -1)",{},{view_333: None},,transformer_h_27_mlp_c_fc_bias,view_333,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_420
call_method,view,"{transformer_h_27_ln_2: None, size_420: None}","(transformer_h_27_ln_2, -1, size_420)",{},{addmm_110: None},,size_420,transformer_h_27_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_333
get_attr,transformer.h.27.mlp.c_fc.weight,{},(),{},{addmm_110: None},,view_333,addmm_110,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_27_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_27_mlp_c_fc_bias: None, view_333: None, transformer_h_27_mlp_c_fc_weight: None}","(transformer_h_27_mlp_c_fc_bias, view_333, transformer_h_27_mlp_c_fc_weight)",{},{view_334: None},,transformer_h_27_mlp_c_fc_weight,view_334,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_110
call_method,view,"{addmm_110: None, add_335: None}","(addmm_110, add_335)",{},"{mul_108: None, pow_56: None, add_336: None}",,addmm_110,mul_108,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_334
call_function,<built-in function mul>,{view_334: None},"(0.5, view_334)",{},{mul_111: None},,view_334,pow_56,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_108
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_334: None},"(view_334, 3.0)",{},{mul_109: None},,mul_108,mul_109,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_56
call_function,<built-in function mul>,{pow_56: None},"(0.044715, pow_56)",{},{add_336: None},,pow_56,add_336,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_109
call_function,<built-in function add>,"{view_334: None, mul_109: None}","(view_334, mul_109)",{},{mul_110: None},,mul_109,mul_110,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_336
call_function,<built-in function mul>,{add_336: None},"(0.7978845608028654, add_336)",{},{tanh_27: None},,add_336,tanh_27,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_110
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_110: None},"(mul_110,)",{},{add_337: None},,mul_110,add_337,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_27
call_function,<built-in function add>,{tanh_27: None},"(1.0, tanh_27)",{},{mul_111: None},,tanh_27,mul_111,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_337
call_function,<built-in function mul>,"{mul_108: None, add_337: None}","(mul_108, add_337)",{},"{size_421: None, size_422: None, view_335: None}",,add_337,size_421,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_111
call_method,size,{mul_111: None},"(mul_111,)",{},{getitem_339: None},,mul_111,getitem_339,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_421
call_function,<built-in function getitem>,{size_421: None},"(size_421, slice(None, -1, None))",{},{add_338: None},,size_421,add_338,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_339
call_function,<built-in function add>,{getitem_339: None},"(getitem_339, (1280,))",{},{view_336: None},,getitem_339,transformer_h_27_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_338
get_attr,transformer.h.27.mlp.c_proj.bias,{},(),{},{addmm_111: None},,add_338,size_422,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_27_mlp_c_proj_bias
call_method,size,{mul_111: None},"(mul_111, -1)",{},{view_335: None},,transformer_h_27_mlp_c_proj_bias,view_335,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_422
call_method,view,"{mul_111: None, size_422: None}","(mul_111, -1, size_422)",{},{addmm_111: None},,size_422,transformer_h_27_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_335
get_attr,transformer.h.27.mlp.c_proj.weight,{},(),{},{addmm_111: None},,view_335,addmm_111,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_27_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_27_mlp_c_proj_bias: None, view_335: None, transformer_h_27_mlp_c_proj_weight: None}","(transformer_h_27_mlp_c_proj_bias, view_335, transformer_h_27_mlp_c_proj_weight)",{},{view_336: None},,transformer_h_27_mlp_c_proj_weight,view_336,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_111
call_method,view,"{addmm_111: None, add_338: None}","(addmm_111, add_338)",{},{transformer_h_27_mlp_dropout: None},,addmm_111,transformer_h_27_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_336
call_module,transformer.h.27.mlp.dropout,{view_336: None},"(view_336,)",{},{add_339: None},,view_336,add_339,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.27.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.27.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_27_mlp_dropout
call_function,<built-in function add>,"{add_334: None, transformer_h_27_mlp_dropout: None}","(add_334, transformer_h_27_mlp_dropout)",{},"{transformer_h_28_ln_1: None, add_346: None}",,transformer_h_27_mlp_dropout,transformer_h_28_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.27', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_339
call_module,transformer.h.28.ln_1,{add_339: None},"(add_339,)",{},"{size_423: None, size_424: None, view_337: None}",,add_339,size_423,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_28_ln_1
call_method,size,{transformer_h_28_ln_1: None},"(transformer_h_28_ln_1,)",{},{getitem_340: None},,transformer_h_28_ln_1,getitem_340,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.28.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_423
call_function,<built-in function getitem>,{size_423: None},"(size_423, slice(None, -1, None))",{},{add_340: None},,size_423,add_340,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.28.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_340
call_function,<built-in function add>,{getitem_340: None},"(getitem_340, (3840,))",{},{view_338: None},,getitem_340,transformer_h_28_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.28.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_340
get_attr,transformer.h.28.attn.c_attn.bias,{},(),{},{addmm_112: None},,add_340,size_424,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.28.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_28_attn_c_attn_bias
call_method,size,{transformer_h_28_ln_1: None},"(transformer_h_28_ln_1, -1)",{},{view_337: None},,transformer_h_28_attn_c_attn_bias,view_337,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.28.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_424
call_method,view,"{transformer_h_28_ln_1: None, size_424: None}","(transformer_h_28_ln_1, -1, size_424)",{},{addmm_112: None},,size_424,transformer_h_28_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.28.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_337
get_attr,transformer.h.28.attn.c_attn.weight,{},(),{},{addmm_112: None},,view_337,addmm_112,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.28.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_28_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_28_attn_c_attn_bias: None, view_337: None, transformer_h_28_attn_c_attn_weight: None}","(transformer_h_28_attn_c_attn_bias, view_337, transformer_h_28_attn_c_attn_weight)",{},{view_338: None},,transformer_h_28_attn_c_attn_weight,view_338,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.28.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_112
call_method,view,"{addmm_112: None, add_340: None}","(addmm_112, add_340)",{},{split_28: None},,addmm_112,split_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.28.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_338
call_method,split,{view_338: None},"(view_338, 1280)",{'dim': 2},"{getitem_341: None, getitem_342: None, getitem_343: None}",,view_338,getitem_341,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_28
call_function,<built-in function getitem>,{split_28: None},"(split_28, 0)",{},"{size_425: None, view_339: None}",,split_28,getitem_342,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_341
call_function,<built-in function getitem>,{split_28: None},"(split_28, 1)",{},"{size_426: None, view_340: None}",,getitem_341,getitem_343,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_342
call_function,<built-in function getitem>,{split_28: None},"(split_28, 2)",{},"{size_427: None, view_341: None}",,getitem_342,size_425,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_343
call_method,size,{getitem_341: None},"(getitem_341,)",{},{getitem_344: None},,getitem_343,getitem_344,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_425
call_function,<built-in function getitem>,{size_425: None},"(size_425, slice(None, -1, None))",{},{add_341: None},,size_425,add_341,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_344
call_function,<built-in function add>,{getitem_344: None},"(getitem_344, (20, 64))",{},{view_339: None},,getitem_344,view_339,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_341
call_method,view,"{getitem_341: None, add_341: None}","(getitem_341, add_341)",{},{permute_112: None},,add_341,permute_112,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_339
call_method,permute,{view_339: None},"(view_339, 0, 2, 1, 3)",{},"{matmul_56: None, size_429: None}",,view_339,size_426,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_112
call_method,size,{getitem_342: None},"(getitem_342,)",{},{getitem_345: None},,permute_112,getitem_345,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_426
call_function,<built-in function getitem>,{size_426: None},"(size_426, slice(None, -1, None))",{},{add_342: None},,size_426,add_342,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_345
call_function,<built-in function add>,{getitem_345: None},"(getitem_345, (20, 64))",{},{view_340: None},,getitem_345,view_340,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_342
call_method,view,"{getitem_342: None, add_342: None}","(getitem_342, add_342)",{},{permute_113: None},,add_342,permute_113,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_340
call_method,permute,{view_340: None},"(view_340, 0, 2, 1, 3)",{},"{transpose_28: None, size_430: None, output: None}",,view_340,size_427,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_113
call_method,size,{getitem_343: None},"(getitem_343,)",{},{getitem_346: None},,permute_113,getitem_346,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_427
call_function,<built-in function getitem>,{size_427: None},"(size_427, slice(None, -1, None))",{},{add_343: None},,size_427,add_343,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_346
call_function,<built-in function add>,{getitem_346: None},"(getitem_346, (20, 64))",{},{view_341: None},,getitem_346,view_341,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_343
call_method,view,"{getitem_343: None, add_343: None}","(getitem_343, add_343)",{},{permute_114: None},,add_343,permute_114,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_341
call_method,permute,{view_341: None},"(view_341, 0, 2, 1, 3)",{},"{size_428: None, getattr_233: None, matmul_57: None, output: None}",,view_341,transpose_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_114
call_method,transpose,{permute_113: None},"(permute_113, -1, -2)",{},{matmul_56: None},,permute_114,matmul_56,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_28
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_112: None, transpose_28: None}","(permute_112, transpose_28)",{},"{getattr_226: None, getattr_227: None, truediv_28: None}",,transpose_28,size_428,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_56
call_method,size,{permute_114: None},"(permute_114, -1)",{},{pow_57: None},,matmul_56,pow_57,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_428
call_function,<built-in function pow>,{size_428: None},"(size_428, 0.5)",{},{full_56: None},,size_428,getattr_226,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_57
call_function,<built-in function getattr>,{matmul_56: None},"(matmul_56, 'dtype')",{},{full_56: None},,pow_57,getattr_227,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_226
call_function,<built-in function getattr>,{matmul_56: None},"(matmul_56, 'device')",{},{full_56: None},,getattr_226,full_56,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_227
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_57: None, getattr_226: None, getattr_227: None}","([], pow_57)","{'dtype': getattr_226, 'device': getattr_227}",{truediv_28: None},,getattr_227,truediv_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_56
call_function,<built-in function truediv>,"{matmul_56: None, full_56: None}","(matmul_56, full_56)",{},"{getattr_228: None, getattr_230: None, getattr_231: None, getattr_232: None, to_28: None}",,full_56,size_429,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_28
call_method,size,{permute_112: None},"(permute_112, -2)",{},{sub_28: None},,truediv_28,size_430,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_429
call_method,size,{permute_113: None},"(permute_113, -2)",{},"{sub_28: None, getitem_347: None}",,size_429,transformer_h_28_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_430
get_attr,transformer.h.28.attn.bias,{},(),{},{getitem_347: None},,size_430,sub_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_28_attn_bias
call_function,<built-in function sub>,"{size_430: None, size_429: None}","(size_430, size_429)",{},{getitem_347: None},,transformer_h_28_attn_bias,getitem_347,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_28
call_function,<built-in function getitem>,"{transformer_h_28_attn_bias: None, sub_28: None, size_430: None}","(transformer_h_28_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_28, size_430, None), slice(None, size_430, None)))",{},{where_28: None},,sub_28,getattr_228,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_347
call_function,<built-in function getattr>,{truediv_28: None},"(truediv_28, 'dtype')",{},{finfo_28: None},,getitem_347,finfo_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_228
call_function,<class 'torch.finfo'>,{getattr_228: None},"(getattr_228,)",{},{getattr_229: None},,getattr_228,getattr_229,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_28
call_function,<built-in function getattr>,{finfo_28: None},"(finfo_28, 'min')",{},{full_57: None},,finfo_28,getattr_230,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_229
call_function,<built-in function getattr>,{truediv_28: None},"(truediv_28, 'dtype')",{},{full_57: None},,getattr_229,getattr_231,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_230
call_function,<built-in function getattr>,{truediv_28: None},"(truediv_28, 'device')",{},{full_57: None},,getattr_230,full_57,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_231
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_229: None, getattr_230: None, getattr_231: None}","([], getattr_229)","{'dtype': getattr_230, 'device': getattr_231}",{where_28: None},,getattr_231,getattr_232,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_57
call_function,<built-in function getattr>,{truediv_28: None},"(truediv_28, 'dtype')",{},{to_28: None},,full_57,to_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_232
call_method,to,"{truediv_28: None, getattr_232: None}","(truediv_28, getattr_232)",{},{where_28: None},,getattr_232,where_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_28
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_347: None, to_28: None, full_57: None}","(getitem_347, to_28, full_57)",{},{softmax_28: None},,to_28,softmax_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_28
call_function,<function softmax at 0x7f6fd5135ca0>,{where_28: None},"(where_28,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_29: None},,where_28,getattr_233,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_28
call_function,<built-in function getattr>,{permute_114: None},"(permute_114, 'dtype')",{},{type_29: None},,softmax_28,type_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_233
call_method,type,"{softmax_28: None, getattr_233: None}","(softmax_28, getattr_233)",{},{transformer_h_28_attn_attn_dropout: None},,getattr_233,transformer_h_28_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_29
call_module,transformer.h.28.attn.attn_dropout,{type_29: None},"(type_29,)",{},{matmul_57: None},,type_29,matmul_57,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.28.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_28_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_28_attn_attn_dropout: None, permute_114: None}","(transformer_h_28_attn_attn_dropout, permute_114)",{},{permute_115: None},,transformer_h_28_attn_attn_dropout,permute_115,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_57
call_method,permute,{matmul_57: None},"(matmul_57, 0, 2, 1, 3)",{},{contiguous_28: None},,matmul_57,contiguous_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_115
call_method,contiguous,{permute_115: None},"(permute_115,)",{},"{size_431: None, view_342: None}",,permute_115,size_431,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_28
call_method,size,{contiguous_28: None},"(contiguous_28,)",{},{getitem_348: None},,contiguous_28,getitem_348,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_431
call_function,<built-in function getitem>,{size_431: None},"(size_431, slice(None, -2, None))",{},{add_344: None},,size_431,add_344,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_348
call_function,<built-in function add>,{getitem_348: None},"(getitem_348, (1280,))",{},{view_342: None},,getitem_348,view_342,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_344
call_method,view,"{contiguous_28: None, add_344: None}","(contiguous_28, add_344)",{},"{size_432: None, size_433: None, view_343: None}",,add_344,size_432,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_342
call_method,size,{view_342: None},"(view_342,)",{},{getitem_349: None},,view_342,getitem_349,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.28.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_432
call_function,<built-in function getitem>,{size_432: None},"(size_432, slice(None, -1, None))",{},{add_345: None},,size_432,add_345,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.28.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_349
call_function,<built-in function add>,{getitem_349: None},"(getitem_349, (1280,))",{},{view_344: None},,getitem_349,transformer_h_28_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.28.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_345
get_attr,transformer.h.28.attn.c_proj.bias,{},(),{},{addmm_113: None},,add_345,size_433,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.28.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_28_attn_c_proj_bias
call_method,size,{view_342: None},"(view_342, -1)",{},{view_343: None},,transformer_h_28_attn_c_proj_bias,view_343,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.28.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_433
call_method,view,"{view_342: None, size_433: None}","(view_342, -1, size_433)",{},{addmm_113: None},,size_433,transformer_h_28_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.28.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_343
get_attr,transformer.h.28.attn.c_proj.weight,{},(),{},{addmm_113: None},,view_343,addmm_113,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.28.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_28_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_28_attn_c_proj_bias: None, view_343: None, transformer_h_28_attn_c_proj_weight: None}","(transformer_h_28_attn_c_proj_bias, view_343, transformer_h_28_attn_c_proj_weight)",{},{view_344: None},,transformer_h_28_attn_c_proj_weight,view_344,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.28.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_113
call_method,view,"{addmm_113: None, add_345: None}","(addmm_113, add_345)",{},{transformer_h_28_attn_resid_dropout: None},,addmm_113,transformer_h_28_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.28.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_344
call_module,transformer.h.28.attn.resid_dropout,{view_344: None},"(view_344,)",{},{add_346: None},,view_344,add_346,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.28.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_28_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_28_attn_resid_dropout: None, add_339: None}","(transformer_h_28_attn_resid_dropout, add_339)",{},"{transformer_h_28_ln_2: None, add_351: None}",,transformer_h_28_attn_resid_dropout,transformer_h_28_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_346
call_module,transformer.h.28.ln_2,{add_346: None},"(add_346,)",{},"{size_434: None, size_435: None, view_345: None}",,add_346,size_434,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_28_ln_2
call_method,size,{transformer_h_28_ln_2: None},"(transformer_h_28_ln_2,)",{},{getitem_350: None},,transformer_h_28_ln_2,getitem_350,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_434
call_function,<built-in function getitem>,{size_434: None},"(size_434, slice(None, -1, None))",{},{add_347: None},,size_434,add_347,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_350
call_function,<built-in function add>,{getitem_350: None},"(getitem_350, (5120,))",{},{view_346: None},,getitem_350,transformer_h_28_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_347
get_attr,transformer.h.28.mlp.c_fc.bias,{},(),{},{addmm_114: None},,add_347,size_435,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_28_mlp_c_fc_bias
call_method,size,{transformer_h_28_ln_2: None},"(transformer_h_28_ln_2, -1)",{},{view_345: None},,transformer_h_28_mlp_c_fc_bias,view_345,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_435
call_method,view,"{transformer_h_28_ln_2: None, size_435: None}","(transformer_h_28_ln_2, -1, size_435)",{},{addmm_114: None},,size_435,transformer_h_28_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_345
get_attr,transformer.h.28.mlp.c_fc.weight,{},(),{},{addmm_114: None},,view_345,addmm_114,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_28_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_28_mlp_c_fc_bias: None, view_345: None, transformer_h_28_mlp_c_fc_weight: None}","(transformer_h_28_mlp_c_fc_bias, view_345, transformer_h_28_mlp_c_fc_weight)",{},{view_346: None},,transformer_h_28_mlp_c_fc_weight,view_346,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_114
call_method,view,"{addmm_114: None, add_347: None}","(addmm_114, add_347)",{},"{mul_112: None, pow_58: None, add_348: None}",,addmm_114,mul_112,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_346
call_function,<built-in function mul>,{view_346: None},"(0.5, view_346)",{},{mul_115: None},,view_346,pow_58,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_112
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_346: None},"(view_346, 3.0)",{},{mul_113: None},,mul_112,mul_113,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_58
call_function,<built-in function mul>,{pow_58: None},"(0.044715, pow_58)",{},{add_348: None},,pow_58,add_348,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_113
call_function,<built-in function add>,"{view_346: None, mul_113: None}","(view_346, mul_113)",{},{mul_114: None},,mul_113,mul_114,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_348
call_function,<built-in function mul>,{add_348: None},"(0.7978845608028654, add_348)",{},{tanh_28: None},,add_348,tanh_28,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_114
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_114: None},"(mul_114,)",{},{add_349: None},,mul_114,add_349,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_28
call_function,<built-in function add>,{tanh_28: None},"(1.0, tanh_28)",{},{mul_115: None},,tanh_28,mul_115,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_349
call_function,<built-in function mul>,"{mul_112: None, add_349: None}","(mul_112, add_349)",{},"{size_436: None, size_437: None, view_347: None}",,add_349,size_436,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_115
call_method,size,{mul_115: None},"(mul_115,)",{},{getitem_351: None},,mul_115,getitem_351,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_436
call_function,<built-in function getitem>,{size_436: None},"(size_436, slice(None, -1, None))",{},{add_350: None},,size_436,add_350,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_351
call_function,<built-in function add>,{getitem_351: None},"(getitem_351, (1280,))",{},{view_348: None},,getitem_351,transformer_h_28_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_350
get_attr,transformer.h.28.mlp.c_proj.bias,{},(),{},{addmm_115: None},,add_350,size_437,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_28_mlp_c_proj_bias
call_method,size,{mul_115: None},"(mul_115, -1)",{},{view_347: None},,transformer_h_28_mlp_c_proj_bias,view_347,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_437
call_method,view,"{mul_115: None, size_437: None}","(mul_115, -1, size_437)",{},{addmm_115: None},,size_437,transformer_h_28_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_347
get_attr,transformer.h.28.mlp.c_proj.weight,{},(),{},{addmm_115: None},,view_347,addmm_115,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_28_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_28_mlp_c_proj_bias: None, view_347: None, transformer_h_28_mlp_c_proj_weight: None}","(transformer_h_28_mlp_c_proj_bias, view_347, transformer_h_28_mlp_c_proj_weight)",{},{view_348: None},,transformer_h_28_mlp_c_proj_weight,view_348,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_115
call_method,view,"{addmm_115: None, add_350: None}","(addmm_115, add_350)",{},{transformer_h_28_mlp_dropout: None},,addmm_115,transformer_h_28_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_348
call_module,transformer.h.28.mlp.dropout,{view_348: None},"(view_348,)",{},{add_351: None},,view_348,add_351,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.28.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.28.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_28_mlp_dropout
call_function,<built-in function add>,"{add_346: None, transformer_h_28_mlp_dropout: None}","(add_346, transformer_h_28_mlp_dropout)",{},"{transformer_h_29_ln_1: None, add_358: None}",,transformer_h_28_mlp_dropout,transformer_h_29_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.28', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_351
call_module,transformer.h.29.ln_1,{add_351: None},"(add_351,)",{},"{size_438: None, size_439: None, view_349: None}",,add_351,size_438,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_29_ln_1
call_method,size,{transformer_h_29_ln_1: None},"(transformer_h_29_ln_1,)",{},{getitem_352: None},,transformer_h_29_ln_1,getitem_352,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.29.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_438
call_function,<built-in function getitem>,{size_438: None},"(size_438, slice(None, -1, None))",{},{add_352: None},,size_438,add_352,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.29.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_352
call_function,<built-in function add>,{getitem_352: None},"(getitem_352, (3840,))",{},{view_350: None},,getitem_352,transformer_h_29_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.29.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_352
get_attr,transformer.h.29.attn.c_attn.bias,{},(),{},{addmm_116: None},,add_352,size_439,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.29.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_29_attn_c_attn_bias
call_method,size,{transformer_h_29_ln_1: None},"(transformer_h_29_ln_1, -1)",{},{view_349: None},,transformer_h_29_attn_c_attn_bias,view_349,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.29.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_439
call_method,view,"{transformer_h_29_ln_1: None, size_439: None}","(transformer_h_29_ln_1, -1, size_439)",{},{addmm_116: None},,size_439,transformer_h_29_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.29.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_349
get_attr,transformer.h.29.attn.c_attn.weight,{},(),{},{addmm_116: None},,view_349,addmm_116,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.29.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_29_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_29_attn_c_attn_bias: None, view_349: None, transformer_h_29_attn_c_attn_weight: None}","(transformer_h_29_attn_c_attn_bias, view_349, transformer_h_29_attn_c_attn_weight)",{},{view_350: None},,transformer_h_29_attn_c_attn_weight,view_350,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.29.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_116
call_method,view,"{addmm_116: None, add_352: None}","(addmm_116, add_352)",{},{split_29: None},,addmm_116,split_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.29.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_350
call_method,split,{view_350: None},"(view_350, 1280)",{'dim': 2},"{getitem_353: None, getitem_354: None, getitem_355: None}",,view_350,getitem_353,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_29
call_function,<built-in function getitem>,{split_29: None},"(split_29, 0)",{},"{size_440: None, view_351: None}",,split_29,getitem_354,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_353
call_function,<built-in function getitem>,{split_29: None},"(split_29, 1)",{},"{size_441: None, view_352: None}",,getitem_353,getitem_355,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_354
call_function,<built-in function getitem>,{split_29: None},"(split_29, 2)",{},"{size_442: None, view_353: None}",,getitem_354,size_440,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_355
call_method,size,{getitem_353: None},"(getitem_353,)",{},{getitem_356: None},,getitem_355,getitem_356,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_440
call_function,<built-in function getitem>,{size_440: None},"(size_440, slice(None, -1, None))",{},{add_353: None},,size_440,add_353,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_356
call_function,<built-in function add>,{getitem_356: None},"(getitem_356, (20, 64))",{},{view_351: None},,getitem_356,view_351,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_353
call_method,view,"{getitem_353: None, add_353: None}","(getitem_353, add_353)",{},{permute_116: None},,add_353,permute_116,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_351
call_method,permute,{view_351: None},"(view_351, 0, 2, 1, 3)",{},"{matmul_58: None, size_444: None}",,view_351,size_441,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_116
call_method,size,{getitem_354: None},"(getitem_354,)",{},{getitem_357: None},,permute_116,getitem_357,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_441
call_function,<built-in function getitem>,{size_441: None},"(size_441, slice(None, -1, None))",{},{add_354: None},,size_441,add_354,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_357
call_function,<built-in function add>,{getitem_357: None},"(getitem_357, (20, 64))",{},{view_352: None},,getitem_357,view_352,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_354
call_method,view,"{getitem_354: None, add_354: None}","(getitem_354, add_354)",{},{permute_117: None},,add_354,permute_117,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_352
call_method,permute,{view_352: None},"(view_352, 0, 2, 1, 3)",{},"{transpose_29: None, size_445: None, output: None}",,view_352,size_442,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_117
call_method,size,{getitem_355: None},"(getitem_355,)",{},{getitem_358: None},,permute_117,getitem_358,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_442
call_function,<built-in function getitem>,{size_442: None},"(size_442, slice(None, -1, None))",{},{add_355: None},,size_442,add_355,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_358
call_function,<built-in function add>,{getitem_358: None},"(getitem_358, (20, 64))",{},{view_353: None},,getitem_358,view_353,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_355
call_method,view,"{getitem_355: None, add_355: None}","(getitem_355, add_355)",{},{permute_118: None},,add_355,permute_118,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_353
call_method,permute,{view_353: None},"(view_353, 0, 2, 1, 3)",{},"{size_443: None, getattr_241: None, matmul_59: None, output: None}",,view_353,transpose_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_118
call_method,transpose,{permute_117: None},"(permute_117, -1, -2)",{},{matmul_58: None},,permute_118,matmul_58,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_29
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_116: None, transpose_29: None}","(permute_116, transpose_29)",{},"{getattr_234: None, getattr_235: None, truediv_29: None}",,transpose_29,size_443,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_58
call_method,size,{permute_118: None},"(permute_118, -1)",{},{pow_59: None},,matmul_58,pow_59,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_443
call_function,<built-in function pow>,{size_443: None},"(size_443, 0.5)",{},{full_58: None},,size_443,getattr_234,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_59
call_function,<built-in function getattr>,{matmul_58: None},"(matmul_58, 'dtype')",{},{full_58: None},,pow_59,getattr_235,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_234
call_function,<built-in function getattr>,{matmul_58: None},"(matmul_58, 'device')",{},{full_58: None},,getattr_234,full_58,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_235
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_59: None, getattr_234: None, getattr_235: None}","([], pow_59)","{'dtype': getattr_234, 'device': getattr_235}",{truediv_29: None},,getattr_235,truediv_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_58
call_function,<built-in function truediv>,"{matmul_58: None, full_58: None}","(matmul_58, full_58)",{},"{getattr_236: None, getattr_238: None, getattr_239: None, getattr_240: None, to_29: None}",,full_58,size_444,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_29
call_method,size,{permute_116: None},"(permute_116, -2)",{},{sub_29: None},,truediv_29,size_445,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_444
call_method,size,{permute_117: None},"(permute_117, -2)",{},"{sub_29: None, getitem_359: None}",,size_444,transformer_h_29_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_445
get_attr,transformer.h.29.attn.bias,{},(),{},{getitem_359: None},,size_445,sub_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_29_attn_bias
call_function,<built-in function sub>,"{size_445: None, size_444: None}","(size_445, size_444)",{},{getitem_359: None},,transformer_h_29_attn_bias,getitem_359,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_29
call_function,<built-in function getitem>,"{transformer_h_29_attn_bias: None, sub_29: None, size_445: None}","(transformer_h_29_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_29, size_445, None), slice(None, size_445, None)))",{},{where_29: None},,sub_29,getattr_236,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_359
call_function,<built-in function getattr>,{truediv_29: None},"(truediv_29, 'dtype')",{},{finfo_29: None},,getitem_359,finfo_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_236
call_function,<class 'torch.finfo'>,{getattr_236: None},"(getattr_236,)",{},{getattr_237: None},,getattr_236,getattr_237,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_29
call_function,<built-in function getattr>,{finfo_29: None},"(finfo_29, 'min')",{},{full_59: None},,finfo_29,getattr_238,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_237
call_function,<built-in function getattr>,{truediv_29: None},"(truediv_29, 'dtype')",{},{full_59: None},,getattr_237,getattr_239,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_238
call_function,<built-in function getattr>,{truediv_29: None},"(truediv_29, 'device')",{},{full_59: None},,getattr_238,full_59,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_239
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_237: None, getattr_238: None, getattr_239: None}","([], getattr_237)","{'dtype': getattr_238, 'device': getattr_239}",{where_29: None},,getattr_239,getattr_240,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_59
call_function,<built-in function getattr>,{truediv_29: None},"(truediv_29, 'dtype')",{},{to_29: None},,full_59,to_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_240
call_method,to,"{truediv_29: None, getattr_240: None}","(truediv_29, getattr_240)",{},{where_29: None},,getattr_240,where_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_29
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_359: None, to_29: None, full_59: None}","(getitem_359, to_29, full_59)",{},{softmax_29: None},,to_29,softmax_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_29
call_function,<function softmax at 0x7f6fd5135ca0>,{where_29: None},"(where_29,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_30: None},,where_29,getattr_241,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_29
call_function,<built-in function getattr>,{permute_118: None},"(permute_118, 'dtype')",{},{type_30: None},,softmax_29,type_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_241
call_method,type,"{softmax_29: None, getattr_241: None}","(softmax_29, getattr_241)",{},{transformer_h_29_attn_attn_dropout: None},,getattr_241,transformer_h_29_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_30
call_module,transformer.h.29.attn.attn_dropout,{type_30: None},"(type_30,)",{},{matmul_59: None},,type_30,matmul_59,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.29.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_29_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_29_attn_attn_dropout: None, permute_118: None}","(transformer_h_29_attn_attn_dropout, permute_118)",{},{permute_119: None},,transformer_h_29_attn_attn_dropout,permute_119,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_59
call_method,permute,{matmul_59: None},"(matmul_59, 0, 2, 1, 3)",{},{contiguous_29: None},,matmul_59,contiguous_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_119
call_method,contiguous,{permute_119: None},"(permute_119,)",{},"{size_446: None, view_354: None}",,permute_119,size_446,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_29
call_method,size,{contiguous_29: None},"(contiguous_29,)",{},{getitem_360: None},,contiguous_29,getitem_360,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_446
call_function,<built-in function getitem>,{size_446: None},"(size_446, slice(None, -2, None))",{},{add_356: None},,size_446,add_356,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_360
call_function,<built-in function add>,{getitem_360: None},"(getitem_360, (1280,))",{},{view_354: None},,getitem_360,view_354,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_356
call_method,view,"{contiguous_29: None, add_356: None}","(contiguous_29, add_356)",{},"{size_447: None, size_448: None, view_355: None}",,add_356,size_447,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_354
call_method,size,{view_354: None},"(view_354,)",{},{getitem_361: None},,view_354,getitem_361,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.29.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_447
call_function,<built-in function getitem>,{size_447: None},"(size_447, slice(None, -1, None))",{},{add_357: None},,size_447,add_357,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.29.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_361
call_function,<built-in function add>,{getitem_361: None},"(getitem_361, (1280,))",{},{view_356: None},,getitem_361,transformer_h_29_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.29.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_357
get_attr,transformer.h.29.attn.c_proj.bias,{},(),{},{addmm_117: None},,add_357,size_448,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.29.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_29_attn_c_proj_bias
call_method,size,{view_354: None},"(view_354, -1)",{},{view_355: None},,transformer_h_29_attn_c_proj_bias,view_355,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.29.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_448
call_method,view,"{view_354: None, size_448: None}","(view_354, -1, size_448)",{},{addmm_117: None},,size_448,transformer_h_29_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.29.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_355
get_attr,transformer.h.29.attn.c_proj.weight,{},(),{},{addmm_117: None},,view_355,addmm_117,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.29.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_29_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_29_attn_c_proj_bias: None, view_355: None, transformer_h_29_attn_c_proj_weight: None}","(transformer_h_29_attn_c_proj_bias, view_355, transformer_h_29_attn_c_proj_weight)",{},{view_356: None},,transformer_h_29_attn_c_proj_weight,view_356,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.29.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_117
call_method,view,"{addmm_117: None, add_357: None}","(addmm_117, add_357)",{},{transformer_h_29_attn_resid_dropout: None},,addmm_117,transformer_h_29_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.29.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_356
call_module,transformer.h.29.attn.resid_dropout,{view_356: None},"(view_356,)",{},{add_358: None},,view_356,add_358,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.29.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_29_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_29_attn_resid_dropout: None, add_351: None}","(transformer_h_29_attn_resid_dropout, add_351)",{},"{transformer_h_29_ln_2: None, add_363: None}",,transformer_h_29_attn_resid_dropout,transformer_h_29_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_358
call_module,transformer.h.29.ln_2,{add_358: None},"(add_358,)",{},"{size_449: None, size_450: None, view_357: None}",,add_358,size_449,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_29_ln_2
call_method,size,{transformer_h_29_ln_2: None},"(transformer_h_29_ln_2,)",{},{getitem_362: None},,transformer_h_29_ln_2,getitem_362,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_449
call_function,<built-in function getitem>,{size_449: None},"(size_449, slice(None, -1, None))",{},{add_359: None},,size_449,add_359,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_362
call_function,<built-in function add>,{getitem_362: None},"(getitem_362, (5120,))",{},{view_358: None},,getitem_362,transformer_h_29_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_359
get_attr,transformer.h.29.mlp.c_fc.bias,{},(),{},{addmm_118: None},,add_359,size_450,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_29_mlp_c_fc_bias
call_method,size,{transformer_h_29_ln_2: None},"(transformer_h_29_ln_2, -1)",{},{view_357: None},,transformer_h_29_mlp_c_fc_bias,view_357,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_450
call_method,view,"{transformer_h_29_ln_2: None, size_450: None}","(transformer_h_29_ln_2, -1, size_450)",{},{addmm_118: None},,size_450,transformer_h_29_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_357
get_attr,transformer.h.29.mlp.c_fc.weight,{},(),{},{addmm_118: None},,view_357,addmm_118,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_29_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_29_mlp_c_fc_bias: None, view_357: None, transformer_h_29_mlp_c_fc_weight: None}","(transformer_h_29_mlp_c_fc_bias, view_357, transformer_h_29_mlp_c_fc_weight)",{},{view_358: None},,transformer_h_29_mlp_c_fc_weight,view_358,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_118
call_method,view,"{addmm_118: None, add_359: None}","(addmm_118, add_359)",{},"{mul_116: None, pow_60: None, add_360: None}",,addmm_118,mul_116,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_358
call_function,<built-in function mul>,{view_358: None},"(0.5, view_358)",{},{mul_119: None},,view_358,pow_60,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_116
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_358: None},"(view_358, 3.0)",{},{mul_117: None},,mul_116,mul_117,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_60
call_function,<built-in function mul>,{pow_60: None},"(0.044715, pow_60)",{},{add_360: None},,pow_60,add_360,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_117
call_function,<built-in function add>,"{view_358: None, mul_117: None}","(view_358, mul_117)",{},{mul_118: None},,mul_117,mul_118,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_360
call_function,<built-in function mul>,{add_360: None},"(0.7978845608028654, add_360)",{},{tanh_29: None},,add_360,tanh_29,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_118
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_118: None},"(mul_118,)",{},{add_361: None},,mul_118,add_361,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_29
call_function,<built-in function add>,{tanh_29: None},"(1.0, tanh_29)",{},{mul_119: None},,tanh_29,mul_119,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_361
call_function,<built-in function mul>,"{mul_116: None, add_361: None}","(mul_116, add_361)",{},"{size_451: None, size_452: None, view_359: None}",,add_361,size_451,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_119
call_method,size,{mul_119: None},"(mul_119,)",{},{getitem_363: None},,mul_119,getitem_363,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_451
call_function,<built-in function getitem>,{size_451: None},"(size_451, slice(None, -1, None))",{},{add_362: None},,size_451,add_362,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_363
call_function,<built-in function add>,{getitem_363: None},"(getitem_363, (1280,))",{},{view_360: None},,getitem_363,transformer_h_29_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_362
get_attr,transformer.h.29.mlp.c_proj.bias,{},(),{},{addmm_119: None},,add_362,size_452,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_29_mlp_c_proj_bias
call_method,size,{mul_119: None},"(mul_119, -1)",{},{view_359: None},,transformer_h_29_mlp_c_proj_bias,view_359,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_452
call_method,view,"{mul_119: None, size_452: None}","(mul_119, -1, size_452)",{},{addmm_119: None},,size_452,transformer_h_29_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_359
get_attr,transformer.h.29.mlp.c_proj.weight,{},(),{},{addmm_119: None},,view_359,addmm_119,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_29_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_29_mlp_c_proj_bias: None, view_359: None, transformer_h_29_mlp_c_proj_weight: None}","(transformer_h_29_mlp_c_proj_bias, view_359, transformer_h_29_mlp_c_proj_weight)",{},{view_360: None},,transformer_h_29_mlp_c_proj_weight,view_360,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_119
call_method,view,"{addmm_119: None, add_362: None}","(addmm_119, add_362)",{},{transformer_h_29_mlp_dropout: None},,addmm_119,transformer_h_29_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_360
call_module,transformer.h.29.mlp.dropout,{view_360: None},"(view_360,)",{},{add_363: None},,view_360,add_363,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.29.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.29.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_29_mlp_dropout
call_function,<built-in function add>,"{add_358: None, transformer_h_29_mlp_dropout: None}","(add_358, transformer_h_29_mlp_dropout)",{},"{transformer_h_30_ln_1: None, add_370: None}",,transformer_h_29_mlp_dropout,transformer_h_30_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.29', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_363
call_module,transformer.h.30.ln_1,{add_363: None},"(add_363,)",{},"{size_453: None, size_454: None, view_361: None}",,add_363,size_453,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_30_ln_1
call_method,size,{transformer_h_30_ln_1: None},"(transformer_h_30_ln_1,)",{},{getitem_364: None},,transformer_h_30_ln_1,getitem_364,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.30.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_453
call_function,<built-in function getitem>,{size_453: None},"(size_453, slice(None, -1, None))",{},{add_364: None},,size_453,add_364,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.30.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_364
call_function,<built-in function add>,{getitem_364: None},"(getitem_364, (3840,))",{},{view_362: None},,getitem_364,transformer_h_30_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.30.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_364
get_attr,transformer.h.30.attn.c_attn.bias,{},(),{},{addmm_120: None},,add_364,size_454,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.30.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_30_attn_c_attn_bias
call_method,size,{transformer_h_30_ln_1: None},"(transformer_h_30_ln_1, -1)",{},{view_361: None},,transformer_h_30_attn_c_attn_bias,view_361,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.30.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_454
call_method,view,"{transformer_h_30_ln_1: None, size_454: None}","(transformer_h_30_ln_1, -1, size_454)",{},{addmm_120: None},,size_454,transformer_h_30_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.30.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_361
get_attr,transformer.h.30.attn.c_attn.weight,{},(),{},{addmm_120: None},,view_361,addmm_120,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.30.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_30_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_30_attn_c_attn_bias: None, view_361: None, transformer_h_30_attn_c_attn_weight: None}","(transformer_h_30_attn_c_attn_bias, view_361, transformer_h_30_attn_c_attn_weight)",{},{view_362: None},,transformer_h_30_attn_c_attn_weight,view_362,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.30.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_120
call_method,view,"{addmm_120: None, add_364: None}","(addmm_120, add_364)",{},{split_30: None},,addmm_120,split_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.30.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_362
call_method,split,{view_362: None},"(view_362, 1280)",{'dim': 2},"{getitem_365: None, getitem_366: None, getitem_367: None}",,view_362,getitem_365,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_30
call_function,<built-in function getitem>,{split_30: None},"(split_30, 0)",{},"{size_455: None, view_363: None}",,split_30,getitem_366,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_365
call_function,<built-in function getitem>,{split_30: None},"(split_30, 1)",{},"{size_456: None, view_364: None}",,getitem_365,getitem_367,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_366
call_function,<built-in function getitem>,{split_30: None},"(split_30, 2)",{},"{size_457: None, view_365: None}",,getitem_366,size_455,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_367
call_method,size,{getitem_365: None},"(getitem_365,)",{},{getitem_368: None},,getitem_367,getitem_368,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_455
call_function,<built-in function getitem>,{size_455: None},"(size_455, slice(None, -1, None))",{},{add_365: None},,size_455,add_365,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_368
call_function,<built-in function add>,{getitem_368: None},"(getitem_368, (20, 64))",{},{view_363: None},,getitem_368,view_363,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_365
call_method,view,"{getitem_365: None, add_365: None}","(getitem_365, add_365)",{},{permute_120: None},,add_365,permute_120,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_363
call_method,permute,{view_363: None},"(view_363, 0, 2, 1, 3)",{},"{matmul_60: None, size_459: None}",,view_363,size_456,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_120
call_method,size,{getitem_366: None},"(getitem_366,)",{},{getitem_369: None},,permute_120,getitem_369,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_456
call_function,<built-in function getitem>,{size_456: None},"(size_456, slice(None, -1, None))",{},{add_366: None},,size_456,add_366,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_369
call_function,<built-in function add>,{getitem_369: None},"(getitem_369, (20, 64))",{},{view_364: None},,getitem_369,view_364,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_366
call_method,view,"{getitem_366: None, add_366: None}","(getitem_366, add_366)",{},{permute_121: None},,add_366,permute_121,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_364
call_method,permute,{view_364: None},"(view_364, 0, 2, 1, 3)",{},"{transpose_30: None, size_460: None, output: None}",,view_364,size_457,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_121
call_method,size,{getitem_367: None},"(getitem_367,)",{},{getitem_370: None},,permute_121,getitem_370,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_457
call_function,<built-in function getitem>,{size_457: None},"(size_457, slice(None, -1, None))",{},{add_367: None},,size_457,add_367,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_370
call_function,<built-in function add>,{getitem_370: None},"(getitem_370, (20, 64))",{},{view_365: None},,getitem_370,view_365,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_367
call_method,view,"{getitem_367: None, add_367: None}","(getitem_367, add_367)",{},{permute_122: None},,add_367,permute_122,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_365
call_method,permute,{view_365: None},"(view_365, 0, 2, 1, 3)",{},"{size_458: None, getattr_249: None, matmul_61: None, output: None}",,view_365,transpose_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_122
call_method,transpose,{permute_121: None},"(permute_121, -1, -2)",{},{matmul_60: None},,permute_122,matmul_60,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_30
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_120: None, transpose_30: None}","(permute_120, transpose_30)",{},"{getattr_242: None, getattr_243: None, truediv_30: None}",,transpose_30,size_458,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_60
call_method,size,{permute_122: None},"(permute_122, -1)",{},{pow_61: None},,matmul_60,pow_61,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_458
call_function,<built-in function pow>,{size_458: None},"(size_458, 0.5)",{},{full_60: None},,size_458,getattr_242,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_61
call_function,<built-in function getattr>,{matmul_60: None},"(matmul_60, 'dtype')",{},{full_60: None},,pow_61,getattr_243,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_242
call_function,<built-in function getattr>,{matmul_60: None},"(matmul_60, 'device')",{},{full_60: None},,getattr_242,full_60,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_243
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_61: None, getattr_242: None, getattr_243: None}","([], pow_61)","{'dtype': getattr_242, 'device': getattr_243}",{truediv_30: None},,getattr_243,truediv_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_60
call_function,<built-in function truediv>,"{matmul_60: None, full_60: None}","(matmul_60, full_60)",{},"{getattr_244: None, getattr_246: None, getattr_247: None, getattr_248: None, to_30: None}",,full_60,size_459,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_30
call_method,size,{permute_120: None},"(permute_120, -2)",{},{sub_30: None},,truediv_30,size_460,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_459
call_method,size,{permute_121: None},"(permute_121, -2)",{},"{sub_30: None, getitem_371: None}",,size_459,transformer_h_30_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_460
get_attr,transformer.h.30.attn.bias,{},(),{},{getitem_371: None},,size_460,sub_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_30_attn_bias
call_function,<built-in function sub>,"{size_460: None, size_459: None}","(size_460, size_459)",{},{getitem_371: None},,transformer_h_30_attn_bias,getitem_371,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_30
call_function,<built-in function getitem>,"{transformer_h_30_attn_bias: None, sub_30: None, size_460: None}","(transformer_h_30_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_30, size_460, None), slice(None, size_460, None)))",{},{where_30: None},,sub_30,getattr_244,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_371
call_function,<built-in function getattr>,{truediv_30: None},"(truediv_30, 'dtype')",{},{finfo_30: None},,getitem_371,finfo_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_244
call_function,<class 'torch.finfo'>,{getattr_244: None},"(getattr_244,)",{},{getattr_245: None},,getattr_244,getattr_245,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_30
call_function,<built-in function getattr>,{finfo_30: None},"(finfo_30, 'min')",{},{full_61: None},,finfo_30,getattr_246,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_245
call_function,<built-in function getattr>,{truediv_30: None},"(truediv_30, 'dtype')",{},{full_61: None},,getattr_245,getattr_247,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_246
call_function,<built-in function getattr>,{truediv_30: None},"(truediv_30, 'device')",{},{full_61: None},,getattr_246,full_61,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_247
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_245: None, getattr_246: None, getattr_247: None}","([], getattr_245)","{'dtype': getattr_246, 'device': getattr_247}",{where_30: None},,getattr_247,getattr_248,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_61
call_function,<built-in function getattr>,{truediv_30: None},"(truediv_30, 'dtype')",{},{to_30: None},,full_61,to_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_248
call_method,to,"{truediv_30: None, getattr_248: None}","(truediv_30, getattr_248)",{},{where_30: None},,getattr_248,where_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_30
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_371: None, to_30: None, full_61: None}","(getitem_371, to_30, full_61)",{},{softmax_30: None},,to_30,softmax_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_30
call_function,<function softmax at 0x7f6fd5135ca0>,{where_30: None},"(where_30,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_31: None},,where_30,getattr_249,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_30
call_function,<built-in function getattr>,{permute_122: None},"(permute_122, 'dtype')",{},{type_31: None},,softmax_30,type_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_249
call_method,type,"{softmax_30: None, getattr_249: None}","(softmax_30, getattr_249)",{},{transformer_h_30_attn_attn_dropout: None},,getattr_249,transformer_h_30_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_31
call_module,transformer.h.30.attn.attn_dropout,{type_31: None},"(type_31,)",{},{matmul_61: None},,type_31,matmul_61,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.30.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_30_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_30_attn_attn_dropout: None, permute_122: None}","(transformer_h_30_attn_attn_dropout, permute_122)",{},{permute_123: None},,transformer_h_30_attn_attn_dropout,permute_123,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_61
call_method,permute,{matmul_61: None},"(matmul_61, 0, 2, 1, 3)",{},{contiguous_30: None},,matmul_61,contiguous_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_123
call_method,contiguous,{permute_123: None},"(permute_123,)",{},"{size_461: None, view_366: None}",,permute_123,size_461,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_30
call_method,size,{contiguous_30: None},"(contiguous_30,)",{},{getitem_372: None},,contiguous_30,getitem_372,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_461
call_function,<built-in function getitem>,{size_461: None},"(size_461, slice(None, -2, None))",{},{add_368: None},,size_461,add_368,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_372
call_function,<built-in function add>,{getitem_372: None},"(getitem_372, (1280,))",{},{view_366: None},,getitem_372,view_366,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_368
call_method,view,"{contiguous_30: None, add_368: None}","(contiguous_30, add_368)",{},"{size_462: None, size_463: None, view_367: None}",,add_368,size_462,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_366
call_method,size,{view_366: None},"(view_366,)",{},{getitem_373: None},,view_366,getitem_373,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.30.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_462
call_function,<built-in function getitem>,{size_462: None},"(size_462, slice(None, -1, None))",{},{add_369: None},,size_462,add_369,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.30.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_373
call_function,<built-in function add>,{getitem_373: None},"(getitem_373, (1280,))",{},{view_368: None},,getitem_373,transformer_h_30_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.30.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_369
get_attr,transformer.h.30.attn.c_proj.bias,{},(),{},{addmm_121: None},,add_369,size_463,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.30.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_30_attn_c_proj_bias
call_method,size,{view_366: None},"(view_366, -1)",{},{view_367: None},,transformer_h_30_attn_c_proj_bias,view_367,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.30.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_463
call_method,view,"{view_366: None, size_463: None}","(view_366, -1, size_463)",{},{addmm_121: None},,size_463,transformer_h_30_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.30.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_367
get_attr,transformer.h.30.attn.c_proj.weight,{},(),{},{addmm_121: None},,view_367,addmm_121,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.30.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_30_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_30_attn_c_proj_bias: None, view_367: None, transformer_h_30_attn_c_proj_weight: None}","(transformer_h_30_attn_c_proj_bias, view_367, transformer_h_30_attn_c_proj_weight)",{},{view_368: None},,transformer_h_30_attn_c_proj_weight,view_368,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.30.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_121
call_method,view,"{addmm_121: None, add_369: None}","(addmm_121, add_369)",{},{transformer_h_30_attn_resid_dropout: None},,addmm_121,transformer_h_30_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.30.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_368
call_module,transformer.h.30.attn.resid_dropout,{view_368: None},"(view_368,)",{},{add_370: None},,view_368,add_370,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.30.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_30_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_30_attn_resid_dropout: None, add_363: None}","(transformer_h_30_attn_resid_dropout, add_363)",{},"{transformer_h_30_ln_2: None, add_375: None}",,transformer_h_30_attn_resid_dropout,transformer_h_30_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_370
call_module,transformer.h.30.ln_2,{add_370: None},"(add_370,)",{},"{size_464: None, size_465: None, view_369: None}",,add_370,size_464,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_30_ln_2
call_method,size,{transformer_h_30_ln_2: None},"(transformer_h_30_ln_2,)",{},{getitem_374: None},,transformer_h_30_ln_2,getitem_374,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_464
call_function,<built-in function getitem>,{size_464: None},"(size_464, slice(None, -1, None))",{},{add_371: None},,size_464,add_371,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_374
call_function,<built-in function add>,{getitem_374: None},"(getitem_374, (5120,))",{},{view_370: None},,getitem_374,transformer_h_30_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_371
get_attr,transformer.h.30.mlp.c_fc.bias,{},(),{},{addmm_122: None},,add_371,size_465,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_30_mlp_c_fc_bias
call_method,size,{transformer_h_30_ln_2: None},"(transformer_h_30_ln_2, -1)",{},{view_369: None},,transformer_h_30_mlp_c_fc_bias,view_369,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_465
call_method,view,"{transformer_h_30_ln_2: None, size_465: None}","(transformer_h_30_ln_2, -1, size_465)",{},{addmm_122: None},,size_465,transformer_h_30_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_369
get_attr,transformer.h.30.mlp.c_fc.weight,{},(),{},{addmm_122: None},,view_369,addmm_122,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_30_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_30_mlp_c_fc_bias: None, view_369: None, transformer_h_30_mlp_c_fc_weight: None}","(transformer_h_30_mlp_c_fc_bias, view_369, transformer_h_30_mlp_c_fc_weight)",{},{view_370: None},,transformer_h_30_mlp_c_fc_weight,view_370,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_122
call_method,view,"{addmm_122: None, add_371: None}","(addmm_122, add_371)",{},"{mul_120: None, pow_62: None, add_372: None}",,addmm_122,mul_120,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_370
call_function,<built-in function mul>,{view_370: None},"(0.5, view_370)",{},{mul_123: None},,view_370,pow_62,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_120
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_370: None},"(view_370, 3.0)",{},{mul_121: None},,mul_120,mul_121,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_62
call_function,<built-in function mul>,{pow_62: None},"(0.044715, pow_62)",{},{add_372: None},,pow_62,add_372,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_121
call_function,<built-in function add>,"{view_370: None, mul_121: None}","(view_370, mul_121)",{},{mul_122: None},,mul_121,mul_122,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_372
call_function,<built-in function mul>,{add_372: None},"(0.7978845608028654, add_372)",{},{tanh_30: None},,add_372,tanh_30,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_122
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_122: None},"(mul_122,)",{},{add_373: None},,mul_122,add_373,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_30
call_function,<built-in function add>,{tanh_30: None},"(1.0, tanh_30)",{},{mul_123: None},,tanh_30,mul_123,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_373
call_function,<built-in function mul>,"{mul_120: None, add_373: None}","(mul_120, add_373)",{},"{size_466: None, size_467: None, view_371: None}",,add_373,size_466,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_123
call_method,size,{mul_123: None},"(mul_123,)",{},{getitem_375: None},,mul_123,getitem_375,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_466
call_function,<built-in function getitem>,{size_466: None},"(size_466, slice(None, -1, None))",{},{add_374: None},,size_466,add_374,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_375
call_function,<built-in function add>,{getitem_375: None},"(getitem_375, (1280,))",{},{view_372: None},,getitem_375,transformer_h_30_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_374
get_attr,transformer.h.30.mlp.c_proj.bias,{},(),{},{addmm_123: None},,add_374,size_467,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_30_mlp_c_proj_bias
call_method,size,{mul_123: None},"(mul_123, -1)",{},{view_371: None},,transformer_h_30_mlp_c_proj_bias,view_371,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_467
call_method,view,"{mul_123: None, size_467: None}","(mul_123, -1, size_467)",{},{addmm_123: None},,size_467,transformer_h_30_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_371
get_attr,transformer.h.30.mlp.c_proj.weight,{},(),{},{addmm_123: None},,view_371,addmm_123,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_30_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_30_mlp_c_proj_bias: None, view_371: None, transformer_h_30_mlp_c_proj_weight: None}","(transformer_h_30_mlp_c_proj_bias, view_371, transformer_h_30_mlp_c_proj_weight)",{},{view_372: None},,transformer_h_30_mlp_c_proj_weight,view_372,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_123
call_method,view,"{addmm_123: None, add_374: None}","(addmm_123, add_374)",{},{transformer_h_30_mlp_dropout: None},,addmm_123,transformer_h_30_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_372
call_module,transformer.h.30.mlp.dropout,{view_372: None},"(view_372,)",{},{add_375: None},,view_372,add_375,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.30.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.30.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_30_mlp_dropout
call_function,<built-in function add>,"{add_370: None, transformer_h_30_mlp_dropout: None}","(add_370, transformer_h_30_mlp_dropout)",{},"{transformer_h_31_ln_1: None, add_382: None}",,transformer_h_30_mlp_dropout,transformer_h_31_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.30', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_375
call_module,transformer.h.31.ln_1,{add_375: None},"(add_375,)",{},"{size_468: None, size_469: None, view_373: None}",,add_375,size_468,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_31_ln_1
call_method,size,{transformer_h_31_ln_1: None},"(transformer_h_31_ln_1,)",{},{getitem_376: None},,transformer_h_31_ln_1,getitem_376,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.31.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_468
call_function,<built-in function getitem>,{size_468: None},"(size_468, slice(None, -1, None))",{},{add_376: None},,size_468,add_376,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.31.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_376
call_function,<built-in function add>,{getitem_376: None},"(getitem_376, (3840,))",{},{view_374: None},,getitem_376,transformer_h_31_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.31.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_376
get_attr,transformer.h.31.attn.c_attn.bias,{},(),{},{addmm_124: None},,add_376,size_469,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.31.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_31_attn_c_attn_bias
call_method,size,{transformer_h_31_ln_1: None},"(transformer_h_31_ln_1, -1)",{},{view_373: None},,transformer_h_31_attn_c_attn_bias,view_373,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.31.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_469
call_method,view,"{transformer_h_31_ln_1: None, size_469: None}","(transformer_h_31_ln_1, -1, size_469)",{},{addmm_124: None},,size_469,transformer_h_31_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.31.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_373
get_attr,transformer.h.31.attn.c_attn.weight,{},(),{},{addmm_124: None},,view_373,addmm_124,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.31.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_31_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_31_attn_c_attn_bias: None, view_373: None, transformer_h_31_attn_c_attn_weight: None}","(transformer_h_31_attn_c_attn_bias, view_373, transformer_h_31_attn_c_attn_weight)",{},{view_374: None},,transformer_h_31_attn_c_attn_weight,view_374,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.31.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_124
call_method,view,"{addmm_124: None, add_376: None}","(addmm_124, add_376)",{},{split_31: None},,addmm_124,split_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.31.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_374
call_method,split,{view_374: None},"(view_374, 1280)",{'dim': 2},"{getitem_377: None, getitem_378: None, getitem_379: None}",,view_374,getitem_377,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_31
call_function,<built-in function getitem>,{split_31: None},"(split_31, 0)",{},"{size_470: None, view_375: None}",,split_31,getitem_378,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_377
call_function,<built-in function getitem>,{split_31: None},"(split_31, 1)",{},"{size_471: None, view_376: None}",,getitem_377,getitem_379,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_378
call_function,<built-in function getitem>,{split_31: None},"(split_31, 2)",{},"{size_472: None, view_377: None}",,getitem_378,size_470,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_379
call_method,size,{getitem_377: None},"(getitem_377,)",{},{getitem_380: None},,getitem_379,getitem_380,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_470
call_function,<built-in function getitem>,{size_470: None},"(size_470, slice(None, -1, None))",{},{add_377: None},,size_470,add_377,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_380
call_function,<built-in function add>,{getitem_380: None},"(getitem_380, (20, 64))",{},{view_375: None},,getitem_380,view_375,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_377
call_method,view,"{getitem_377: None, add_377: None}","(getitem_377, add_377)",{},{permute_124: None},,add_377,permute_124,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_375
call_method,permute,{view_375: None},"(view_375, 0, 2, 1, 3)",{},"{matmul_62: None, size_474: None}",,view_375,size_471,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_124
call_method,size,{getitem_378: None},"(getitem_378,)",{},{getitem_381: None},,permute_124,getitem_381,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_471
call_function,<built-in function getitem>,{size_471: None},"(size_471, slice(None, -1, None))",{},{add_378: None},,size_471,add_378,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_381
call_function,<built-in function add>,{getitem_381: None},"(getitem_381, (20, 64))",{},{view_376: None},,getitem_381,view_376,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_378
call_method,view,"{getitem_378: None, add_378: None}","(getitem_378, add_378)",{},{permute_125: None},,add_378,permute_125,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_376
call_method,permute,{view_376: None},"(view_376, 0, 2, 1, 3)",{},"{transpose_31: None, size_475: None, output: None}",,view_376,size_472,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_125
call_method,size,{getitem_379: None},"(getitem_379,)",{},{getitem_382: None},,permute_125,getitem_382,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_472
call_function,<built-in function getitem>,{size_472: None},"(size_472, slice(None, -1, None))",{},{add_379: None},,size_472,add_379,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_382
call_function,<built-in function add>,{getitem_382: None},"(getitem_382, (20, 64))",{},{view_377: None},,getitem_382,view_377,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_379
call_method,view,"{getitem_379: None, add_379: None}","(getitem_379, add_379)",{},{permute_126: None},,add_379,permute_126,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_377
call_method,permute,{view_377: None},"(view_377, 0, 2, 1, 3)",{},"{size_473: None, getattr_257: None, matmul_63: None, output: None}",,view_377,transpose_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_126
call_method,transpose,{permute_125: None},"(permute_125, -1, -2)",{},{matmul_62: None},,permute_126,matmul_62,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_31
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_124: None, transpose_31: None}","(permute_124, transpose_31)",{},"{getattr_250: None, getattr_251: None, truediv_31: None}",,transpose_31,size_473,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_62
call_method,size,{permute_126: None},"(permute_126, -1)",{},{pow_63: None},,matmul_62,pow_63,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_473
call_function,<built-in function pow>,{size_473: None},"(size_473, 0.5)",{},{full_62: None},,size_473,getattr_250,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_63
call_function,<built-in function getattr>,{matmul_62: None},"(matmul_62, 'dtype')",{},{full_62: None},,pow_63,getattr_251,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_250
call_function,<built-in function getattr>,{matmul_62: None},"(matmul_62, 'device')",{},{full_62: None},,getattr_250,full_62,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_251
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_63: None, getattr_250: None, getattr_251: None}","([], pow_63)","{'dtype': getattr_250, 'device': getattr_251}",{truediv_31: None},,getattr_251,truediv_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_62
call_function,<built-in function truediv>,"{matmul_62: None, full_62: None}","(matmul_62, full_62)",{},"{getattr_252: None, getattr_254: None, getattr_255: None, getattr_256: None, to_31: None}",,full_62,size_474,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_31
call_method,size,{permute_124: None},"(permute_124, -2)",{},{sub_31: None},,truediv_31,size_475,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_474
call_method,size,{permute_125: None},"(permute_125, -2)",{},"{sub_31: None, getitem_383: None}",,size_474,transformer_h_31_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_475
get_attr,transformer.h.31.attn.bias,{},(),{},{getitem_383: None},,size_475,sub_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_31_attn_bias
call_function,<built-in function sub>,"{size_475: None, size_474: None}","(size_475, size_474)",{},{getitem_383: None},,transformer_h_31_attn_bias,getitem_383,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_31
call_function,<built-in function getitem>,"{transformer_h_31_attn_bias: None, sub_31: None, size_475: None}","(transformer_h_31_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_31, size_475, None), slice(None, size_475, None)))",{},{where_31: None},,sub_31,getattr_252,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_383
call_function,<built-in function getattr>,{truediv_31: None},"(truediv_31, 'dtype')",{},{finfo_31: None},,getitem_383,finfo_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_252
call_function,<class 'torch.finfo'>,{getattr_252: None},"(getattr_252,)",{},{getattr_253: None},,getattr_252,getattr_253,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_31
call_function,<built-in function getattr>,{finfo_31: None},"(finfo_31, 'min')",{},{full_63: None},,finfo_31,getattr_254,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_253
call_function,<built-in function getattr>,{truediv_31: None},"(truediv_31, 'dtype')",{},{full_63: None},,getattr_253,getattr_255,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_254
call_function,<built-in function getattr>,{truediv_31: None},"(truediv_31, 'device')",{},{full_63: None},,getattr_254,full_63,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_255
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_253: None, getattr_254: None, getattr_255: None}","([], getattr_253)","{'dtype': getattr_254, 'device': getattr_255}",{where_31: None},,getattr_255,getattr_256,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_63
call_function,<built-in function getattr>,{truediv_31: None},"(truediv_31, 'dtype')",{},{to_31: None},,full_63,to_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_256
call_method,to,"{truediv_31: None, getattr_256: None}","(truediv_31, getattr_256)",{},{where_31: None},,getattr_256,where_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_31
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_383: None, to_31: None, full_63: None}","(getitem_383, to_31, full_63)",{},{softmax_31: None},,to_31,softmax_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_31
call_function,<function softmax at 0x7f6fd5135ca0>,{where_31: None},"(where_31,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_32: None},,where_31,getattr_257,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_31
call_function,<built-in function getattr>,{permute_126: None},"(permute_126, 'dtype')",{},{type_32: None},,softmax_31,type_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_257
call_method,type,"{softmax_31: None, getattr_257: None}","(softmax_31, getattr_257)",{},{transformer_h_31_attn_attn_dropout: None},,getattr_257,transformer_h_31_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_32
call_module,transformer.h.31.attn.attn_dropout,{type_32: None},"(type_32,)",{},{matmul_63: None},,type_32,matmul_63,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.31.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_31_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_31_attn_attn_dropout: None, permute_126: None}","(transformer_h_31_attn_attn_dropout, permute_126)",{},{permute_127: None},,transformer_h_31_attn_attn_dropout,permute_127,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_63
call_method,permute,{matmul_63: None},"(matmul_63, 0, 2, 1, 3)",{},{contiguous_31: None},,matmul_63,contiguous_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_127
call_method,contiguous,{permute_127: None},"(permute_127,)",{},"{size_476: None, view_378: None}",,permute_127,size_476,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_31
call_method,size,{contiguous_31: None},"(contiguous_31,)",{},{getitem_384: None},,contiguous_31,getitem_384,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_476
call_function,<built-in function getitem>,{size_476: None},"(size_476, slice(None, -2, None))",{},{add_380: None},,size_476,add_380,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_384
call_function,<built-in function add>,{getitem_384: None},"(getitem_384, (1280,))",{},{view_378: None},,getitem_384,view_378,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_380
call_method,view,"{contiguous_31: None, add_380: None}","(contiguous_31, add_380)",{},"{size_477: None, size_478: None, view_379: None}",,add_380,size_477,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_378
call_method,size,{view_378: None},"(view_378,)",{},{getitem_385: None},,view_378,getitem_385,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.31.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_477
call_function,<built-in function getitem>,{size_477: None},"(size_477, slice(None, -1, None))",{},{add_381: None},,size_477,add_381,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.31.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_385
call_function,<built-in function add>,{getitem_385: None},"(getitem_385, (1280,))",{},{view_380: None},,getitem_385,transformer_h_31_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.31.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_381
get_attr,transformer.h.31.attn.c_proj.bias,{},(),{},{addmm_125: None},,add_381,size_478,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.31.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_31_attn_c_proj_bias
call_method,size,{view_378: None},"(view_378, -1)",{},{view_379: None},,transformer_h_31_attn_c_proj_bias,view_379,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.31.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_478
call_method,view,"{view_378: None, size_478: None}","(view_378, -1, size_478)",{},{addmm_125: None},,size_478,transformer_h_31_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.31.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_379
get_attr,transformer.h.31.attn.c_proj.weight,{},(),{},{addmm_125: None},,view_379,addmm_125,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.31.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_31_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_31_attn_c_proj_bias: None, view_379: None, transformer_h_31_attn_c_proj_weight: None}","(transformer_h_31_attn_c_proj_bias, view_379, transformer_h_31_attn_c_proj_weight)",{},{view_380: None},,transformer_h_31_attn_c_proj_weight,view_380,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.31.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_125
call_method,view,"{addmm_125: None, add_381: None}","(addmm_125, add_381)",{},{transformer_h_31_attn_resid_dropout: None},,addmm_125,transformer_h_31_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.31.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_380
call_module,transformer.h.31.attn.resid_dropout,{view_380: None},"(view_380,)",{},{add_382: None},,view_380,add_382,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.31.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_31_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_31_attn_resid_dropout: None, add_375: None}","(transformer_h_31_attn_resid_dropout, add_375)",{},"{transformer_h_31_ln_2: None, add_387: None}",,transformer_h_31_attn_resid_dropout,transformer_h_31_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_382
call_module,transformer.h.31.ln_2,{add_382: None},"(add_382,)",{},"{size_479: None, size_480: None, view_381: None}",,add_382,size_479,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_31_ln_2
call_method,size,{transformer_h_31_ln_2: None},"(transformer_h_31_ln_2,)",{},{getitem_386: None},,transformer_h_31_ln_2,getitem_386,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_479
call_function,<built-in function getitem>,{size_479: None},"(size_479, slice(None, -1, None))",{},{add_383: None},,size_479,add_383,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_386
call_function,<built-in function add>,{getitem_386: None},"(getitem_386, (5120,))",{},{view_382: None},,getitem_386,transformer_h_31_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_383
get_attr,transformer.h.31.mlp.c_fc.bias,{},(),{},{addmm_126: None},,add_383,size_480,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_31_mlp_c_fc_bias
call_method,size,{transformer_h_31_ln_2: None},"(transformer_h_31_ln_2, -1)",{},{view_381: None},,transformer_h_31_mlp_c_fc_bias,view_381,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_480
call_method,view,"{transformer_h_31_ln_2: None, size_480: None}","(transformer_h_31_ln_2, -1, size_480)",{},{addmm_126: None},,size_480,transformer_h_31_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_381
get_attr,transformer.h.31.mlp.c_fc.weight,{},(),{},{addmm_126: None},,view_381,addmm_126,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_31_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_31_mlp_c_fc_bias: None, view_381: None, transformer_h_31_mlp_c_fc_weight: None}","(transformer_h_31_mlp_c_fc_bias, view_381, transformer_h_31_mlp_c_fc_weight)",{},{view_382: None},,transformer_h_31_mlp_c_fc_weight,view_382,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_126
call_method,view,"{addmm_126: None, add_383: None}","(addmm_126, add_383)",{},"{mul_124: None, pow_64: None, add_384: None}",,addmm_126,mul_124,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_382
call_function,<built-in function mul>,{view_382: None},"(0.5, view_382)",{},{mul_127: None},,view_382,pow_64,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_124
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_382: None},"(view_382, 3.0)",{},{mul_125: None},,mul_124,mul_125,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_64
call_function,<built-in function mul>,{pow_64: None},"(0.044715, pow_64)",{},{add_384: None},,pow_64,add_384,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_125
call_function,<built-in function add>,"{view_382: None, mul_125: None}","(view_382, mul_125)",{},{mul_126: None},,mul_125,mul_126,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_384
call_function,<built-in function mul>,{add_384: None},"(0.7978845608028654, add_384)",{},{tanh_31: None},,add_384,tanh_31,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_126
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_126: None},"(mul_126,)",{},{add_385: None},,mul_126,add_385,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_31
call_function,<built-in function add>,{tanh_31: None},"(1.0, tanh_31)",{},{mul_127: None},,tanh_31,mul_127,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_385
call_function,<built-in function mul>,"{mul_124: None, add_385: None}","(mul_124, add_385)",{},"{size_481: None, size_482: None, view_383: None}",,add_385,size_481,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_127
call_method,size,{mul_127: None},"(mul_127,)",{},{getitem_387: None},,mul_127,getitem_387,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_481
call_function,<built-in function getitem>,{size_481: None},"(size_481, slice(None, -1, None))",{},{add_386: None},,size_481,add_386,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_387
call_function,<built-in function add>,{getitem_387: None},"(getitem_387, (1280,))",{},{view_384: None},,getitem_387,transformer_h_31_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_386
get_attr,transformer.h.31.mlp.c_proj.bias,{},(),{},{addmm_127: None},,add_386,size_482,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_31_mlp_c_proj_bias
call_method,size,{mul_127: None},"(mul_127, -1)",{},{view_383: None},,transformer_h_31_mlp_c_proj_bias,view_383,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_482
call_method,view,"{mul_127: None, size_482: None}","(mul_127, -1, size_482)",{},{addmm_127: None},,size_482,transformer_h_31_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_383
get_attr,transformer.h.31.mlp.c_proj.weight,{},(),{},{addmm_127: None},,view_383,addmm_127,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_31_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_31_mlp_c_proj_bias: None, view_383: None, transformer_h_31_mlp_c_proj_weight: None}","(transformer_h_31_mlp_c_proj_bias, view_383, transformer_h_31_mlp_c_proj_weight)",{},{view_384: None},,transformer_h_31_mlp_c_proj_weight,view_384,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_127
call_method,view,"{addmm_127: None, add_386: None}","(addmm_127, add_386)",{},{transformer_h_31_mlp_dropout: None},,addmm_127,transformer_h_31_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_384
call_module,transformer.h.31.mlp.dropout,{view_384: None},"(view_384,)",{},{add_387: None},,view_384,add_387,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.31.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.31.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_31_mlp_dropout
call_function,<built-in function add>,"{add_382: None, transformer_h_31_mlp_dropout: None}","(add_382, transformer_h_31_mlp_dropout)",{},"{transformer_h_32_ln_1: None, add_394: None}",,transformer_h_31_mlp_dropout,transformer_h_32_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.31', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_387
call_module,transformer.h.32.ln_1,{add_387: None},"(add_387,)",{},"{size_483: None, size_484: None, view_385: None}",,add_387,size_483,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_32_ln_1
call_method,size,{transformer_h_32_ln_1: None},"(transformer_h_32_ln_1,)",{},{getitem_388: None},,transformer_h_32_ln_1,getitem_388,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.32.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_483
call_function,<built-in function getitem>,{size_483: None},"(size_483, slice(None, -1, None))",{},{add_388: None},,size_483,add_388,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.32.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_388
call_function,<built-in function add>,{getitem_388: None},"(getitem_388, (3840,))",{},{view_386: None},,getitem_388,transformer_h_32_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.32.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_388
get_attr,transformer.h.32.attn.c_attn.bias,{},(),{},{addmm_128: None},,add_388,size_484,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.32.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_32_attn_c_attn_bias
call_method,size,{transformer_h_32_ln_1: None},"(transformer_h_32_ln_1, -1)",{},{view_385: None},,transformer_h_32_attn_c_attn_bias,view_385,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.32.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_484
call_method,view,"{transformer_h_32_ln_1: None, size_484: None}","(transformer_h_32_ln_1, -1, size_484)",{},{addmm_128: None},,size_484,transformer_h_32_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.32.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_385
get_attr,transformer.h.32.attn.c_attn.weight,{},(),{},{addmm_128: None},,view_385,addmm_128,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.32.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_32_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_32_attn_c_attn_bias: None, view_385: None, transformer_h_32_attn_c_attn_weight: None}","(transformer_h_32_attn_c_attn_bias, view_385, transformer_h_32_attn_c_attn_weight)",{},{view_386: None},,transformer_h_32_attn_c_attn_weight,view_386,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.32.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_128
call_method,view,"{addmm_128: None, add_388: None}","(addmm_128, add_388)",{},{split_32: None},,addmm_128,split_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.32.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_386
call_method,split,{view_386: None},"(view_386, 1280)",{'dim': 2},"{getitem_389: None, getitem_390: None, getitem_391: None}",,view_386,getitem_389,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_32
call_function,<built-in function getitem>,{split_32: None},"(split_32, 0)",{},"{size_485: None, view_387: None}",,split_32,getitem_390,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_389
call_function,<built-in function getitem>,{split_32: None},"(split_32, 1)",{},"{size_486: None, view_388: None}",,getitem_389,getitem_391,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_390
call_function,<built-in function getitem>,{split_32: None},"(split_32, 2)",{},"{size_487: None, view_389: None}",,getitem_390,size_485,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_391
call_method,size,{getitem_389: None},"(getitem_389,)",{},{getitem_392: None},,getitem_391,getitem_392,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_485
call_function,<built-in function getitem>,{size_485: None},"(size_485, slice(None, -1, None))",{},{add_389: None},,size_485,add_389,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_392
call_function,<built-in function add>,{getitem_392: None},"(getitem_392, (20, 64))",{},{view_387: None},,getitem_392,view_387,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_389
call_method,view,"{getitem_389: None, add_389: None}","(getitem_389, add_389)",{},{permute_128: None},,add_389,permute_128,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_387
call_method,permute,{view_387: None},"(view_387, 0, 2, 1, 3)",{},"{matmul_64: None, size_489: None}",,view_387,size_486,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_128
call_method,size,{getitem_390: None},"(getitem_390,)",{},{getitem_393: None},,permute_128,getitem_393,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_486
call_function,<built-in function getitem>,{size_486: None},"(size_486, slice(None, -1, None))",{},{add_390: None},,size_486,add_390,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_393
call_function,<built-in function add>,{getitem_393: None},"(getitem_393, (20, 64))",{},{view_388: None},,getitem_393,view_388,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_390
call_method,view,"{getitem_390: None, add_390: None}","(getitem_390, add_390)",{},{permute_129: None},,add_390,permute_129,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_388
call_method,permute,{view_388: None},"(view_388, 0, 2, 1, 3)",{},"{transpose_32: None, size_490: None, output: None}",,view_388,size_487,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_129
call_method,size,{getitem_391: None},"(getitem_391,)",{},{getitem_394: None},,permute_129,getitem_394,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_487
call_function,<built-in function getitem>,{size_487: None},"(size_487, slice(None, -1, None))",{},{add_391: None},,size_487,add_391,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_394
call_function,<built-in function add>,{getitem_394: None},"(getitem_394, (20, 64))",{},{view_389: None},,getitem_394,view_389,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_391
call_method,view,"{getitem_391: None, add_391: None}","(getitem_391, add_391)",{},{permute_130: None},,add_391,permute_130,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_389
call_method,permute,{view_389: None},"(view_389, 0, 2, 1, 3)",{},"{size_488: None, getattr_265: None, matmul_65: None, output: None}",,view_389,transpose_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_130
call_method,transpose,{permute_129: None},"(permute_129, -1, -2)",{},{matmul_64: None},,permute_130,matmul_64,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_32
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_128: None, transpose_32: None}","(permute_128, transpose_32)",{},"{getattr_258: None, getattr_259: None, truediv_32: None}",,transpose_32,size_488,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_64
call_method,size,{permute_130: None},"(permute_130, -1)",{},{pow_65: None},,matmul_64,pow_65,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_488
call_function,<built-in function pow>,{size_488: None},"(size_488, 0.5)",{},{full_64: None},,size_488,getattr_258,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_65
call_function,<built-in function getattr>,{matmul_64: None},"(matmul_64, 'dtype')",{},{full_64: None},,pow_65,getattr_259,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_258
call_function,<built-in function getattr>,{matmul_64: None},"(matmul_64, 'device')",{},{full_64: None},,getattr_258,full_64,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_259
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_65: None, getattr_258: None, getattr_259: None}","([], pow_65)","{'dtype': getattr_258, 'device': getattr_259}",{truediv_32: None},,getattr_259,truediv_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_64
call_function,<built-in function truediv>,"{matmul_64: None, full_64: None}","(matmul_64, full_64)",{},"{getattr_260: None, getattr_262: None, getattr_263: None, getattr_264: None, to_32: None}",,full_64,size_489,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_32
call_method,size,{permute_128: None},"(permute_128, -2)",{},{sub_32: None},,truediv_32,size_490,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_489
call_method,size,{permute_129: None},"(permute_129, -2)",{},"{sub_32: None, getitem_395: None}",,size_489,transformer_h_32_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_490
get_attr,transformer.h.32.attn.bias,{},(),{},{getitem_395: None},,size_490,sub_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_32_attn_bias
call_function,<built-in function sub>,"{size_490: None, size_489: None}","(size_490, size_489)",{},{getitem_395: None},,transformer_h_32_attn_bias,getitem_395,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_32
call_function,<built-in function getitem>,"{transformer_h_32_attn_bias: None, sub_32: None, size_490: None}","(transformer_h_32_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_32, size_490, None), slice(None, size_490, None)))",{},{where_32: None},,sub_32,getattr_260,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_395
call_function,<built-in function getattr>,{truediv_32: None},"(truediv_32, 'dtype')",{},{finfo_32: None},,getitem_395,finfo_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_260
call_function,<class 'torch.finfo'>,{getattr_260: None},"(getattr_260,)",{},{getattr_261: None},,getattr_260,getattr_261,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_32
call_function,<built-in function getattr>,{finfo_32: None},"(finfo_32, 'min')",{},{full_65: None},,finfo_32,getattr_262,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_261
call_function,<built-in function getattr>,{truediv_32: None},"(truediv_32, 'dtype')",{},{full_65: None},,getattr_261,getattr_263,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_262
call_function,<built-in function getattr>,{truediv_32: None},"(truediv_32, 'device')",{},{full_65: None},,getattr_262,full_65,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_263
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_261: None, getattr_262: None, getattr_263: None}","([], getattr_261)","{'dtype': getattr_262, 'device': getattr_263}",{where_32: None},,getattr_263,getattr_264,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_65
call_function,<built-in function getattr>,{truediv_32: None},"(truediv_32, 'dtype')",{},{to_32: None},,full_65,to_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_264
call_method,to,"{truediv_32: None, getattr_264: None}","(truediv_32, getattr_264)",{},{where_32: None},,getattr_264,where_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_32
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_395: None, to_32: None, full_65: None}","(getitem_395, to_32, full_65)",{},{softmax_32: None},,to_32,softmax_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_32
call_function,<function softmax at 0x7f6fd5135ca0>,{where_32: None},"(where_32,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_33: None},,where_32,getattr_265,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_32
call_function,<built-in function getattr>,{permute_130: None},"(permute_130, 'dtype')",{},{type_33: None},,softmax_32,type_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_265
call_method,type,"{softmax_32: None, getattr_265: None}","(softmax_32, getattr_265)",{},{transformer_h_32_attn_attn_dropout: None},,getattr_265,transformer_h_32_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_33
call_module,transformer.h.32.attn.attn_dropout,{type_33: None},"(type_33,)",{},{matmul_65: None},,type_33,matmul_65,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.32.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_32_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_32_attn_attn_dropout: None, permute_130: None}","(transformer_h_32_attn_attn_dropout, permute_130)",{},{permute_131: None},,transformer_h_32_attn_attn_dropout,permute_131,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_65
call_method,permute,{matmul_65: None},"(matmul_65, 0, 2, 1, 3)",{},{contiguous_32: None},,matmul_65,contiguous_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_131
call_method,contiguous,{permute_131: None},"(permute_131,)",{},"{size_491: None, view_390: None}",,permute_131,size_491,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_32
call_method,size,{contiguous_32: None},"(contiguous_32,)",{},{getitem_396: None},,contiguous_32,getitem_396,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_491
call_function,<built-in function getitem>,{size_491: None},"(size_491, slice(None, -2, None))",{},{add_392: None},,size_491,add_392,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_396
call_function,<built-in function add>,{getitem_396: None},"(getitem_396, (1280,))",{},{view_390: None},,getitem_396,view_390,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_392
call_method,view,"{contiguous_32: None, add_392: None}","(contiguous_32, add_392)",{},"{size_492: None, size_493: None, view_391: None}",,add_392,size_492,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_390
call_method,size,{view_390: None},"(view_390,)",{},{getitem_397: None},,view_390,getitem_397,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.32.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_492
call_function,<built-in function getitem>,{size_492: None},"(size_492, slice(None, -1, None))",{},{add_393: None},,size_492,add_393,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.32.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_397
call_function,<built-in function add>,{getitem_397: None},"(getitem_397, (1280,))",{},{view_392: None},,getitem_397,transformer_h_32_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.32.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_393
get_attr,transformer.h.32.attn.c_proj.bias,{},(),{},{addmm_129: None},,add_393,size_493,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.32.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_32_attn_c_proj_bias
call_method,size,{view_390: None},"(view_390, -1)",{},{view_391: None},,transformer_h_32_attn_c_proj_bias,view_391,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.32.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_493
call_method,view,"{view_390: None, size_493: None}","(view_390, -1, size_493)",{},{addmm_129: None},,size_493,transformer_h_32_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.32.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_391
get_attr,transformer.h.32.attn.c_proj.weight,{},(),{},{addmm_129: None},,view_391,addmm_129,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.32.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_32_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_32_attn_c_proj_bias: None, view_391: None, transformer_h_32_attn_c_proj_weight: None}","(transformer_h_32_attn_c_proj_bias, view_391, transformer_h_32_attn_c_proj_weight)",{},{view_392: None},,transformer_h_32_attn_c_proj_weight,view_392,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.32.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_129
call_method,view,"{addmm_129: None, add_393: None}","(addmm_129, add_393)",{},{transformer_h_32_attn_resid_dropout: None},,addmm_129,transformer_h_32_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.32.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_392
call_module,transformer.h.32.attn.resid_dropout,{view_392: None},"(view_392,)",{},{add_394: None},,view_392,add_394,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.32.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_32_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_32_attn_resid_dropout: None, add_387: None}","(transformer_h_32_attn_resid_dropout, add_387)",{},"{transformer_h_32_ln_2: None, add_399: None}",,transformer_h_32_attn_resid_dropout,transformer_h_32_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_394
call_module,transformer.h.32.ln_2,{add_394: None},"(add_394,)",{},"{size_494: None, size_495: None, view_393: None}",,add_394,size_494,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_32_ln_2
call_method,size,{transformer_h_32_ln_2: None},"(transformer_h_32_ln_2,)",{},{getitem_398: None},,transformer_h_32_ln_2,getitem_398,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_494
call_function,<built-in function getitem>,{size_494: None},"(size_494, slice(None, -1, None))",{},{add_395: None},,size_494,add_395,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_398
call_function,<built-in function add>,{getitem_398: None},"(getitem_398, (5120,))",{},{view_394: None},,getitem_398,transformer_h_32_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_395
get_attr,transformer.h.32.mlp.c_fc.bias,{},(),{},{addmm_130: None},,add_395,size_495,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_32_mlp_c_fc_bias
call_method,size,{transformer_h_32_ln_2: None},"(transformer_h_32_ln_2, -1)",{},{view_393: None},,transformer_h_32_mlp_c_fc_bias,view_393,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_495
call_method,view,"{transformer_h_32_ln_2: None, size_495: None}","(transformer_h_32_ln_2, -1, size_495)",{},{addmm_130: None},,size_495,transformer_h_32_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_393
get_attr,transformer.h.32.mlp.c_fc.weight,{},(),{},{addmm_130: None},,view_393,addmm_130,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_32_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_32_mlp_c_fc_bias: None, view_393: None, transformer_h_32_mlp_c_fc_weight: None}","(transformer_h_32_mlp_c_fc_bias, view_393, transformer_h_32_mlp_c_fc_weight)",{},{view_394: None},,transformer_h_32_mlp_c_fc_weight,view_394,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_130
call_method,view,"{addmm_130: None, add_395: None}","(addmm_130, add_395)",{},"{mul_128: None, pow_66: None, add_396: None}",,addmm_130,mul_128,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_394
call_function,<built-in function mul>,{view_394: None},"(0.5, view_394)",{},{mul_131: None},,view_394,pow_66,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_128
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_394: None},"(view_394, 3.0)",{},{mul_129: None},,mul_128,mul_129,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_66
call_function,<built-in function mul>,{pow_66: None},"(0.044715, pow_66)",{},{add_396: None},,pow_66,add_396,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_129
call_function,<built-in function add>,"{view_394: None, mul_129: None}","(view_394, mul_129)",{},{mul_130: None},,mul_129,mul_130,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_396
call_function,<built-in function mul>,{add_396: None},"(0.7978845608028654, add_396)",{},{tanh_32: None},,add_396,tanh_32,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_130
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_130: None},"(mul_130,)",{},{add_397: None},,mul_130,add_397,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_32
call_function,<built-in function add>,{tanh_32: None},"(1.0, tanh_32)",{},{mul_131: None},,tanh_32,mul_131,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_397
call_function,<built-in function mul>,"{mul_128: None, add_397: None}","(mul_128, add_397)",{},"{size_496: None, size_497: None, view_395: None}",,add_397,size_496,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_131
call_method,size,{mul_131: None},"(mul_131,)",{},{getitem_399: None},,mul_131,getitem_399,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_496
call_function,<built-in function getitem>,{size_496: None},"(size_496, slice(None, -1, None))",{},{add_398: None},,size_496,add_398,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_399
call_function,<built-in function add>,{getitem_399: None},"(getitem_399, (1280,))",{},{view_396: None},,getitem_399,transformer_h_32_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_398
get_attr,transformer.h.32.mlp.c_proj.bias,{},(),{},{addmm_131: None},,add_398,size_497,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_32_mlp_c_proj_bias
call_method,size,{mul_131: None},"(mul_131, -1)",{},{view_395: None},,transformer_h_32_mlp_c_proj_bias,view_395,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_497
call_method,view,"{mul_131: None, size_497: None}","(mul_131, -1, size_497)",{},{addmm_131: None},,size_497,transformer_h_32_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_395
get_attr,transformer.h.32.mlp.c_proj.weight,{},(),{},{addmm_131: None},,view_395,addmm_131,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_32_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_32_mlp_c_proj_bias: None, view_395: None, transformer_h_32_mlp_c_proj_weight: None}","(transformer_h_32_mlp_c_proj_bias, view_395, transformer_h_32_mlp_c_proj_weight)",{},{view_396: None},,transformer_h_32_mlp_c_proj_weight,view_396,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_131
call_method,view,"{addmm_131: None, add_398: None}","(addmm_131, add_398)",{},{transformer_h_32_mlp_dropout: None},,addmm_131,transformer_h_32_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_396
call_module,transformer.h.32.mlp.dropout,{view_396: None},"(view_396,)",{},{add_399: None},,view_396,add_399,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.32.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.32.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_32_mlp_dropout
call_function,<built-in function add>,"{add_394: None, transformer_h_32_mlp_dropout: None}","(add_394, transformer_h_32_mlp_dropout)",{},"{transformer_h_33_ln_1: None, add_406: None}",,transformer_h_32_mlp_dropout,transformer_h_33_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.32', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_399
call_module,transformer.h.33.ln_1,{add_399: None},"(add_399,)",{},"{size_498: None, size_499: None, view_397: None}",,add_399,size_498,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_33_ln_1
call_method,size,{transformer_h_33_ln_1: None},"(transformer_h_33_ln_1,)",{},{getitem_400: None},,transformer_h_33_ln_1,getitem_400,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.33.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_498
call_function,<built-in function getitem>,{size_498: None},"(size_498, slice(None, -1, None))",{},{add_400: None},,size_498,add_400,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.33.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_400
call_function,<built-in function add>,{getitem_400: None},"(getitem_400, (3840,))",{},{view_398: None},,getitem_400,transformer_h_33_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.33.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_400
get_attr,transformer.h.33.attn.c_attn.bias,{},(),{},{addmm_132: None},,add_400,size_499,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.33.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_33_attn_c_attn_bias
call_method,size,{transformer_h_33_ln_1: None},"(transformer_h_33_ln_1, -1)",{},{view_397: None},,transformer_h_33_attn_c_attn_bias,view_397,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.33.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_499
call_method,view,"{transformer_h_33_ln_1: None, size_499: None}","(transformer_h_33_ln_1, -1, size_499)",{},{addmm_132: None},,size_499,transformer_h_33_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.33.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_397
get_attr,transformer.h.33.attn.c_attn.weight,{},(),{},{addmm_132: None},,view_397,addmm_132,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.33.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_33_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_33_attn_c_attn_bias: None, view_397: None, transformer_h_33_attn_c_attn_weight: None}","(transformer_h_33_attn_c_attn_bias, view_397, transformer_h_33_attn_c_attn_weight)",{},{view_398: None},,transformer_h_33_attn_c_attn_weight,view_398,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.33.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_132
call_method,view,"{addmm_132: None, add_400: None}","(addmm_132, add_400)",{},{split_33: None},,addmm_132,split_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.33.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_398
call_method,split,{view_398: None},"(view_398, 1280)",{'dim': 2},"{getitem_401: None, getitem_402: None, getitem_403: None}",,view_398,getitem_401,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_33
call_function,<built-in function getitem>,{split_33: None},"(split_33, 0)",{},"{size_500: None, view_399: None}",,split_33,getitem_402,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_401
call_function,<built-in function getitem>,{split_33: None},"(split_33, 1)",{},"{size_501: None, view_400: None}",,getitem_401,getitem_403,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_402
call_function,<built-in function getitem>,{split_33: None},"(split_33, 2)",{},"{size_502: None, view_401: None}",,getitem_402,size_500,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_403
call_method,size,{getitem_401: None},"(getitem_401,)",{},{getitem_404: None},,getitem_403,getitem_404,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_500
call_function,<built-in function getitem>,{size_500: None},"(size_500, slice(None, -1, None))",{},{add_401: None},,size_500,add_401,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_404
call_function,<built-in function add>,{getitem_404: None},"(getitem_404, (20, 64))",{},{view_399: None},,getitem_404,view_399,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_401
call_method,view,"{getitem_401: None, add_401: None}","(getitem_401, add_401)",{},{permute_132: None},,add_401,permute_132,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_399
call_method,permute,{view_399: None},"(view_399, 0, 2, 1, 3)",{},"{matmul_66: None, size_504: None}",,view_399,size_501,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_132
call_method,size,{getitem_402: None},"(getitem_402,)",{},{getitem_405: None},,permute_132,getitem_405,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_501
call_function,<built-in function getitem>,{size_501: None},"(size_501, slice(None, -1, None))",{},{add_402: None},,size_501,add_402,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_405
call_function,<built-in function add>,{getitem_405: None},"(getitem_405, (20, 64))",{},{view_400: None},,getitem_405,view_400,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_402
call_method,view,"{getitem_402: None, add_402: None}","(getitem_402, add_402)",{},{permute_133: None},,add_402,permute_133,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_400
call_method,permute,{view_400: None},"(view_400, 0, 2, 1, 3)",{},"{transpose_33: None, size_505: None, output: None}",,view_400,size_502,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_133
call_method,size,{getitem_403: None},"(getitem_403,)",{},{getitem_406: None},,permute_133,getitem_406,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_502
call_function,<built-in function getitem>,{size_502: None},"(size_502, slice(None, -1, None))",{},{add_403: None},,size_502,add_403,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_406
call_function,<built-in function add>,{getitem_406: None},"(getitem_406, (20, 64))",{},{view_401: None},,getitem_406,view_401,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_403
call_method,view,"{getitem_403: None, add_403: None}","(getitem_403, add_403)",{},{permute_134: None},,add_403,permute_134,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_401
call_method,permute,{view_401: None},"(view_401, 0, 2, 1, 3)",{},"{size_503: None, getattr_273: None, matmul_67: None, output: None}",,view_401,transpose_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_134
call_method,transpose,{permute_133: None},"(permute_133, -1, -2)",{},{matmul_66: None},,permute_134,matmul_66,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_33
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_132: None, transpose_33: None}","(permute_132, transpose_33)",{},"{getattr_266: None, getattr_267: None, truediv_33: None}",,transpose_33,size_503,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_66
call_method,size,{permute_134: None},"(permute_134, -1)",{},{pow_67: None},,matmul_66,pow_67,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_503
call_function,<built-in function pow>,{size_503: None},"(size_503, 0.5)",{},{full_66: None},,size_503,getattr_266,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_67
call_function,<built-in function getattr>,{matmul_66: None},"(matmul_66, 'dtype')",{},{full_66: None},,pow_67,getattr_267,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_266
call_function,<built-in function getattr>,{matmul_66: None},"(matmul_66, 'device')",{},{full_66: None},,getattr_266,full_66,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_267
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_67: None, getattr_266: None, getattr_267: None}","([], pow_67)","{'dtype': getattr_266, 'device': getattr_267}",{truediv_33: None},,getattr_267,truediv_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_66
call_function,<built-in function truediv>,"{matmul_66: None, full_66: None}","(matmul_66, full_66)",{},"{getattr_268: None, getattr_270: None, getattr_271: None, getattr_272: None, to_33: None}",,full_66,size_504,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_33
call_method,size,{permute_132: None},"(permute_132, -2)",{},{sub_33: None},,truediv_33,size_505,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_504
call_method,size,{permute_133: None},"(permute_133, -2)",{},"{sub_33: None, getitem_407: None}",,size_504,transformer_h_33_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_505
get_attr,transformer.h.33.attn.bias,{},(),{},{getitem_407: None},,size_505,sub_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_33_attn_bias
call_function,<built-in function sub>,"{size_505: None, size_504: None}","(size_505, size_504)",{},{getitem_407: None},,transformer_h_33_attn_bias,getitem_407,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_33
call_function,<built-in function getitem>,"{transformer_h_33_attn_bias: None, sub_33: None, size_505: None}","(transformer_h_33_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_33, size_505, None), slice(None, size_505, None)))",{},{where_33: None},,sub_33,getattr_268,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_407
call_function,<built-in function getattr>,{truediv_33: None},"(truediv_33, 'dtype')",{},{finfo_33: None},,getitem_407,finfo_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_268
call_function,<class 'torch.finfo'>,{getattr_268: None},"(getattr_268,)",{},{getattr_269: None},,getattr_268,getattr_269,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_33
call_function,<built-in function getattr>,{finfo_33: None},"(finfo_33, 'min')",{},{full_67: None},,finfo_33,getattr_270,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_269
call_function,<built-in function getattr>,{truediv_33: None},"(truediv_33, 'dtype')",{},{full_67: None},,getattr_269,getattr_271,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_270
call_function,<built-in function getattr>,{truediv_33: None},"(truediv_33, 'device')",{},{full_67: None},,getattr_270,full_67,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_271
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_269: None, getattr_270: None, getattr_271: None}","([], getattr_269)","{'dtype': getattr_270, 'device': getattr_271}",{where_33: None},,getattr_271,getattr_272,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_67
call_function,<built-in function getattr>,{truediv_33: None},"(truediv_33, 'dtype')",{},{to_33: None},,full_67,to_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_272
call_method,to,"{truediv_33: None, getattr_272: None}","(truediv_33, getattr_272)",{},{where_33: None},,getattr_272,where_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_33
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_407: None, to_33: None, full_67: None}","(getitem_407, to_33, full_67)",{},{softmax_33: None},,to_33,softmax_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_33
call_function,<function softmax at 0x7f6fd5135ca0>,{where_33: None},"(where_33,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_34: None},,where_33,getattr_273,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_33
call_function,<built-in function getattr>,{permute_134: None},"(permute_134, 'dtype')",{},{type_34: None},,softmax_33,type_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_273
call_method,type,"{softmax_33: None, getattr_273: None}","(softmax_33, getattr_273)",{},{transformer_h_33_attn_attn_dropout: None},,getattr_273,transformer_h_33_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_34
call_module,transformer.h.33.attn.attn_dropout,{type_34: None},"(type_34,)",{},{matmul_67: None},,type_34,matmul_67,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.33.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_33_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_33_attn_attn_dropout: None, permute_134: None}","(transformer_h_33_attn_attn_dropout, permute_134)",{},{permute_135: None},,transformer_h_33_attn_attn_dropout,permute_135,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_67
call_method,permute,{matmul_67: None},"(matmul_67, 0, 2, 1, 3)",{},{contiguous_33: None},,matmul_67,contiguous_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_135
call_method,contiguous,{permute_135: None},"(permute_135,)",{},"{size_506: None, view_402: None}",,permute_135,size_506,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_33
call_method,size,{contiguous_33: None},"(contiguous_33,)",{},{getitem_408: None},,contiguous_33,getitem_408,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_506
call_function,<built-in function getitem>,{size_506: None},"(size_506, slice(None, -2, None))",{},{add_404: None},,size_506,add_404,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_408
call_function,<built-in function add>,{getitem_408: None},"(getitem_408, (1280,))",{},{view_402: None},,getitem_408,view_402,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_404
call_method,view,"{contiguous_33: None, add_404: None}","(contiguous_33, add_404)",{},"{size_507: None, size_508: None, view_403: None}",,add_404,size_507,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_402
call_method,size,{view_402: None},"(view_402,)",{},{getitem_409: None},,view_402,getitem_409,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.33.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_507
call_function,<built-in function getitem>,{size_507: None},"(size_507, slice(None, -1, None))",{},{add_405: None},,size_507,add_405,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.33.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_409
call_function,<built-in function add>,{getitem_409: None},"(getitem_409, (1280,))",{},{view_404: None},,getitem_409,transformer_h_33_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.33.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_405
get_attr,transformer.h.33.attn.c_proj.bias,{},(),{},{addmm_133: None},,add_405,size_508,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.33.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_33_attn_c_proj_bias
call_method,size,{view_402: None},"(view_402, -1)",{},{view_403: None},,transformer_h_33_attn_c_proj_bias,view_403,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.33.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_508
call_method,view,"{view_402: None, size_508: None}","(view_402, -1, size_508)",{},{addmm_133: None},,size_508,transformer_h_33_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.33.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_403
get_attr,transformer.h.33.attn.c_proj.weight,{},(),{},{addmm_133: None},,view_403,addmm_133,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.33.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_33_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_33_attn_c_proj_bias: None, view_403: None, transformer_h_33_attn_c_proj_weight: None}","(transformer_h_33_attn_c_proj_bias, view_403, transformer_h_33_attn_c_proj_weight)",{},{view_404: None},,transformer_h_33_attn_c_proj_weight,view_404,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.33.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_133
call_method,view,"{addmm_133: None, add_405: None}","(addmm_133, add_405)",{},{transformer_h_33_attn_resid_dropout: None},,addmm_133,transformer_h_33_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.33.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_404
call_module,transformer.h.33.attn.resid_dropout,{view_404: None},"(view_404,)",{},{add_406: None},,view_404,add_406,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.33.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_33_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_33_attn_resid_dropout: None, add_399: None}","(transformer_h_33_attn_resid_dropout, add_399)",{},"{transformer_h_33_ln_2: None, add_411: None}",,transformer_h_33_attn_resid_dropout,transformer_h_33_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_406
call_module,transformer.h.33.ln_2,{add_406: None},"(add_406,)",{},"{size_509: None, size_510: None, view_405: None}",,add_406,size_509,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_33_ln_2
call_method,size,{transformer_h_33_ln_2: None},"(transformer_h_33_ln_2,)",{},{getitem_410: None},,transformer_h_33_ln_2,getitem_410,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_509
call_function,<built-in function getitem>,{size_509: None},"(size_509, slice(None, -1, None))",{},{add_407: None},,size_509,add_407,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_410
call_function,<built-in function add>,{getitem_410: None},"(getitem_410, (5120,))",{},{view_406: None},,getitem_410,transformer_h_33_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_407
get_attr,transformer.h.33.mlp.c_fc.bias,{},(),{},{addmm_134: None},,add_407,size_510,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_33_mlp_c_fc_bias
call_method,size,{transformer_h_33_ln_2: None},"(transformer_h_33_ln_2, -1)",{},{view_405: None},,transformer_h_33_mlp_c_fc_bias,view_405,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_510
call_method,view,"{transformer_h_33_ln_2: None, size_510: None}","(transformer_h_33_ln_2, -1, size_510)",{},{addmm_134: None},,size_510,transformer_h_33_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_405
get_attr,transformer.h.33.mlp.c_fc.weight,{},(),{},{addmm_134: None},,view_405,addmm_134,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_33_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_33_mlp_c_fc_bias: None, view_405: None, transformer_h_33_mlp_c_fc_weight: None}","(transformer_h_33_mlp_c_fc_bias, view_405, transformer_h_33_mlp_c_fc_weight)",{},{view_406: None},,transformer_h_33_mlp_c_fc_weight,view_406,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_134
call_method,view,"{addmm_134: None, add_407: None}","(addmm_134, add_407)",{},"{mul_132: None, pow_68: None, add_408: None}",,addmm_134,mul_132,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_406
call_function,<built-in function mul>,{view_406: None},"(0.5, view_406)",{},{mul_135: None},,view_406,pow_68,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_132
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_406: None},"(view_406, 3.0)",{},{mul_133: None},,mul_132,mul_133,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_68
call_function,<built-in function mul>,{pow_68: None},"(0.044715, pow_68)",{},{add_408: None},,pow_68,add_408,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_133
call_function,<built-in function add>,"{view_406: None, mul_133: None}","(view_406, mul_133)",{},{mul_134: None},,mul_133,mul_134,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_408
call_function,<built-in function mul>,{add_408: None},"(0.7978845608028654, add_408)",{},{tanh_33: None},,add_408,tanh_33,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_134
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_134: None},"(mul_134,)",{},{add_409: None},,mul_134,add_409,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_33
call_function,<built-in function add>,{tanh_33: None},"(1.0, tanh_33)",{},{mul_135: None},,tanh_33,mul_135,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_409
call_function,<built-in function mul>,"{mul_132: None, add_409: None}","(mul_132, add_409)",{},"{size_511: None, size_512: None, view_407: None}",,add_409,size_511,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_135
call_method,size,{mul_135: None},"(mul_135,)",{},{getitem_411: None},,mul_135,getitem_411,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_511
call_function,<built-in function getitem>,{size_511: None},"(size_511, slice(None, -1, None))",{},{add_410: None},,size_511,add_410,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_411
call_function,<built-in function add>,{getitem_411: None},"(getitem_411, (1280,))",{},{view_408: None},,getitem_411,transformer_h_33_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_410
get_attr,transformer.h.33.mlp.c_proj.bias,{},(),{},{addmm_135: None},,add_410,size_512,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_33_mlp_c_proj_bias
call_method,size,{mul_135: None},"(mul_135, -1)",{},{view_407: None},,transformer_h_33_mlp_c_proj_bias,view_407,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_512
call_method,view,"{mul_135: None, size_512: None}","(mul_135, -1, size_512)",{},{addmm_135: None},,size_512,transformer_h_33_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_407
get_attr,transformer.h.33.mlp.c_proj.weight,{},(),{},{addmm_135: None},,view_407,addmm_135,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_33_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_33_mlp_c_proj_bias: None, view_407: None, transformer_h_33_mlp_c_proj_weight: None}","(transformer_h_33_mlp_c_proj_bias, view_407, transformer_h_33_mlp_c_proj_weight)",{},{view_408: None},,transformer_h_33_mlp_c_proj_weight,view_408,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_135
call_method,view,"{addmm_135: None, add_410: None}","(addmm_135, add_410)",{},{transformer_h_33_mlp_dropout: None},,addmm_135,transformer_h_33_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_408
call_module,transformer.h.33.mlp.dropout,{view_408: None},"(view_408,)",{},{add_411: None},,view_408,add_411,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.33.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.33.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_33_mlp_dropout
call_function,<built-in function add>,"{add_406: None, transformer_h_33_mlp_dropout: None}","(add_406, transformer_h_33_mlp_dropout)",{},"{transformer_h_34_ln_1: None, add_418: None}",,transformer_h_33_mlp_dropout,transformer_h_34_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.33', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_411
call_module,transformer.h.34.ln_1,{add_411: None},"(add_411,)",{},"{size_513: None, size_514: None, view_409: None}",,add_411,size_513,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_34_ln_1
call_method,size,{transformer_h_34_ln_1: None},"(transformer_h_34_ln_1,)",{},{getitem_412: None},,transformer_h_34_ln_1,getitem_412,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.34.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_513
call_function,<built-in function getitem>,{size_513: None},"(size_513, slice(None, -1, None))",{},{add_412: None},,size_513,add_412,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.34.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_412
call_function,<built-in function add>,{getitem_412: None},"(getitem_412, (3840,))",{},{view_410: None},,getitem_412,transformer_h_34_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.34.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_412
get_attr,transformer.h.34.attn.c_attn.bias,{},(),{},{addmm_136: None},,add_412,size_514,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.34.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_34_attn_c_attn_bias
call_method,size,{transformer_h_34_ln_1: None},"(transformer_h_34_ln_1, -1)",{},{view_409: None},,transformer_h_34_attn_c_attn_bias,view_409,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.34.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_514
call_method,view,"{transformer_h_34_ln_1: None, size_514: None}","(transformer_h_34_ln_1, -1, size_514)",{},{addmm_136: None},,size_514,transformer_h_34_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.34.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_409
get_attr,transformer.h.34.attn.c_attn.weight,{},(),{},{addmm_136: None},,view_409,addmm_136,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.34.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_34_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_34_attn_c_attn_bias: None, view_409: None, transformer_h_34_attn_c_attn_weight: None}","(transformer_h_34_attn_c_attn_bias, view_409, transformer_h_34_attn_c_attn_weight)",{},{view_410: None},,transformer_h_34_attn_c_attn_weight,view_410,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.34.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_136
call_method,view,"{addmm_136: None, add_412: None}","(addmm_136, add_412)",{},{split_34: None},,addmm_136,split_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.34.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_410
call_method,split,{view_410: None},"(view_410, 1280)",{'dim': 2},"{getitem_413: None, getitem_414: None, getitem_415: None}",,view_410,getitem_413,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_34
call_function,<built-in function getitem>,{split_34: None},"(split_34, 0)",{},"{size_515: None, view_411: None}",,split_34,getitem_414,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_413
call_function,<built-in function getitem>,{split_34: None},"(split_34, 1)",{},"{size_516: None, view_412: None}",,getitem_413,getitem_415,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_414
call_function,<built-in function getitem>,{split_34: None},"(split_34, 2)",{},"{size_517: None, view_413: None}",,getitem_414,size_515,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_415
call_method,size,{getitem_413: None},"(getitem_413,)",{},{getitem_416: None},,getitem_415,getitem_416,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_515
call_function,<built-in function getitem>,{size_515: None},"(size_515, slice(None, -1, None))",{},{add_413: None},,size_515,add_413,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_416
call_function,<built-in function add>,{getitem_416: None},"(getitem_416, (20, 64))",{},{view_411: None},,getitem_416,view_411,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_413
call_method,view,"{getitem_413: None, add_413: None}","(getitem_413, add_413)",{},{permute_136: None},,add_413,permute_136,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_411
call_method,permute,{view_411: None},"(view_411, 0, 2, 1, 3)",{},"{matmul_68: None, size_519: None}",,view_411,size_516,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_136
call_method,size,{getitem_414: None},"(getitem_414,)",{},{getitem_417: None},,permute_136,getitem_417,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_516
call_function,<built-in function getitem>,{size_516: None},"(size_516, slice(None, -1, None))",{},{add_414: None},,size_516,add_414,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_417
call_function,<built-in function add>,{getitem_417: None},"(getitem_417, (20, 64))",{},{view_412: None},,getitem_417,view_412,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_414
call_method,view,"{getitem_414: None, add_414: None}","(getitem_414, add_414)",{},{permute_137: None},,add_414,permute_137,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_412
call_method,permute,{view_412: None},"(view_412, 0, 2, 1, 3)",{},"{transpose_34: None, size_520: None, output: None}",,view_412,size_517,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_137
call_method,size,{getitem_415: None},"(getitem_415,)",{},{getitem_418: None},,permute_137,getitem_418,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_517
call_function,<built-in function getitem>,{size_517: None},"(size_517, slice(None, -1, None))",{},{add_415: None},,size_517,add_415,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_418
call_function,<built-in function add>,{getitem_418: None},"(getitem_418, (20, 64))",{},{view_413: None},,getitem_418,view_413,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_415
call_method,view,"{getitem_415: None, add_415: None}","(getitem_415, add_415)",{},{permute_138: None},,add_415,permute_138,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_413
call_method,permute,{view_413: None},"(view_413, 0, 2, 1, 3)",{},"{size_518: None, getattr_281: None, matmul_69: None, output: None}",,view_413,transpose_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_138
call_method,transpose,{permute_137: None},"(permute_137, -1, -2)",{},{matmul_68: None},,permute_138,matmul_68,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_34
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_136: None, transpose_34: None}","(permute_136, transpose_34)",{},"{getattr_274: None, getattr_275: None, truediv_34: None}",,transpose_34,size_518,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_68
call_method,size,{permute_138: None},"(permute_138, -1)",{},{pow_69: None},,matmul_68,pow_69,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_518
call_function,<built-in function pow>,{size_518: None},"(size_518, 0.5)",{},{full_68: None},,size_518,getattr_274,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_69
call_function,<built-in function getattr>,{matmul_68: None},"(matmul_68, 'dtype')",{},{full_68: None},,pow_69,getattr_275,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_274
call_function,<built-in function getattr>,{matmul_68: None},"(matmul_68, 'device')",{},{full_68: None},,getattr_274,full_68,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_275
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_69: None, getattr_274: None, getattr_275: None}","([], pow_69)","{'dtype': getattr_274, 'device': getattr_275}",{truediv_34: None},,getattr_275,truediv_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_68
call_function,<built-in function truediv>,"{matmul_68: None, full_68: None}","(matmul_68, full_68)",{},"{getattr_276: None, getattr_278: None, getattr_279: None, getattr_280: None, to_34: None}",,full_68,size_519,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_34
call_method,size,{permute_136: None},"(permute_136, -2)",{},{sub_34: None},,truediv_34,size_520,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_519
call_method,size,{permute_137: None},"(permute_137, -2)",{},"{sub_34: None, getitem_419: None}",,size_519,transformer_h_34_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_520
get_attr,transformer.h.34.attn.bias,{},(),{},{getitem_419: None},,size_520,sub_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_34_attn_bias
call_function,<built-in function sub>,"{size_520: None, size_519: None}","(size_520, size_519)",{},{getitem_419: None},,transformer_h_34_attn_bias,getitem_419,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_34
call_function,<built-in function getitem>,"{transformer_h_34_attn_bias: None, sub_34: None, size_520: None}","(transformer_h_34_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_34, size_520, None), slice(None, size_520, None)))",{},{where_34: None},,sub_34,getattr_276,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_419
call_function,<built-in function getattr>,{truediv_34: None},"(truediv_34, 'dtype')",{},{finfo_34: None},,getitem_419,finfo_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_276
call_function,<class 'torch.finfo'>,{getattr_276: None},"(getattr_276,)",{},{getattr_277: None},,getattr_276,getattr_277,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_34
call_function,<built-in function getattr>,{finfo_34: None},"(finfo_34, 'min')",{},{full_69: None},,finfo_34,getattr_278,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_277
call_function,<built-in function getattr>,{truediv_34: None},"(truediv_34, 'dtype')",{},{full_69: None},,getattr_277,getattr_279,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_278
call_function,<built-in function getattr>,{truediv_34: None},"(truediv_34, 'device')",{},{full_69: None},,getattr_278,full_69,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_279
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_277: None, getattr_278: None, getattr_279: None}","([], getattr_277)","{'dtype': getattr_278, 'device': getattr_279}",{where_34: None},,getattr_279,getattr_280,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_69
call_function,<built-in function getattr>,{truediv_34: None},"(truediv_34, 'dtype')",{},{to_34: None},,full_69,to_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_280
call_method,to,"{truediv_34: None, getattr_280: None}","(truediv_34, getattr_280)",{},{where_34: None},,getattr_280,where_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_34
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_419: None, to_34: None, full_69: None}","(getitem_419, to_34, full_69)",{},{softmax_34: None},,to_34,softmax_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_34
call_function,<function softmax at 0x7f6fd5135ca0>,{where_34: None},"(where_34,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_35: None},,where_34,getattr_281,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_34
call_function,<built-in function getattr>,{permute_138: None},"(permute_138, 'dtype')",{},{type_35: None},,softmax_34,type_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_281
call_method,type,"{softmax_34: None, getattr_281: None}","(softmax_34, getattr_281)",{},{transformer_h_34_attn_attn_dropout: None},,getattr_281,transformer_h_34_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_35
call_module,transformer.h.34.attn.attn_dropout,{type_35: None},"(type_35,)",{},{matmul_69: None},,type_35,matmul_69,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.34.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_34_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_34_attn_attn_dropout: None, permute_138: None}","(transformer_h_34_attn_attn_dropout, permute_138)",{},{permute_139: None},,transformer_h_34_attn_attn_dropout,permute_139,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_69
call_method,permute,{matmul_69: None},"(matmul_69, 0, 2, 1, 3)",{},{contiguous_34: None},,matmul_69,contiguous_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_139
call_method,contiguous,{permute_139: None},"(permute_139,)",{},"{size_521: None, view_414: None}",,permute_139,size_521,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_34
call_method,size,{contiguous_34: None},"(contiguous_34,)",{},{getitem_420: None},,contiguous_34,getitem_420,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_521
call_function,<built-in function getitem>,{size_521: None},"(size_521, slice(None, -2, None))",{},{add_416: None},,size_521,add_416,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_420
call_function,<built-in function add>,{getitem_420: None},"(getitem_420, (1280,))",{},{view_414: None},,getitem_420,view_414,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_416
call_method,view,"{contiguous_34: None, add_416: None}","(contiguous_34, add_416)",{},"{size_522: None, size_523: None, view_415: None}",,add_416,size_522,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_414
call_method,size,{view_414: None},"(view_414,)",{},{getitem_421: None},,view_414,getitem_421,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.34.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_522
call_function,<built-in function getitem>,{size_522: None},"(size_522, slice(None, -1, None))",{},{add_417: None},,size_522,add_417,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.34.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_421
call_function,<built-in function add>,{getitem_421: None},"(getitem_421, (1280,))",{},{view_416: None},,getitem_421,transformer_h_34_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.34.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_417
get_attr,transformer.h.34.attn.c_proj.bias,{},(),{},{addmm_137: None},,add_417,size_523,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.34.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_34_attn_c_proj_bias
call_method,size,{view_414: None},"(view_414, -1)",{},{view_415: None},,transformer_h_34_attn_c_proj_bias,view_415,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.34.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_523
call_method,view,"{view_414: None, size_523: None}","(view_414, -1, size_523)",{},{addmm_137: None},,size_523,transformer_h_34_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.34.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_415
get_attr,transformer.h.34.attn.c_proj.weight,{},(),{},{addmm_137: None},,view_415,addmm_137,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.34.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_34_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_34_attn_c_proj_bias: None, view_415: None, transformer_h_34_attn_c_proj_weight: None}","(transformer_h_34_attn_c_proj_bias, view_415, transformer_h_34_attn_c_proj_weight)",{},{view_416: None},,transformer_h_34_attn_c_proj_weight,view_416,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.34.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_137
call_method,view,"{addmm_137: None, add_417: None}","(addmm_137, add_417)",{},{transformer_h_34_attn_resid_dropout: None},,addmm_137,transformer_h_34_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.34.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_416
call_module,transformer.h.34.attn.resid_dropout,{view_416: None},"(view_416,)",{},{add_418: None},,view_416,add_418,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.34.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_34_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_34_attn_resid_dropout: None, add_411: None}","(transformer_h_34_attn_resid_dropout, add_411)",{},"{transformer_h_34_ln_2: None, add_423: None}",,transformer_h_34_attn_resid_dropout,transformer_h_34_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_418
call_module,transformer.h.34.ln_2,{add_418: None},"(add_418,)",{},"{size_524: None, size_525: None, view_417: None}",,add_418,size_524,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_34_ln_2
call_method,size,{transformer_h_34_ln_2: None},"(transformer_h_34_ln_2,)",{},{getitem_422: None},,transformer_h_34_ln_2,getitem_422,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_524
call_function,<built-in function getitem>,{size_524: None},"(size_524, slice(None, -1, None))",{},{add_419: None},,size_524,add_419,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_422
call_function,<built-in function add>,{getitem_422: None},"(getitem_422, (5120,))",{},{view_418: None},,getitem_422,transformer_h_34_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_419
get_attr,transformer.h.34.mlp.c_fc.bias,{},(),{},{addmm_138: None},,add_419,size_525,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_34_mlp_c_fc_bias
call_method,size,{transformer_h_34_ln_2: None},"(transformer_h_34_ln_2, -1)",{},{view_417: None},,transformer_h_34_mlp_c_fc_bias,view_417,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_525
call_method,view,"{transformer_h_34_ln_2: None, size_525: None}","(transformer_h_34_ln_2, -1, size_525)",{},{addmm_138: None},,size_525,transformer_h_34_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_417
get_attr,transformer.h.34.mlp.c_fc.weight,{},(),{},{addmm_138: None},,view_417,addmm_138,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_34_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_34_mlp_c_fc_bias: None, view_417: None, transformer_h_34_mlp_c_fc_weight: None}","(transformer_h_34_mlp_c_fc_bias, view_417, transformer_h_34_mlp_c_fc_weight)",{},{view_418: None},,transformer_h_34_mlp_c_fc_weight,view_418,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_138
call_method,view,"{addmm_138: None, add_419: None}","(addmm_138, add_419)",{},"{mul_136: None, pow_70: None, add_420: None}",,addmm_138,mul_136,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_418
call_function,<built-in function mul>,{view_418: None},"(0.5, view_418)",{},{mul_139: None},,view_418,pow_70,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_136
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_418: None},"(view_418, 3.0)",{},{mul_137: None},,mul_136,mul_137,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_70
call_function,<built-in function mul>,{pow_70: None},"(0.044715, pow_70)",{},{add_420: None},,pow_70,add_420,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_137
call_function,<built-in function add>,"{view_418: None, mul_137: None}","(view_418, mul_137)",{},{mul_138: None},,mul_137,mul_138,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_420
call_function,<built-in function mul>,{add_420: None},"(0.7978845608028654, add_420)",{},{tanh_34: None},,add_420,tanh_34,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_138
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_138: None},"(mul_138,)",{},{add_421: None},,mul_138,add_421,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_34
call_function,<built-in function add>,{tanh_34: None},"(1.0, tanh_34)",{},{mul_139: None},,tanh_34,mul_139,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_421
call_function,<built-in function mul>,"{mul_136: None, add_421: None}","(mul_136, add_421)",{},"{size_526: None, size_527: None, view_419: None}",,add_421,size_526,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_139
call_method,size,{mul_139: None},"(mul_139,)",{},{getitem_423: None},,mul_139,getitem_423,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_526
call_function,<built-in function getitem>,{size_526: None},"(size_526, slice(None, -1, None))",{},{add_422: None},,size_526,add_422,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_423
call_function,<built-in function add>,{getitem_423: None},"(getitem_423, (1280,))",{},{view_420: None},,getitem_423,transformer_h_34_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_422
get_attr,transformer.h.34.mlp.c_proj.bias,{},(),{},{addmm_139: None},,add_422,size_527,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_34_mlp_c_proj_bias
call_method,size,{mul_139: None},"(mul_139, -1)",{},{view_419: None},,transformer_h_34_mlp_c_proj_bias,view_419,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_527
call_method,view,"{mul_139: None, size_527: None}","(mul_139, -1, size_527)",{},{addmm_139: None},,size_527,transformer_h_34_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_419
get_attr,transformer.h.34.mlp.c_proj.weight,{},(),{},{addmm_139: None},,view_419,addmm_139,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_34_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_34_mlp_c_proj_bias: None, view_419: None, transformer_h_34_mlp_c_proj_weight: None}","(transformer_h_34_mlp_c_proj_bias, view_419, transformer_h_34_mlp_c_proj_weight)",{},{view_420: None},,transformer_h_34_mlp_c_proj_weight,view_420,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_139
call_method,view,"{addmm_139: None, add_422: None}","(addmm_139, add_422)",{},{transformer_h_34_mlp_dropout: None},,addmm_139,transformer_h_34_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_420
call_module,transformer.h.34.mlp.dropout,{view_420: None},"(view_420,)",{},{add_423: None},,view_420,add_423,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.34.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.34.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_34_mlp_dropout
call_function,<built-in function add>,"{add_418: None, transformer_h_34_mlp_dropout: None}","(add_418, transformer_h_34_mlp_dropout)",{},"{transformer_h_35_ln_1: None, add_430: None}",,transformer_h_34_mlp_dropout,transformer_h_35_ln_1,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.34', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_423
call_module,transformer.h.35.ln_1,{add_423: None},"(add_423,)",{},"{size_528: None, size_529: None, view_421: None}",,add_423,size_528,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_35_ln_1
call_method,size,{transformer_h_35_ln_1: None},"(transformer_h_35_ln_1,)",{},{getitem_424: None},,transformer_h_35_ln_1,getitem_424,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.35.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_528
call_function,<built-in function getitem>,{size_528: None},"(size_528, slice(None, -1, None))",{},{add_424: None},,size_528,add_424,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.35.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_424
call_function,<built-in function add>,{getitem_424: None},"(getitem_424, (3840,))",{},{view_422: None},,getitem_424,transformer_h_35_attn_c_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.35.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_424
get_attr,transformer.h.35.attn.c_attn.bias,{},(),{},{addmm_140: None},,add_424,size_529,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.35.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(3840,)",torch.float32,transformer_h_35_attn_c_attn_bias
call_method,size,{transformer_h_35_ln_1: None},"(transformer_h_35_ln_1, -1)",{},{view_421: None},,transformer_h_35_attn_c_attn_bias,view_421,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.35.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_529
call_method,view,"{transformer_h_35_ln_1: None, size_529: None}","(transformer_h_35_ln_1, -1, size_529)",{},{addmm_140: None},,size_529,transformer_h_35_attn_c_attn_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.35.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_421
get_attr,transformer.h.35.attn.c_attn.weight,{},(),{},{addmm_140: None},,view_421,addmm_140,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.35.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 3840)",torch.float32,transformer_h_35_attn_c_attn_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_35_attn_c_attn_bias: None, view_421: None, transformer_h_35_attn_c_attn_weight: None}","(transformer_h_35_attn_c_attn_bias, view_421, transformer_h_35_attn_c_attn_weight)",{},{view_422: None},,transformer_h_35_attn_c_attn_weight,view_422,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.35.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[3840], [8192, 1280], [1280, 3840]]","[True, True, True]",True,"(8192, 3840)",torch.float32,addmm_140
call_method,view,"{addmm_140: None, add_424: None}","(addmm_140, add_424)",{},{split_35: None},,addmm_140,split_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.35.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 3840], [1]]","[True, True]",True,"(8, 1024, 3840)",torch.float32,view_422
call_method,split,{view_422: None},"(view_422, 1280)",{'dim': 2},"{getitem_425: None, getitem_426: None, getitem_427: None}",,view_422,getitem_425,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 3840]]",[True],True,"(1,)",,split_35
call_function,<built-in function getitem>,{split_35: None},"(split_35, 0)",{},"{size_530: None, view_423: None}",,split_35,getitem_426,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_425
call_function,<built-in function getitem>,{split_35: None},"(split_35, 1)",{},"{size_531: None, view_424: None}",,getitem_425,getitem_427,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_426
call_function,<built-in function getitem>,{split_35: None},"(split_35, 2)",{},"{size_532: None, view_425: None}",,getitem_426,size_530,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],False,"(8, 1024, 1280)",torch.float32,getitem_427
call_method,size,{getitem_425: None},"(getitem_425,)",{},{getitem_428: None},,getitem_427,getitem_428,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_530
call_function,<built-in function getitem>,{size_530: None},"(size_530, slice(None, -1, None))",{},{add_425: None},,size_530,add_425,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_428
call_function,<built-in function add>,{getitem_428: None},"(getitem_428, (20, 64))",{},{view_423: None},,getitem_428,view_423,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_425
call_method,view,"{getitem_425: None, add_425: None}","(getitem_425, add_425)",{},{permute_140: None},,add_425,permute_140,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_423
call_method,permute,{view_423: None},"(view_423, 0, 2, 1, 3)",{},"{matmul_70: None, size_534: None}",,view_423,size_531,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_140
call_method,size,{getitem_426: None},"(getitem_426,)",{},{getitem_429: None},,permute_140,getitem_429,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_531
call_function,<built-in function getitem>,{size_531: None},"(size_531, slice(None, -1, None))",{},{add_426: None},,size_531,add_426,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_429
call_function,<built-in function add>,{getitem_429: None},"(getitem_429, (20, 64))",{},{view_424: None},,getitem_429,view_424,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_426
call_method,view,"{getitem_426: None, add_426: None}","(getitem_426, add_426)",{},{permute_141: None},,add_426,permute_141,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_424
call_method,permute,{view_424: None},"(view_424, 0, 2, 1, 3)",{},"{transpose_35: None, size_535: None, output: None}",,view_424,size_532,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_141
call_method,size,{getitem_427: None},"(getitem_427,)",{},{getitem_430: None},,permute_141,getitem_430,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280]]",[False],True,"(1,)",,size_532
call_function,<built-in function getitem>,{size_532: None},"(size_532, slice(None, -1, None))",{},{add_427: None},,size_532,add_427,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_430
call_function,<built-in function add>,{getitem_430: None},"(getitem_430, (20, 64))",{},{view_425: None},,getitem_430,view_425,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_427
call_method,view,"{getitem_427: None, add_427: None}","(getitem_427, add_427)",{},{permute_142: None},,add_427,permute_142,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 1280], [1]]","[False, True]",False,"(8, 1024, 20, 64)",torch.float32,view_425
call_method,permute,{view_425: None},"(view_425, 0, 2, 1, 3)",{},"{size_533: None, getattr_289: None, matmul_71: None, output: None}",,view_425,transpose_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],False,"(8, 20, 1024, 64)",torch.float32,permute_142
call_method,transpose,{permute_141: None},"(permute_141, -1, -2)",{},{matmul_70: None},,permute_142,matmul_70,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],False,"(8, 20, 64, 1024)",torch.float32,transpose_35
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{permute_140: None, transpose_35: None}","(permute_140, transpose_35)",{},"{getattr_282: None, getattr_283: None, truediv_35: None}",,transpose_35,size_533,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64], [8, 20, 64, 1024]]","[False, False]",True,"(8, 20, 1024, 1024)",torch.float32,matmul_70
call_method,size,{permute_142: None},"(permute_142, -1)",{},{pow_71: None},,matmul_70,pow_71,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_533
call_function,<built-in function pow>,{size_533: None},"(size_533, 0.5)",{},{full_70: None},,size_533,getattr_282,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,pow_71
call_function,<built-in function getattr>,{matmul_70: None},"(matmul_70, 'dtype')",{},{full_70: None},,pow_71,getattr_283,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_282
call_function,<built-in function getattr>,{matmul_70: None},"(matmul_70, 'device')",{},{full_70: None},,getattr_282,full_70,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_283
call_function,<built-in method full of type object at 0x7f703d574d60>,"{pow_71: None, getattr_282: None, getattr_283: None}","([], pow_71)","{'dtype': getattr_282, 'device': getattr_283}",{truediv_35: None},,getattr_283,truediv_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_70
call_function,<built-in function truediv>,"{matmul_70: None, full_70: None}","(matmul_70, full_70)",{},"{getattr_284: None, getattr_286: None, getattr_287: None, getattr_288: None, to_35: None}",,full_70,size_534,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,truediv_35
call_method,size,{permute_140: None},"(permute_140, -2)",{},{sub_35: None},,truediv_35,size_535,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_534
call_method,size,{permute_141: None},"(permute_141, -2)",{},"{sub_35: None, getitem_431: None}",,size_534,transformer_h_35_attn_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,size_535
get_attr,transformer.h.35.attn.bias,{},(),{},{getitem_431: None},,size_535,sub_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_35_attn_bias
call_function,<built-in function sub>,"{size_535: None, size_534: None}","(size_535, size_534)",{},{getitem_431: None},,transformer_h_35_attn_bias,getitem_431,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1]]","[True, True]",True,"(1,)",,sub_35
call_function,<built-in function getitem>,"{transformer_h_35_attn_bias: None, sub_35: None, size_535: None}","(transformer_h_35_attn_bias, (slice(None, None, None), slice(None, None, None), slice(sub_35, size_535, None), slice(None, size_535, None)))",{},{where_35: None},,sub_35,getattr_284,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_431
call_function,<built-in function getattr>,{truediv_35: None},"(truediv_35, 'dtype')",{},{finfo_35: None},,getitem_431,finfo_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_284
call_function,<class 'torch.finfo'>,{getattr_284: None},"(getattr_284,)",{},{getattr_285: None},,getattr_284,getattr_285,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,finfo_35
call_function,<built-in function getattr>,{finfo_35: None},"(finfo_35, 'min')",{},{full_71: None},,finfo_35,getattr_286,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getattr_285
call_function,<built-in function getattr>,{truediv_35: None},"(truediv_35, 'dtype')",{},{full_71: None},,getattr_285,getattr_287,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_286
call_function,<built-in function getattr>,{truediv_35: None},"(truediv_35, 'device')",{},{full_71: None},,getattr_286,full_71,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_287
call_function,<built-in method full of type object at 0x7f703d574d60>,"{getattr_285: None, getattr_286: None, getattr_287: None}","([], getattr_285)","{'dtype': getattr_286, 'device': getattr_287}",{where_35: None},,getattr_287,getattr_288,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_71
call_function,<built-in function getattr>,{truediv_35: None},"(truediv_35, 'dtype')",{},{to_35: None},,full_71,to_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_288
call_method,to,"{truediv_35: None, getattr_288: None}","(truediv_35, getattr_288)",{},{where_35: None},,getattr_288,where_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,to_35
call_function,<built-in method where of type object at 0x7f703d574d60>,"{getitem_431: None, to_35: None, full_71: None}","(getitem_431, to_35, full_71)",{},{softmax_35: None},,to_35,softmax_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[1, 1, 1024, 1024], [8, 20, 1024, 1024], [1]]","[True, True, True]",True,"(8, 20, 1024, 1024)",torch.float32,where_35
call_function,<function softmax at 0x7f6fd5135ca0>,{where_35: None},"(where_35,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{type_36: None},,where_35,getattr_289,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,softmax_35
call_function,<built-in function getattr>,{permute_142: None},"(permute_142, 'dtype')",{},{type_36: None},,softmax_35,type_36,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[False],True,"(1,)",,getattr_289
call_method,type,"{softmax_35: None, getattr_289: None}","(softmax_35, getattr_289)",{},{transformer_h_35_attn_attn_dropout: None},,getattr_289,transformer_h_35_attn_attn_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [1]]","[True, True]",True,"(8, 20, 1024, 1024)",torch.float32,type_36
call_module,transformer.h.35.attn.attn_dropout,{type_36: None},"(type_36,)",{},{matmul_71: None},,type_36,matmul_71,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.35.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 20, 1024, 1024]]",[True],True,"(8, 20, 1024, 1024)",torch.float32,transformer_h_35_attn_attn_dropout
call_function,<built-in method matmul of type object at 0x7f703d574d60>,"{transformer_h_35_attn_attn_dropout: None, permute_142: None}","(transformer_h_35_attn_attn_dropout, permute_142)",{},{permute_143: None},,transformer_h_35_attn_attn_dropout,permute_143,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 1024], [8, 20, 1024, 64]]","[True, False]",True,"(8, 20, 1024, 64)",torch.float32,matmul_71
call_method,permute,{matmul_71: None},"(matmul_71, 0, 2, 1, 3)",{},{contiguous_35: None},,matmul_71,contiguous_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 20, 1024, 64]]",[True],False,"(8, 1024, 20, 64)",torch.float32,permute_143
call_method,contiguous,{permute_143: None},"(permute_143,)",{},"{size_536: None, view_426: None}",,permute_143,size_536,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[False],True,"(8, 1024, 20, 64)",torch.float32,contiguous_35
call_method,size,{contiguous_35: None},"(contiguous_35,)",{},{getitem_432: None},,contiguous_35,getitem_432,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64]]",[True],True,"(1,)",,size_536
call_function,<built-in function getitem>,{size_536: None},"(size_536, slice(None, -2, None))",{},{add_428: None},,size_536,add_428,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,getitem_432
call_function,<built-in function add>,{getitem_432: None},"(getitem_432, (1280,))",{},{view_426: None},,getitem_432,view_426,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}",[[1]],[True],True,"(1,)",,add_428
call_method,view,"{contiguous_35: None, add_428: None}","(contiguous_35, add_428)",{},"{size_537: None, size_538: None, view_427: None}",,add_428,size_537,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)])}","[[8, 1024, 20, 64], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_426
call_method,size,{view_426: None},"(view_426,)",{},{getitem_433: None},,view_426,getitem_433,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.35.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_537
call_function,<built-in function getitem>,{size_537: None},"(size_537, slice(None, -1, None))",{},{add_429: None},,size_537,add_429,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.35.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_433
call_function,<built-in function add>,{getitem_433: None},"(getitem_433, (1280,))",{},{view_428: None},,getitem_433,transformer_h_35_attn_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.35.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_429
get_attr,transformer.h.35.attn.c_proj.bias,{},(),{},{addmm_141: None},,add_429,size_538,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.35.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_35_attn_c_proj_bias
call_method,size,{view_426: None},"(view_426, -1)",{},{view_427: None},,transformer_h_35_attn_c_proj_bias,view_427,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.35.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_538
call_method,view,"{view_426: None, size_538: None}","(view_426, -1, size_538)",{},{addmm_141: None},,size_538,transformer_h_35_attn_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.35.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_427
get_attr,transformer.h.35.attn.c_proj.weight,{},(),{},{addmm_141: None},,view_427,addmm_141,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.35.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 1280)",torch.float32,transformer_h_35_attn_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_35_attn_c_proj_bias: None, view_427: None, transformer_h_35_attn_c_proj_weight: None}","(transformer_h_35_attn_c_proj_bias, view_427, transformer_h_35_attn_c_proj_weight)",{},{view_428: None},,transformer_h_35_attn_c_proj_weight,view_428,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.35.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 1280], [1280, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_141
call_method,view,"{addmm_141: None, add_429: None}","(addmm_141, add_429)",{},{transformer_h_35_attn_resid_dropout: None},,addmm_141,transformer_h_35_attn_resid_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.35.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_428
call_module,transformer.h.35.attn.resid_dropout,{view_428: None},"(view_428,)",{},{add_430: None},,view_428,add_430,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>), ('transformer.h.35.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_35_attn_resid_dropout
call_function,<built-in function add>,"{transformer_h_35_attn_resid_dropout: None, add_423: None}","(transformer_h_35_attn_resid_dropout, add_423)",{},"{transformer_h_35_ln_2: None, add_435: None}",,transformer_h_35_attn_resid_dropout,transformer_h_35_ln_2,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_430
call_module,transformer.h.35.ln_2,{add_430: None},"(add_430,)",{},"{size_539: None, size_540: None, view_429: None}",,add_430,size_539,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_35_ln_2
call_method,size,{transformer_h_35_ln_2: None},"(transformer_h_35_ln_2,)",{},{getitem_434: None},,transformer_h_35_ln_2,getitem_434,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_539
call_function,<built-in function getitem>,{size_539: None},"(size_539, slice(None, -1, None))",{},{add_431: None},,size_539,add_431,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_434
call_function,<built-in function add>,{getitem_434: None},"(getitem_434, (5120,))",{},{view_430: None},,getitem_434,transformer_h_35_mlp_c_fc_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_431
get_attr,transformer.h.35.mlp.c_fc.bias,{},(),{},{addmm_142: None},,add_431,size_540,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120,)",torch.float32,transformer_h_35_mlp_c_fc_bias
call_method,size,{transformer_h_35_ln_2: None},"(transformer_h_35_ln_2, -1)",{},{view_429: None},,transformer_h_35_mlp_c_fc_bias,view_429,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280]]",[True],True,"(1,)",,size_540
call_method,view,"{transformer_h_35_ln_2: None, size_540: None}","(transformer_h_35_ln_2, -1, size_540)",{},{addmm_142: None},,size_540,transformer_h_35_mlp_c_fc_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8192, 1280)",torch.float32,view_429
get_attr,transformer.h.35.mlp.c_fc.weight,{},(),{},{addmm_142: None},,view_429,addmm_142,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280, 5120)",torch.float32,transformer_h_35_mlp_c_fc_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_35_mlp_c_fc_bias: None, view_429: None, transformer_h_35_mlp_c_fc_weight: None}","(transformer_h_35_mlp_c_fc_bias, view_429, transformer_h_35_mlp_c_fc_weight)",{},{view_430: None},,transformer_h_35_mlp_c_fc_weight,view_430,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[5120], [8192, 1280], [1280, 5120]]","[True, True, True]",True,"(8192, 5120)",torch.float32,addmm_142
call_method,view,"{addmm_142: None, add_431: None}","(addmm_142, add_431)",{},"{mul_140: None, pow_72: None, add_432: None}",,addmm_142,mul_140,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 5120], [1]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,view_430
call_function,<built-in function mul>,{view_430: None},"(0.5, view_430)",{},{mul_143: None},,view_430,pow_72,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_140
call_function,<built-in method pow of type object at 0x7f703d574d60>,{view_430: None},"(view_430, 3.0)",{},{mul_141: None},,mul_140,mul_141,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,pow_72
call_function,<built-in function mul>,{pow_72: None},"(0.044715, pow_72)",{},{add_432: None},,pow_72,add_432,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_141
call_function,<built-in function add>,"{view_430: None, mul_141: None}","(view_430, mul_141)",{},{mul_142: None},,mul_141,mul_142,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,add_432
call_function,<built-in function mul>,{add_432: None},"(0.7978845608028654, add_432)",{},{tanh_35: None},,add_432,tanh_35,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,mul_142
call_function,<built-in method tanh of type object at 0x7f703d574d60>,{mul_142: None},"(mul_142,)",{},{add_433: None},,mul_142,add_433,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,tanh_35
call_function,<built-in function add>,{tanh_35: None},"(1.0, tanh_35)",{},{mul_143: None},,tanh_35,mul_143,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120]]",[True],True,"(8, 1024, 5120)",torch.float32,add_433
call_function,<built-in function mul>,"{mul_140: None, add_433: None}","(mul_140, add_433)",{},"{size_541: None, size_542: None, view_431: None}",,add_433,size_541,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.act', <class 'transformers.activations.NewGELUActivation'>)])}","[[8, 1024, 5120], [8, 1024, 5120]]","[True, True]",True,"(8, 1024, 5120)",torch.float32,mul_143
call_method,size,{mul_143: None},"(mul_143,)",{},{getitem_435: None},,mul_143,getitem_435,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_541
call_function,<built-in function getitem>,{size_541: None},"(size_541, slice(None, -1, None))",{},{add_434: None},,size_541,add_434,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,getitem_435
call_function,<built-in function add>,{getitem_435: None},"(getitem_435, (1280,))",{},{view_432: None},,getitem_435,transformer_h_35_mlp_c_proj_bias,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[[1]],[True],True,"(1,)",,add_434
get_attr,transformer.h.35.mlp.c_proj.bias,{},(),{},{addmm_143: None},,add_434,size_542,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(1280,)",torch.float32,transformer_h_35_mlp_c_proj_bias
call_method,size,{mul_143: None},"(mul_143, -1)",{},{view_431: None},,transformer_h_35_mlp_c_proj_bias,view_431,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120]]",[True],True,"(1,)",,size_542
call_method,view,"{mul_143: None, size_542: None}","(mul_143, -1, size_542)",{},{addmm_143: None},,size_542,transformer_h_35_mlp_c_proj_weight,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8, 1024, 5120], [1]]","[True, True]",True,"(8192, 5120)",torch.float32,view_431
get_attr,transformer.h.35.mlp.c_proj.weight,{},(),{},{addmm_143: None},,view_431,addmm_143,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}",[],[],True,"(5120, 1280)",torch.float32,transformer_h_35_mlp_c_proj_weight
call_function,<built-in method addmm of type object at 0x7f703d574d60>,"{transformer_h_35_mlp_c_proj_bias: None, view_431: None, transformer_h_35_mlp_c_proj_weight: None}","(transformer_h_35_mlp_c_proj_bias, view_431, transformer_h_35_mlp_c_proj_weight)",{},{view_432: None},,transformer_h_35_mlp_c_proj_weight,view_432,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[1280], [8192, 5120], [5120, 1280]]","[True, True, True]",True,"(8192, 1280)",torch.float32,addmm_143
call_method,view,"{addmm_143: None, add_434: None}","(addmm_143, add_434)",{},{transformer_h_35_mlp_dropout: None},,addmm_143,transformer_h_35_mlp_dropout,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>)])}","[[8192, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_432
call_module,transformer.h.35.mlp.dropout,{view_432: None},"(view_432,)",{},{add_435: None},,view_432,add_435,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>), ('transformer.h.35.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>), ('transformer.h.35.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_h_35_mlp_dropout
call_function,<built-in function add>,"{add_430: None, transformer_h_35_mlp_dropout: None}","(add_430, transformer_h_35_mlp_dropout)",{},{transformer_ln_f: None},,transformer_h_35_mlp_dropout,transformer_ln_f,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.h.35', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)])}","[[8, 1024, 1280], [8, 1024, 1280]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,add_435
call_module,transformer.ln_f,{add_435: None},"(add_435,)",{},{view_433: None},,add_435,view_433,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>), ('transformer.ln_f', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 1280)",torch.float32,transformer_ln_f
call_method,view,"{transformer_ln_f: None, add_3: None}","(transformer_ln_f, add_3)",{},{lm_head: None},,transformer_ln_f,lm_head,False,,"{'nn_module_stack': OrderedDict([('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)])}","[[8, 1024, 1280], [1]]","[True, True]",True,"(8, 1024, 1280)",torch.float32,view_433
call_module,lm_head,{view_433: None},"(view_433,)",{},{output: None},,view_433,output,False,,"{'nn_module_stack': OrderedDict([('lm_head', <class 'torch.nn.modules.linear.Linear'>)])}","[[8, 1024, 1280]]",[True],True,"(8, 1024, 50257)",torch.float32,lm_head
output,output,"{lm_head: None, permute_1: None, permute_2: None, permute_5: None, permute_6: None, permute_9: None, permute_10: None, permute_13: None, permute_14: None, permute_17: None, permute_18: None, permute_21: None, permute_22: None, permute_25: None, permute_26: None, permute_29: None, permute_30: None, permute_33: None, permute_34: None, permute_37: None, permute_38: None, permute_41: None, permute_42: None, permute_45: None, permute_46: None, permute_49: None, permute_50: None, permute_53: None, permute_54: None, permute_57: None, permute_58: None, permute_61: None, permute_62: None, permute_65: None, permute_66: None, permute_69: None, permute_70: None, permute_73: None, permute_74: None, permute_77: None, permute_78: None, permute_81: None, permute_82: None, permute_85: None, permute_86: None, permute_89: None, permute_90: None, permute_93: None, permute_94: None, permute_97: None, permute_98: None, permute_101: None, permute_102: None, permute_105: None, permute_106: None, permute_109: None, permute_110: None, permute_113: None, permute_114: None, permute_117: None, permute_118: None, permute_121: None, permute_122: None, permute_125: None, permute_126: None, permute_129: None, permute_130: None, permute_133: None, permute_134: None, permute_137: None, permute_138: None, permute_141: None, permute_142: None}","({'logits': lm_head, 'past_key_values': ((permute_1, permute_2), (permute_5, permute_6), (permute_9, permute_10), (permute_13, permute_14), (permute_17, permute_18), (permute_21, permute_22), (permute_25, permute_26), (permute_29, permute_30), (permute_33, permute_34), (permute_37, permute_38), (permute_41, permute_42), (permute_45, permute_46), (permute_49, permute_50), (permute_53, permute_54), (permute_57, permute_58), (permute_61, permute_62), (permute_65, permute_66), (permute_69, permute_70), (permute_73, permute_74), (permute_77, permute_78), (permute_81, permute_82), (permute_85, permute_86), (permute_89, permute_90), (permute_93, permute_94), (permute_97, permute_98), (permute_101, permute_102), (permute_105, permute_106), (permute_109, permute_110), (permute_113, permute_114), (permute_117, permute_118), (permute_121, permute_122), (permute_125, permute_126), (permute_129, permute_130), (permute_133, permute_134), (permute_137, permute_138), (permute_141, permute_142))},)",{},{},,lm_head,,False,,{},"[[8, 1024, 50257], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64], [8, 20, 1024, 64]]","[True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]",True,"(8, 1024, 50257)",torch.float32,output
