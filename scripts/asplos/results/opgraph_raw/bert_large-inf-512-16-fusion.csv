op,target,_input_nodes,_args,_kwargs,users,type,_prev,_next,_erased,_repr_fn,meta,input_shapes,input_contiguous,contiguous,output_shape,dtype,Name
placeholder,input_ids,{},(),{},"{size: None, getattr_1: None, size_1: None, bert_embeddings_word_embeddings: None}",<class 'torch.Tensor'>,,size,False,,{},[],[],True,"(16, 512)",torch.int64,input_ids
call_method,size,{input_ids: None},"(input_ids,)",{},"{getitem: None, getitem_1: None}",,input_ids,getitem,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>)])}","[[16, 512]]",[True],True,"(1,)",,size
call_function,<built-in function getitem>,{size: None},"(size, 0)",{},"{ones: None, expand: None}",,size,getitem_1,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>)])}",[[1]],[True],True,"(1,)",,getitem
call_function,<built-in function getitem>,{size: None},"(size, 1)",{},"{add: None, getitem_2: None, expand: None}",,getitem,add,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>)])}",[[1]],[True],True,"(1,)",,getitem_1
call_function,<built-in function add>,{getitem_1: None},"(getitem_1, 0)",{},{ones: None},,getitem_1,getattr_1,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>)])}",[[1]],[True],True,"(1,)",,add
call_function,<built-in function getattr>,{input_ids: None},"(input_ids, 'device')",{},{ones: None},,add,ones,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>)])}","[[16, 512]]",[True],True,"(1,)",,getattr_1
call_function,<built-in method ones of type object at 0x7f807641ed60>,"{getitem: None, add: None, getattr_1: None}","((getitem, add),)",{'device': getattr_1},"{dim: None, dim_1: None, dim_2: None, getitem_3: None}",,getattr_1,bert_embeddings_token_type_ids,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>)])}","[[1], [1], [1]]","[True, True, True]",True,"(16, 512)",torch.float32,ones
get_attr,bert.embeddings.token_type_ids,{},(),{},{getitem_2: None},,ones,getitem_2,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>)])}",[],[],True,"(1, 512)",torch.int64,bert_embeddings_token_type_ids
call_function,<built-in function getitem>,"{bert_embeddings_token_type_ids: None, getitem_1: None}","(bert_embeddings_token_type_ids, (slice(None, None, None), slice(None, getitem_1, None)))",{},{expand: None},,bert_embeddings_token_type_ids,expand,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>)])}","[[1, 512], [1]]","[True, True]",True,"(1, 512)",torch.int64,getitem_2
call_method,expand,"{getitem_2: None, getitem: None, getitem_1: None}","(getitem_2, getitem, getitem_1)",{},{bert_embeddings_token_type_embeddings: None},,getitem_2,dim,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>)])}","[[1, 512], [1], [1]]","[True, True, True]",False,"(16, 512)",torch.int64,expand
call_method,dim,{ones: None},"(ones,)",{},{eq: None},,expand,eq,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>)])}","[[16, 512]]",[True],True,"(1,)",,dim
call_function,<built-in function eq>,{dim: None},"(dim, 2)",{},{},,dim,dim_1,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>)])}",[[1]],[True],True,"(1,)",,eq
call_method,dim,{ones: None},"(ones,)",{},{eq_1: None},,eq,eq_1,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>)])}","[[16, 512]]",[True],True,"(1,)",,dim_1
call_function,<built-in function eq>,{dim_1: None},"(dim_1, 3)",{},{},,dim_1,dim_2,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>)])}",[[1]],[True],True,"(1,)",,eq_1
call_method,dim,{ones: None},"(ones,)",{},{eq_2: None},,eq_1,eq_2,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>)])}","[[16, 512]]",[True],True,"(1,)",,dim_2
call_function,<built-in function eq>,{dim_2: None},"(dim_2, 2)",{},{},,dim_2,getitem_3,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>)])}",[[1]],[True],True,"(1,)",,eq_2
call_function,<built-in function getitem>,{ones: None},"(ones, (slice(None, None, None), None, None, slice(None, None, None)))",{},{to: None},,eq_2,to,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>)])}","[[16, 512]]",[True],True,"(16, 1, 1, 512)",torch.float32,getitem_3
call_method,to,{getitem_3: None},"(getitem_3,)",{'dtype': torch.float32},{sub: None},,getitem_3,sub,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>)])}","[[16, 1, 1, 512]]",[True],True,"(16, 1, 1, 512)",torch.float32,to
call_function,<built-in function sub>,{to: None},"(1.0, to)",{},{mul: None},,to,mul,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>)])}","[[16, 1, 1, 512]]",[True],True,"(16, 1, 1, 512)",torch.float32,sub
call_function,<built-in function mul>,{sub: None},"(sub, -3.4028234663852886e+38)",{},"{add_7: None, add_14: None, add_21: None, add_28: None, add_35: None, add_42: None, add_49: None, add_56: None, add_63: None, add_70: None, add_77: None, add_84: None, add_91: None, add_98: None, add_105: None, add_112: None, add_119: None, add_126: None, add_133: None, add_140: None, add_147: None, add_154: None, add_161: None, add_168: None}",,sub,size_1,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>)])}","[[16, 1, 1, 512]]",[True],True,"(16, 1, 1, 512)",torch.float32,mul
call_method,size,{input_ids: None},"(input_ids,)",{},{getitem_4: None},,mul,getitem_4,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.embeddings', <class 'transformers.models.bert.modeling_bert.BertEmbeddings'>)])}","[[16, 512]]",[True],True,"(1,)",,size_1
call_function,<built-in function getitem>,{size_1: None},"(size_1, 1)",{},{add_1: None},,size_1,bert_embeddings_position_ids,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.embeddings', <class 'transformers.models.bert.modeling_bert.BertEmbeddings'>)])}",[[1]],[True],True,"(1,)",,getitem_4
get_attr,bert.embeddings.position_ids,{},(),{},{getitem_5: None},,getitem_4,add_1,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.embeddings', <class 'transformers.models.bert.modeling_bert.BertEmbeddings'>)])}",[],[],True,"(1, 512)",torch.int64,bert_embeddings_position_ids
call_function,<built-in function add>,{getitem_4: None},"(getitem_4, 0)",{},{getitem_5: None},,bert_embeddings_position_ids,getitem_5,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.embeddings', <class 'transformers.models.bert.modeling_bert.BertEmbeddings'>)])}",[[1]],[True],True,"(1,)",,add_1
call_function,<built-in function getitem>,"{bert_embeddings_position_ids: None, add_1: None}","(bert_embeddings_position_ids, (slice(None, None, None), slice(0, add_1, None)))",{},{bert_embeddings_position_embeddings: None},,add_1,bert_embeddings_word_embeddings,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.embeddings', <class 'transformers.models.bert.modeling_bert.BertEmbeddings'>)])}","[[1, 512], [1]]","[True, True]",True,"(1, 512)",torch.int64,getitem_5
call_module,bert.embeddings.word_embeddings,{input_ids: None},"(input_ids,)",{},{add_2: None},,getitem_5,bert_embeddings_token_type_embeddings,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.embeddings', <class 'transformers.models.bert.modeling_bert.BertEmbeddings'>), ('bert.embeddings.word_embeddings', <class 'torch.nn.modules.sparse.Embedding'>)])}","[[16, 512]]",[True],True,"(16, 512, 1024)",torch.float32,bert_embeddings_word_embeddings
call_module,bert.embeddings.token_type_embeddings,{expand: None},"(expand,)",{},{add_2: None},,bert_embeddings_word_embeddings,add_2,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.embeddings', <class 'transformers.models.bert.modeling_bert.BertEmbeddings'>), ('bert.embeddings.token_type_embeddings', <class 'torch.nn.modules.sparse.Embedding'>)])}","[[16, 512]]",[False],True,"(16, 512, 1024)",torch.float32,bert_embeddings_token_type_embeddings
call_function,<built-in function add>,"{bert_embeddings_word_embeddings: None, bert_embeddings_token_type_embeddings: None}","(bert_embeddings_word_embeddings, bert_embeddings_token_type_embeddings)",{},{add_3: None},,bert_embeddings_token_type_embeddings,bert_embeddings_position_embeddings,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.embeddings', <class 'transformers.models.bert.modeling_bert.BertEmbeddings'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_2
call_module,bert.embeddings.position_embeddings,{getitem_5: None},"(getitem_5,)",{},{add_3: None},,add_2,add_3,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.embeddings', <class 'transformers.models.bert.modeling_bert.BertEmbeddings'>), ('bert.embeddings.position_embeddings', <class 'torch.nn.modules.sparse.Embedding'>)])}","[[1, 512]]",[True],True,"(1, 512, 1024)",torch.float32,bert_embeddings_position_embeddings
call_function,<built-in function add>,"{add_2: None, bert_embeddings_position_embeddings: None}","(add_2, bert_embeddings_position_embeddings)",{},{bert_embeddings_layer_norm: None},,bert_embeddings_position_embeddings,bert_embeddings_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.embeddings', <class 'transformers.models.bert.modeling_bert.BertEmbeddings'>)])}","[[16, 512, 1024], [1, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_3
call_module,bert.embeddings.LayerNorm,{add_3: None},"(add_3,)",{},{bert_embeddings_dropout: None},,add_3,bert_embeddings_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.embeddings', <class 'transformers.models.bert.modeling_bert.BertEmbeddings'>), ('bert.embeddings.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_embeddings_layer_norm
call_module,bert.embeddings.dropout,{bert_embeddings_layer_norm: None},"(bert_embeddings_layer_norm,)",{},"{bert_encoder_layer_0_attention_self_query: None, bert_encoder_layer_0_attention_self_key: None, bert_encoder_layer_0_attention_self_value: None, add_9: None}",,bert_embeddings_layer_norm,bert_encoder_layer_0_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.embeddings', <class 'transformers.models.bert.modeling_bert.BertEmbeddings'>), ('bert.embeddings.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_embeddings_dropout
call_module,bert.encoder.layer.0.attention.self.query,{bert_embeddings_dropout: None},"(bert_embeddings_dropout,)",{},"{size_4: None, view_2: None}",,bert_embeddings_dropout,bert_encoder_layer_0_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.0.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_0_attention_self_query
call_module,bert.encoder.layer.0.attention.self.key,{bert_embeddings_dropout: None},"(bert_embeddings_dropout,)",{},"{size_2: None, view: None}",,bert_encoder_layer_0_attention_self_query,size_2,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.0.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_0_attention_self_key
call_method,size,{bert_encoder_layer_0_attention_self_key: None},"(bert_encoder_layer_0_attention_self_key,)",{},{getitem_6: None},,bert_encoder_layer_0_attention_self_key,getitem_6,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_2
call_function,<built-in function getitem>,{size_2: None},"(size_2, slice(None, -1, None))",{},{add_4: None},,size_2,add_4,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_6
call_function,<built-in function add>,{getitem_6: None},"(getitem_6, (16, 64))",{},{view: None},,getitem_6,view,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_4
call_method,view,"{bert_encoder_layer_0_attention_self_key: None, add_4: None}","(bert_encoder_layer_0_attention_self_key, add_4)",{},{permute: None},,add_4,permute,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view
call_method,permute,{view: None},"(view, 0, 2, 1, 3)",{},{transpose: None},,view,bert_encoder_layer_0_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute
call_module,bert.encoder.layer.0.attention.self.value,{bert_embeddings_dropout: None},"(bert_embeddings_dropout,)",{},"{size_3: None, view_1: None}",,permute,size_3,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.0.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_0_attention_self_value
call_method,size,{bert_encoder_layer_0_attention_self_value: None},"(bert_encoder_layer_0_attention_self_value,)",{},{getitem_7: None},,bert_encoder_layer_0_attention_self_value,getitem_7,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_3
call_function,<built-in function getitem>,{size_3: None},"(size_3, slice(None, -1, None))",{},{add_5: None},,size_3,add_5,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_7
call_function,<built-in function add>,{getitem_7: None},"(getitem_7, (16, 64))",{},{view_1: None},,getitem_7,view_1,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_5
call_method,view,"{bert_encoder_layer_0_attention_self_value: None, add_5: None}","(bert_encoder_layer_0_attention_self_value, add_5)",{},{permute_1: None},,add_5,permute_1,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_1
call_method,permute,{view_1: None},"(view_1, 0, 2, 1, 3)",{},{matmul_1: None},,view_1,size_4,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_1
call_method,size,{bert_encoder_layer_0_attention_self_query: None},"(bert_encoder_layer_0_attention_self_query,)",{},{getitem_8: None},,permute_1,getitem_8,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_4
call_function,<built-in function getitem>,{size_4: None},"(size_4, slice(None, -1, None))",{},{add_6: None},,size_4,add_6,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_8
call_function,<built-in function add>,{getitem_8: None},"(getitem_8, (16, 64))",{},{view_2: None},,getitem_8,view_2,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_6
call_method,view,"{bert_encoder_layer_0_attention_self_query: None, add_6: None}","(bert_encoder_layer_0_attention_self_query, add_6)",{},{permute_2: None},,add_6,permute_2,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_2
call_method,permute,{view_2: None},"(view_2, 0, 2, 1, 3)",{},{matmul: None},,view_2,transpose,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_2
call_method,transpose,{permute: None},"(permute, -1, -2)",{},{matmul: None},,permute_2,matmul,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_2: None, transpose: None}","(permute_2, transpose)",{},{truediv: None},,transpose,truediv,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul
call_function,<built-in function truediv>,{matmul: None},"(matmul, 8.0)",{},{add_7: None},,matmul,add_7,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv
call_function,<built-in function add>,"{truediv: None, mul: None}","(truediv, mul)",{},{softmax: None},,truediv,softmax,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_7
call_function,<function softmax at 0x7f800dfdfca0>,{add_7: None},"(add_7,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_0_attention_self_dropout: None},,add_7,bert_encoder_layer_0_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax
call_module,bert.encoder.layer.0.attention.self.dropout,{softmax: None},"(softmax,)",{},{matmul_1: None},,softmax,matmul_1,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.0.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_0_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_0_attention_self_dropout: None, permute_1: None}","(bert_encoder_layer_0_attention_self_dropout, permute_1)",{},{permute_3: None},,bert_encoder_layer_0_attention_self_dropout,permute_3,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_1
call_method,permute,{matmul_1: None},"(matmul_1, 0, 2, 1, 3)",{},{contiguous: None},,matmul_1,contiguous,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_3
call_method,contiguous,{permute_3: None},"(permute_3,)",{},"{size_5: None, view_3: None}",,permute_3,size_5,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous
call_method,size,{contiguous: None},"(contiguous,)",{},{getitem_9: None},,contiguous,getitem_9,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_5
call_function,<built-in function getitem>,{size_5: None},"(size_5, slice(None, -2, None))",{},{add_8: None},,size_5,add_8,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_9
call_function,<built-in function add>,{getitem_9: None},"(getitem_9, (1024,))",{},{view_3: None},,getitem_9,view_3,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_8
call_method,view,"{contiguous: None, add_8: None}","(contiguous, add_8)",{},{bert_encoder_layer_0_attention_output_dense: None},,add_8,bert_encoder_layer_0_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_3
call_module,bert.encoder.layer.0.attention.output.dense,{view_3: None},"(view_3,)",{},{bert_encoder_layer_0_attention_output_dropout: None},,view_3,bert_encoder_layer_0_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.0.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_0_attention_output_dense
call_module,bert.encoder.layer.0.attention.output.dropout,{bert_encoder_layer_0_attention_output_dense: None},"(bert_encoder_layer_0_attention_output_dense,)",{},{add_9: None},,bert_encoder_layer_0_attention_output_dense,add_9,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.0.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_0_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_0_attention_output_dropout: None, bert_embeddings_dropout: None}","(bert_encoder_layer_0_attention_output_dropout, bert_embeddings_dropout)",{},{bert_encoder_layer_0_attention_output_layer_norm: None},,bert_encoder_layer_0_attention_output_dropout,bert_encoder_layer_0_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_9
call_module,bert.encoder.layer.0.attention.output.LayerNorm,{add_9: None},"(add_9,)",{},"{bert_encoder_layer_0_intermediate_dense: None, add_10: None}",,add_9,bert_encoder_layer_0_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.0.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.0.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_0_attention_output_layer_norm
call_module,bert.encoder.layer.0.intermediate.dense,{bert_encoder_layer_0_attention_output_layer_norm: None},"(bert_encoder_layer_0_attention_output_layer_norm,)",{},{gelu: None},,bert_encoder_layer_0_attention_output_layer_norm,gelu,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.0.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_0_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_0_intermediate_dense: None},"(bert_encoder_layer_0_intermediate_dense,)",{},{bert_encoder_layer_0_output_dense: None},,bert_encoder_layer_0_intermediate_dense,bert_encoder_layer_0_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.0.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu
call_module,bert.encoder.layer.0.output.dense,{gelu: None},"(gelu,)",{},{bert_encoder_layer_0_output_dropout: None},,gelu,bert_encoder_layer_0_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.0.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_0_output_dense
call_module,bert.encoder.layer.0.output.dropout,{bert_encoder_layer_0_output_dense: None},"(bert_encoder_layer_0_output_dense,)",{},{add_10: None},,bert_encoder_layer_0_output_dense,add_10,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.0.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_0_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_0_output_dropout: None, bert_encoder_layer_0_attention_output_layer_norm: None}","(bert_encoder_layer_0_output_dropout, bert_encoder_layer_0_attention_output_layer_norm)",{},{bert_encoder_layer_0_output_layer_norm: None},,bert_encoder_layer_0_output_dropout,bert_encoder_layer_0_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_10
call_module,bert.encoder.layer.0.output.LayerNorm,{add_10: None},"(add_10,)",{},"{bert_encoder_layer_1_attention_self_query: None, bert_encoder_layer_1_attention_self_key: None, bert_encoder_layer_1_attention_self_value: None, add_16: None}",,add_10,bert_encoder_layer_1_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.0', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.0.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.0.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_0_output_layer_norm
call_module,bert.encoder.layer.1.attention.self.query,{bert_encoder_layer_0_output_layer_norm: None},"(bert_encoder_layer_0_output_layer_norm,)",{},"{size_8: None, view_6: None}",,bert_encoder_layer_0_output_layer_norm,bert_encoder_layer_1_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.1.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_1_attention_self_query
call_module,bert.encoder.layer.1.attention.self.key,{bert_encoder_layer_0_output_layer_norm: None},"(bert_encoder_layer_0_output_layer_norm,)",{},"{size_6: None, view_4: None}",,bert_encoder_layer_1_attention_self_query,size_6,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.1.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_1_attention_self_key
call_method,size,{bert_encoder_layer_1_attention_self_key: None},"(bert_encoder_layer_1_attention_self_key,)",{},{getitem_10: None},,bert_encoder_layer_1_attention_self_key,getitem_10,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_6
call_function,<built-in function getitem>,{size_6: None},"(size_6, slice(None, -1, None))",{},{add_11: None},,size_6,add_11,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_10
call_function,<built-in function add>,{getitem_10: None},"(getitem_10, (16, 64))",{},{view_4: None},,getitem_10,view_4,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_11
call_method,view,"{bert_encoder_layer_1_attention_self_key: None, add_11: None}","(bert_encoder_layer_1_attention_self_key, add_11)",{},{permute_4: None},,add_11,permute_4,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_4
call_method,permute,{view_4: None},"(view_4, 0, 2, 1, 3)",{},{transpose_1: None},,view_4,bert_encoder_layer_1_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_4
call_module,bert.encoder.layer.1.attention.self.value,{bert_encoder_layer_0_output_layer_norm: None},"(bert_encoder_layer_0_output_layer_norm,)",{},"{size_7: None, view_5: None}",,permute_4,size_7,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.1.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_1_attention_self_value
call_method,size,{bert_encoder_layer_1_attention_self_value: None},"(bert_encoder_layer_1_attention_self_value,)",{},{getitem_11: None},,bert_encoder_layer_1_attention_self_value,getitem_11,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_7
call_function,<built-in function getitem>,{size_7: None},"(size_7, slice(None, -1, None))",{},{add_12: None},,size_7,add_12,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_11
call_function,<built-in function add>,{getitem_11: None},"(getitem_11, (16, 64))",{},{view_5: None},,getitem_11,view_5,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_12
call_method,view,"{bert_encoder_layer_1_attention_self_value: None, add_12: None}","(bert_encoder_layer_1_attention_self_value, add_12)",{},{permute_5: None},,add_12,permute_5,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_5
call_method,permute,{view_5: None},"(view_5, 0, 2, 1, 3)",{},{matmul_3: None},,view_5,size_8,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_5
call_method,size,{bert_encoder_layer_1_attention_self_query: None},"(bert_encoder_layer_1_attention_self_query,)",{},{getitem_12: None},,permute_5,getitem_12,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_8
call_function,<built-in function getitem>,{size_8: None},"(size_8, slice(None, -1, None))",{},{add_13: None},,size_8,add_13,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_12
call_function,<built-in function add>,{getitem_12: None},"(getitem_12, (16, 64))",{},{view_6: None},,getitem_12,view_6,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_13
call_method,view,"{bert_encoder_layer_1_attention_self_query: None, add_13: None}","(bert_encoder_layer_1_attention_self_query, add_13)",{},{permute_6: None},,add_13,permute_6,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_6
call_method,permute,{view_6: None},"(view_6, 0, 2, 1, 3)",{},{matmul_2: None},,view_6,transpose_1,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_6
call_method,transpose,{permute_4: None},"(permute_4, -1, -2)",{},{matmul_2: None},,permute_6,matmul_2,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_1
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_6: None, transpose_1: None}","(permute_6, transpose_1)",{},{truediv_1: None},,transpose_1,truediv_1,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_2
call_function,<built-in function truediv>,{matmul_2: None},"(matmul_2, 8.0)",{},{add_14: None},,matmul_2,add_14,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_1
call_function,<built-in function add>,"{truediv_1: None, mul: None}","(truediv_1, mul)",{},{softmax_1: None},,truediv_1,softmax_1,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_14
call_function,<function softmax at 0x7f800dfdfca0>,{add_14: None},"(add_14,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_1_attention_self_dropout: None},,add_14,bert_encoder_layer_1_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_1
call_module,bert.encoder.layer.1.attention.self.dropout,{softmax_1: None},"(softmax_1,)",{},{matmul_3: None},,softmax_1,matmul_3,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.1.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_1_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_1_attention_self_dropout: None, permute_5: None}","(bert_encoder_layer_1_attention_self_dropout, permute_5)",{},{permute_7: None},,bert_encoder_layer_1_attention_self_dropout,permute_7,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_3
call_method,permute,{matmul_3: None},"(matmul_3, 0, 2, 1, 3)",{},{contiguous_1: None},,matmul_3,contiguous_1,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_7
call_method,contiguous,{permute_7: None},"(permute_7,)",{},"{size_9: None, view_7: None}",,permute_7,size_9,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_1
call_method,size,{contiguous_1: None},"(contiguous_1,)",{},{getitem_13: None},,contiguous_1,getitem_13,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_9
call_function,<built-in function getitem>,{size_9: None},"(size_9, slice(None, -2, None))",{},{add_15: None},,size_9,add_15,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_13
call_function,<built-in function add>,{getitem_13: None},"(getitem_13, (1024,))",{},{view_7: None},,getitem_13,view_7,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_15
call_method,view,"{contiguous_1: None, add_15: None}","(contiguous_1, add_15)",{},{bert_encoder_layer_1_attention_output_dense: None},,add_15,bert_encoder_layer_1_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_7
call_module,bert.encoder.layer.1.attention.output.dense,{view_7: None},"(view_7,)",{},{bert_encoder_layer_1_attention_output_dropout: None},,view_7,bert_encoder_layer_1_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.1.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_1_attention_output_dense
call_module,bert.encoder.layer.1.attention.output.dropout,{bert_encoder_layer_1_attention_output_dense: None},"(bert_encoder_layer_1_attention_output_dense,)",{},{add_16: None},,bert_encoder_layer_1_attention_output_dense,add_16,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.1.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_1_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_1_attention_output_dropout: None, bert_encoder_layer_0_output_layer_norm: None}","(bert_encoder_layer_1_attention_output_dropout, bert_encoder_layer_0_output_layer_norm)",{},{bert_encoder_layer_1_attention_output_layer_norm: None},,bert_encoder_layer_1_attention_output_dropout,bert_encoder_layer_1_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_16
call_module,bert.encoder.layer.1.attention.output.LayerNorm,{add_16: None},"(add_16,)",{},"{bert_encoder_layer_1_intermediate_dense: None, add_17: None}",,add_16,bert_encoder_layer_1_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.1.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.1.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_1_attention_output_layer_norm
call_module,bert.encoder.layer.1.intermediate.dense,{bert_encoder_layer_1_attention_output_layer_norm: None},"(bert_encoder_layer_1_attention_output_layer_norm,)",{},{gelu_1: None},,bert_encoder_layer_1_attention_output_layer_norm,gelu_1,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.1.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_1_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_1_intermediate_dense: None},"(bert_encoder_layer_1_intermediate_dense,)",{},{bert_encoder_layer_1_output_dense: None},,bert_encoder_layer_1_intermediate_dense,bert_encoder_layer_1_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.1.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_1
call_module,bert.encoder.layer.1.output.dense,{gelu_1: None},"(gelu_1,)",{},{bert_encoder_layer_1_output_dropout: None},,gelu_1,bert_encoder_layer_1_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.1.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_1_output_dense
call_module,bert.encoder.layer.1.output.dropout,{bert_encoder_layer_1_output_dense: None},"(bert_encoder_layer_1_output_dense,)",{},{add_17: None},,bert_encoder_layer_1_output_dense,add_17,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.1.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_1_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_1_output_dropout: None, bert_encoder_layer_1_attention_output_layer_norm: None}","(bert_encoder_layer_1_output_dropout, bert_encoder_layer_1_attention_output_layer_norm)",{},{bert_encoder_layer_1_output_layer_norm: None},,bert_encoder_layer_1_output_dropout,bert_encoder_layer_1_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_17
call_module,bert.encoder.layer.1.output.LayerNorm,{add_17: None},"(add_17,)",{},"{bert_encoder_layer_2_attention_self_query: None, bert_encoder_layer_2_attention_self_key: None, bert_encoder_layer_2_attention_self_value: None, add_23: None}",,add_17,bert_encoder_layer_2_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.1', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.1.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.1.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_1_output_layer_norm
call_module,bert.encoder.layer.2.attention.self.query,{bert_encoder_layer_1_output_layer_norm: None},"(bert_encoder_layer_1_output_layer_norm,)",{},"{size_12: None, view_10: None}",,bert_encoder_layer_1_output_layer_norm,bert_encoder_layer_2_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.2.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_2_attention_self_query
call_module,bert.encoder.layer.2.attention.self.key,{bert_encoder_layer_1_output_layer_norm: None},"(bert_encoder_layer_1_output_layer_norm,)",{},"{size_10: None, view_8: None}",,bert_encoder_layer_2_attention_self_query,size_10,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.2.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_2_attention_self_key
call_method,size,{bert_encoder_layer_2_attention_self_key: None},"(bert_encoder_layer_2_attention_self_key,)",{},{getitem_14: None},,bert_encoder_layer_2_attention_self_key,getitem_14,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_10
call_function,<built-in function getitem>,{size_10: None},"(size_10, slice(None, -1, None))",{},{add_18: None},,size_10,add_18,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_14
call_function,<built-in function add>,{getitem_14: None},"(getitem_14, (16, 64))",{},{view_8: None},,getitem_14,view_8,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_18
call_method,view,"{bert_encoder_layer_2_attention_self_key: None, add_18: None}","(bert_encoder_layer_2_attention_self_key, add_18)",{},{permute_8: None},,add_18,permute_8,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_8
call_method,permute,{view_8: None},"(view_8, 0, 2, 1, 3)",{},{transpose_2: None},,view_8,bert_encoder_layer_2_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_8
call_module,bert.encoder.layer.2.attention.self.value,{bert_encoder_layer_1_output_layer_norm: None},"(bert_encoder_layer_1_output_layer_norm,)",{},"{size_11: None, view_9: None}",,permute_8,size_11,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.2.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_2_attention_self_value
call_method,size,{bert_encoder_layer_2_attention_self_value: None},"(bert_encoder_layer_2_attention_self_value,)",{},{getitem_15: None},,bert_encoder_layer_2_attention_self_value,getitem_15,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_11
call_function,<built-in function getitem>,{size_11: None},"(size_11, slice(None, -1, None))",{},{add_19: None},,size_11,add_19,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_15
call_function,<built-in function add>,{getitem_15: None},"(getitem_15, (16, 64))",{},{view_9: None},,getitem_15,view_9,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_19
call_method,view,"{bert_encoder_layer_2_attention_self_value: None, add_19: None}","(bert_encoder_layer_2_attention_self_value, add_19)",{},{permute_9: None},,add_19,permute_9,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_9
call_method,permute,{view_9: None},"(view_9, 0, 2, 1, 3)",{},{matmul_5: None},,view_9,size_12,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_9
call_method,size,{bert_encoder_layer_2_attention_self_query: None},"(bert_encoder_layer_2_attention_self_query,)",{},{getitem_16: None},,permute_9,getitem_16,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_12
call_function,<built-in function getitem>,{size_12: None},"(size_12, slice(None, -1, None))",{},{add_20: None},,size_12,add_20,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_16
call_function,<built-in function add>,{getitem_16: None},"(getitem_16, (16, 64))",{},{view_10: None},,getitem_16,view_10,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_20
call_method,view,"{bert_encoder_layer_2_attention_self_query: None, add_20: None}","(bert_encoder_layer_2_attention_self_query, add_20)",{},{permute_10: None},,add_20,permute_10,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_10
call_method,permute,{view_10: None},"(view_10, 0, 2, 1, 3)",{},{matmul_4: None},,view_10,transpose_2,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_10
call_method,transpose,{permute_8: None},"(permute_8, -1, -2)",{},{matmul_4: None},,permute_10,matmul_4,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_2
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_10: None, transpose_2: None}","(permute_10, transpose_2)",{},{truediv_2: None},,transpose_2,truediv_2,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_4
call_function,<built-in function truediv>,{matmul_4: None},"(matmul_4, 8.0)",{},{add_21: None},,matmul_4,add_21,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_2
call_function,<built-in function add>,"{truediv_2: None, mul: None}","(truediv_2, mul)",{},{softmax_2: None},,truediv_2,softmax_2,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_21
call_function,<function softmax at 0x7f800dfdfca0>,{add_21: None},"(add_21,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_2_attention_self_dropout: None},,add_21,bert_encoder_layer_2_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_2
call_module,bert.encoder.layer.2.attention.self.dropout,{softmax_2: None},"(softmax_2,)",{},{matmul_5: None},,softmax_2,matmul_5,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.2.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_2_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_2_attention_self_dropout: None, permute_9: None}","(bert_encoder_layer_2_attention_self_dropout, permute_9)",{},{permute_11: None},,bert_encoder_layer_2_attention_self_dropout,permute_11,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_5
call_method,permute,{matmul_5: None},"(matmul_5, 0, 2, 1, 3)",{},{contiguous_2: None},,matmul_5,contiguous_2,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_11
call_method,contiguous,{permute_11: None},"(permute_11,)",{},"{size_13: None, view_11: None}",,permute_11,size_13,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_2
call_method,size,{contiguous_2: None},"(contiguous_2,)",{},{getitem_17: None},,contiguous_2,getitem_17,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_13
call_function,<built-in function getitem>,{size_13: None},"(size_13, slice(None, -2, None))",{},{add_22: None},,size_13,add_22,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_17
call_function,<built-in function add>,{getitem_17: None},"(getitem_17, (1024,))",{},{view_11: None},,getitem_17,view_11,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_22
call_method,view,"{contiguous_2: None, add_22: None}","(contiguous_2, add_22)",{},{bert_encoder_layer_2_attention_output_dense: None},,add_22,bert_encoder_layer_2_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_11
call_module,bert.encoder.layer.2.attention.output.dense,{view_11: None},"(view_11,)",{},{bert_encoder_layer_2_attention_output_dropout: None},,view_11,bert_encoder_layer_2_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.2.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_2_attention_output_dense
call_module,bert.encoder.layer.2.attention.output.dropout,{bert_encoder_layer_2_attention_output_dense: None},"(bert_encoder_layer_2_attention_output_dense,)",{},{add_23: None},,bert_encoder_layer_2_attention_output_dense,add_23,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.2.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_2_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_2_attention_output_dropout: None, bert_encoder_layer_1_output_layer_norm: None}","(bert_encoder_layer_2_attention_output_dropout, bert_encoder_layer_1_output_layer_norm)",{},{bert_encoder_layer_2_attention_output_layer_norm: None},,bert_encoder_layer_2_attention_output_dropout,bert_encoder_layer_2_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_23
call_module,bert.encoder.layer.2.attention.output.LayerNorm,{add_23: None},"(add_23,)",{},"{bert_encoder_layer_2_intermediate_dense: None, add_24: None}",,add_23,bert_encoder_layer_2_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.2.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.2.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_2_attention_output_layer_norm
call_module,bert.encoder.layer.2.intermediate.dense,{bert_encoder_layer_2_attention_output_layer_norm: None},"(bert_encoder_layer_2_attention_output_layer_norm,)",{},{gelu_2: None},,bert_encoder_layer_2_attention_output_layer_norm,gelu_2,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.2.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_2_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_2_intermediate_dense: None},"(bert_encoder_layer_2_intermediate_dense,)",{},{bert_encoder_layer_2_output_dense: None},,bert_encoder_layer_2_intermediate_dense,bert_encoder_layer_2_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.2.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_2
call_module,bert.encoder.layer.2.output.dense,{gelu_2: None},"(gelu_2,)",{},{bert_encoder_layer_2_output_dropout: None},,gelu_2,bert_encoder_layer_2_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.2.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_2_output_dense
call_module,bert.encoder.layer.2.output.dropout,{bert_encoder_layer_2_output_dense: None},"(bert_encoder_layer_2_output_dense,)",{},{add_24: None},,bert_encoder_layer_2_output_dense,add_24,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.2.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_2_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_2_output_dropout: None, bert_encoder_layer_2_attention_output_layer_norm: None}","(bert_encoder_layer_2_output_dropout, bert_encoder_layer_2_attention_output_layer_norm)",{},{bert_encoder_layer_2_output_layer_norm: None},,bert_encoder_layer_2_output_dropout,bert_encoder_layer_2_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_24
call_module,bert.encoder.layer.2.output.LayerNorm,{add_24: None},"(add_24,)",{},"{bert_encoder_layer_3_attention_self_query: None, bert_encoder_layer_3_attention_self_key: None, bert_encoder_layer_3_attention_self_value: None, add_30: None}",,add_24,bert_encoder_layer_3_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.2', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.2.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.2.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_2_output_layer_norm
call_module,bert.encoder.layer.3.attention.self.query,{bert_encoder_layer_2_output_layer_norm: None},"(bert_encoder_layer_2_output_layer_norm,)",{},"{size_16: None, view_14: None}",,bert_encoder_layer_2_output_layer_norm,bert_encoder_layer_3_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.3.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_3_attention_self_query
call_module,bert.encoder.layer.3.attention.self.key,{bert_encoder_layer_2_output_layer_norm: None},"(bert_encoder_layer_2_output_layer_norm,)",{},"{size_14: None, view_12: None}",,bert_encoder_layer_3_attention_self_query,size_14,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.3.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_3_attention_self_key
call_method,size,{bert_encoder_layer_3_attention_self_key: None},"(bert_encoder_layer_3_attention_self_key,)",{},{getitem_18: None},,bert_encoder_layer_3_attention_self_key,getitem_18,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_14
call_function,<built-in function getitem>,{size_14: None},"(size_14, slice(None, -1, None))",{},{add_25: None},,size_14,add_25,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_18
call_function,<built-in function add>,{getitem_18: None},"(getitem_18, (16, 64))",{},{view_12: None},,getitem_18,view_12,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_25
call_method,view,"{bert_encoder_layer_3_attention_self_key: None, add_25: None}","(bert_encoder_layer_3_attention_self_key, add_25)",{},{permute_12: None},,add_25,permute_12,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_12
call_method,permute,{view_12: None},"(view_12, 0, 2, 1, 3)",{},{transpose_3: None},,view_12,bert_encoder_layer_3_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_12
call_module,bert.encoder.layer.3.attention.self.value,{bert_encoder_layer_2_output_layer_norm: None},"(bert_encoder_layer_2_output_layer_norm,)",{},"{size_15: None, view_13: None}",,permute_12,size_15,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.3.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_3_attention_self_value
call_method,size,{bert_encoder_layer_3_attention_self_value: None},"(bert_encoder_layer_3_attention_self_value,)",{},{getitem_19: None},,bert_encoder_layer_3_attention_self_value,getitem_19,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_15
call_function,<built-in function getitem>,{size_15: None},"(size_15, slice(None, -1, None))",{},{add_26: None},,size_15,add_26,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_19
call_function,<built-in function add>,{getitem_19: None},"(getitem_19, (16, 64))",{},{view_13: None},,getitem_19,view_13,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_26
call_method,view,"{bert_encoder_layer_3_attention_self_value: None, add_26: None}","(bert_encoder_layer_3_attention_self_value, add_26)",{},{permute_13: None},,add_26,permute_13,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_13
call_method,permute,{view_13: None},"(view_13, 0, 2, 1, 3)",{},{matmul_7: None},,view_13,size_16,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_13
call_method,size,{bert_encoder_layer_3_attention_self_query: None},"(bert_encoder_layer_3_attention_self_query,)",{},{getitem_20: None},,permute_13,getitem_20,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_16
call_function,<built-in function getitem>,{size_16: None},"(size_16, slice(None, -1, None))",{},{add_27: None},,size_16,add_27,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_20
call_function,<built-in function add>,{getitem_20: None},"(getitem_20, (16, 64))",{},{view_14: None},,getitem_20,view_14,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_27
call_method,view,"{bert_encoder_layer_3_attention_self_query: None, add_27: None}","(bert_encoder_layer_3_attention_self_query, add_27)",{},{permute_14: None},,add_27,permute_14,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_14
call_method,permute,{view_14: None},"(view_14, 0, 2, 1, 3)",{},{matmul_6: None},,view_14,transpose_3,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_14
call_method,transpose,{permute_12: None},"(permute_12, -1, -2)",{},{matmul_6: None},,permute_14,matmul_6,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_3
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_14: None, transpose_3: None}","(permute_14, transpose_3)",{},{truediv_3: None},,transpose_3,truediv_3,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_6
call_function,<built-in function truediv>,{matmul_6: None},"(matmul_6, 8.0)",{},{add_28: None},,matmul_6,add_28,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_3
call_function,<built-in function add>,"{truediv_3: None, mul: None}","(truediv_3, mul)",{},{softmax_3: None},,truediv_3,softmax_3,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_28
call_function,<function softmax at 0x7f800dfdfca0>,{add_28: None},"(add_28,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_3_attention_self_dropout: None},,add_28,bert_encoder_layer_3_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_3
call_module,bert.encoder.layer.3.attention.self.dropout,{softmax_3: None},"(softmax_3,)",{},{matmul_7: None},,softmax_3,matmul_7,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.3.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_3_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_3_attention_self_dropout: None, permute_13: None}","(bert_encoder_layer_3_attention_self_dropout, permute_13)",{},{permute_15: None},,bert_encoder_layer_3_attention_self_dropout,permute_15,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_7
call_method,permute,{matmul_7: None},"(matmul_7, 0, 2, 1, 3)",{},{contiguous_3: None},,matmul_7,contiguous_3,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_15
call_method,contiguous,{permute_15: None},"(permute_15,)",{},"{size_17: None, view_15: None}",,permute_15,size_17,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_3
call_method,size,{contiguous_3: None},"(contiguous_3,)",{},{getitem_21: None},,contiguous_3,getitem_21,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_17
call_function,<built-in function getitem>,{size_17: None},"(size_17, slice(None, -2, None))",{},{add_29: None},,size_17,add_29,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_21
call_function,<built-in function add>,{getitem_21: None},"(getitem_21, (1024,))",{},{view_15: None},,getitem_21,view_15,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_29
call_method,view,"{contiguous_3: None, add_29: None}","(contiguous_3, add_29)",{},{bert_encoder_layer_3_attention_output_dense: None},,add_29,bert_encoder_layer_3_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_15
call_module,bert.encoder.layer.3.attention.output.dense,{view_15: None},"(view_15,)",{},{bert_encoder_layer_3_attention_output_dropout: None},,view_15,bert_encoder_layer_3_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.3.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_3_attention_output_dense
call_module,bert.encoder.layer.3.attention.output.dropout,{bert_encoder_layer_3_attention_output_dense: None},"(bert_encoder_layer_3_attention_output_dense,)",{},{add_30: None},,bert_encoder_layer_3_attention_output_dense,add_30,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.3.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_3_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_3_attention_output_dropout: None, bert_encoder_layer_2_output_layer_norm: None}","(bert_encoder_layer_3_attention_output_dropout, bert_encoder_layer_2_output_layer_norm)",{},{bert_encoder_layer_3_attention_output_layer_norm: None},,bert_encoder_layer_3_attention_output_dropout,bert_encoder_layer_3_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_30
call_module,bert.encoder.layer.3.attention.output.LayerNorm,{add_30: None},"(add_30,)",{},"{bert_encoder_layer_3_intermediate_dense: None, add_31: None}",,add_30,bert_encoder_layer_3_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.3.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.3.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_3_attention_output_layer_norm
call_module,bert.encoder.layer.3.intermediate.dense,{bert_encoder_layer_3_attention_output_layer_norm: None},"(bert_encoder_layer_3_attention_output_layer_norm,)",{},{gelu_3: None},,bert_encoder_layer_3_attention_output_layer_norm,gelu_3,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.3.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_3_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_3_intermediate_dense: None},"(bert_encoder_layer_3_intermediate_dense,)",{},{bert_encoder_layer_3_output_dense: None},,bert_encoder_layer_3_intermediate_dense,bert_encoder_layer_3_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.3.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_3
call_module,bert.encoder.layer.3.output.dense,{gelu_3: None},"(gelu_3,)",{},{bert_encoder_layer_3_output_dropout: None},,gelu_3,bert_encoder_layer_3_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.3.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_3_output_dense
call_module,bert.encoder.layer.3.output.dropout,{bert_encoder_layer_3_output_dense: None},"(bert_encoder_layer_3_output_dense,)",{},{add_31: None},,bert_encoder_layer_3_output_dense,add_31,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.3.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_3_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_3_output_dropout: None, bert_encoder_layer_3_attention_output_layer_norm: None}","(bert_encoder_layer_3_output_dropout, bert_encoder_layer_3_attention_output_layer_norm)",{},{bert_encoder_layer_3_output_layer_norm: None},,bert_encoder_layer_3_output_dropout,bert_encoder_layer_3_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_31
call_module,bert.encoder.layer.3.output.LayerNorm,{add_31: None},"(add_31,)",{},"{bert_encoder_layer_4_attention_self_query: None, bert_encoder_layer_4_attention_self_key: None, bert_encoder_layer_4_attention_self_value: None, add_37: None}",,add_31,bert_encoder_layer_4_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.3', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.3.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.3.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_3_output_layer_norm
call_module,bert.encoder.layer.4.attention.self.query,{bert_encoder_layer_3_output_layer_norm: None},"(bert_encoder_layer_3_output_layer_norm,)",{},"{size_20: None, view_18: None}",,bert_encoder_layer_3_output_layer_norm,bert_encoder_layer_4_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.4.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_4_attention_self_query
call_module,bert.encoder.layer.4.attention.self.key,{bert_encoder_layer_3_output_layer_norm: None},"(bert_encoder_layer_3_output_layer_norm,)",{},"{size_18: None, view_16: None}",,bert_encoder_layer_4_attention_self_query,size_18,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.4.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_4_attention_self_key
call_method,size,{bert_encoder_layer_4_attention_self_key: None},"(bert_encoder_layer_4_attention_self_key,)",{},{getitem_22: None},,bert_encoder_layer_4_attention_self_key,getitem_22,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_18
call_function,<built-in function getitem>,{size_18: None},"(size_18, slice(None, -1, None))",{},{add_32: None},,size_18,add_32,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_22
call_function,<built-in function add>,{getitem_22: None},"(getitem_22, (16, 64))",{},{view_16: None},,getitem_22,view_16,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_32
call_method,view,"{bert_encoder_layer_4_attention_self_key: None, add_32: None}","(bert_encoder_layer_4_attention_self_key, add_32)",{},{permute_16: None},,add_32,permute_16,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_16
call_method,permute,{view_16: None},"(view_16, 0, 2, 1, 3)",{},{transpose_4: None},,view_16,bert_encoder_layer_4_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_16
call_module,bert.encoder.layer.4.attention.self.value,{bert_encoder_layer_3_output_layer_norm: None},"(bert_encoder_layer_3_output_layer_norm,)",{},"{size_19: None, view_17: None}",,permute_16,size_19,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.4.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_4_attention_self_value
call_method,size,{bert_encoder_layer_4_attention_self_value: None},"(bert_encoder_layer_4_attention_self_value,)",{},{getitem_23: None},,bert_encoder_layer_4_attention_self_value,getitem_23,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_19
call_function,<built-in function getitem>,{size_19: None},"(size_19, slice(None, -1, None))",{},{add_33: None},,size_19,add_33,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_23
call_function,<built-in function add>,{getitem_23: None},"(getitem_23, (16, 64))",{},{view_17: None},,getitem_23,view_17,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_33
call_method,view,"{bert_encoder_layer_4_attention_self_value: None, add_33: None}","(bert_encoder_layer_4_attention_self_value, add_33)",{},{permute_17: None},,add_33,permute_17,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_17
call_method,permute,{view_17: None},"(view_17, 0, 2, 1, 3)",{},{matmul_9: None},,view_17,size_20,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_17
call_method,size,{bert_encoder_layer_4_attention_self_query: None},"(bert_encoder_layer_4_attention_self_query,)",{},{getitem_24: None},,permute_17,getitem_24,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_20
call_function,<built-in function getitem>,{size_20: None},"(size_20, slice(None, -1, None))",{},{add_34: None},,size_20,add_34,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_24
call_function,<built-in function add>,{getitem_24: None},"(getitem_24, (16, 64))",{},{view_18: None},,getitem_24,view_18,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_34
call_method,view,"{bert_encoder_layer_4_attention_self_query: None, add_34: None}","(bert_encoder_layer_4_attention_self_query, add_34)",{},{permute_18: None},,add_34,permute_18,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_18
call_method,permute,{view_18: None},"(view_18, 0, 2, 1, 3)",{},{matmul_8: None},,view_18,transpose_4,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_18
call_method,transpose,{permute_16: None},"(permute_16, -1, -2)",{},{matmul_8: None},,permute_18,matmul_8,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_4
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_18: None, transpose_4: None}","(permute_18, transpose_4)",{},{truediv_4: None},,transpose_4,truediv_4,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_8
call_function,<built-in function truediv>,{matmul_8: None},"(matmul_8, 8.0)",{},{add_35: None},,matmul_8,add_35,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_4
call_function,<built-in function add>,"{truediv_4: None, mul: None}","(truediv_4, mul)",{},{softmax_4: None},,truediv_4,softmax_4,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_35
call_function,<function softmax at 0x7f800dfdfca0>,{add_35: None},"(add_35,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_4_attention_self_dropout: None},,add_35,bert_encoder_layer_4_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_4
call_module,bert.encoder.layer.4.attention.self.dropout,{softmax_4: None},"(softmax_4,)",{},{matmul_9: None},,softmax_4,matmul_9,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.4.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_4_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_4_attention_self_dropout: None, permute_17: None}","(bert_encoder_layer_4_attention_self_dropout, permute_17)",{},{permute_19: None},,bert_encoder_layer_4_attention_self_dropout,permute_19,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_9
call_method,permute,{matmul_9: None},"(matmul_9, 0, 2, 1, 3)",{},{contiguous_4: None},,matmul_9,contiguous_4,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_19
call_method,contiguous,{permute_19: None},"(permute_19,)",{},"{size_21: None, view_19: None}",,permute_19,size_21,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_4
call_method,size,{contiguous_4: None},"(contiguous_4,)",{},{getitem_25: None},,contiguous_4,getitem_25,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_21
call_function,<built-in function getitem>,{size_21: None},"(size_21, slice(None, -2, None))",{},{add_36: None},,size_21,add_36,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_25
call_function,<built-in function add>,{getitem_25: None},"(getitem_25, (1024,))",{},{view_19: None},,getitem_25,view_19,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_36
call_method,view,"{contiguous_4: None, add_36: None}","(contiguous_4, add_36)",{},{bert_encoder_layer_4_attention_output_dense: None},,add_36,bert_encoder_layer_4_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_19
call_module,bert.encoder.layer.4.attention.output.dense,{view_19: None},"(view_19,)",{},{bert_encoder_layer_4_attention_output_dropout: None},,view_19,bert_encoder_layer_4_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.4.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_4_attention_output_dense
call_module,bert.encoder.layer.4.attention.output.dropout,{bert_encoder_layer_4_attention_output_dense: None},"(bert_encoder_layer_4_attention_output_dense,)",{},{add_37: None},,bert_encoder_layer_4_attention_output_dense,add_37,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.4.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_4_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_4_attention_output_dropout: None, bert_encoder_layer_3_output_layer_norm: None}","(bert_encoder_layer_4_attention_output_dropout, bert_encoder_layer_3_output_layer_norm)",{},{bert_encoder_layer_4_attention_output_layer_norm: None},,bert_encoder_layer_4_attention_output_dropout,bert_encoder_layer_4_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_37
call_module,bert.encoder.layer.4.attention.output.LayerNorm,{add_37: None},"(add_37,)",{},"{bert_encoder_layer_4_intermediate_dense: None, add_38: None}",,add_37,bert_encoder_layer_4_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.4.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.4.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_4_attention_output_layer_norm
call_module,bert.encoder.layer.4.intermediate.dense,{bert_encoder_layer_4_attention_output_layer_norm: None},"(bert_encoder_layer_4_attention_output_layer_norm,)",{},{gelu_4: None},,bert_encoder_layer_4_attention_output_layer_norm,gelu_4,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.4.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_4_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_4_intermediate_dense: None},"(bert_encoder_layer_4_intermediate_dense,)",{},{bert_encoder_layer_4_output_dense: None},,bert_encoder_layer_4_intermediate_dense,bert_encoder_layer_4_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.4.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_4
call_module,bert.encoder.layer.4.output.dense,{gelu_4: None},"(gelu_4,)",{},{bert_encoder_layer_4_output_dropout: None},,gelu_4,bert_encoder_layer_4_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.4.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_4_output_dense
call_module,bert.encoder.layer.4.output.dropout,{bert_encoder_layer_4_output_dense: None},"(bert_encoder_layer_4_output_dense,)",{},{add_38: None},,bert_encoder_layer_4_output_dense,add_38,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.4.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_4_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_4_output_dropout: None, bert_encoder_layer_4_attention_output_layer_norm: None}","(bert_encoder_layer_4_output_dropout, bert_encoder_layer_4_attention_output_layer_norm)",{},{bert_encoder_layer_4_output_layer_norm: None},,bert_encoder_layer_4_output_dropout,bert_encoder_layer_4_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_38
call_module,bert.encoder.layer.4.output.LayerNorm,{add_38: None},"(add_38,)",{},"{bert_encoder_layer_5_attention_self_query: None, bert_encoder_layer_5_attention_self_key: None, bert_encoder_layer_5_attention_self_value: None, add_44: None}",,add_38,bert_encoder_layer_5_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.4', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.4.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.4.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_4_output_layer_norm
call_module,bert.encoder.layer.5.attention.self.query,{bert_encoder_layer_4_output_layer_norm: None},"(bert_encoder_layer_4_output_layer_norm,)",{},"{size_24: None, view_22: None}",,bert_encoder_layer_4_output_layer_norm,bert_encoder_layer_5_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.5.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_5_attention_self_query
call_module,bert.encoder.layer.5.attention.self.key,{bert_encoder_layer_4_output_layer_norm: None},"(bert_encoder_layer_4_output_layer_norm,)",{},"{size_22: None, view_20: None}",,bert_encoder_layer_5_attention_self_query,size_22,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.5.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_5_attention_self_key
call_method,size,{bert_encoder_layer_5_attention_self_key: None},"(bert_encoder_layer_5_attention_self_key,)",{},{getitem_26: None},,bert_encoder_layer_5_attention_self_key,getitem_26,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_22
call_function,<built-in function getitem>,{size_22: None},"(size_22, slice(None, -1, None))",{},{add_39: None},,size_22,add_39,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_26
call_function,<built-in function add>,{getitem_26: None},"(getitem_26, (16, 64))",{},{view_20: None},,getitem_26,view_20,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_39
call_method,view,"{bert_encoder_layer_5_attention_self_key: None, add_39: None}","(bert_encoder_layer_5_attention_self_key, add_39)",{},{permute_20: None},,add_39,permute_20,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_20
call_method,permute,{view_20: None},"(view_20, 0, 2, 1, 3)",{},{transpose_5: None},,view_20,bert_encoder_layer_5_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_20
call_module,bert.encoder.layer.5.attention.self.value,{bert_encoder_layer_4_output_layer_norm: None},"(bert_encoder_layer_4_output_layer_norm,)",{},"{size_23: None, view_21: None}",,permute_20,size_23,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.5.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_5_attention_self_value
call_method,size,{bert_encoder_layer_5_attention_self_value: None},"(bert_encoder_layer_5_attention_self_value,)",{},{getitem_27: None},,bert_encoder_layer_5_attention_self_value,getitem_27,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_23
call_function,<built-in function getitem>,{size_23: None},"(size_23, slice(None, -1, None))",{},{add_40: None},,size_23,add_40,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_27
call_function,<built-in function add>,{getitem_27: None},"(getitem_27, (16, 64))",{},{view_21: None},,getitem_27,view_21,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_40
call_method,view,"{bert_encoder_layer_5_attention_self_value: None, add_40: None}","(bert_encoder_layer_5_attention_self_value, add_40)",{},{permute_21: None},,add_40,permute_21,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_21
call_method,permute,{view_21: None},"(view_21, 0, 2, 1, 3)",{},{matmul_11: None},,view_21,size_24,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_21
call_method,size,{bert_encoder_layer_5_attention_self_query: None},"(bert_encoder_layer_5_attention_self_query,)",{},{getitem_28: None},,permute_21,getitem_28,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_24
call_function,<built-in function getitem>,{size_24: None},"(size_24, slice(None, -1, None))",{},{add_41: None},,size_24,add_41,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_28
call_function,<built-in function add>,{getitem_28: None},"(getitem_28, (16, 64))",{},{view_22: None},,getitem_28,view_22,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_41
call_method,view,"{bert_encoder_layer_5_attention_self_query: None, add_41: None}","(bert_encoder_layer_5_attention_self_query, add_41)",{},{permute_22: None},,add_41,permute_22,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_22
call_method,permute,{view_22: None},"(view_22, 0, 2, 1, 3)",{},{matmul_10: None},,view_22,transpose_5,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_22
call_method,transpose,{permute_20: None},"(permute_20, -1, -2)",{},{matmul_10: None},,permute_22,matmul_10,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_5
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_22: None, transpose_5: None}","(permute_22, transpose_5)",{},{truediv_5: None},,transpose_5,truediv_5,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_10
call_function,<built-in function truediv>,{matmul_10: None},"(matmul_10, 8.0)",{},{add_42: None},,matmul_10,add_42,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_5
call_function,<built-in function add>,"{truediv_5: None, mul: None}","(truediv_5, mul)",{},{softmax_5: None},,truediv_5,softmax_5,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_42
call_function,<function softmax at 0x7f800dfdfca0>,{add_42: None},"(add_42,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_5_attention_self_dropout: None},,add_42,bert_encoder_layer_5_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_5
call_module,bert.encoder.layer.5.attention.self.dropout,{softmax_5: None},"(softmax_5,)",{},{matmul_11: None},,softmax_5,matmul_11,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.5.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_5_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_5_attention_self_dropout: None, permute_21: None}","(bert_encoder_layer_5_attention_self_dropout, permute_21)",{},{permute_23: None},,bert_encoder_layer_5_attention_self_dropout,permute_23,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_11
call_method,permute,{matmul_11: None},"(matmul_11, 0, 2, 1, 3)",{},{contiguous_5: None},,matmul_11,contiguous_5,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_23
call_method,contiguous,{permute_23: None},"(permute_23,)",{},"{size_25: None, view_23: None}",,permute_23,size_25,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_5
call_method,size,{contiguous_5: None},"(contiguous_5,)",{},{getitem_29: None},,contiguous_5,getitem_29,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_25
call_function,<built-in function getitem>,{size_25: None},"(size_25, slice(None, -2, None))",{},{add_43: None},,size_25,add_43,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_29
call_function,<built-in function add>,{getitem_29: None},"(getitem_29, (1024,))",{},{view_23: None},,getitem_29,view_23,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_43
call_method,view,"{contiguous_5: None, add_43: None}","(contiguous_5, add_43)",{},{bert_encoder_layer_5_attention_output_dense: None},,add_43,bert_encoder_layer_5_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_23
call_module,bert.encoder.layer.5.attention.output.dense,{view_23: None},"(view_23,)",{},{bert_encoder_layer_5_attention_output_dropout: None},,view_23,bert_encoder_layer_5_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.5.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_5_attention_output_dense
call_module,bert.encoder.layer.5.attention.output.dropout,{bert_encoder_layer_5_attention_output_dense: None},"(bert_encoder_layer_5_attention_output_dense,)",{},{add_44: None},,bert_encoder_layer_5_attention_output_dense,add_44,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.5.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_5_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_5_attention_output_dropout: None, bert_encoder_layer_4_output_layer_norm: None}","(bert_encoder_layer_5_attention_output_dropout, bert_encoder_layer_4_output_layer_norm)",{},{bert_encoder_layer_5_attention_output_layer_norm: None},,bert_encoder_layer_5_attention_output_dropout,bert_encoder_layer_5_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_44
call_module,bert.encoder.layer.5.attention.output.LayerNorm,{add_44: None},"(add_44,)",{},"{bert_encoder_layer_5_intermediate_dense: None, add_45: None}",,add_44,bert_encoder_layer_5_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.5.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.5.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_5_attention_output_layer_norm
call_module,bert.encoder.layer.5.intermediate.dense,{bert_encoder_layer_5_attention_output_layer_norm: None},"(bert_encoder_layer_5_attention_output_layer_norm,)",{},{gelu_5: None},,bert_encoder_layer_5_attention_output_layer_norm,gelu_5,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.5.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_5_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_5_intermediate_dense: None},"(bert_encoder_layer_5_intermediate_dense,)",{},{bert_encoder_layer_5_output_dense: None},,bert_encoder_layer_5_intermediate_dense,bert_encoder_layer_5_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.5.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_5
call_module,bert.encoder.layer.5.output.dense,{gelu_5: None},"(gelu_5,)",{},{bert_encoder_layer_5_output_dropout: None},,gelu_5,bert_encoder_layer_5_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.5.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_5_output_dense
call_module,bert.encoder.layer.5.output.dropout,{bert_encoder_layer_5_output_dense: None},"(bert_encoder_layer_5_output_dense,)",{},{add_45: None},,bert_encoder_layer_5_output_dense,add_45,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.5.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_5_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_5_output_dropout: None, bert_encoder_layer_5_attention_output_layer_norm: None}","(bert_encoder_layer_5_output_dropout, bert_encoder_layer_5_attention_output_layer_norm)",{},{bert_encoder_layer_5_output_layer_norm: None},,bert_encoder_layer_5_output_dropout,bert_encoder_layer_5_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_45
call_module,bert.encoder.layer.5.output.LayerNorm,{add_45: None},"(add_45,)",{},"{bert_encoder_layer_6_attention_self_query: None, bert_encoder_layer_6_attention_self_key: None, bert_encoder_layer_6_attention_self_value: None, add_51: None}",,add_45,bert_encoder_layer_6_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.5', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.5.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.5.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_5_output_layer_norm
call_module,bert.encoder.layer.6.attention.self.query,{bert_encoder_layer_5_output_layer_norm: None},"(bert_encoder_layer_5_output_layer_norm,)",{},"{size_28: None, view_26: None}",,bert_encoder_layer_5_output_layer_norm,bert_encoder_layer_6_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.6.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_6_attention_self_query
call_module,bert.encoder.layer.6.attention.self.key,{bert_encoder_layer_5_output_layer_norm: None},"(bert_encoder_layer_5_output_layer_norm,)",{},"{size_26: None, view_24: None}",,bert_encoder_layer_6_attention_self_query,size_26,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.6.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_6_attention_self_key
call_method,size,{bert_encoder_layer_6_attention_self_key: None},"(bert_encoder_layer_6_attention_self_key,)",{},{getitem_30: None},,bert_encoder_layer_6_attention_self_key,getitem_30,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_26
call_function,<built-in function getitem>,{size_26: None},"(size_26, slice(None, -1, None))",{},{add_46: None},,size_26,add_46,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_30
call_function,<built-in function add>,{getitem_30: None},"(getitem_30, (16, 64))",{},{view_24: None},,getitem_30,view_24,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_46
call_method,view,"{bert_encoder_layer_6_attention_self_key: None, add_46: None}","(bert_encoder_layer_6_attention_self_key, add_46)",{},{permute_24: None},,add_46,permute_24,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_24
call_method,permute,{view_24: None},"(view_24, 0, 2, 1, 3)",{},{transpose_6: None},,view_24,bert_encoder_layer_6_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_24
call_module,bert.encoder.layer.6.attention.self.value,{bert_encoder_layer_5_output_layer_norm: None},"(bert_encoder_layer_5_output_layer_norm,)",{},"{size_27: None, view_25: None}",,permute_24,size_27,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.6.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_6_attention_self_value
call_method,size,{bert_encoder_layer_6_attention_self_value: None},"(bert_encoder_layer_6_attention_self_value,)",{},{getitem_31: None},,bert_encoder_layer_6_attention_self_value,getitem_31,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_27
call_function,<built-in function getitem>,{size_27: None},"(size_27, slice(None, -1, None))",{},{add_47: None},,size_27,add_47,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_31
call_function,<built-in function add>,{getitem_31: None},"(getitem_31, (16, 64))",{},{view_25: None},,getitem_31,view_25,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_47
call_method,view,"{bert_encoder_layer_6_attention_self_value: None, add_47: None}","(bert_encoder_layer_6_attention_self_value, add_47)",{},{permute_25: None},,add_47,permute_25,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_25
call_method,permute,{view_25: None},"(view_25, 0, 2, 1, 3)",{},{matmul_13: None},,view_25,size_28,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_25
call_method,size,{bert_encoder_layer_6_attention_self_query: None},"(bert_encoder_layer_6_attention_self_query,)",{},{getitem_32: None},,permute_25,getitem_32,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_28
call_function,<built-in function getitem>,{size_28: None},"(size_28, slice(None, -1, None))",{},{add_48: None},,size_28,add_48,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_32
call_function,<built-in function add>,{getitem_32: None},"(getitem_32, (16, 64))",{},{view_26: None},,getitem_32,view_26,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_48
call_method,view,"{bert_encoder_layer_6_attention_self_query: None, add_48: None}","(bert_encoder_layer_6_attention_self_query, add_48)",{},{permute_26: None},,add_48,permute_26,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_26
call_method,permute,{view_26: None},"(view_26, 0, 2, 1, 3)",{},{matmul_12: None},,view_26,transpose_6,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_26
call_method,transpose,{permute_24: None},"(permute_24, -1, -2)",{},{matmul_12: None},,permute_26,matmul_12,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_6
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_26: None, transpose_6: None}","(permute_26, transpose_6)",{},{truediv_6: None},,transpose_6,truediv_6,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_12
call_function,<built-in function truediv>,{matmul_12: None},"(matmul_12, 8.0)",{},{add_49: None},,matmul_12,add_49,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_6
call_function,<built-in function add>,"{truediv_6: None, mul: None}","(truediv_6, mul)",{},{softmax_6: None},,truediv_6,softmax_6,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_49
call_function,<function softmax at 0x7f800dfdfca0>,{add_49: None},"(add_49,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_6_attention_self_dropout: None},,add_49,bert_encoder_layer_6_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_6
call_module,bert.encoder.layer.6.attention.self.dropout,{softmax_6: None},"(softmax_6,)",{},{matmul_13: None},,softmax_6,matmul_13,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.6.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_6_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_6_attention_self_dropout: None, permute_25: None}","(bert_encoder_layer_6_attention_self_dropout, permute_25)",{},{permute_27: None},,bert_encoder_layer_6_attention_self_dropout,permute_27,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_13
call_method,permute,{matmul_13: None},"(matmul_13, 0, 2, 1, 3)",{},{contiguous_6: None},,matmul_13,contiguous_6,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_27
call_method,contiguous,{permute_27: None},"(permute_27,)",{},"{size_29: None, view_27: None}",,permute_27,size_29,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_6
call_method,size,{contiguous_6: None},"(contiguous_6,)",{},{getitem_33: None},,contiguous_6,getitem_33,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_29
call_function,<built-in function getitem>,{size_29: None},"(size_29, slice(None, -2, None))",{},{add_50: None},,size_29,add_50,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_33
call_function,<built-in function add>,{getitem_33: None},"(getitem_33, (1024,))",{},{view_27: None},,getitem_33,view_27,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_50
call_method,view,"{contiguous_6: None, add_50: None}","(contiguous_6, add_50)",{},{bert_encoder_layer_6_attention_output_dense: None},,add_50,bert_encoder_layer_6_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_27
call_module,bert.encoder.layer.6.attention.output.dense,{view_27: None},"(view_27,)",{},{bert_encoder_layer_6_attention_output_dropout: None},,view_27,bert_encoder_layer_6_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.6.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_6_attention_output_dense
call_module,bert.encoder.layer.6.attention.output.dropout,{bert_encoder_layer_6_attention_output_dense: None},"(bert_encoder_layer_6_attention_output_dense,)",{},{add_51: None},,bert_encoder_layer_6_attention_output_dense,add_51,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.6.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_6_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_6_attention_output_dropout: None, bert_encoder_layer_5_output_layer_norm: None}","(bert_encoder_layer_6_attention_output_dropout, bert_encoder_layer_5_output_layer_norm)",{},{bert_encoder_layer_6_attention_output_layer_norm: None},,bert_encoder_layer_6_attention_output_dropout,bert_encoder_layer_6_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_51
call_module,bert.encoder.layer.6.attention.output.LayerNorm,{add_51: None},"(add_51,)",{},"{bert_encoder_layer_6_intermediate_dense: None, add_52: None}",,add_51,bert_encoder_layer_6_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.6.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.6.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_6_attention_output_layer_norm
call_module,bert.encoder.layer.6.intermediate.dense,{bert_encoder_layer_6_attention_output_layer_norm: None},"(bert_encoder_layer_6_attention_output_layer_norm,)",{},{gelu_6: None},,bert_encoder_layer_6_attention_output_layer_norm,gelu_6,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.6.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_6_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_6_intermediate_dense: None},"(bert_encoder_layer_6_intermediate_dense,)",{},{bert_encoder_layer_6_output_dense: None},,bert_encoder_layer_6_intermediate_dense,bert_encoder_layer_6_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.6.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_6
call_module,bert.encoder.layer.6.output.dense,{gelu_6: None},"(gelu_6,)",{},{bert_encoder_layer_6_output_dropout: None},,gelu_6,bert_encoder_layer_6_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.6.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_6_output_dense
call_module,bert.encoder.layer.6.output.dropout,{bert_encoder_layer_6_output_dense: None},"(bert_encoder_layer_6_output_dense,)",{},{add_52: None},,bert_encoder_layer_6_output_dense,add_52,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.6.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_6_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_6_output_dropout: None, bert_encoder_layer_6_attention_output_layer_norm: None}","(bert_encoder_layer_6_output_dropout, bert_encoder_layer_6_attention_output_layer_norm)",{},{bert_encoder_layer_6_output_layer_norm: None},,bert_encoder_layer_6_output_dropout,bert_encoder_layer_6_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_52
call_module,bert.encoder.layer.6.output.LayerNorm,{add_52: None},"(add_52,)",{},"{bert_encoder_layer_7_attention_self_query: None, bert_encoder_layer_7_attention_self_key: None, bert_encoder_layer_7_attention_self_value: None, add_58: None}",,add_52,bert_encoder_layer_7_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.6', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.6.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.6.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_6_output_layer_norm
call_module,bert.encoder.layer.7.attention.self.query,{bert_encoder_layer_6_output_layer_norm: None},"(bert_encoder_layer_6_output_layer_norm,)",{},"{size_32: None, view_30: None}",,bert_encoder_layer_6_output_layer_norm,bert_encoder_layer_7_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.7.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_7_attention_self_query
call_module,bert.encoder.layer.7.attention.self.key,{bert_encoder_layer_6_output_layer_norm: None},"(bert_encoder_layer_6_output_layer_norm,)",{},"{size_30: None, view_28: None}",,bert_encoder_layer_7_attention_self_query,size_30,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.7.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_7_attention_self_key
call_method,size,{bert_encoder_layer_7_attention_self_key: None},"(bert_encoder_layer_7_attention_self_key,)",{},{getitem_34: None},,bert_encoder_layer_7_attention_self_key,getitem_34,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_30
call_function,<built-in function getitem>,{size_30: None},"(size_30, slice(None, -1, None))",{},{add_53: None},,size_30,add_53,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_34
call_function,<built-in function add>,{getitem_34: None},"(getitem_34, (16, 64))",{},{view_28: None},,getitem_34,view_28,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_53
call_method,view,"{bert_encoder_layer_7_attention_self_key: None, add_53: None}","(bert_encoder_layer_7_attention_self_key, add_53)",{},{permute_28: None},,add_53,permute_28,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_28
call_method,permute,{view_28: None},"(view_28, 0, 2, 1, 3)",{},{transpose_7: None},,view_28,bert_encoder_layer_7_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_28
call_module,bert.encoder.layer.7.attention.self.value,{bert_encoder_layer_6_output_layer_norm: None},"(bert_encoder_layer_6_output_layer_norm,)",{},"{size_31: None, view_29: None}",,permute_28,size_31,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.7.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_7_attention_self_value
call_method,size,{bert_encoder_layer_7_attention_self_value: None},"(bert_encoder_layer_7_attention_self_value,)",{},{getitem_35: None},,bert_encoder_layer_7_attention_self_value,getitem_35,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_31
call_function,<built-in function getitem>,{size_31: None},"(size_31, slice(None, -1, None))",{},{add_54: None},,size_31,add_54,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_35
call_function,<built-in function add>,{getitem_35: None},"(getitem_35, (16, 64))",{},{view_29: None},,getitem_35,view_29,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_54
call_method,view,"{bert_encoder_layer_7_attention_self_value: None, add_54: None}","(bert_encoder_layer_7_attention_self_value, add_54)",{},{permute_29: None},,add_54,permute_29,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_29
call_method,permute,{view_29: None},"(view_29, 0, 2, 1, 3)",{},{matmul_15: None},,view_29,size_32,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_29
call_method,size,{bert_encoder_layer_7_attention_self_query: None},"(bert_encoder_layer_7_attention_self_query,)",{},{getitem_36: None},,permute_29,getitem_36,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_32
call_function,<built-in function getitem>,{size_32: None},"(size_32, slice(None, -1, None))",{},{add_55: None},,size_32,add_55,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_36
call_function,<built-in function add>,{getitem_36: None},"(getitem_36, (16, 64))",{},{view_30: None},,getitem_36,view_30,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_55
call_method,view,"{bert_encoder_layer_7_attention_self_query: None, add_55: None}","(bert_encoder_layer_7_attention_self_query, add_55)",{},{permute_30: None},,add_55,permute_30,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_30
call_method,permute,{view_30: None},"(view_30, 0, 2, 1, 3)",{},{matmul_14: None},,view_30,transpose_7,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_30
call_method,transpose,{permute_28: None},"(permute_28, -1, -2)",{},{matmul_14: None},,permute_30,matmul_14,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_7
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_30: None, transpose_7: None}","(permute_30, transpose_7)",{},{truediv_7: None},,transpose_7,truediv_7,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_14
call_function,<built-in function truediv>,{matmul_14: None},"(matmul_14, 8.0)",{},{add_56: None},,matmul_14,add_56,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_7
call_function,<built-in function add>,"{truediv_7: None, mul: None}","(truediv_7, mul)",{},{softmax_7: None},,truediv_7,softmax_7,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_56
call_function,<function softmax at 0x7f800dfdfca0>,{add_56: None},"(add_56,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_7_attention_self_dropout: None},,add_56,bert_encoder_layer_7_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_7
call_module,bert.encoder.layer.7.attention.self.dropout,{softmax_7: None},"(softmax_7,)",{},{matmul_15: None},,softmax_7,matmul_15,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.7.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_7_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_7_attention_self_dropout: None, permute_29: None}","(bert_encoder_layer_7_attention_self_dropout, permute_29)",{},{permute_31: None},,bert_encoder_layer_7_attention_self_dropout,permute_31,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_15
call_method,permute,{matmul_15: None},"(matmul_15, 0, 2, 1, 3)",{},{contiguous_7: None},,matmul_15,contiguous_7,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_31
call_method,contiguous,{permute_31: None},"(permute_31,)",{},"{size_33: None, view_31: None}",,permute_31,size_33,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_7
call_method,size,{contiguous_7: None},"(contiguous_7,)",{},{getitem_37: None},,contiguous_7,getitem_37,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_33
call_function,<built-in function getitem>,{size_33: None},"(size_33, slice(None, -2, None))",{},{add_57: None},,size_33,add_57,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_37
call_function,<built-in function add>,{getitem_37: None},"(getitem_37, (1024,))",{},{view_31: None},,getitem_37,view_31,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_57
call_method,view,"{contiguous_7: None, add_57: None}","(contiguous_7, add_57)",{},{bert_encoder_layer_7_attention_output_dense: None},,add_57,bert_encoder_layer_7_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_31
call_module,bert.encoder.layer.7.attention.output.dense,{view_31: None},"(view_31,)",{},{bert_encoder_layer_7_attention_output_dropout: None},,view_31,bert_encoder_layer_7_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.7.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_7_attention_output_dense
call_module,bert.encoder.layer.7.attention.output.dropout,{bert_encoder_layer_7_attention_output_dense: None},"(bert_encoder_layer_7_attention_output_dense,)",{},{add_58: None},,bert_encoder_layer_7_attention_output_dense,add_58,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.7.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_7_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_7_attention_output_dropout: None, bert_encoder_layer_6_output_layer_norm: None}","(bert_encoder_layer_7_attention_output_dropout, bert_encoder_layer_6_output_layer_norm)",{},{bert_encoder_layer_7_attention_output_layer_norm: None},,bert_encoder_layer_7_attention_output_dropout,bert_encoder_layer_7_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_58
call_module,bert.encoder.layer.7.attention.output.LayerNorm,{add_58: None},"(add_58,)",{},"{bert_encoder_layer_7_intermediate_dense: None, add_59: None}",,add_58,bert_encoder_layer_7_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.7.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.7.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_7_attention_output_layer_norm
call_module,bert.encoder.layer.7.intermediate.dense,{bert_encoder_layer_7_attention_output_layer_norm: None},"(bert_encoder_layer_7_attention_output_layer_norm,)",{},{gelu_7: None},,bert_encoder_layer_7_attention_output_layer_norm,gelu_7,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.7.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_7_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_7_intermediate_dense: None},"(bert_encoder_layer_7_intermediate_dense,)",{},{bert_encoder_layer_7_output_dense: None},,bert_encoder_layer_7_intermediate_dense,bert_encoder_layer_7_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.7.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_7
call_module,bert.encoder.layer.7.output.dense,{gelu_7: None},"(gelu_7,)",{},{bert_encoder_layer_7_output_dropout: None},,gelu_7,bert_encoder_layer_7_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.7.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_7_output_dense
call_module,bert.encoder.layer.7.output.dropout,{bert_encoder_layer_7_output_dense: None},"(bert_encoder_layer_7_output_dense,)",{},{add_59: None},,bert_encoder_layer_7_output_dense,add_59,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.7.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_7_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_7_output_dropout: None, bert_encoder_layer_7_attention_output_layer_norm: None}","(bert_encoder_layer_7_output_dropout, bert_encoder_layer_7_attention_output_layer_norm)",{},{bert_encoder_layer_7_output_layer_norm: None},,bert_encoder_layer_7_output_dropout,bert_encoder_layer_7_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_59
call_module,bert.encoder.layer.7.output.LayerNorm,{add_59: None},"(add_59,)",{},"{bert_encoder_layer_8_attention_self_query: None, bert_encoder_layer_8_attention_self_key: None, bert_encoder_layer_8_attention_self_value: None, add_65: None}",,add_59,bert_encoder_layer_8_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.7', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.7.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.7.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_7_output_layer_norm
call_module,bert.encoder.layer.8.attention.self.query,{bert_encoder_layer_7_output_layer_norm: None},"(bert_encoder_layer_7_output_layer_norm,)",{},"{size_36: None, view_34: None}",,bert_encoder_layer_7_output_layer_norm,bert_encoder_layer_8_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.8.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_8_attention_self_query
call_module,bert.encoder.layer.8.attention.self.key,{bert_encoder_layer_7_output_layer_norm: None},"(bert_encoder_layer_7_output_layer_norm,)",{},"{size_34: None, view_32: None}",,bert_encoder_layer_8_attention_self_query,size_34,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.8.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_8_attention_self_key
call_method,size,{bert_encoder_layer_8_attention_self_key: None},"(bert_encoder_layer_8_attention_self_key,)",{},{getitem_38: None},,bert_encoder_layer_8_attention_self_key,getitem_38,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_34
call_function,<built-in function getitem>,{size_34: None},"(size_34, slice(None, -1, None))",{},{add_60: None},,size_34,add_60,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_38
call_function,<built-in function add>,{getitem_38: None},"(getitem_38, (16, 64))",{},{view_32: None},,getitem_38,view_32,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_60
call_method,view,"{bert_encoder_layer_8_attention_self_key: None, add_60: None}","(bert_encoder_layer_8_attention_self_key, add_60)",{},{permute_32: None},,add_60,permute_32,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_32
call_method,permute,{view_32: None},"(view_32, 0, 2, 1, 3)",{},{transpose_8: None},,view_32,bert_encoder_layer_8_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_32
call_module,bert.encoder.layer.8.attention.self.value,{bert_encoder_layer_7_output_layer_norm: None},"(bert_encoder_layer_7_output_layer_norm,)",{},"{size_35: None, view_33: None}",,permute_32,size_35,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.8.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_8_attention_self_value
call_method,size,{bert_encoder_layer_8_attention_self_value: None},"(bert_encoder_layer_8_attention_self_value,)",{},{getitem_39: None},,bert_encoder_layer_8_attention_self_value,getitem_39,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_35
call_function,<built-in function getitem>,{size_35: None},"(size_35, slice(None, -1, None))",{},{add_61: None},,size_35,add_61,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_39
call_function,<built-in function add>,{getitem_39: None},"(getitem_39, (16, 64))",{},{view_33: None},,getitem_39,view_33,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_61
call_method,view,"{bert_encoder_layer_8_attention_self_value: None, add_61: None}","(bert_encoder_layer_8_attention_self_value, add_61)",{},{permute_33: None},,add_61,permute_33,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_33
call_method,permute,{view_33: None},"(view_33, 0, 2, 1, 3)",{},{matmul_17: None},,view_33,size_36,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_33
call_method,size,{bert_encoder_layer_8_attention_self_query: None},"(bert_encoder_layer_8_attention_self_query,)",{},{getitem_40: None},,permute_33,getitem_40,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_36
call_function,<built-in function getitem>,{size_36: None},"(size_36, slice(None, -1, None))",{},{add_62: None},,size_36,add_62,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_40
call_function,<built-in function add>,{getitem_40: None},"(getitem_40, (16, 64))",{},{view_34: None},,getitem_40,view_34,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_62
call_method,view,"{bert_encoder_layer_8_attention_self_query: None, add_62: None}","(bert_encoder_layer_8_attention_self_query, add_62)",{},{permute_34: None},,add_62,permute_34,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_34
call_method,permute,{view_34: None},"(view_34, 0, 2, 1, 3)",{},{matmul_16: None},,view_34,transpose_8,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_34
call_method,transpose,{permute_32: None},"(permute_32, -1, -2)",{},{matmul_16: None},,permute_34,matmul_16,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_8
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_34: None, transpose_8: None}","(permute_34, transpose_8)",{},{truediv_8: None},,transpose_8,truediv_8,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_16
call_function,<built-in function truediv>,{matmul_16: None},"(matmul_16, 8.0)",{},{add_63: None},,matmul_16,add_63,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_8
call_function,<built-in function add>,"{truediv_8: None, mul: None}","(truediv_8, mul)",{},{softmax_8: None},,truediv_8,softmax_8,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_63
call_function,<function softmax at 0x7f800dfdfca0>,{add_63: None},"(add_63,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_8_attention_self_dropout: None},,add_63,bert_encoder_layer_8_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_8
call_module,bert.encoder.layer.8.attention.self.dropout,{softmax_8: None},"(softmax_8,)",{},{matmul_17: None},,softmax_8,matmul_17,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.8.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_8_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_8_attention_self_dropout: None, permute_33: None}","(bert_encoder_layer_8_attention_self_dropout, permute_33)",{},{permute_35: None},,bert_encoder_layer_8_attention_self_dropout,permute_35,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_17
call_method,permute,{matmul_17: None},"(matmul_17, 0, 2, 1, 3)",{},{contiguous_8: None},,matmul_17,contiguous_8,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_35
call_method,contiguous,{permute_35: None},"(permute_35,)",{},"{size_37: None, view_35: None}",,permute_35,size_37,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_8
call_method,size,{contiguous_8: None},"(contiguous_8,)",{},{getitem_41: None},,contiguous_8,getitem_41,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_37
call_function,<built-in function getitem>,{size_37: None},"(size_37, slice(None, -2, None))",{},{add_64: None},,size_37,add_64,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_41
call_function,<built-in function add>,{getitem_41: None},"(getitem_41, (1024,))",{},{view_35: None},,getitem_41,view_35,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_64
call_method,view,"{contiguous_8: None, add_64: None}","(contiguous_8, add_64)",{},{bert_encoder_layer_8_attention_output_dense: None},,add_64,bert_encoder_layer_8_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_35
call_module,bert.encoder.layer.8.attention.output.dense,{view_35: None},"(view_35,)",{},{bert_encoder_layer_8_attention_output_dropout: None},,view_35,bert_encoder_layer_8_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.8.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_8_attention_output_dense
call_module,bert.encoder.layer.8.attention.output.dropout,{bert_encoder_layer_8_attention_output_dense: None},"(bert_encoder_layer_8_attention_output_dense,)",{},{add_65: None},,bert_encoder_layer_8_attention_output_dense,add_65,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.8.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_8_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_8_attention_output_dropout: None, bert_encoder_layer_7_output_layer_norm: None}","(bert_encoder_layer_8_attention_output_dropout, bert_encoder_layer_7_output_layer_norm)",{},{bert_encoder_layer_8_attention_output_layer_norm: None},,bert_encoder_layer_8_attention_output_dropout,bert_encoder_layer_8_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_65
call_module,bert.encoder.layer.8.attention.output.LayerNorm,{add_65: None},"(add_65,)",{},"{bert_encoder_layer_8_intermediate_dense: None, add_66: None}",,add_65,bert_encoder_layer_8_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.8.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.8.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_8_attention_output_layer_norm
call_module,bert.encoder.layer.8.intermediate.dense,{bert_encoder_layer_8_attention_output_layer_norm: None},"(bert_encoder_layer_8_attention_output_layer_norm,)",{},{gelu_8: None},,bert_encoder_layer_8_attention_output_layer_norm,gelu_8,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.8.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_8_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_8_intermediate_dense: None},"(bert_encoder_layer_8_intermediate_dense,)",{},{bert_encoder_layer_8_output_dense: None},,bert_encoder_layer_8_intermediate_dense,bert_encoder_layer_8_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.8.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_8
call_module,bert.encoder.layer.8.output.dense,{gelu_8: None},"(gelu_8,)",{},{bert_encoder_layer_8_output_dropout: None},,gelu_8,bert_encoder_layer_8_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.8.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_8_output_dense
call_module,bert.encoder.layer.8.output.dropout,{bert_encoder_layer_8_output_dense: None},"(bert_encoder_layer_8_output_dense,)",{},{add_66: None},,bert_encoder_layer_8_output_dense,add_66,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.8.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_8_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_8_output_dropout: None, bert_encoder_layer_8_attention_output_layer_norm: None}","(bert_encoder_layer_8_output_dropout, bert_encoder_layer_8_attention_output_layer_norm)",{},{bert_encoder_layer_8_output_layer_norm: None},,bert_encoder_layer_8_output_dropout,bert_encoder_layer_8_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_66
call_module,bert.encoder.layer.8.output.LayerNorm,{add_66: None},"(add_66,)",{},"{bert_encoder_layer_9_attention_self_query: None, bert_encoder_layer_9_attention_self_key: None, bert_encoder_layer_9_attention_self_value: None, add_72: None}",,add_66,bert_encoder_layer_9_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.8', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.8.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.8.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_8_output_layer_norm
call_module,bert.encoder.layer.9.attention.self.query,{bert_encoder_layer_8_output_layer_norm: None},"(bert_encoder_layer_8_output_layer_norm,)",{},"{size_40: None, view_38: None}",,bert_encoder_layer_8_output_layer_norm,bert_encoder_layer_9_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.9.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_9_attention_self_query
call_module,bert.encoder.layer.9.attention.self.key,{bert_encoder_layer_8_output_layer_norm: None},"(bert_encoder_layer_8_output_layer_norm,)",{},"{size_38: None, view_36: None}",,bert_encoder_layer_9_attention_self_query,size_38,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.9.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_9_attention_self_key
call_method,size,{bert_encoder_layer_9_attention_self_key: None},"(bert_encoder_layer_9_attention_self_key,)",{},{getitem_42: None},,bert_encoder_layer_9_attention_self_key,getitem_42,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_38
call_function,<built-in function getitem>,{size_38: None},"(size_38, slice(None, -1, None))",{},{add_67: None},,size_38,add_67,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_42
call_function,<built-in function add>,{getitem_42: None},"(getitem_42, (16, 64))",{},{view_36: None},,getitem_42,view_36,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_67
call_method,view,"{bert_encoder_layer_9_attention_self_key: None, add_67: None}","(bert_encoder_layer_9_attention_self_key, add_67)",{},{permute_36: None},,add_67,permute_36,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_36
call_method,permute,{view_36: None},"(view_36, 0, 2, 1, 3)",{},{transpose_9: None},,view_36,bert_encoder_layer_9_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_36
call_module,bert.encoder.layer.9.attention.self.value,{bert_encoder_layer_8_output_layer_norm: None},"(bert_encoder_layer_8_output_layer_norm,)",{},"{size_39: None, view_37: None}",,permute_36,size_39,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.9.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_9_attention_self_value
call_method,size,{bert_encoder_layer_9_attention_self_value: None},"(bert_encoder_layer_9_attention_self_value,)",{},{getitem_43: None},,bert_encoder_layer_9_attention_self_value,getitem_43,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_39
call_function,<built-in function getitem>,{size_39: None},"(size_39, slice(None, -1, None))",{},{add_68: None},,size_39,add_68,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_43
call_function,<built-in function add>,{getitem_43: None},"(getitem_43, (16, 64))",{},{view_37: None},,getitem_43,view_37,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_68
call_method,view,"{bert_encoder_layer_9_attention_self_value: None, add_68: None}","(bert_encoder_layer_9_attention_self_value, add_68)",{},{permute_37: None},,add_68,permute_37,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_37
call_method,permute,{view_37: None},"(view_37, 0, 2, 1, 3)",{},{matmul_19: None},,view_37,size_40,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_37
call_method,size,{bert_encoder_layer_9_attention_self_query: None},"(bert_encoder_layer_9_attention_self_query,)",{},{getitem_44: None},,permute_37,getitem_44,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_40
call_function,<built-in function getitem>,{size_40: None},"(size_40, slice(None, -1, None))",{},{add_69: None},,size_40,add_69,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_44
call_function,<built-in function add>,{getitem_44: None},"(getitem_44, (16, 64))",{},{view_38: None},,getitem_44,view_38,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_69
call_method,view,"{bert_encoder_layer_9_attention_self_query: None, add_69: None}","(bert_encoder_layer_9_attention_self_query, add_69)",{},{permute_38: None},,add_69,permute_38,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_38
call_method,permute,{view_38: None},"(view_38, 0, 2, 1, 3)",{},{matmul_18: None},,view_38,transpose_9,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_38
call_method,transpose,{permute_36: None},"(permute_36, -1, -2)",{},{matmul_18: None},,permute_38,matmul_18,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_9
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_38: None, transpose_9: None}","(permute_38, transpose_9)",{},{truediv_9: None},,transpose_9,truediv_9,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_18
call_function,<built-in function truediv>,{matmul_18: None},"(matmul_18, 8.0)",{},{add_70: None},,matmul_18,add_70,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_9
call_function,<built-in function add>,"{truediv_9: None, mul: None}","(truediv_9, mul)",{},{softmax_9: None},,truediv_9,softmax_9,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_70
call_function,<function softmax at 0x7f800dfdfca0>,{add_70: None},"(add_70,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_9_attention_self_dropout: None},,add_70,bert_encoder_layer_9_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_9
call_module,bert.encoder.layer.9.attention.self.dropout,{softmax_9: None},"(softmax_9,)",{},{matmul_19: None},,softmax_9,matmul_19,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.9.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_9_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_9_attention_self_dropout: None, permute_37: None}","(bert_encoder_layer_9_attention_self_dropout, permute_37)",{},{permute_39: None},,bert_encoder_layer_9_attention_self_dropout,permute_39,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_19
call_method,permute,{matmul_19: None},"(matmul_19, 0, 2, 1, 3)",{},{contiguous_9: None},,matmul_19,contiguous_9,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_39
call_method,contiguous,{permute_39: None},"(permute_39,)",{},"{size_41: None, view_39: None}",,permute_39,size_41,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_9
call_method,size,{contiguous_9: None},"(contiguous_9,)",{},{getitem_45: None},,contiguous_9,getitem_45,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_41
call_function,<built-in function getitem>,{size_41: None},"(size_41, slice(None, -2, None))",{},{add_71: None},,size_41,add_71,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_45
call_function,<built-in function add>,{getitem_45: None},"(getitem_45, (1024,))",{},{view_39: None},,getitem_45,view_39,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_71
call_method,view,"{contiguous_9: None, add_71: None}","(contiguous_9, add_71)",{},{bert_encoder_layer_9_attention_output_dense: None},,add_71,bert_encoder_layer_9_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_39
call_module,bert.encoder.layer.9.attention.output.dense,{view_39: None},"(view_39,)",{},{bert_encoder_layer_9_attention_output_dropout: None},,view_39,bert_encoder_layer_9_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.9.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_9_attention_output_dense
call_module,bert.encoder.layer.9.attention.output.dropout,{bert_encoder_layer_9_attention_output_dense: None},"(bert_encoder_layer_9_attention_output_dense,)",{},{add_72: None},,bert_encoder_layer_9_attention_output_dense,add_72,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.9.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_9_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_9_attention_output_dropout: None, bert_encoder_layer_8_output_layer_norm: None}","(bert_encoder_layer_9_attention_output_dropout, bert_encoder_layer_8_output_layer_norm)",{},{bert_encoder_layer_9_attention_output_layer_norm: None},,bert_encoder_layer_9_attention_output_dropout,bert_encoder_layer_9_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_72
call_module,bert.encoder.layer.9.attention.output.LayerNorm,{add_72: None},"(add_72,)",{},"{bert_encoder_layer_9_intermediate_dense: None, add_73: None}",,add_72,bert_encoder_layer_9_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.9.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.9.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_9_attention_output_layer_norm
call_module,bert.encoder.layer.9.intermediate.dense,{bert_encoder_layer_9_attention_output_layer_norm: None},"(bert_encoder_layer_9_attention_output_layer_norm,)",{},{gelu_9: None},,bert_encoder_layer_9_attention_output_layer_norm,gelu_9,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.9.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_9_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_9_intermediate_dense: None},"(bert_encoder_layer_9_intermediate_dense,)",{},{bert_encoder_layer_9_output_dense: None},,bert_encoder_layer_9_intermediate_dense,bert_encoder_layer_9_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.9.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_9
call_module,bert.encoder.layer.9.output.dense,{gelu_9: None},"(gelu_9,)",{},{bert_encoder_layer_9_output_dropout: None},,gelu_9,bert_encoder_layer_9_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.9.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_9_output_dense
call_module,bert.encoder.layer.9.output.dropout,{bert_encoder_layer_9_output_dense: None},"(bert_encoder_layer_9_output_dense,)",{},{add_73: None},,bert_encoder_layer_9_output_dense,add_73,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.9.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_9_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_9_output_dropout: None, bert_encoder_layer_9_attention_output_layer_norm: None}","(bert_encoder_layer_9_output_dropout, bert_encoder_layer_9_attention_output_layer_norm)",{},{bert_encoder_layer_9_output_layer_norm: None},,bert_encoder_layer_9_output_dropout,bert_encoder_layer_9_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_73
call_module,bert.encoder.layer.9.output.LayerNorm,{add_73: None},"(add_73,)",{},"{bert_encoder_layer_10_attention_self_query: None, bert_encoder_layer_10_attention_self_key: None, bert_encoder_layer_10_attention_self_value: None, add_79: None}",,add_73,bert_encoder_layer_10_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.9', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.9.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.9.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_9_output_layer_norm
call_module,bert.encoder.layer.10.attention.self.query,{bert_encoder_layer_9_output_layer_norm: None},"(bert_encoder_layer_9_output_layer_norm,)",{},"{size_44: None, view_42: None}",,bert_encoder_layer_9_output_layer_norm,bert_encoder_layer_10_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.10.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_10_attention_self_query
call_module,bert.encoder.layer.10.attention.self.key,{bert_encoder_layer_9_output_layer_norm: None},"(bert_encoder_layer_9_output_layer_norm,)",{},"{size_42: None, view_40: None}",,bert_encoder_layer_10_attention_self_query,size_42,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.10.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_10_attention_self_key
call_method,size,{bert_encoder_layer_10_attention_self_key: None},"(bert_encoder_layer_10_attention_self_key,)",{},{getitem_46: None},,bert_encoder_layer_10_attention_self_key,getitem_46,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_42
call_function,<built-in function getitem>,{size_42: None},"(size_42, slice(None, -1, None))",{},{add_74: None},,size_42,add_74,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_46
call_function,<built-in function add>,{getitem_46: None},"(getitem_46, (16, 64))",{},{view_40: None},,getitem_46,view_40,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_74
call_method,view,"{bert_encoder_layer_10_attention_self_key: None, add_74: None}","(bert_encoder_layer_10_attention_self_key, add_74)",{},{permute_40: None},,add_74,permute_40,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_40
call_method,permute,{view_40: None},"(view_40, 0, 2, 1, 3)",{},{transpose_10: None},,view_40,bert_encoder_layer_10_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_40
call_module,bert.encoder.layer.10.attention.self.value,{bert_encoder_layer_9_output_layer_norm: None},"(bert_encoder_layer_9_output_layer_norm,)",{},"{size_43: None, view_41: None}",,permute_40,size_43,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.10.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_10_attention_self_value
call_method,size,{bert_encoder_layer_10_attention_self_value: None},"(bert_encoder_layer_10_attention_self_value,)",{},{getitem_47: None},,bert_encoder_layer_10_attention_self_value,getitem_47,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_43
call_function,<built-in function getitem>,{size_43: None},"(size_43, slice(None, -1, None))",{},{add_75: None},,size_43,add_75,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_47
call_function,<built-in function add>,{getitem_47: None},"(getitem_47, (16, 64))",{},{view_41: None},,getitem_47,view_41,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_75
call_method,view,"{bert_encoder_layer_10_attention_self_value: None, add_75: None}","(bert_encoder_layer_10_attention_self_value, add_75)",{},{permute_41: None},,add_75,permute_41,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_41
call_method,permute,{view_41: None},"(view_41, 0, 2, 1, 3)",{},{matmul_21: None},,view_41,size_44,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_41
call_method,size,{bert_encoder_layer_10_attention_self_query: None},"(bert_encoder_layer_10_attention_self_query,)",{},{getitem_48: None},,permute_41,getitem_48,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_44
call_function,<built-in function getitem>,{size_44: None},"(size_44, slice(None, -1, None))",{},{add_76: None},,size_44,add_76,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_48
call_function,<built-in function add>,{getitem_48: None},"(getitem_48, (16, 64))",{},{view_42: None},,getitem_48,view_42,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_76
call_method,view,"{bert_encoder_layer_10_attention_self_query: None, add_76: None}","(bert_encoder_layer_10_attention_self_query, add_76)",{},{permute_42: None},,add_76,permute_42,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_42
call_method,permute,{view_42: None},"(view_42, 0, 2, 1, 3)",{},{matmul_20: None},,view_42,transpose_10,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_42
call_method,transpose,{permute_40: None},"(permute_40, -1, -2)",{},{matmul_20: None},,permute_42,matmul_20,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_10
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_42: None, transpose_10: None}","(permute_42, transpose_10)",{},{truediv_10: None},,transpose_10,truediv_10,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_20
call_function,<built-in function truediv>,{matmul_20: None},"(matmul_20, 8.0)",{},{add_77: None},,matmul_20,add_77,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_10
call_function,<built-in function add>,"{truediv_10: None, mul: None}","(truediv_10, mul)",{},{softmax_10: None},,truediv_10,softmax_10,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_77
call_function,<function softmax at 0x7f800dfdfca0>,{add_77: None},"(add_77,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_10_attention_self_dropout: None},,add_77,bert_encoder_layer_10_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_10
call_module,bert.encoder.layer.10.attention.self.dropout,{softmax_10: None},"(softmax_10,)",{},{matmul_21: None},,softmax_10,matmul_21,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.10.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_10_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_10_attention_self_dropout: None, permute_41: None}","(bert_encoder_layer_10_attention_self_dropout, permute_41)",{},{permute_43: None},,bert_encoder_layer_10_attention_self_dropout,permute_43,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_21
call_method,permute,{matmul_21: None},"(matmul_21, 0, 2, 1, 3)",{},{contiguous_10: None},,matmul_21,contiguous_10,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_43
call_method,contiguous,{permute_43: None},"(permute_43,)",{},"{size_45: None, view_43: None}",,permute_43,size_45,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_10
call_method,size,{contiguous_10: None},"(contiguous_10,)",{},{getitem_49: None},,contiguous_10,getitem_49,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_45
call_function,<built-in function getitem>,{size_45: None},"(size_45, slice(None, -2, None))",{},{add_78: None},,size_45,add_78,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_49
call_function,<built-in function add>,{getitem_49: None},"(getitem_49, (1024,))",{},{view_43: None},,getitem_49,view_43,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_78
call_method,view,"{contiguous_10: None, add_78: None}","(contiguous_10, add_78)",{},{bert_encoder_layer_10_attention_output_dense: None},,add_78,bert_encoder_layer_10_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_43
call_module,bert.encoder.layer.10.attention.output.dense,{view_43: None},"(view_43,)",{},{bert_encoder_layer_10_attention_output_dropout: None},,view_43,bert_encoder_layer_10_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.10.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_10_attention_output_dense
call_module,bert.encoder.layer.10.attention.output.dropout,{bert_encoder_layer_10_attention_output_dense: None},"(bert_encoder_layer_10_attention_output_dense,)",{},{add_79: None},,bert_encoder_layer_10_attention_output_dense,add_79,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.10.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_10_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_10_attention_output_dropout: None, bert_encoder_layer_9_output_layer_norm: None}","(bert_encoder_layer_10_attention_output_dropout, bert_encoder_layer_9_output_layer_norm)",{},{bert_encoder_layer_10_attention_output_layer_norm: None},,bert_encoder_layer_10_attention_output_dropout,bert_encoder_layer_10_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_79
call_module,bert.encoder.layer.10.attention.output.LayerNorm,{add_79: None},"(add_79,)",{},"{bert_encoder_layer_10_intermediate_dense: None, add_80: None}",,add_79,bert_encoder_layer_10_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.10.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.10.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_10_attention_output_layer_norm
call_module,bert.encoder.layer.10.intermediate.dense,{bert_encoder_layer_10_attention_output_layer_norm: None},"(bert_encoder_layer_10_attention_output_layer_norm,)",{},{gelu_10: None},,bert_encoder_layer_10_attention_output_layer_norm,gelu_10,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.10.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_10_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_10_intermediate_dense: None},"(bert_encoder_layer_10_intermediate_dense,)",{},{bert_encoder_layer_10_output_dense: None},,bert_encoder_layer_10_intermediate_dense,bert_encoder_layer_10_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.10.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_10
call_module,bert.encoder.layer.10.output.dense,{gelu_10: None},"(gelu_10,)",{},{bert_encoder_layer_10_output_dropout: None},,gelu_10,bert_encoder_layer_10_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.10.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_10_output_dense
call_module,bert.encoder.layer.10.output.dropout,{bert_encoder_layer_10_output_dense: None},"(bert_encoder_layer_10_output_dense,)",{},{add_80: None},,bert_encoder_layer_10_output_dense,add_80,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.10.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_10_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_10_output_dropout: None, bert_encoder_layer_10_attention_output_layer_norm: None}","(bert_encoder_layer_10_output_dropout, bert_encoder_layer_10_attention_output_layer_norm)",{},{bert_encoder_layer_10_output_layer_norm: None},,bert_encoder_layer_10_output_dropout,bert_encoder_layer_10_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_80
call_module,bert.encoder.layer.10.output.LayerNorm,{add_80: None},"(add_80,)",{},"{bert_encoder_layer_11_attention_self_query: None, bert_encoder_layer_11_attention_self_key: None, bert_encoder_layer_11_attention_self_value: None, add_86: None}",,add_80,bert_encoder_layer_11_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.10', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.10.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.10.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_10_output_layer_norm
call_module,bert.encoder.layer.11.attention.self.query,{bert_encoder_layer_10_output_layer_norm: None},"(bert_encoder_layer_10_output_layer_norm,)",{},"{size_48: None, view_46: None}",,bert_encoder_layer_10_output_layer_norm,bert_encoder_layer_11_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.11.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_11_attention_self_query
call_module,bert.encoder.layer.11.attention.self.key,{bert_encoder_layer_10_output_layer_norm: None},"(bert_encoder_layer_10_output_layer_norm,)",{},"{size_46: None, view_44: None}",,bert_encoder_layer_11_attention_self_query,size_46,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.11.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_11_attention_self_key
call_method,size,{bert_encoder_layer_11_attention_self_key: None},"(bert_encoder_layer_11_attention_self_key,)",{},{getitem_50: None},,bert_encoder_layer_11_attention_self_key,getitem_50,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_46
call_function,<built-in function getitem>,{size_46: None},"(size_46, slice(None, -1, None))",{},{add_81: None},,size_46,add_81,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_50
call_function,<built-in function add>,{getitem_50: None},"(getitem_50, (16, 64))",{},{view_44: None},,getitem_50,view_44,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_81
call_method,view,"{bert_encoder_layer_11_attention_self_key: None, add_81: None}","(bert_encoder_layer_11_attention_self_key, add_81)",{},{permute_44: None},,add_81,permute_44,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_44
call_method,permute,{view_44: None},"(view_44, 0, 2, 1, 3)",{},{transpose_11: None},,view_44,bert_encoder_layer_11_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_44
call_module,bert.encoder.layer.11.attention.self.value,{bert_encoder_layer_10_output_layer_norm: None},"(bert_encoder_layer_10_output_layer_norm,)",{},"{size_47: None, view_45: None}",,permute_44,size_47,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.11.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_11_attention_self_value
call_method,size,{bert_encoder_layer_11_attention_self_value: None},"(bert_encoder_layer_11_attention_self_value,)",{},{getitem_51: None},,bert_encoder_layer_11_attention_self_value,getitem_51,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_47
call_function,<built-in function getitem>,{size_47: None},"(size_47, slice(None, -1, None))",{},{add_82: None},,size_47,add_82,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_51
call_function,<built-in function add>,{getitem_51: None},"(getitem_51, (16, 64))",{},{view_45: None},,getitem_51,view_45,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_82
call_method,view,"{bert_encoder_layer_11_attention_self_value: None, add_82: None}","(bert_encoder_layer_11_attention_self_value, add_82)",{},{permute_45: None},,add_82,permute_45,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_45
call_method,permute,{view_45: None},"(view_45, 0, 2, 1, 3)",{},{matmul_23: None},,view_45,size_48,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_45
call_method,size,{bert_encoder_layer_11_attention_self_query: None},"(bert_encoder_layer_11_attention_self_query,)",{},{getitem_52: None},,permute_45,getitem_52,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_48
call_function,<built-in function getitem>,{size_48: None},"(size_48, slice(None, -1, None))",{},{add_83: None},,size_48,add_83,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_52
call_function,<built-in function add>,{getitem_52: None},"(getitem_52, (16, 64))",{},{view_46: None},,getitem_52,view_46,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_83
call_method,view,"{bert_encoder_layer_11_attention_self_query: None, add_83: None}","(bert_encoder_layer_11_attention_self_query, add_83)",{},{permute_46: None},,add_83,permute_46,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_46
call_method,permute,{view_46: None},"(view_46, 0, 2, 1, 3)",{},{matmul_22: None},,view_46,transpose_11,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_46
call_method,transpose,{permute_44: None},"(permute_44, -1, -2)",{},{matmul_22: None},,permute_46,matmul_22,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_11
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_46: None, transpose_11: None}","(permute_46, transpose_11)",{},{truediv_11: None},,transpose_11,truediv_11,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_22
call_function,<built-in function truediv>,{matmul_22: None},"(matmul_22, 8.0)",{},{add_84: None},,matmul_22,add_84,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_11
call_function,<built-in function add>,"{truediv_11: None, mul: None}","(truediv_11, mul)",{},{softmax_11: None},,truediv_11,softmax_11,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_84
call_function,<function softmax at 0x7f800dfdfca0>,{add_84: None},"(add_84,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_11_attention_self_dropout: None},,add_84,bert_encoder_layer_11_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_11
call_module,bert.encoder.layer.11.attention.self.dropout,{softmax_11: None},"(softmax_11,)",{},{matmul_23: None},,softmax_11,matmul_23,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.11.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_11_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_11_attention_self_dropout: None, permute_45: None}","(bert_encoder_layer_11_attention_self_dropout, permute_45)",{},{permute_47: None},,bert_encoder_layer_11_attention_self_dropout,permute_47,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_23
call_method,permute,{matmul_23: None},"(matmul_23, 0, 2, 1, 3)",{},{contiguous_11: None},,matmul_23,contiguous_11,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_47
call_method,contiguous,{permute_47: None},"(permute_47,)",{},"{size_49: None, view_47: None}",,permute_47,size_49,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_11
call_method,size,{contiguous_11: None},"(contiguous_11,)",{},{getitem_53: None},,contiguous_11,getitem_53,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_49
call_function,<built-in function getitem>,{size_49: None},"(size_49, slice(None, -2, None))",{},{add_85: None},,size_49,add_85,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_53
call_function,<built-in function add>,{getitem_53: None},"(getitem_53, (1024,))",{},{view_47: None},,getitem_53,view_47,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_85
call_method,view,"{contiguous_11: None, add_85: None}","(contiguous_11, add_85)",{},{bert_encoder_layer_11_attention_output_dense: None},,add_85,bert_encoder_layer_11_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_47
call_module,bert.encoder.layer.11.attention.output.dense,{view_47: None},"(view_47,)",{},{bert_encoder_layer_11_attention_output_dropout: None},,view_47,bert_encoder_layer_11_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.11.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_11_attention_output_dense
call_module,bert.encoder.layer.11.attention.output.dropout,{bert_encoder_layer_11_attention_output_dense: None},"(bert_encoder_layer_11_attention_output_dense,)",{},{add_86: None},,bert_encoder_layer_11_attention_output_dense,add_86,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.11.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_11_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_11_attention_output_dropout: None, bert_encoder_layer_10_output_layer_norm: None}","(bert_encoder_layer_11_attention_output_dropout, bert_encoder_layer_10_output_layer_norm)",{},{bert_encoder_layer_11_attention_output_layer_norm: None},,bert_encoder_layer_11_attention_output_dropout,bert_encoder_layer_11_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_86
call_module,bert.encoder.layer.11.attention.output.LayerNorm,{add_86: None},"(add_86,)",{},"{bert_encoder_layer_11_intermediate_dense: None, add_87: None}",,add_86,bert_encoder_layer_11_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.11.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.11.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_11_attention_output_layer_norm
call_module,bert.encoder.layer.11.intermediate.dense,{bert_encoder_layer_11_attention_output_layer_norm: None},"(bert_encoder_layer_11_attention_output_layer_norm,)",{},{gelu_11: None},,bert_encoder_layer_11_attention_output_layer_norm,gelu_11,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.11.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_11_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_11_intermediate_dense: None},"(bert_encoder_layer_11_intermediate_dense,)",{},{bert_encoder_layer_11_output_dense: None},,bert_encoder_layer_11_intermediate_dense,bert_encoder_layer_11_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.11.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_11
call_module,bert.encoder.layer.11.output.dense,{gelu_11: None},"(gelu_11,)",{},{bert_encoder_layer_11_output_dropout: None},,gelu_11,bert_encoder_layer_11_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.11.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_11_output_dense
call_module,bert.encoder.layer.11.output.dropout,{bert_encoder_layer_11_output_dense: None},"(bert_encoder_layer_11_output_dense,)",{},{add_87: None},,bert_encoder_layer_11_output_dense,add_87,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.11.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_11_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_11_output_dropout: None, bert_encoder_layer_11_attention_output_layer_norm: None}","(bert_encoder_layer_11_output_dropout, bert_encoder_layer_11_attention_output_layer_norm)",{},{bert_encoder_layer_11_output_layer_norm: None},,bert_encoder_layer_11_output_dropout,bert_encoder_layer_11_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_87
call_module,bert.encoder.layer.11.output.LayerNorm,{add_87: None},"(add_87,)",{},"{bert_encoder_layer_12_attention_self_query: None, bert_encoder_layer_12_attention_self_key: None, bert_encoder_layer_12_attention_self_value: None, add_93: None}",,add_87,bert_encoder_layer_12_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.11', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.11.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.11.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_11_output_layer_norm
call_module,bert.encoder.layer.12.attention.self.query,{bert_encoder_layer_11_output_layer_norm: None},"(bert_encoder_layer_11_output_layer_norm,)",{},"{size_52: None, view_50: None}",,bert_encoder_layer_11_output_layer_norm,bert_encoder_layer_12_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.12.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_12_attention_self_query
call_module,bert.encoder.layer.12.attention.self.key,{bert_encoder_layer_11_output_layer_norm: None},"(bert_encoder_layer_11_output_layer_norm,)",{},"{size_50: None, view_48: None}",,bert_encoder_layer_12_attention_self_query,size_50,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.12.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_12_attention_self_key
call_method,size,{bert_encoder_layer_12_attention_self_key: None},"(bert_encoder_layer_12_attention_self_key,)",{},{getitem_54: None},,bert_encoder_layer_12_attention_self_key,getitem_54,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_50
call_function,<built-in function getitem>,{size_50: None},"(size_50, slice(None, -1, None))",{},{add_88: None},,size_50,add_88,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_54
call_function,<built-in function add>,{getitem_54: None},"(getitem_54, (16, 64))",{},{view_48: None},,getitem_54,view_48,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_88
call_method,view,"{bert_encoder_layer_12_attention_self_key: None, add_88: None}","(bert_encoder_layer_12_attention_self_key, add_88)",{},{permute_48: None},,add_88,permute_48,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_48
call_method,permute,{view_48: None},"(view_48, 0, 2, 1, 3)",{},{transpose_12: None},,view_48,bert_encoder_layer_12_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_48
call_module,bert.encoder.layer.12.attention.self.value,{bert_encoder_layer_11_output_layer_norm: None},"(bert_encoder_layer_11_output_layer_norm,)",{},"{size_51: None, view_49: None}",,permute_48,size_51,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.12.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_12_attention_self_value
call_method,size,{bert_encoder_layer_12_attention_self_value: None},"(bert_encoder_layer_12_attention_self_value,)",{},{getitem_55: None},,bert_encoder_layer_12_attention_self_value,getitem_55,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_51
call_function,<built-in function getitem>,{size_51: None},"(size_51, slice(None, -1, None))",{},{add_89: None},,size_51,add_89,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_55
call_function,<built-in function add>,{getitem_55: None},"(getitem_55, (16, 64))",{},{view_49: None},,getitem_55,view_49,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_89
call_method,view,"{bert_encoder_layer_12_attention_self_value: None, add_89: None}","(bert_encoder_layer_12_attention_self_value, add_89)",{},{permute_49: None},,add_89,permute_49,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_49
call_method,permute,{view_49: None},"(view_49, 0, 2, 1, 3)",{},{matmul_25: None},,view_49,size_52,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_49
call_method,size,{bert_encoder_layer_12_attention_self_query: None},"(bert_encoder_layer_12_attention_self_query,)",{},{getitem_56: None},,permute_49,getitem_56,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_52
call_function,<built-in function getitem>,{size_52: None},"(size_52, slice(None, -1, None))",{},{add_90: None},,size_52,add_90,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_56
call_function,<built-in function add>,{getitem_56: None},"(getitem_56, (16, 64))",{},{view_50: None},,getitem_56,view_50,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_90
call_method,view,"{bert_encoder_layer_12_attention_self_query: None, add_90: None}","(bert_encoder_layer_12_attention_self_query, add_90)",{},{permute_50: None},,add_90,permute_50,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_50
call_method,permute,{view_50: None},"(view_50, 0, 2, 1, 3)",{},{matmul_24: None},,view_50,transpose_12,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_50
call_method,transpose,{permute_48: None},"(permute_48, -1, -2)",{},{matmul_24: None},,permute_50,matmul_24,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_12
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_50: None, transpose_12: None}","(permute_50, transpose_12)",{},{truediv_12: None},,transpose_12,truediv_12,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_24
call_function,<built-in function truediv>,{matmul_24: None},"(matmul_24, 8.0)",{},{add_91: None},,matmul_24,add_91,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_12
call_function,<built-in function add>,"{truediv_12: None, mul: None}","(truediv_12, mul)",{},{softmax_12: None},,truediv_12,softmax_12,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_91
call_function,<function softmax at 0x7f800dfdfca0>,{add_91: None},"(add_91,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_12_attention_self_dropout: None},,add_91,bert_encoder_layer_12_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_12
call_module,bert.encoder.layer.12.attention.self.dropout,{softmax_12: None},"(softmax_12,)",{},{matmul_25: None},,softmax_12,matmul_25,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.12.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_12_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_12_attention_self_dropout: None, permute_49: None}","(bert_encoder_layer_12_attention_self_dropout, permute_49)",{},{permute_51: None},,bert_encoder_layer_12_attention_self_dropout,permute_51,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_25
call_method,permute,{matmul_25: None},"(matmul_25, 0, 2, 1, 3)",{},{contiguous_12: None},,matmul_25,contiguous_12,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_51
call_method,contiguous,{permute_51: None},"(permute_51,)",{},"{size_53: None, view_51: None}",,permute_51,size_53,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_12
call_method,size,{contiguous_12: None},"(contiguous_12,)",{},{getitem_57: None},,contiguous_12,getitem_57,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_53
call_function,<built-in function getitem>,{size_53: None},"(size_53, slice(None, -2, None))",{},{add_92: None},,size_53,add_92,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_57
call_function,<built-in function add>,{getitem_57: None},"(getitem_57, (1024,))",{},{view_51: None},,getitem_57,view_51,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_92
call_method,view,"{contiguous_12: None, add_92: None}","(contiguous_12, add_92)",{},{bert_encoder_layer_12_attention_output_dense: None},,add_92,bert_encoder_layer_12_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_51
call_module,bert.encoder.layer.12.attention.output.dense,{view_51: None},"(view_51,)",{},{bert_encoder_layer_12_attention_output_dropout: None},,view_51,bert_encoder_layer_12_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.12.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_12_attention_output_dense
call_module,bert.encoder.layer.12.attention.output.dropout,{bert_encoder_layer_12_attention_output_dense: None},"(bert_encoder_layer_12_attention_output_dense,)",{},{add_93: None},,bert_encoder_layer_12_attention_output_dense,add_93,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.12.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_12_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_12_attention_output_dropout: None, bert_encoder_layer_11_output_layer_norm: None}","(bert_encoder_layer_12_attention_output_dropout, bert_encoder_layer_11_output_layer_norm)",{},{bert_encoder_layer_12_attention_output_layer_norm: None},,bert_encoder_layer_12_attention_output_dropout,bert_encoder_layer_12_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_93
call_module,bert.encoder.layer.12.attention.output.LayerNorm,{add_93: None},"(add_93,)",{},"{bert_encoder_layer_12_intermediate_dense: None, add_94: None}",,add_93,bert_encoder_layer_12_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.12.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.12.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_12_attention_output_layer_norm
call_module,bert.encoder.layer.12.intermediate.dense,{bert_encoder_layer_12_attention_output_layer_norm: None},"(bert_encoder_layer_12_attention_output_layer_norm,)",{},{gelu_12: None},,bert_encoder_layer_12_attention_output_layer_norm,gelu_12,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.12.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_12_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_12_intermediate_dense: None},"(bert_encoder_layer_12_intermediate_dense,)",{},{bert_encoder_layer_12_output_dense: None},,bert_encoder_layer_12_intermediate_dense,bert_encoder_layer_12_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.12.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_12
call_module,bert.encoder.layer.12.output.dense,{gelu_12: None},"(gelu_12,)",{},{bert_encoder_layer_12_output_dropout: None},,gelu_12,bert_encoder_layer_12_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.12.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_12_output_dense
call_module,bert.encoder.layer.12.output.dropout,{bert_encoder_layer_12_output_dense: None},"(bert_encoder_layer_12_output_dense,)",{},{add_94: None},,bert_encoder_layer_12_output_dense,add_94,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.12.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_12_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_12_output_dropout: None, bert_encoder_layer_12_attention_output_layer_norm: None}","(bert_encoder_layer_12_output_dropout, bert_encoder_layer_12_attention_output_layer_norm)",{},{bert_encoder_layer_12_output_layer_norm: None},,bert_encoder_layer_12_output_dropout,bert_encoder_layer_12_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_94
call_module,bert.encoder.layer.12.output.LayerNorm,{add_94: None},"(add_94,)",{},"{bert_encoder_layer_13_attention_self_query: None, bert_encoder_layer_13_attention_self_key: None, bert_encoder_layer_13_attention_self_value: None, add_100: None}",,add_94,bert_encoder_layer_13_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.12', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.12.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.12.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_12_output_layer_norm
call_module,bert.encoder.layer.13.attention.self.query,{bert_encoder_layer_12_output_layer_norm: None},"(bert_encoder_layer_12_output_layer_norm,)",{},"{size_56: None, view_54: None}",,bert_encoder_layer_12_output_layer_norm,bert_encoder_layer_13_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.13.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_13_attention_self_query
call_module,bert.encoder.layer.13.attention.self.key,{bert_encoder_layer_12_output_layer_norm: None},"(bert_encoder_layer_12_output_layer_norm,)",{},"{size_54: None, view_52: None}",,bert_encoder_layer_13_attention_self_query,size_54,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.13.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_13_attention_self_key
call_method,size,{bert_encoder_layer_13_attention_self_key: None},"(bert_encoder_layer_13_attention_self_key,)",{},{getitem_58: None},,bert_encoder_layer_13_attention_self_key,getitem_58,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_54
call_function,<built-in function getitem>,{size_54: None},"(size_54, slice(None, -1, None))",{},{add_95: None},,size_54,add_95,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_58
call_function,<built-in function add>,{getitem_58: None},"(getitem_58, (16, 64))",{},{view_52: None},,getitem_58,view_52,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_95
call_method,view,"{bert_encoder_layer_13_attention_self_key: None, add_95: None}","(bert_encoder_layer_13_attention_self_key, add_95)",{},{permute_52: None},,add_95,permute_52,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_52
call_method,permute,{view_52: None},"(view_52, 0, 2, 1, 3)",{},{transpose_13: None},,view_52,bert_encoder_layer_13_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_52
call_module,bert.encoder.layer.13.attention.self.value,{bert_encoder_layer_12_output_layer_norm: None},"(bert_encoder_layer_12_output_layer_norm,)",{},"{size_55: None, view_53: None}",,permute_52,size_55,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.13.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_13_attention_self_value
call_method,size,{bert_encoder_layer_13_attention_self_value: None},"(bert_encoder_layer_13_attention_self_value,)",{},{getitem_59: None},,bert_encoder_layer_13_attention_self_value,getitem_59,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_55
call_function,<built-in function getitem>,{size_55: None},"(size_55, slice(None, -1, None))",{},{add_96: None},,size_55,add_96,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_59
call_function,<built-in function add>,{getitem_59: None},"(getitem_59, (16, 64))",{},{view_53: None},,getitem_59,view_53,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_96
call_method,view,"{bert_encoder_layer_13_attention_self_value: None, add_96: None}","(bert_encoder_layer_13_attention_self_value, add_96)",{},{permute_53: None},,add_96,permute_53,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_53
call_method,permute,{view_53: None},"(view_53, 0, 2, 1, 3)",{},{matmul_27: None},,view_53,size_56,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_53
call_method,size,{bert_encoder_layer_13_attention_self_query: None},"(bert_encoder_layer_13_attention_self_query,)",{},{getitem_60: None},,permute_53,getitem_60,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_56
call_function,<built-in function getitem>,{size_56: None},"(size_56, slice(None, -1, None))",{},{add_97: None},,size_56,add_97,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_60
call_function,<built-in function add>,{getitem_60: None},"(getitem_60, (16, 64))",{},{view_54: None},,getitem_60,view_54,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_97
call_method,view,"{bert_encoder_layer_13_attention_self_query: None, add_97: None}","(bert_encoder_layer_13_attention_self_query, add_97)",{},{permute_54: None},,add_97,permute_54,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_54
call_method,permute,{view_54: None},"(view_54, 0, 2, 1, 3)",{},{matmul_26: None},,view_54,transpose_13,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_54
call_method,transpose,{permute_52: None},"(permute_52, -1, -2)",{},{matmul_26: None},,permute_54,matmul_26,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_13
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_54: None, transpose_13: None}","(permute_54, transpose_13)",{},{truediv_13: None},,transpose_13,truediv_13,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_26
call_function,<built-in function truediv>,{matmul_26: None},"(matmul_26, 8.0)",{},{add_98: None},,matmul_26,add_98,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_13
call_function,<built-in function add>,"{truediv_13: None, mul: None}","(truediv_13, mul)",{},{softmax_13: None},,truediv_13,softmax_13,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_98
call_function,<function softmax at 0x7f800dfdfca0>,{add_98: None},"(add_98,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_13_attention_self_dropout: None},,add_98,bert_encoder_layer_13_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_13
call_module,bert.encoder.layer.13.attention.self.dropout,{softmax_13: None},"(softmax_13,)",{},{matmul_27: None},,softmax_13,matmul_27,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.13.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_13_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_13_attention_self_dropout: None, permute_53: None}","(bert_encoder_layer_13_attention_self_dropout, permute_53)",{},{permute_55: None},,bert_encoder_layer_13_attention_self_dropout,permute_55,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_27
call_method,permute,{matmul_27: None},"(matmul_27, 0, 2, 1, 3)",{},{contiguous_13: None},,matmul_27,contiguous_13,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_55
call_method,contiguous,{permute_55: None},"(permute_55,)",{},"{size_57: None, view_55: None}",,permute_55,size_57,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_13
call_method,size,{contiguous_13: None},"(contiguous_13,)",{},{getitem_61: None},,contiguous_13,getitem_61,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_57
call_function,<built-in function getitem>,{size_57: None},"(size_57, slice(None, -2, None))",{},{add_99: None},,size_57,add_99,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_61
call_function,<built-in function add>,{getitem_61: None},"(getitem_61, (1024,))",{},{view_55: None},,getitem_61,view_55,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_99
call_method,view,"{contiguous_13: None, add_99: None}","(contiguous_13, add_99)",{},{bert_encoder_layer_13_attention_output_dense: None},,add_99,bert_encoder_layer_13_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_55
call_module,bert.encoder.layer.13.attention.output.dense,{view_55: None},"(view_55,)",{},{bert_encoder_layer_13_attention_output_dropout: None},,view_55,bert_encoder_layer_13_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.13.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_13_attention_output_dense
call_module,bert.encoder.layer.13.attention.output.dropout,{bert_encoder_layer_13_attention_output_dense: None},"(bert_encoder_layer_13_attention_output_dense,)",{},{add_100: None},,bert_encoder_layer_13_attention_output_dense,add_100,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.13.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_13_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_13_attention_output_dropout: None, bert_encoder_layer_12_output_layer_norm: None}","(bert_encoder_layer_13_attention_output_dropout, bert_encoder_layer_12_output_layer_norm)",{},{bert_encoder_layer_13_attention_output_layer_norm: None},,bert_encoder_layer_13_attention_output_dropout,bert_encoder_layer_13_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_100
call_module,bert.encoder.layer.13.attention.output.LayerNorm,{add_100: None},"(add_100,)",{},"{bert_encoder_layer_13_intermediate_dense: None, add_101: None}",,add_100,bert_encoder_layer_13_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.13.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.13.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_13_attention_output_layer_norm
call_module,bert.encoder.layer.13.intermediate.dense,{bert_encoder_layer_13_attention_output_layer_norm: None},"(bert_encoder_layer_13_attention_output_layer_norm,)",{},{gelu_13: None},,bert_encoder_layer_13_attention_output_layer_norm,gelu_13,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.13.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_13_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_13_intermediate_dense: None},"(bert_encoder_layer_13_intermediate_dense,)",{},{bert_encoder_layer_13_output_dense: None},,bert_encoder_layer_13_intermediate_dense,bert_encoder_layer_13_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.13.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_13
call_module,bert.encoder.layer.13.output.dense,{gelu_13: None},"(gelu_13,)",{},{bert_encoder_layer_13_output_dropout: None},,gelu_13,bert_encoder_layer_13_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.13.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_13_output_dense
call_module,bert.encoder.layer.13.output.dropout,{bert_encoder_layer_13_output_dense: None},"(bert_encoder_layer_13_output_dense,)",{},{add_101: None},,bert_encoder_layer_13_output_dense,add_101,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.13.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_13_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_13_output_dropout: None, bert_encoder_layer_13_attention_output_layer_norm: None}","(bert_encoder_layer_13_output_dropout, bert_encoder_layer_13_attention_output_layer_norm)",{},{bert_encoder_layer_13_output_layer_norm: None},,bert_encoder_layer_13_output_dropout,bert_encoder_layer_13_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_101
call_module,bert.encoder.layer.13.output.LayerNorm,{add_101: None},"(add_101,)",{},"{bert_encoder_layer_14_attention_self_query: None, bert_encoder_layer_14_attention_self_key: None, bert_encoder_layer_14_attention_self_value: None, add_107: None}",,add_101,bert_encoder_layer_14_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.13', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.13.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.13.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_13_output_layer_norm
call_module,bert.encoder.layer.14.attention.self.query,{bert_encoder_layer_13_output_layer_norm: None},"(bert_encoder_layer_13_output_layer_norm,)",{},"{size_60: None, view_58: None}",,bert_encoder_layer_13_output_layer_norm,bert_encoder_layer_14_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.14.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_14_attention_self_query
call_module,bert.encoder.layer.14.attention.self.key,{bert_encoder_layer_13_output_layer_norm: None},"(bert_encoder_layer_13_output_layer_norm,)",{},"{size_58: None, view_56: None}",,bert_encoder_layer_14_attention_self_query,size_58,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.14.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_14_attention_self_key
call_method,size,{bert_encoder_layer_14_attention_self_key: None},"(bert_encoder_layer_14_attention_self_key,)",{},{getitem_62: None},,bert_encoder_layer_14_attention_self_key,getitem_62,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_58
call_function,<built-in function getitem>,{size_58: None},"(size_58, slice(None, -1, None))",{},{add_102: None},,size_58,add_102,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_62
call_function,<built-in function add>,{getitem_62: None},"(getitem_62, (16, 64))",{},{view_56: None},,getitem_62,view_56,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_102
call_method,view,"{bert_encoder_layer_14_attention_self_key: None, add_102: None}","(bert_encoder_layer_14_attention_self_key, add_102)",{},{permute_56: None},,add_102,permute_56,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_56
call_method,permute,{view_56: None},"(view_56, 0, 2, 1, 3)",{},{transpose_14: None},,view_56,bert_encoder_layer_14_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_56
call_module,bert.encoder.layer.14.attention.self.value,{bert_encoder_layer_13_output_layer_norm: None},"(bert_encoder_layer_13_output_layer_norm,)",{},"{size_59: None, view_57: None}",,permute_56,size_59,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.14.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_14_attention_self_value
call_method,size,{bert_encoder_layer_14_attention_self_value: None},"(bert_encoder_layer_14_attention_self_value,)",{},{getitem_63: None},,bert_encoder_layer_14_attention_self_value,getitem_63,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_59
call_function,<built-in function getitem>,{size_59: None},"(size_59, slice(None, -1, None))",{},{add_103: None},,size_59,add_103,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_63
call_function,<built-in function add>,{getitem_63: None},"(getitem_63, (16, 64))",{},{view_57: None},,getitem_63,view_57,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_103
call_method,view,"{bert_encoder_layer_14_attention_self_value: None, add_103: None}","(bert_encoder_layer_14_attention_self_value, add_103)",{},{permute_57: None},,add_103,permute_57,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_57
call_method,permute,{view_57: None},"(view_57, 0, 2, 1, 3)",{},{matmul_29: None},,view_57,size_60,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_57
call_method,size,{bert_encoder_layer_14_attention_self_query: None},"(bert_encoder_layer_14_attention_self_query,)",{},{getitem_64: None},,permute_57,getitem_64,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_60
call_function,<built-in function getitem>,{size_60: None},"(size_60, slice(None, -1, None))",{},{add_104: None},,size_60,add_104,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_64
call_function,<built-in function add>,{getitem_64: None},"(getitem_64, (16, 64))",{},{view_58: None},,getitem_64,view_58,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_104
call_method,view,"{bert_encoder_layer_14_attention_self_query: None, add_104: None}","(bert_encoder_layer_14_attention_self_query, add_104)",{},{permute_58: None},,add_104,permute_58,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_58
call_method,permute,{view_58: None},"(view_58, 0, 2, 1, 3)",{},{matmul_28: None},,view_58,transpose_14,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_58
call_method,transpose,{permute_56: None},"(permute_56, -1, -2)",{},{matmul_28: None},,permute_58,matmul_28,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_14
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_58: None, transpose_14: None}","(permute_58, transpose_14)",{},{truediv_14: None},,transpose_14,truediv_14,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_28
call_function,<built-in function truediv>,{matmul_28: None},"(matmul_28, 8.0)",{},{add_105: None},,matmul_28,add_105,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_14
call_function,<built-in function add>,"{truediv_14: None, mul: None}","(truediv_14, mul)",{},{softmax_14: None},,truediv_14,softmax_14,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_105
call_function,<function softmax at 0x7f800dfdfca0>,{add_105: None},"(add_105,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_14_attention_self_dropout: None},,add_105,bert_encoder_layer_14_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_14
call_module,bert.encoder.layer.14.attention.self.dropout,{softmax_14: None},"(softmax_14,)",{},{matmul_29: None},,softmax_14,matmul_29,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.14.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_14_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_14_attention_self_dropout: None, permute_57: None}","(bert_encoder_layer_14_attention_self_dropout, permute_57)",{},{permute_59: None},,bert_encoder_layer_14_attention_self_dropout,permute_59,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_29
call_method,permute,{matmul_29: None},"(matmul_29, 0, 2, 1, 3)",{},{contiguous_14: None},,matmul_29,contiguous_14,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_59
call_method,contiguous,{permute_59: None},"(permute_59,)",{},"{size_61: None, view_59: None}",,permute_59,size_61,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_14
call_method,size,{contiguous_14: None},"(contiguous_14,)",{},{getitem_65: None},,contiguous_14,getitem_65,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_61
call_function,<built-in function getitem>,{size_61: None},"(size_61, slice(None, -2, None))",{},{add_106: None},,size_61,add_106,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_65
call_function,<built-in function add>,{getitem_65: None},"(getitem_65, (1024,))",{},{view_59: None},,getitem_65,view_59,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_106
call_method,view,"{contiguous_14: None, add_106: None}","(contiguous_14, add_106)",{},{bert_encoder_layer_14_attention_output_dense: None},,add_106,bert_encoder_layer_14_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_59
call_module,bert.encoder.layer.14.attention.output.dense,{view_59: None},"(view_59,)",{},{bert_encoder_layer_14_attention_output_dropout: None},,view_59,bert_encoder_layer_14_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.14.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_14_attention_output_dense
call_module,bert.encoder.layer.14.attention.output.dropout,{bert_encoder_layer_14_attention_output_dense: None},"(bert_encoder_layer_14_attention_output_dense,)",{},{add_107: None},,bert_encoder_layer_14_attention_output_dense,add_107,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.14.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_14_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_14_attention_output_dropout: None, bert_encoder_layer_13_output_layer_norm: None}","(bert_encoder_layer_14_attention_output_dropout, bert_encoder_layer_13_output_layer_norm)",{},{bert_encoder_layer_14_attention_output_layer_norm: None},,bert_encoder_layer_14_attention_output_dropout,bert_encoder_layer_14_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_107
call_module,bert.encoder.layer.14.attention.output.LayerNorm,{add_107: None},"(add_107,)",{},"{bert_encoder_layer_14_intermediate_dense: None, add_108: None}",,add_107,bert_encoder_layer_14_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.14.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.14.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_14_attention_output_layer_norm
call_module,bert.encoder.layer.14.intermediate.dense,{bert_encoder_layer_14_attention_output_layer_norm: None},"(bert_encoder_layer_14_attention_output_layer_norm,)",{},{gelu_14: None},,bert_encoder_layer_14_attention_output_layer_norm,gelu_14,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.14.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_14_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_14_intermediate_dense: None},"(bert_encoder_layer_14_intermediate_dense,)",{},{bert_encoder_layer_14_output_dense: None},,bert_encoder_layer_14_intermediate_dense,bert_encoder_layer_14_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.14.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_14
call_module,bert.encoder.layer.14.output.dense,{gelu_14: None},"(gelu_14,)",{},{bert_encoder_layer_14_output_dropout: None},,gelu_14,bert_encoder_layer_14_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.14.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_14_output_dense
call_module,bert.encoder.layer.14.output.dropout,{bert_encoder_layer_14_output_dense: None},"(bert_encoder_layer_14_output_dense,)",{},{add_108: None},,bert_encoder_layer_14_output_dense,add_108,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.14.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_14_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_14_output_dropout: None, bert_encoder_layer_14_attention_output_layer_norm: None}","(bert_encoder_layer_14_output_dropout, bert_encoder_layer_14_attention_output_layer_norm)",{},{bert_encoder_layer_14_output_layer_norm: None},,bert_encoder_layer_14_output_dropout,bert_encoder_layer_14_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_108
call_module,bert.encoder.layer.14.output.LayerNorm,{add_108: None},"(add_108,)",{},"{bert_encoder_layer_15_attention_self_query: None, bert_encoder_layer_15_attention_self_key: None, bert_encoder_layer_15_attention_self_value: None, add_114: None}",,add_108,bert_encoder_layer_15_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.14', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.14.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.14.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_14_output_layer_norm
call_module,bert.encoder.layer.15.attention.self.query,{bert_encoder_layer_14_output_layer_norm: None},"(bert_encoder_layer_14_output_layer_norm,)",{},"{size_64: None, view_62: None}",,bert_encoder_layer_14_output_layer_norm,bert_encoder_layer_15_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.15.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_15_attention_self_query
call_module,bert.encoder.layer.15.attention.self.key,{bert_encoder_layer_14_output_layer_norm: None},"(bert_encoder_layer_14_output_layer_norm,)",{},"{size_62: None, view_60: None}",,bert_encoder_layer_15_attention_self_query,size_62,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.15.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_15_attention_self_key
call_method,size,{bert_encoder_layer_15_attention_self_key: None},"(bert_encoder_layer_15_attention_self_key,)",{},{getitem_66: None},,bert_encoder_layer_15_attention_self_key,getitem_66,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_62
call_function,<built-in function getitem>,{size_62: None},"(size_62, slice(None, -1, None))",{},{add_109: None},,size_62,add_109,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_66
call_function,<built-in function add>,{getitem_66: None},"(getitem_66, (16, 64))",{},{view_60: None},,getitem_66,view_60,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_109
call_method,view,"{bert_encoder_layer_15_attention_self_key: None, add_109: None}","(bert_encoder_layer_15_attention_self_key, add_109)",{},{permute_60: None},,add_109,permute_60,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_60
call_method,permute,{view_60: None},"(view_60, 0, 2, 1, 3)",{},{transpose_15: None},,view_60,bert_encoder_layer_15_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_60
call_module,bert.encoder.layer.15.attention.self.value,{bert_encoder_layer_14_output_layer_norm: None},"(bert_encoder_layer_14_output_layer_norm,)",{},"{size_63: None, view_61: None}",,permute_60,size_63,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.15.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_15_attention_self_value
call_method,size,{bert_encoder_layer_15_attention_self_value: None},"(bert_encoder_layer_15_attention_self_value,)",{},{getitem_67: None},,bert_encoder_layer_15_attention_self_value,getitem_67,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_63
call_function,<built-in function getitem>,{size_63: None},"(size_63, slice(None, -1, None))",{},{add_110: None},,size_63,add_110,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_67
call_function,<built-in function add>,{getitem_67: None},"(getitem_67, (16, 64))",{},{view_61: None},,getitem_67,view_61,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_110
call_method,view,"{bert_encoder_layer_15_attention_self_value: None, add_110: None}","(bert_encoder_layer_15_attention_self_value, add_110)",{},{permute_61: None},,add_110,permute_61,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_61
call_method,permute,{view_61: None},"(view_61, 0, 2, 1, 3)",{},{matmul_31: None},,view_61,size_64,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_61
call_method,size,{bert_encoder_layer_15_attention_self_query: None},"(bert_encoder_layer_15_attention_self_query,)",{},{getitem_68: None},,permute_61,getitem_68,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_64
call_function,<built-in function getitem>,{size_64: None},"(size_64, slice(None, -1, None))",{},{add_111: None},,size_64,add_111,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_68
call_function,<built-in function add>,{getitem_68: None},"(getitem_68, (16, 64))",{},{view_62: None},,getitem_68,view_62,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_111
call_method,view,"{bert_encoder_layer_15_attention_self_query: None, add_111: None}","(bert_encoder_layer_15_attention_self_query, add_111)",{},{permute_62: None},,add_111,permute_62,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_62
call_method,permute,{view_62: None},"(view_62, 0, 2, 1, 3)",{},{matmul_30: None},,view_62,transpose_15,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_62
call_method,transpose,{permute_60: None},"(permute_60, -1, -2)",{},{matmul_30: None},,permute_62,matmul_30,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_15
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_62: None, transpose_15: None}","(permute_62, transpose_15)",{},{truediv_15: None},,transpose_15,truediv_15,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_30
call_function,<built-in function truediv>,{matmul_30: None},"(matmul_30, 8.0)",{},{add_112: None},,matmul_30,add_112,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_15
call_function,<built-in function add>,"{truediv_15: None, mul: None}","(truediv_15, mul)",{},{softmax_15: None},,truediv_15,softmax_15,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_112
call_function,<function softmax at 0x7f800dfdfca0>,{add_112: None},"(add_112,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_15_attention_self_dropout: None},,add_112,bert_encoder_layer_15_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_15
call_module,bert.encoder.layer.15.attention.self.dropout,{softmax_15: None},"(softmax_15,)",{},{matmul_31: None},,softmax_15,matmul_31,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.15.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_15_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_15_attention_self_dropout: None, permute_61: None}","(bert_encoder_layer_15_attention_self_dropout, permute_61)",{},{permute_63: None},,bert_encoder_layer_15_attention_self_dropout,permute_63,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_31
call_method,permute,{matmul_31: None},"(matmul_31, 0, 2, 1, 3)",{},{contiguous_15: None},,matmul_31,contiguous_15,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_63
call_method,contiguous,{permute_63: None},"(permute_63,)",{},"{size_65: None, view_63: None}",,permute_63,size_65,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_15
call_method,size,{contiguous_15: None},"(contiguous_15,)",{},{getitem_69: None},,contiguous_15,getitem_69,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_65
call_function,<built-in function getitem>,{size_65: None},"(size_65, slice(None, -2, None))",{},{add_113: None},,size_65,add_113,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_69
call_function,<built-in function add>,{getitem_69: None},"(getitem_69, (1024,))",{},{view_63: None},,getitem_69,view_63,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_113
call_method,view,"{contiguous_15: None, add_113: None}","(contiguous_15, add_113)",{},{bert_encoder_layer_15_attention_output_dense: None},,add_113,bert_encoder_layer_15_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_63
call_module,bert.encoder.layer.15.attention.output.dense,{view_63: None},"(view_63,)",{},{bert_encoder_layer_15_attention_output_dropout: None},,view_63,bert_encoder_layer_15_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.15.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_15_attention_output_dense
call_module,bert.encoder.layer.15.attention.output.dropout,{bert_encoder_layer_15_attention_output_dense: None},"(bert_encoder_layer_15_attention_output_dense,)",{},{add_114: None},,bert_encoder_layer_15_attention_output_dense,add_114,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.15.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_15_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_15_attention_output_dropout: None, bert_encoder_layer_14_output_layer_norm: None}","(bert_encoder_layer_15_attention_output_dropout, bert_encoder_layer_14_output_layer_norm)",{},{bert_encoder_layer_15_attention_output_layer_norm: None},,bert_encoder_layer_15_attention_output_dropout,bert_encoder_layer_15_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_114
call_module,bert.encoder.layer.15.attention.output.LayerNorm,{add_114: None},"(add_114,)",{},"{bert_encoder_layer_15_intermediate_dense: None, add_115: None}",,add_114,bert_encoder_layer_15_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.15.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.15.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_15_attention_output_layer_norm
call_module,bert.encoder.layer.15.intermediate.dense,{bert_encoder_layer_15_attention_output_layer_norm: None},"(bert_encoder_layer_15_attention_output_layer_norm,)",{},{gelu_15: None},,bert_encoder_layer_15_attention_output_layer_norm,gelu_15,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.15.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_15_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_15_intermediate_dense: None},"(bert_encoder_layer_15_intermediate_dense,)",{},{bert_encoder_layer_15_output_dense: None},,bert_encoder_layer_15_intermediate_dense,bert_encoder_layer_15_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.15.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_15
call_module,bert.encoder.layer.15.output.dense,{gelu_15: None},"(gelu_15,)",{},{bert_encoder_layer_15_output_dropout: None},,gelu_15,bert_encoder_layer_15_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.15.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_15_output_dense
call_module,bert.encoder.layer.15.output.dropout,{bert_encoder_layer_15_output_dense: None},"(bert_encoder_layer_15_output_dense,)",{},{add_115: None},,bert_encoder_layer_15_output_dense,add_115,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.15.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_15_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_15_output_dropout: None, bert_encoder_layer_15_attention_output_layer_norm: None}","(bert_encoder_layer_15_output_dropout, bert_encoder_layer_15_attention_output_layer_norm)",{},{bert_encoder_layer_15_output_layer_norm: None},,bert_encoder_layer_15_output_dropout,bert_encoder_layer_15_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_115
call_module,bert.encoder.layer.15.output.LayerNorm,{add_115: None},"(add_115,)",{},"{bert_encoder_layer_16_attention_self_query: None, bert_encoder_layer_16_attention_self_key: None, bert_encoder_layer_16_attention_self_value: None, add_121: None}",,add_115,bert_encoder_layer_16_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.15', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.15.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.15.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_15_output_layer_norm
call_module,bert.encoder.layer.16.attention.self.query,{bert_encoder_layer_15_output_layer_norm: None},"(bert_encoder_layer_15_output_layer_norm,)",{},"{size_68: None, view_66: None}",,bert_encoder_layer_15_output_layer_norm,bert_encoder_layer_16_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.16.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_16_attention_self_query
call_module,bert.encoder.layer.16.attention.self.key,{bert_encoder_layer_15_output_layer_norm: None},"(bert_encoder_layer_15_output_layer_norm,)",{},"{size_66: None, view_64: None}",,bert_encoder_layer_16_attention_self_query,size_66,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.16.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_16_attention_self_key
call_method,size,{bert_encoder_layer_16_attention_self_key: None},"(bert_encoder_layer_16_attention_self_key,)",{},{getitem_70: None},,bert_encoder_layer_16_attention_self_key,getitem_70,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_66
call_function,<built-in function getitem>,{size_66: None},"(size_66, slice(None, -1, None))",{},{add_116: None},,size_66,add_116,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_70
call_function,<built-in function add>,{getitem_70: None},"(getitem_70, (16, 64))",{},{view_64: None},,getitem_70,view_64,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_116
call_method,view,"{bert_encoder_layer_16_attention_self_key: None, add_116: None}","(bert_encoder_layer_16_attention_self_key, add_116)",{},{permute_64: None},,add_116,permute_64,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_64
call_method,permute,{view_64: None},"(view_64, 0, 2, 1, 3)",{},{transpose_16: None},,view_64,bert_encoder_layer_16_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_64
call_module,bert.encoder.layer.16.attention.self.value,{bert_encoder_layer_15_output_layer_norm: None},"(bert_encoder_layer_15_output_layer_norm,)",{},"{size_67: None, view_65: None}",,permute_64,size_67,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.16.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_16_attention_self_value
call_method,size,{bert_encoder_layer_16_attention_self_value: None},"(bert_encoder_layer_16_attention_self_value,)",{},{getitem_71: None},,bert_encoder_layer_16_attention_self_value,getitem_71,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_67
call_function,<built-in function getitem>,{size_67: None},"(size_67, slice(None, -1, None))",{},{add_117: None},,size_67,add_117,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_71
call_function,<built-in function add>,{getitem_71: None},"(getitem_71, (16, 64))",{},{view_65: None},,getitem_71,view_65,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_117
call_method,view,"{bert_encoder_layer_16_attention_self_value: None, add_117: None}","(bert_encoder_layer_16_attention_self_value, add_117)",{},{permute_65: None},,add_117,permute_65,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_65
call_method,permute,{view_65: None},"(view_65, 0, 2, 1, 3)",{},{matmul_33: None},,view_65,size_68,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_65
call_method,size,{bert_encoder_layer_16_attention_self_query: None},"(bert_encoder_layer_16_attention_self_query,)",{},{getitem_72: None},,permute_65,getitem_72,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_68
call_function,<built-in function getitem>,{size_68: None},"(size_68, slice(None, -1, None))",{},{add_118: None},,size_68,add_118,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_72
call_function,<built-in function add>,{getitem_72: None},"(getitem_72, (16, 64))",{},{view_66: None},,getitem_72,view_66,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_118
call_method,view,"{bert_encoder_layer_16_attention_self_query: None, add_118: None}","(bert_encoder_layer_16_attention_self_query, add_118)",{},{permute_66: None},,add_118,permute_66,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_66
call_method,permute,{view_66: None},"(view_66, 0, 2, 1, 3)",{},{matmul_32: None},,view_66,transpose_16,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_66
call_method,transpose,{permute_64: None},"(permute_64, -1, -2)",{},{matmul_32: None},,permute_66,matmul_32,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_16
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_66: None, transpose_16: None}","(permute_66, transpose_16)",{},{truediv_16: None},,transpose_16,truediv_16,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_32
call_function,<built-in function truediv>,{matmul_32: None},"(matmul_32, 8.0)",{},{add_119: None},,matmul_32,add_119,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_16
call_function,<built-in function add>,"{truediv_16: None, mul: None}","(truediv_16, mul)",{},{softmax_16: None},,truediv_16,softmax_16,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_119
call_function,<function softmax at 0x7f800dfdfca0>,{add_119: None},"(add_119,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_16_attention_self_dropout: None},,add_119,bert_encoder_layer_16_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_16
call_module,bert.encoder.layer.16.attention.self.dropout,{softmax_16: None},"(softmax_16,)",{},{matmul_33: None},,softmax_16,matmul_33,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.16.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_16_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_16_attention_self_dropout: None, permute_65: None}","(bert_encoder_layer_16_attention_self_dropout, permute_65)",{},{permute_67: None},,bert_encoder_layer_16_attention_self_dropout,permute_67,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_33
call_method,permute,{matmul_33: None},"(matmul_33, 0, 2, 1, 3)",{},{contiguous_16: None},,matmul_33,contiguous_16,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_67
call_method,contiguous,{permute_67: None},"(permute_67,)",{},"{size_69: None, view_67: None}",,permute_67,size_69,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_16
call_method,size,{contiguous_16: None},"(contiguous_16,)",{},{getitem_73: None},,contiguous_16,getitem_73,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_69
call_function,<built-in function getitem>,{size_69: None},"(size_69, slice(None, -2, None))",{},{add_120: None},,size_69,add_120,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_73
call_function,<built-in function add>,{getitem_73: None},"(getitem_73, (1024,))",{},{view_67: None},,getitem_73,view_67,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_120
call_method,view,"{contiguous_16: None, add_120: None}","(contiguous_16, add_120)",{},{bert_encoder_layer_16_attention_output_dense: None},,add_120,bert_encoder_layer_16_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_67
call_module,bert.encoder.layer.16.attention.output.dense,{view_67: None},"(view_67,)",{},{bert_encoder_layer_16_attention_output_dropout: None},,view_67,bert_encoder_layer_16_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.16.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_16_attention_output_dense
call_module,bert.encoder.layer.16.attention.output.dropout,{bert_encoder_layer_16_attention_output_dense: None},"(bert_encoder_layer_16_attention_output_dense,)",{},{add_121: None},,bert_encoder_layer_16_attention_output_dense,add_121,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.16.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_16_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_16_attention_output_dropout: None, bert_encoder_layer_15_output_layer_norm: None}","(bert_encoder_layer_16_attention_output_dropout, bert_encoder_layer_15_output_layer_norm)",{},{bert_encoder_layer_16_attention_output_layer_norm: None},,bert_encoder_layer_16_attention_output_dropout,bert_encoder_layer_16_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_121
call_module,bert.encoder.layer.16.attention.output.LayerNorm,{add_121: None},"(add_121,)",{},"{bert_encoder_layer_16_intermediate_dense: None, add_122: None}",,add_121,bert_encoder_layer_16_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.16.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.16.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_16_attention_output_layer_norm
call_module,bert.encoder.layer.16.intermediate.dense,{bert_encoder_layer_16_attention_output_layer_norm: None},"(bert_encoder_layer_16_attention_output_layer_norm,)",{},{gelu_16: None},,bert_encoder_layer_16_attention_output_layer_norm,gelu_16,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.16.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_16_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_16_intermediate_dense: None},"(bert_encoder_layer_16_intermediate_dense,)",{},{bert_encoder_layer_16_output_dense: None},,bert_encoder_layer_16_intermediate_dense,bert_encoder_layer_16_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.16.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_16
call_module,bert.encoder.layer.16.output.dense,{gelu_16: None},"(gelu_16,)",{},{bert_encoder_layer_16_output_dropout: None},,gelu_16,bert_encoder_layer_16_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.16.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_16_output_dense
call_module,bert.encoder.layer.16.output.dropout,{bert_encoder_layer_16_output_dense: None},"(bert_encoder_layer_16_output_dense,)",{},{add_122: None},,bert_encoder_layer_16_output_dense,add_122,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.16.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_16_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_16_output_dropout: None, bert_encoder_layer_16_attention_output_layer_norm: None}","(bert_encoder_layer_16_output_dropout, bert_encoder_layer_16_attention_output_layer_norm)",{},{bert_encoder_layer_16_output_layer_norm: None},,bert_encoder_layer_16_output_dropout,bert_encoder_layer_16_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_122
call_module,bert.encoder.layer.16.output.LayerNorm,{add_122: None},"(add_122,)",{},"{bert_encoder_layer_17_attention_self_query: None, bert_encoder_layer_17_attention_self_key: None, bert_encoder_layer_17_attention_self_value: None, add_128: None}",,add_122,bert_encoder_layer_17_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.16', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.16.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.16.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_16_output_layer_norm
call_module,bert.encoder.layer.17.attention.self.query,{bert_encoder_layer_16_output_layer_norm: None},"(bert_encoder_layer_16_output_layer_norm,)",{},"{size_72: None, view_70: None}",,bert_encoder_layer_16_output_layer_norm,bert_encoder_layer_17_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.17.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_17_attention_self_query
call_module,bert.encoder.layer.17.attention.self.key,{bert_encoder_layer_16_output_layer_norm: None},"(bert_encoder_layer_16_output_layer_norm,)",{},"{size_70: None, view_68: None}",,bert_encoder_layer_17_attention_self_query,size_70,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.17.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_17_attention_self_key
call_method,size,{bert_encoder_layer_17_attention_self_key: None},"(bert_encoder_layer_17_attention_self_key,)",{},{getitem_74: None},,bert_encoder_layer_17_attention_self_key,getitem_74,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_70
call_function,<built-in function getitem>,{size_70: None},"(size_70, slice(None, -1, None))",{},{add_123: None},,size_70,add_123,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_74
call_function,<built-in function add>,{getitem_74: None},"(getitem_74, (16, 64))",{},{view_68: None},,getitem_74,view_68,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_123
call_method,view,"{bert_encoder_layer_17_attention_self_key: None, add_123: None}","(bert_encoder_layer_17_attention_self_key, add_123)",{},{permute_68: None},,add_123,permute_68,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_68
call_method,permute,{view_68: None},"(view_68, 0, 2, 1, 3)",{},{transpose_17: None},,view_68,bert_encoder_layer_17_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_68
call_module,bert.encoder.layer.17.attention.self.value,{bert_encoder_layer_16_output_layer_norm: None},"(bert_encoder_layer_16_output_layer_norm,)",{},"{size_71: None, view_69: None}",,permute_68,size_71,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.17.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_17_attention_self_value
call_method,size,{bert_encoder_layer_17_attention_self_value: None},"(bert_encoder_layer_17_attention_self_value,)",{},{getitem_75: None},,bert_encoder_layer_17_attention_self_value,getitem_75,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_71
call_function,<built-in function getitem>,{size_71: None},"(size_71, slice(None, -1, None))",{},{add_124: None},,size_71,add_124,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_75
call_function,<built-in function add>,{getitem_75: None},"(getitem_75, (16, 64))",{},{view_69: None},,getitem_75,view_69,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_124
call_method,view,"{bert_encoder_layer_17_attention_self_value: None, add_124: None}","(bert_encoder_layer_17_attention_self_value, add_124)",{},{permute_69: None},,add_124,permute_69,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_69
call_method,permute,{view_69: None},"(view_69, 0, 2, 1, 3)",{},{matmul_35: None},,view_69,size_72,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_69
call_method,size,{bert_encoder_layer_17_attention_self_query: None},"(bert_encoder_layer_17_attention_self_query,)",{},{getitem_76: None},,permute_69,getitem_76,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_72
call_function,<built-in function getitem>,{size_72: None},"(size_72, slice(None, -1, None))",{},{add_125: None},,size_72,add_125,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_76
call_function,<built-in function add>,{getitem_76: None},"(getitem_76, (16, 64))",{},{view_70: None},,getitem_76,view_70,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_125
call_method,view,"{bert_encoder_layer_17_attention_self_query: None, add_125: None}","(bert_encoder_layer_17_attention_self_query, add_125)",{},{permute_70: None},,add_125,permute_70,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_70
call_method,permute,{view_70: None},"(view_70, 0, 2, 1, 3)",{},{matmul_34: None},,view_70,transpose_17,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_70
call_method,transpose,{permute_68: None},"(permute_68, -1, -2)",{},{matmul_34: None},,permute_70,matmul_34,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_17
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_70: None, transpose_17: None}","(permute_70, transpose_17)",{},{truediv_17: None},,transpose_17,truediv_17,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_34
call_function,<built-in function truediv>,{matmul_34: None},"(matmul_34, 8.0)",{},{add_126: None},,matmul_34,add_126,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_17
call_function,<built-in function add>,"{truediv_17: None, mul: None}","(truediv_17, mul)",{},{softmax_17: None},,truediv_17,softmax_17,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_126
call_function,<function softmax at 0x7f800dfdfca0>,{add_126: None},"(add_126,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_17_attention_self_dropout: None},,add_126,bert_encoder_layer_17_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_17
call_module,bert.encoder.layer.17.attention.self.dropout,{softmax_17: None},"(softmax_17,)",{},{matmul_35: None},,softmax_17,matmul_35,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.17.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_17_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_17_attention_self_dropout: None, permute_69: None}","(bert_encoder_layer_17_attention_self_dropout, permute_69)",{},{permute_71: None},,bert_encoder_layer_17_attention_self_dropout,permute_71,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_35
call_method,permute,{matmul_35: None},"(matmul_35, 0, 2, 1, 3)",{},{contiguous_17: None},,matmul_35,contiguous_17,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_71
call_method,contiguous,{permute_71: None},"(permute_71,)",{},"{size_73: None, view_71: None}",,permute_71,size_73,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_17
call_method,size,{contiguous_17: None},"(contiguous_17,)",{},{getitem_77: None},,contiguous_17,getitem_77,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_73
call_function,<built-in function getitem>,{size_73: None},"(size_73, slice(None, -2, None))",{},{add_127: None},,size_73,add_127,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_77
call_function,<built-in function add>,{getitem_77: None},"(getitem_77, (1024,))",{},{view_71: None},,getitem_77,view_71,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_127
call_method,view,"{contiguous_17: None, add_127: None}","(contiguous_17, add_127)",{},{bert_encoder_layer_17_attention_output_dense: None},,add_127,bert_encoder_layer_17_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_71
call_module,bert.encoder.layer.17.attention.output.dense,{view_71: None},"(view_71,)",{},{bert_encoder_layer_17_attention_output_dropout: None},,view_71,bert_encoder_layer_17_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.17.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_17_attention_output_dense
call_module,bert.encoder.layer.17.attention.output.dropout,{bert_encoder_layer_17_attention_output_dense: None},"(bert_encoder_layer_17_attention_output_dense,)",{},{add_128: None},,bert_encoder_layer_17_attention_output_dense,add_128,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.17.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_17_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_17_attention_output_dropout: None, bert_encoder_layer_16_output_layer_norm: None}","(bert_encoder_layer_17_attention_output_dropout, bert_encoder_layer_16_output_layer_norm)",{},{bert_encoder_layer_17_attention_output_layer_norm: None},,bert_encoder_layer_17_attention_output_dropout,bert_encoder_layer_17_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_128
call_module,bert.encoder.layer.17.attention.output.LayerNorm,{add_128: None},"(add_128,)",{},"{bert_encoder_layer_17_intermediate_dense: None, add_129: None}",,add_128,bert_encoder_layer_17_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.17.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.17.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_17_attention_output_layer_norm
call_module,bert.encoder.layer.17.intermediate.dense,{bert_encoder_layer_17_attention_output_layer_norm: None},"(bert_encoder_layer_17_attention_output_layer_norm,)",{},{gelu_17: None},,bert_encoder_layer_17_attention_output_layer_norm,gelu_17,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.17.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_17_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_17_intermediate_dense: None},"(bert_encoder_layer_17_intermediate_dense,)",{},{bert_encoder_layer_17_output_dense: None},,bert_encoder_layer_17_intermediate_dense,bert_encoder_layer_17_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.17.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_17
call_module,bert.encoder.layer.17.output.dense,{gelu_17: None},"(gelu_17,)",{},{bert_encoder_layer_17_output_dropout: None},,gelu_17,bert_encoder_layer_17_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.17.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_17_output_dense
call_module,bert.encoder.layer.17.output.dropout,{bert_encoder_layer_17_output_dense: None},"(bert_encoder_layer_17_output_dense,)",{},{add_129: None},,bert_encoder_layer_17_output_dense,add_129,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.17.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_17_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_17_output_dropout: None, bert_encoder_layer_17_attention_output_layer_norm: None}","(bert_encoder_layer_17_output_dropout, bert_encoder_layer_17_attention_output_layer_norm)",{},{bert_encoder_layer_17_output_layer_norm: None},,bert_encoder_layer_17_output_dropout,bert_encoder_layer_17_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_129
call_module,bert.encoder.layer.17.output.LayerNorm,{add_129: None},"(add_129,)",{},"{bert_encoder_layer_18_attention_self_query: None, bert_encoder_layer_18_attention_self_key: None, bert_encoder_layer_18_attention_self_value: None, add_135: None}",,add_129,bert_encoder_layer_18_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.17', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.17.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.17.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_17_output_layer_norm
call_module,bert.encoder.layer.18.attention.self.query,{bert_encoder_layer_17_output_layer_norm: None},"(bert_encoder_layer_17_output_layer_norm,)",{},"{size_76: None, view_74: None}",,bert_encoder_layer_17_output_layer_norm,bert_encoder_layer_18_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.18.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_18_attention_self_query
call_module,bert.encoder.layer.18.attention.self.key,{bert_encoder_layer_17_output_layer_norm: None},"(bert_encoder_layer_17_output_layer_norm,)",{},"{size_74: None, view_72: None}",,bert_encoder_layer_18_attention_self_query,size_74,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.18.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_18_attention_self_key
call_method,size,{bert_encoder_layer_18_attention_self_key: None},"(bert_encoder_layer_18_attention_self_key,)",{},{getitem_78: None},,bert_encoder_layer_18_attention_self_key,getitem_78,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_74
call_function,<built-in function getitem>,{size_74: None},"(size_74, slice(None, -1, None))",{},{add_130: None},,size_74,add_130,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_78
call_function,<built-in function add>,{getitem_78: None},"(getitem_78, (16, 64))",{},{view_72: None},,getitem_78,view_72,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_130
call_method,view,"{bert_encoder_layer_18_attention_self_key: None, add_130: None}","(bert_encoder_layer_18_attention_self_key, add_130)",{},{permute_72: None},,add_130,permute_72,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_72
call_method,permute,{view_72: None},"(view_72, 0, 2, 1, 3)",{},{transpose_18: None},,view_72,bert_encoder_layer_18_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_72
call_module,bert.encoder.layer.18.attention.self.value,{bert_encoder_layer_17_output_layer_norm: None},"(bert_encoder_layer_17_output_layer_norm,)",{},"{size_75: None, view_73: None}",,permute_72,size_75,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.18.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_18_attention_self_value
call_method,size,{bert_encoder_layer_18_attention_self_value: None},"(bert_encoder_layer_18_attention_self_value,)",{},{getitem_79: None},,bert_encoder_layer_18_attention_self_value,getitem_79,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_75
call_function,<built-in function getitem>,{size_75: None},"(size_75, slice(None, -1, None))",{},{add_131: None},,size_75,add_131,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_79
call_function,<built-in function add>,{getitem_79: None},"(getitem_79, (16, 64))",{},{view_73: None},,getitem_79,view_73,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_131
call_method,view,"{bert_encoder_layer_18_attention_self_value: None, add_131: None}","(bert_encoder_layer_18_attention_self_value, add_131)",{},{permute_73: None},,add_131,permute_73,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_73
call_method,permute,{view_73: None},"(view_73, 0, 2, 1, 3)",{},{matmul_37: None},,view_73,size_76,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_73
call_method,size,{bert_encoder_layer_18_attention_self_query: None},"(bert_encoder_layer_18_attention_self_query,)",{},{getitem_80: None},,permute_73,getitem_80,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_76
call_function,<built-in function getitem>,{size_76: None},"(size_76, slice(None, -1, None))",{},{add_132: None},,size_76,add_132,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_80
call_function,<built-in function add>,{getitem_80: None},"(getitem_80, (16, 64))",{},{view_74: None},,getitem_80,view_74,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_132
call_method,view,"{bert_encoder_layer_18_attention_self_query: None, add_132: None}","(bert_encoder_layer_18_attention_self_query, add_132)",{},{permute_74: None},,add_132,permute_74,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_74
call_method,permute,{view_74: None},"(view_74, 0, 2, 1, 3)",{},{matmul_36: None},,view_74,transpose_18,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_74
call_method,transpose,{permute_72: None},"(permute_72, -1, -2)",{},{matmul_36: None},,permute_74,matmul_36,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_18
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_74: None, transpose_18: None}","(permute_74, transpose_18)",{},{truediv_18: None},,transpose_18,truediv_18,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_36
call_function,<built-in function truediv>,{matmul_36: None},"(matmul_36, 8.0)",{},{add_133: None},,matmul_36,add_133,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_18
call_function,<built-in function add>,"{truediv_18: None, mul: None}","(truediv_18, mul)",{},{softmax_18: None},,truediv_18,softmax_18,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_133
call_function,<function softmax at 0x7f800dfdfca0>,{add_133: None},"(add_133,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_18_attention_self_dropout: None},,add_133,bert_encoder_layer_18_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_18
call_module,bert.encoder.layer.18.attention.self.dropout,{softmax_18: None},"(softmax_18,)",{},{matmul_37: None},,softmax_18,matmul_37,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.18.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_18_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_18_attention_self_dropout: None, permute_73: None}","(bert_encoder_layer_18_attention_self_dropout, permute_73)",{},{permute_75: None},,bert_encoder_layer_18_attention_self_dropout,permute_75,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_37
call_method,permute,{matmul_37: None},"(matmul_37, 0, 2, 1, 3)",{},{contiguous_18: None},,matmul_37,contiguous_18,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_75
call_method,contiguous,{permute_75: None},"(permute_75,)",{},"{size_77: None, view_75: None}",,permute_75,size_77,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_18
call_method,size,{contiguous_18: None},"(contiguous_18,)",{},{getitem_81: None},,contiguous_18,getitem_81,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_77
call_function,<built-in function getitem>,{size_77: None},"(size_77, slice(None, -2, None))",{},{add_134: None},,size_77,add_134,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_81
call_function,<built-in function add>,{getitem_81: None},"(getitem_81, (1024,))",{},{view_75: None},,getitem_81,view_75,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_134
call_method,view,"{contiguous_18: None, add_134: None}","(contiguous_18, add_134)",{},{bert_encoder_layer_18_attention_output_dense: None},,add_134,bert_encoder_layer_18_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_75
call_module,bert.encoder.layer.18.attention.output.dense,{view_75: None},"(view_75,)",{},{bert_encoder_layer_18_attention_output_dropout: None},,view_75,bert_encoder_layer_18_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.18.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_18_attention_output_dense
call_module,bert.encoder.layer.18.attention.output.dropout,{bert_encoder_layer_18_attention_output_dense: None},"(bert_encoder_layer_18_attention_output_dense,)",{},{add_135: None},,bert_encoder_layer_18_attention_output_dense,add_135,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.18.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_18_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_18_attention_output_dropout: None, bert_encoder_layer_17_output_layer_norm: None}","(bert_encoder_layer_18_attention_output_dropout, bert_encoder_layer_17_output_layer_norm)",{},{bert_encoder_layer_18_attention_output_layer_norm: None},,bert_encoder_layer_18_attention_output_dropout,bert_encoder_layer_18_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_135
call_module,bert.encoder.layer.18.attention.output.LayerNorm,{add_135: None},"(add_135,)",{},"{bert_encoder_layer_18_intermediate_dense: None, add_136: None}",,add_135,bert_encoder_layer_18_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.18.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.18.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_18_attention_output_layer_norm
call_module,bert.encoder.layer.18.intermediate.dense,{bert_encoder_layer_18_attention_output_layer_norm: None},"(bert_encoder_layer_18_attention_output_layer_norm,)",{},{gelu_18: None},,bert_encoder_layer_18_attention_output_layer_norm,gelu_18,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.18.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_18_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_18_intermediate_dense: None},"(bert_encoder_layer_18_intermediate_dense,)",{},{bert_encoder_layer_18_output_dense: None},,bert_encoder_layer_18_intermediate_dense,bert_encoder_layer_18_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.18.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_18
call_module,bert.encoder.layer.18.output.dense,{gelu_18: None},"(gelu_18,)",{},{bert_encoder_layer_18_output_dropout: None},,gelu_18,bert_encoder_layer_18_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.18.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_18_output_dense
call_module,bert.encoder.layer.18.output.dropout,{bert_encoder_layer_18_output_dense: None},"(bert_encoder_layer_18_output_dense,)",{},{add_136: None},,bert_encoder_layer_18_output_dense,add_136,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.18.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_18_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_18_output_dropout: None, bert_encoder_layer_18_attention_output_layer_norm: None}","(bert_encoder_layer_18_output_dropout, bert_encoder_layer_18_attention_output_layer_norm)",{},{bert_encoder_layer_18_output_layer_norm: None},,bert_encoder_layer_18_output_dropout,bert_encoder_layer_18_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_136
call_module,bert.encoder.layer.18.output.LayerNorm,{add_136: None},"(add_136,)",{},"{bert_encoder_layer_19_attention_self_query: None, bert_encoder_layer_19_attention_self_key: None, bert_encoder_layer_19_attention_self_value: None, add_142: None}",,add_136,bert_encoder_layer_19_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.18', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.18.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.18.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_18_output_layer_norm
call_module,bert.encoder.layer.19.attention.self.query,{bert_encoder_layer_18_output_layer_norm: None},"(bert_encoder_layer_18_output_layer_norm,)",{},"{size_80: None, view_78: None}",,bert_encoder_layer_18_output_layer_norm,bert_encoder_layer_19_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.19.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_19_attention_self_query
call_module,bert.encoder.layer.19.attention.self.key,{bert_encoder_layer_18_output_layer_norm: None},"(bert_encoder_layer_18_output_layer_norm,)",{},"{size_78: None, view_76: None}",,bert_encoder_layer_19_attention_self_query,size_78,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.19.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_19_attention_self_key
call_method,size,{bert_encoder_layer_19_attention_self_key: None},"(bert_encoder_layer_19_attention_self_key,)",{},{getitem_82: None},,bert_encoder_layer_19_attention_self_key,getitem_82,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_78
call_function,<built-in function getitem>,{size_78: None},"(size_78, slice(None, -1, None))",{},{add_137: None},,size_78,add_137,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_82
call_function,<built-in function add>,{getitem_82: None},"(getitem_82, (16, 64))",{},{view_76: None},,getitem_82,view_76,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_137
call_method,view,"{bert_encoder_layer_19_attention_self_key: None, add_137: None}","(bert_encoder_layer_19_attention_self_key, add_137)",{},{permute_76: None},,add_137,permute_76,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_76
call_method,permute,{view_76: None},"(view_76, 0, 2, 1, 3)",{},{transpose_19: None},,view_76,bert_encoder_layer_19_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_76
call_module,bert.encoder.layer.19.attention.self.value,{bert_encoder_layer_18_output_layer_norm: None},"(bert_encoder_layer_18_output_layer_norm,)",{},"{size_79: None, view_77: None}",,permute_76,size_79,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.19.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_19_attention_self_value
call_method,size,{bert_encoder_layer_19_attention_self_value: None},"(bert_encoder_layer_19_attention_self_value,)",{},{getitem_83: None},,bert_encoder_layer_19_attention_self_value,getitem_83,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_79
call_function,<built-in function getitem>,{size_79: None},"(size_79, slice(None, -1, None))",{},{add_138: None},,size_79,add_138,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_83
call_function,<built-in function add>,{getitem_83: None},"(getitem_83, (16, 64))",{},{view_77: None},,getitem_83,view_77,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_138
call_method,view,"{bert_encoder_layer_19_attention_self_value: None, add_138: None}","(bert_encoder_layer_19_attention_self_value, add_138)",{},{permute_77: None},,add_138,permute_77,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_77
call_method,permute,{view_77: None},"(view_77, 0, 2, 1, 3)",{},{matmul_39: None},,view_77,size_80,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_77
call_method,size,{bert_encoder_layer_19_attention_self_query: None},"(bert_encoder_layer_19_attention_self_query,)",{},{getitem_84: None},,permute_77,getitem_84,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_80
call_function,<built-in function getitem>,{size_80: None},"(size_80, slice(None, -1, None))",{},{add_139: None},,size_80,add_139,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_84
call_function,<built-in function add>,{getitem_84: None},"(getitem_84, (16, 64))",{},{view_78: None},,getitem_84,view_78,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_139
call_method,view,"{bert_encoder_layer_19_attention_self_query: None, add_139: None}","(bert_encoder_layer_19_attention_self_query, add_139)",{},{permute_78: None},,add_139,permute_78,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_78
call_method,permute,{view_78: None},"(view_78, 0, 2, 1, 3)",{},{matmul_38: None},,view_78,transpose_19,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_78
call_method,transpose,{permute_76: None},"(permute_76, -1, -2)",{},{matmul_38: None},,permute_78,matmul_38,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_19
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_78: None, transpose_19: None}","(permute_78, transpose_19)",{},{truediv_19: None},,transpose_19,truediv_19,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_38
call_function,<built-in function truediv>,{matmul_38: None},"(matmul_38, 8.0)",{},{add_140: None},,matmul_38,add_140,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_19
call_function,<built-in function add>,"{truediv_19: None, mul: None}","(truediv_19, mul)",{},{softmax_19: None},,truediv_19,softmax_19,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_140
call_function,<function softmax at 0x7f800dfdfca0>,{add_140: None},"(add_140,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_19_attention_self_dropout: None},,add_140,bert_encoder_layer_19_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_19
call_module,bert.encoder.layer.19.attention.self.dropout,{softmax_19: None},"(softmax_19,)",{},{matmul_39: None},,softmax_19,matmul_39,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.19.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_19_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_19_attention_self_dropout: None, permute_77: None}","(bert_encoder_layer_19_attention_self_dropout, permute_77)",{},{permute_79: None},,bert_encoder_layer_19_attention_self_dropout,permute_79,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_39
call_method,permute,{matmul_39: None},"(matmul_39, 0, 2, 1, 3)",{},{contiguous_19: None},,matmul_39,contiguous_19,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_79
call_method,contiguous,{permute_79: None},"(permute_79,)",{},"{size_81: None, view_79: None}",,permute_79,size_81,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_19
call_method,size,{contiguous_19: None},"(contiguous_19,)",{},{getitem_85: None},,contiguous_19,getitem_85,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_81
call_function,<built-in function getitem>,{size_81: None},"(size_81, slice(None, -2, None))",{},{add_141: None},,size_81,add_141,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_85
call_function,<built-in function add>,{getitem_85: None},"(getitem_85, (1024,))",{},{view_79: None},,getitem_85,view_79,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_141
call_method,view,"{contiguous_19: None, add_141: None}","(contiguous_19, add_141)",{},{bert_encoder_layer_19_attention_output_dense: None},,add_141,bert_encoder_layer_19_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_79
call_module,bert.encoder.layer.19.attention.output.dense,{view_79: None},"(view_79,)",{},{bert_encoder_layer_19_attention_output_dropout: None},,view_79,bert_encoder_layer_19_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.19.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_19_attention_output_dense
call_module,bert.encoder.layer.19.attention.output.dropout,{bert_encoder_layer_19_attention_output_dense: None},"(bert_encoder_layer_19_attention_output_dense,)",{},{add_142: None},,bert_encoder_layer_19_attention_output_dense,add_142,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.19.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_19_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_19_attention_output_dropout: None, bert_encoder_layer_18_output_layer_norm: None}","(bert_encoder_layer_19_attention_output_dropout, bert_encoder_layer_18_output_layer_norm)",{},{bert_encoder_layer_19_attention_output_layer_norm: None},,bert_encoder_layer_19_attention_output_dropout,bert_encoder_layer_19_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_142
call_module,bert.encoder.layer.19.attention.output.LayerNorm,{add_142: None},"(add_142,)",{},"{bert_encoder_layer_19_intermediate_dense: None, add_143: None}",,add_142,bert_encoder_layer_19_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.19.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.19.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_19_attention_output_layer_norm
call_module,bert.encoder.layer.19.intermediate.dense,{bert_encoder_layer_19_attention_output_layer_norm: None},"(bert_encoder_layer_19_attention_output_layer_norm,)",{},{gelu_19: None},,bert_encoder_layer_19_attention_output_layer_norm,gelu_19,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.19.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_19_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_19_intermediate_dense: None},"(bert_encoder_layer_19_intermediate_dense,)",{},{bert_encoder_layer_19_output_dense: None},,bert_encoder_layer_19_intermediate_dense,bert_encoder_layer_19_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.19.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_19
call_module,bert.encoder.layer.19.output.dense,{gelu_19: None},"(gelu_19,)",{},{bert_encoder_layer_19_output_dropout: None},,gelu_19,bert_encoder_layer_19_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.19.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_19_output_dense
call_module,bert.encoder.layer.19.output.dropout,{bert_encoder_layer_19_output_dense: None},"(bert_encoder_layer_19_output_dense,)",{},{add_143: None},,bert_encoder_layer_19_output_dense,add_143,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.19.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_19_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_19_output_dropout: None, bert_encoder_layer_19_attention_output_layer_norm: None}","(bert_encoder_layer_19_output_dropout, bert_encoder_layer_19_attention_output_layer_norm)",{},{bert_encoder_layer_19_output_layer_norm: None},,bert_encoder_layer_19_output_dropout,bert_encoder_layer_19_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_143
call_module,bert.encoder.layer.19.output.LayerNorm,{add_143: None},"(add_143,)",{},"{bert_encoder_layer_20_attention_self_query: None, bert_encoder_layer_20_attention_self_key: None, bert_encoder_layer_20_attention_self_value: None, add_149: None}",,add_143,bert_encoder_layer_20_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.19', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.19.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.19.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_19_output_layer_norm
call_module,bert.encoder.layer.20.attention.self.query,{bert_encoder_layer_19_output_layer_norm: None},"(bert_encoder_layer_19_output_layer_norm,)",{},"{size_84: None, view_82: None}",,bert_encoder_layer_19_output_layer_norm,bert_encoder_layer_20_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.20.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_20_attention_self_query
call_module,bert.encoder.layer.20.attention.self.key,{bert_encoder_layer_19_output_layer_norm: None},"(bert_encoder_layer_19_output_layer_norm,)",{},"{size_82: None, view_80: None}",,bert_encoder_layer_20_attention_self_query,size_82,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.20.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_20_attention_self_key
call_method,size,{bert_encoder_layer_20_attention_self_key: None},"(bert_encoder_layer_20_attention_self_key,)",{},{getitem_86: None},,bert_encoder_layer_20_attention_self_key,getitem_86,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_82
call_function,<built-in function getitem>,{size_82: None},"(size_82, slice(None, -1, None))",{},{add_144: None},,size_82,add_144,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_86
call_function,<built-in function add>,{getitem_86: None},"(getitem_86, (16, 64))",{},{view_80: None},,getitem_86,view_80,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_144
call_method,view,"{bert_encoder_layer_20_attention_self_key: None, add_144: None}","(bert_encoder_layer_20_attention_self_key, add_144)",{},{permute_80: None},,add_144,permute_80,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_80
call_method,permute,{view_80: None},"(view_80, 0, 2, 1, 3)",{},{transpose_20: None},,view_80,bert_encoder_layer_20_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_80
call_module,bert.encoder.layer.20.attention.self.value,{bert_encoder_layer_19_output_layer_norm: None},"(bert_encoder_layer_19_output_layer_norm,)",{},"{size_83: None, view_81: None}",,permute_80,size_83,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.20.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_20_attention_self_value
call_method,size,{bert_encoder_layer_20_attention_self_value: None},"(bert_encoder_layer_20_attention_self_value,)",{},{getitem_87: None},,bert_encoder_layer_20_attention_self_value,getitem_87,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_83
call_function,<built-in function getitem>,{size_83: None},"(size_83, slice(None, -1, None))",{},{add_145: None},,size_83,add_145,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_87
call_function,<built-in function add>,{getitem_87: None},"(getitem_87, (16, 64))",{},{view_81: None},,getitem_87,view_81,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_145
call_method,view,"{bert_encoder_layer_20_attention_self_value: None, add_145: None}","(bert_encoder_layer_20_attention_self_value, add_145)",{},{permute_81: None},,add_145,permute_81,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_81
call_method,permute,{view_81: None},"(view_81, 0, 2, 1, 3)",{},{matmul_41: None},,view_81,size_84,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_81
call_method,size,{bert_encoder_layer_20_attention_self_query: None},"(bert_encoder_layer_20_attention_self_query,)",{},{getitem_88: None},,permute_81,getitem_88,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_84
call_function,<built-in function getitem>,{size_84: None},"(size_84, slice(None, -1, None))",{},{add_146: None},,size_84,add_146,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_88
call_function,<built-in function add>,{getitem_88: None},"(getitem_88, (16, 64))",{},{view_82: None},,getitem_88,view_82,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_146
call_method,view,"{bert_encoder_layer_20_attention_self_query: None, add_146: None}","(bert_encoder_layer_20_attention_self_query, add_146)",{},{permute_82: None},,add_146,permute_82,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_82
call_method,permute,{view_82: None},"(view_82, 0, 2, 1, 3)",{},{matmul_40: None},,view_82,transpose_20,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_82
call_method,transpose,{permute_80: None},"(permute_80, -1, -2)",{},{matmul_40: None},,permute_82,matmul_40,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_20
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_82: None, transpose_20: None}","(permute_82, transpose_20)",{},{truediv_20: None},,transpose_20,truediv_20,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_40
call_function,<built-in function truediv>,{matmul_40: None},"(matmul_40, 8.0)",{},{add_147: None},,matmul_40,add_147,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_20
call_function,<built-in function add>,"{truediv_20: None, mul: None}","(truediv_20, mul)",{},{softmax_20: None},,truediv_20,softmax_20,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_147
call_function,<function softmax at 0x7f800dfdfca0>,{add_147: None},"(add_147,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_20_attention_self_dropout: None},,add_147,bert_encoder_layer_20_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_20
call_module,bert.encoder.layer.20.attention.self.dropout,{softmax_20: None},"(softmax_20,)",{},{matmul_41: None},,softmax_20,matmul_41,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.20.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_20_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_20_attention_self_dropout: None, permute_81: None}","(bert_encoder_layer_20_attention_self_dropout, permute_81)",{},{permute_83: None},,bert_encoder_layer_20_attention_self_dropout,permute_83,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_41
call_method,permute,{matmul_41: None},"(matmul_41, 0, 2, 1, 3)",{},{contiguous_20: None},,matmul_41,contiguous_20,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_83
call_method,contiguous,{permute_83: None},"(permute_83,)",{},"{size_85: None, view_83: None}",,permute_83,size_85,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_20
call_method,size,{contiguous_20: None},"(contiguous_20,)",{},{getitem_89: None},,contiguous_20,getitem_89,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_85
call_function,<built-in function getitem>,{size_85: None},"(size_85, slice(None, -2, None))",{},{add_148: None},,size_85,add_148,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_89
call_function,<built-in function add>,{getitem_89: None},"(getitem_89, (1024,))",{},{view_83: None},,getitem_89,view_83,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_148
call_method,view,"{contiguous_20: None, add_148: None}","(contiguous_20, add_148)",{},{bert_encoder_layer_20_attention_output_dense: None},,add_148,bert_encoder_layer_20_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_83
call_module,bert.encoder.layer.20.attention.output.dense,{view_83: None},"(view_83,)",{},{bert_encoder_layer_20_attention_output_dropout: None},,view_83,bert_encoder_layer_20_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.20.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_20_attention_output_dense
call_module,bert.encoder.layer.20.attention.output.dropout,{bert_encoder_layer_20_attention_output_dense: None},"(bert_encoder_layer_20_attention_output_dense,)",{},{add_149: None},,bert_encoder_layer_20_attention_output_dense,add_149,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.20.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_20_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_20_attention_output_dropout: None, bert_encoder_layer_19_output_layer_norm: None}","(bert_encoder_layer_20_attention_output_dropout, bert_encoder_layer_19_output_layer_norm)",{},{bert_encoder_layer_20_attention_output_layer_norm: None},,bert_encoder_layer_20_attention_output_dropout,bert_encoder_layer_20_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_149
call_module,bert.encoder.layer.20.attention.output.LayerNorm,{add_149: None},"(add_149,)",{},"{bert_encoder_layer_20_intermediate_dense: None, add_150: None}",,add_149,bert_encoder_layer_20_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.20.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.20.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_20_attention_output_layer_norm
call_module,bert.encoder.layer.20.intermediate.dense,{bert_encoder_layer_20_attention_output_layer_norm: None},"(bert_encoder_layer_20_attention_output_layer_norm,)",{},{gelu_20: None},,bert_encoder_layer_20_attention_output_layer_norm,gelu_20,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.20.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_20_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_20_intermediate_dense: None},"(bert_encoder_layer_20_intermediate_dense,)",{},{bert_encoder_layer_20_output_dense: None},,bert_encoder_layer_20_intermediate_dense,bert_encoder_layer_20_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.20.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_20
call_module,bert.encoder.layer.20.output.dense,{gelu_20: None},"(gelu_20,)",{},{bert_encoder_layer_20_output_dropout: None},,gelu_20,bert_encoder_layer_20_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.20.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_20_output_dense
call_module,bert.encoder.layer.20.output.dropout,{bert_encoder_layer_20_output_dense: None},"(bert_encoder_layer_20_output_dense,)",{},{add_150: None},,bert_encoder_layer_20_output_dense,add_150,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.20.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_20_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_20_output_dropout: None, bert_encoder_layer_20_attention_output_layer_norm: None}","(bert_encoder_layer_20_output_dropout, bert_encoder_layer_20_attention_output_layer_norm)",{},{bert_encoder_layer_20_output_layer_norm: None},,bert_encoder_layer_20_output_dropout,bert_encoder_layer_20_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_150
call_module,bert.encoder.layer.20.output.LayerNorm,{add_150: None},"(add_150,)",{},"{bert_encoder_layer_21_attention_self_query: None, bert_encoder_layer_21_attention_self_key: None, bert_encoder_layer_21_attention_self_value: None, add_156: None}",,add_150,bert_encoder_layer_21_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.20', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.20.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.20.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_20_output_layer_norm
call_module,bert.encoder.layer.21.attention.self.query,{bert_encoder_layer_20_output_layer_norm: None},"(bert_encoder_layer_20_output_layer_norm,)",{},"{size_88: None, view_86: None}",,bert_encoder_layer_20_output_layer_norm,bert_encoder_layer_21_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.21.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_21_attention_self_query
call_module,bert.encoder.layer.21.attention.self.key,{bert_encoder_layer_20_output_layer_norm: None},"(bert_encoder_layer_20_output_layer_norm,)",{},"{size_86: None, view_84: None}",,bert_encoder_layer_21_attention_self_query,size_86,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.21.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_21_attention_self_key
call_method,size,{bert_encoder_layer_21_attention_self_key: None},"(bert_encoder_layer_21_attention_self_key,)",{},{getitem_90: None},,bert_encoder_layer_21_attention_self_key,getitem_90,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_86
call_function,<built-in function getitem>,{size_86: None},"(size_86, slice(None, -1, None))",{},{add_151: None},,size_86,add_151,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_90
call_function,<built-in function add>,{getitem_90: None},"(getitem_90, (16, 64))",{},{view_84: None},,getitem_90,view_84,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_151
call_method,view,"{bert_encoder_layer_21_attention_self_key: None, add_151: None}","(bert_encoder_layer_21_attention_self_key, add_151)",{},{permute_84: None},,add_151,permute_84,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_84
call_method,permute,{view_84: None},"(view_84, 0, 2, 1, 3)",{},{transpose_21: None},,view_84,bert_encoder_layer_21_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_84
call_module,bert.encoder.layer.21.attention.self.value,{bert_encoder_layer_20_output_layer_norm: None},"(bert_encoder_layer_20_output_layer_norm,)",{},"{size_87: None, view_85: None}",,permute_84,size_87,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.21.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_21_attention_self_value
call_method,size,{bert_encoder_layer_21_attention_self_value: None},"(bert_encoder_layer_21_attention_self_value,)",{},{getitem_91: None},,bert_encoder_layer_21_attention_self_value,getitem_91,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_87
call_function,<built-in function getitem>,{size_87: None},"(size_87, slice(None, -1, None))",{},{add_152: None},,size_87,add_152,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_91
call_function,<built-in function add>,{getitem_91: None},"(getitem_91, (16, 64))",{},{view_85: None},,getitem_91,view_85,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_152
call_method,view,"{bert_encoder_layer_21_attention_self_value: None, add_152: None}","(bert_encoder_layer_21_attention_self_value, add_152)",{},{permute_85: None},,add_152,permute_85,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_85
call_method,permute,{view_85: None},"(view_85, 0, 2, 1, 3)",{},{matmul_43: None},,view_85,size_88,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_85
call_method,size,{bert_encoder_layer_21_attention_self_query: None},"(bert_encoder_layer_21_attention_self_query,)",{},{getitem_92: None},,permute_85,getitem_92,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_88
call_function,<built-in function getitem>,{size_88: None},"(size_88, slice(None, -1, None))",{},{add_153: None},,size_88,add_153,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_92
call_function,<built-in function add>,{getitem_92: None},"(getitem_92, (16, 64))",{},{view_86: None},,getitem_92,view_86,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_153
call_method,view,"{bert_encoder_layer_21_attention_self_query: None, add_153: None}","(bert_encoder_layer_21_attention_self_query, add_153)",{},{permute_86: None},,add_153,permute_86,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_86
call_method,permute,{view_86: None},"(view_86, 0, 2, 1, 3)",{},{matmul_42: None},,view_86,transpose_21,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_86
call_method,transpose,{permute_84: None},"(permute_84, -1, -2)",{},{matmul_42: None},,permute_86,matmul_42,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_21
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_86: None, transpose_21: None}","(permute_86, transpose_21)",{},{truediv_21: None},,transpose_21,truediv_21,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_42
call_function,<built-in function truediv>,{matmul_42: None},"(matmul_42, 8.0)",{},{add_154: None},,matmul_42,add_154,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_21
call_function,<built-in function add>,"{truediv_21: None, mul: None}","(truediv_21, mul)",{},{softmax_21: None},,truediv_21,softmax_21,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_154
call_function,<function softmax at 0x7f800dfdfca0>,{add_154: None},"(add_154,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_21_attention_self_dropout: None},,add_154,bert_encoder_layer_21_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_21
call_module,bert.encoder.layer.21.attention.self.dropout,{softmax_21: None},"(softmax_21,)",{},{matmul_43: None},,softmax_21,matmul_43,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.21.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_21_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_21_attention_self_dropout: None, permute_85: None}","(bert_encoder_layer_21_attention_self_dropout, permute_85)",{},{permute_87: None},,bert_encoder_layer_21_attention_self_dropout,permute_87,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_43
call_method,permute,{matmul_43: None},"(matmul_43, 0, 2, 1, 3)",{},{contiguous_21: None},,matmul_43,contiguous_21,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_87
call_method,contiguous,{permute_87: None},"(permute_87,)",{},"{size_89: None, view_87: None}",,permute_87,size_89,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_21
call_method,size,{contiguous_21: None},"(contiguous_21,)",{},{getitem_93: None},,contiguous_21,getitem_93,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_89
call_function,<built-in function getitem>,{size_89: None},"(size_89, slice(None, -2, None))",{},{add_155: None},,size_89,add_155,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_93
call_function,<built-in function add>,{getitem_93: None},"(getitem_93, (1024,))",{},{view_87: None},,getitem_93,view_87,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_155
call_method,view,"{contiguous_21: None, add_155: None}","(contiguous_21, add_155)",{},{bert_encoder_layer_21_attention_output_dense: None},,add_155,bert_encoder_layer_21_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_87
call_module,bert.encoder.layer.21.attention.output.dense,{view_87: None},"(view_87,)",{},{bert_encoder_layer_21_attention_output_dropout: None},,view_87,bert_encoder_layer_21_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.21.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_21_attention_output_dense
call_module,bert.encoder.layer.21.attention.output.dropout,{bert_encoder_layer_21_attention_output_dense: None},"(bert_encoder_layer_21_attention_output_dense,)",{},{add_156: None},,bert_encoder_layer_21_attention_output_dense,add_156,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.21.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_21_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_21_attention_output_dropout: None, bert_encoder_layer_20_output_layer_norm: None}","(bert_encoder_layer_21_attention_output_dropout, bert_encoder_layer_20_output_layer_norm)",{},{bert_encoder_layer_21_attention_output_layer_norm: None},,bert_encoder_layer_21_attention_output_dropout,bert_encoder_layer_21_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_156
call_module,bert.encoder.layer.21.attention.output.LayerNorm,{add_156: None},"(add_156,)",{},"{bert_encoder_layer_21_intermediate_dense: None, add_157: None}",,add_156,bert_encoder_layer_21_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.21.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.21.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_21_attention_output_layer_norm
call_module,bert.encoder.layer.21.intermediate.dense,{bert_encoder_layer_21_attention_output_layer_norm: None},"(bert_encoder_layer_21_attention_output_layer_norm,)",{},{gelu_21: None},,bert_encoder_layer_21_attention_output_layer_norm,gelu_21,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.21.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_21_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_21_intermediate_dense: None},"(bert_encoder_layer_21_intermediate_dense,)",{},{bert_encoder_layer_21_output_dense: None},,bert_encoder_layer_21_intermediate_dense,bert_encoder_layer_21_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.21.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_21
call_module,bert.encoder.layer.21.output.dense,{gelu_21: None},"(gelu_21,)",{},{bert_encoder_layer_21_output_dropout: None},,gelu_21,bert_encoder_layer_21_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.21.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_21_output_dense
call_module,bert.encoder.layer.21.output.dropout,{bert_encoder_layer_21_output_dense: None},"(bert_encoder_layer_21_output_dense,)",{},{add_157: None},,bert_encoder_layer_21_output_dense,add_157,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.21.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_21_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_21_output_dropout: None, bert_encoder_layer_21_attention_output_layer_norm: None}","(bert_encoder_layer_21_output_dropout, bert_encoder_layer_21_attention_output_layer_norm)",{},{bert_encoder_layer_21_output_layer_norm: None},,bert_encoder_layer_21_output_dropout,bert_encoder_layer_21_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_157
call_module,bert.encoder.layer.21.output.LayerNorm,{add_157: None},"(add_157,)",{},"{bert_encoder_layer_22_attention_self_query: None, bert_encoder_layer_22_attention_self_key: None, bert_encoder_layer_22_attention_self_value: None, add_163: None}",,add_157,bert_encoder_layer_22_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.21', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.21.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.21.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_21_output_layer_norm
call_module,bert.encoder.layer.22.attention.self.query,{bert_encoder_layer_21_output_layer_norm: None},"(bert_encoder_layer_21_output_layer_norm,)",{},"{size_92: None, view_90: None}",,bert_encoder_layer_21_output_layer_norm,bert_encoder_layer_22_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.22.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_22_attention_self_query
call_module,bert.encoder.layer.22.attention.self.key,{bert_encoder_layer_21_output_layer_norm: None},"(bert_encoder_layer_21_output_layer_norm,)",{},"{size_90: None, view_88: None}",,bert_encoder_layer_22_attention_self_query,size_90,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.22.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_22_attention_self_key
call_method,size,{bert_encoder_layer_22_attention_self_key: None},"(bert_encoder_layer_22_attention_self_key,)",{},{getitem_94: None},,bert_encoder_layer_22_attention_self_key,getitem_94,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_90
call_function,<built-in function getitem>,{size_90: None},"(size_90, slice(None, -1, None))",{},{add_158: None},,size_90,add_158,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_94
call_function,<built-in function add>,{getitem_94: None},"(getitem_94, (16, 64))",{},{view_88: None},,getitem_94,view_88,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_158
call_method,view,"{bert_encoder_layer_22_attention_self_key: None, add_158: None}","(bert_encoder_layer_22_attention_self_key, add_158)",{},{permute_88: None},,add_158,permute_88,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_88
call_method,permute,{view_88: None},"(view_88, 0, 2, 1, 3)",{},{transpose_22: None},,view_88,bert_encoder_layer_22_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_88
call_module,bert.encoder.layer.22.attention.self.value,{bert_encoder_layer_21_output_layer_norm: None},"(bert_encoder_layer_21_output_layer_norm,)",{},"{size_91: None, view_89: None}",,permute_88,size_91,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.22.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_22_attention_self_value
call_method,size,{bert_encoder_layer_22_attention_self_value: None},"(bert_encoder_layer_22_attention_self_value,)",{},{getitem_95: None},,bert_encoder_layer_22_attention_self_value,getitem_95,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_91
call_function,<built-in function getitem>,{size_91: None},"(size_91, slice(None, -1, None))",{},{add_159: None},,size_91,add_159,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_95
call_function,<built-in function add>,{getitem_95: None},"(getitem_95, (16, 64))",{},{view_89: None},,getitem_95,view_89,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_159
call_method,view,"{bert_encoder_layer_22_attention_self_value: None, add_159: None}","(bert_encoder_layer_22_attention_self_value, add_159)",{},{permute_89: None},,add_159,permute_89,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_89
call_method,permute,{view_89: None},"(view_89, 0, 2, 1, 3)",{},{matmul_45: None},,view_89,size_92,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_89
call_method,size,{bert_encoder_layer_22_attention_self_query: None},"(bert_encoder_layer_22_attention_self_query,)",{},{getitem_96: None},,permute_89,getitem_96,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_92
call_function,<built-in function getitem>,{size_92: None},"(size_92, slice(None, -1, None))",{},{add_160: None},,size_92,add_160,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_96
call_function,<built-in function add>,{getitem_96: None},"(getitem_96, (16, 64))",{},{view_90: None},,getitem_96,view_90,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_160
call_method,view,"{bert_encoder_layer_22_attention_self_query: None, add_160: None}","(bert_encoder_layer_22_attention_self_query, add_160)",{},{permute_90: None},,add_160,permute_90,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_90
call_method,permute,{view_90: None},"(view_90, 0, 2, 1, 3)",{},{matmul_44: None},,view_90,transpose_22,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_90
call_method,transpose,{permute_88: None},"(permute_88, -1, -2)",{},{matmul_44: None},,permute_90,matmul_44,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_22
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_90: None, transpose_22: None}","(permute_90, transpose_22)",{},{truediv_22: None},,transpose_22,truediv_22,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_44
call_function,<built-in function truediv>,{matmul_44: None},"(matmul_44, 8.0)",{},{add_161: None},,matmul_44,add_161,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_22
call_function,<built-in function add>,"{truediv_22: None, mul: None}","(truediv_22, mul)",{},{softmax_22: None},,truediv_22,softmax_22,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_161
call_function,<function softmax at 0x7f800dfdfca0>,{add_161: None},"(add_161,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_22_attention_self_dropout: None},,add_161,bert_encoder_layer_22_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_22
call_module,bert.encoder.layer.22.attention.self.dropout,{softmax_22: None},"(softmax_22,)",{},{matmul_45: None},,softmax_22,matmul_45,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.22.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_22_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_22_attention_self_dropout: None, permute_89: None}","(bert_encoder_layer_22_attention_self_dropout, permute_89)",{},{permute_91: None},,bert_encoder_layer_22_attention_self_dropout,permute_91,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_45
call_method,permute,{matmul_45: None},"(matmul_45, 0, 2, 1, 3)",{},{contiguous_22: None},,matmul_45,contiguous_22,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_91
call_method,contiguous,{permute_91: None},"(permute_91,)",{},"{size_93: None, view_91: None}",,permute_91,size_93,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_22
call_method,size,{contiguous_22: None},"(contiguous_22,)",{},{getitem_97: None},,contiguous_22,getitem_97,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_93
call_function,<built-in function getitem>,{size_93: None},"(size_93, slice(None, -2, None))",{},{add_162: None},,size_93,add_162,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_97
call_function,<built-in function add>,{getitem_97: None},"(getitem_97, (1024,))",{},{view_91: None},,getitem_97,view_91,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_162
call_method,view,"{contiguous_22: None, add_162: None}","(contiguous_22, add_162)",{},{bert_encoder_layer_22_attention_output_dense: None},,add_162,bert_encoder_layer_22_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_91
call_module,bert.encoder.layer.22.attention.output.dense,{view_91: None},"(view_91,)",{},{bert_encoder_layer_22_attention_output_dropout: None},,view_91,bert_encoder_layer_22_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.22.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_22_attention_output_dense
call_module,bert.encoder.layer.22.attention.output.dropout,{bert_encoder_layer_22_attention_output_dense: None},"(bert_encoder_layer_22_attention_output_dense,)",{},{add_163: None},,bert_encoder_layer_22_attention_output_dense,add_163,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.22.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_22_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_22_attention_output_dropout: None, bert_encoder_layer_21_output_layer_norm: None}","(bert_encoder_layer_22_attention_output_dropout, bert_encoder_layer_21_output_layer_norm)",{},{bert_encoder_layer_22_attention_output_layer_norm: None},,bert_encoder_layer_22_attention_output_dropout,bert_encoder_layer_22_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_163
call_module,bert.encoder.layer.22.attention.output.LayerNorm,{add_163: None},"(add_163,)",{},"{bert_encoder_layer_22_intermediate_dense: None, add_164: None}",,add_163,bert_encoder_layer_22_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.22.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.22.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_22_attention_output_layer_norm
call_module,bert.encoder.layer.22.intermediate.dense,{bert_encoder_layer_22_attention_output_layer_norm: None},"(bert_encoder_layer_22_attention_output_layer_norm,)",{},{gelu_22: None},,bert_encoder_layer_22_attention_output_layer_norm,gelu_22,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.22.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_22_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_22_intermediate_dense: None},"(bert_encoder_layer_22_intermediate_dense,)",{},{bert_encoder_layer_22_output_dense: None},,bert_encoder_layer_22_intermediate_dense,bert_encoder_layer_22_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.22.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_22
call_module,bert.encoder.layer.22.output.dense,{gelu_22: None},"(gelu_22,)",{},{bert_encoder_layer_22_output_dropout: None},,gelu_22,bert_encoder_layer_22_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.22.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_22_output_dense
call_module,bert.encoder.layer.22.output.dropout,{bert_encoder_layer_22_output_dense: None},"(bert_encoder_layer_22_output_dense,)",{},{add_164: None},,bert_encoder_layer_22_output_dense,add_164,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.22.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_22_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_22_output_dropout: None, bert_encoder_layer_22_attention_output_layer_norm: None}","(bert_encoder_layer_22_output_dropout, bert_encoder_layer_22_attention_output_layer_norm)",{},{bert_encoder_layer_22_output_layer_norm: None},,bert_encoder_layer_22_output_dropout,bert_encoder_layer_22_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_164
call_module,bert.encoder.layer.22.output.LayerNorm,{add_164: None},"(add_164,)",{},"{bert_encoder_layer_23_attention_self_query: None, bert_encoder_layer_23_attention_self_key: None, bert_encoder_layer_23_attention_self_value: None, add_170: None}",,add_164,bert_encoder_layer_23_attention_self_query,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.22', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.22.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.22.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_22_output_layer_norm
call_module,bert.encoder.layer.23.attention.self.query,{bert_encoder_layer_22_output_layer_norm: None},"(bert_encoder_layer_22_output_layer_norm,)",{},"{size_96: None, view_94: None}",,bert_encoder_layer_22_output_layer_norm,bert_encoder_layer_23_attention_self_key,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.23.attention.self.query', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_23_attention_self_query
call_module,bert.encoder.layer.23.attention.self.key,{bert_encoder_layer_22_output_layer_norm: None},"(bert_encoder_layer_22_output_layer_norm,)",{},"{size_94: None, view_92: None}",,bert_encoder_layer_23_attention_self_query,size_94,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.23.attention.self.key', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_23_attention_self_key
call_method,size,{bert_encoder_layer_23_attention_self_key: None},"(bert_encoder_layer_23_attention_self_key,)",{},{getitem_98: None},,bert_encoder_layer_23_attention_self_key,getitem_98,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_94
call_function,<built-in function getitem>,{size_94: None},"(size_94, slice(None, -1, None))",{},{add_165: None},,size_94,add_165,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_98
call_function,<built-in function add>,{getitem_98: None},"(getitem_98, (16, 64))",{},{view_92: None},,getitem_98,view_92,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_165
call_method,view,"{bert_encoder_layer_23_attention_self_key: None, add_165: None}","(bert_encoder_layer_23_attention_self_key, add_165)",{},{permute_92: None},,add_165,permute_92,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_92
call_method,permute,{view_92: None},"(view_92, 0, 2, 1, 3)",{},{transpose_23: None},,view_92,bert_encoder_layer_23_attention_self_value,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_92
call_module,bert.encoder.layer.23.attention.self.value,{bert_encoder_layer_22_output_layer_norm: None},"(bert_encoder_layer_22_output_layer_norm,)",{},"{size_95: None, view_93: None}",,permute_92,size_95,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.23.attention.self.value', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_23_attention_self_value
call_method,size,{bert_encoder_layer_23_attention_self_value: None},"(bert_encoder_layer_23_attention_self_value,)",{},{getitem_99: None},,bert_encoder_layer_23_attention_self_value,getitem_99,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_95
call_function,<built-in function getitem>,{size_95: None},"(size_95, slice(None, -1, None))",{},{add_166: None},,size_95,add_166,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_99
call_function,<built-in function add>,{getitem_99: None},"(getitem_99, (16, 64))",{},{view_93: None},,getitem_99,view_93,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_166
call_method,view,"{bert_encoder_layer_23_attention_self_value: None, add_166: None}","(bert_encoder_layer_23_attention_self_value, add_166)",{},{permute_93: None},,add_166,permute_93,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_93
call_method,permute,{view_93: None},"(view_93, 0, 2, 1, 3)",{},{matmul_47: None},,view_93,size_96,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_93
call_method,size,{bert_encoder_layer_23_attention_self_query: None},"(bert_encoder_layer_23_attention_self_query,)",{},{getitem_100: None},,permute_93,getitem_100,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024]]",[True],True,"(1,)",,size_96
call_function,<built-in function getitem>,{size_96: None},"(size_96, slice(None, -1, None))",{},{add_167: None},,size_96,add_167,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_100
call_function,<built-in function add>,{getitem_100: None},"(getitem_100, (16, 64))",{},{view_94: None},,getitem_100,view_94,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_167
call_method,view,"{bert_encoder_layer_23_attention_self_query: None, add_167: None}","(bert_encoder_layer_23_attention_self_query, add_167)",{},{permute_94: None},,add_167,permute_94,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 1024], [1]]","[True, True]",True,"(16, 512, 16, 64)",torch.float32,view_94
call_method,permute,{view_94: None},"(view_94, 0, 2, 1, 3)",{},{matmul_46: None},,view_94,transpose_23,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],False,"(16, 16, 512, 64)",torch.float32,permute_94
call_method,transpose,{permute_92: None},"(permute_92, -1, -2)",{},{matmul_46: None},,permute_94,matmul_46,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[False],False,"(16, 16, 64, 512)",torch.float32,transpose_23
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{permute_94: None, transpose_23: None}","(permute_94, transpose_23)",{},{truediv_23: None},,transpose_23,truediv_23,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64], [16, 16, 64, 512]]","[False, False]",True,"(16, 16, 512, 512)",torch.float32,matmul_46
call_function,<built-in function truediv>,{matmul_46: None},"(matmul_46, 8.0)",{},{add_168: None},,matmul_46,add_168,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,truediv_23
call_function,<built-in function add>,"{truediv_23: None, mul: None}","(truediv_23, mul)",{},{softmax_23: None},,truediv_23,softmax_23,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 1, 1, 512]]","[True, True]",True,"(16, 16, 512, 512)",torch.float32,add_168
call_function,<function softmax at 0x7f800dfdfca0>,{add_168: None},"(add_168,)","{'dim': -1, '_stacklevel': 3, 'dtype': None}",{bert_encoder_layer_23_attention_self_dropout: None},,add_168,bert_encoder_layer_23_attention_self_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,softmax_23
call_module,bert.encoder.layer.23.attention.self.dropout,{softmax_23: None},"(softmax_23,)",{},{matmul_47: None},,softmax_23,matmul_47,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>), ('bert.encoder.layer.23.attention.self.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 16, 512, 512]]",[True],True,"(16, 16, 512, 512)",torch.float32,bert_encoder_layer_23_attention_self_dropout
call_function,<built-in method matmul of type object at 0x7f807641ed60>,"{bert_encoder_layer_23_attention_self_dropout: None, permute_93: None}","(bert_encoder_layer_23_attention_self_dropout, permute_93)",{},{permute_95: None},,bert_encoder_layer_23_attention_self_dropout,permute_95,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 512], [16, 16, 512, 64]]","[True, False]",True,"(16, 16, 512, 64)",torch.float32,matmul_47
call_method,permute,{matmul_47: None},"(matmul_47, 0, 2, 1, 3)",{},{contiguous_23: None},,matmul_47,contiguous_23,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 16, 512, 64]]",[True],False,"(16, 512, 16, 64)",torch.float32,permute_95
call_method,contiguous,{permute_95: None},"(permute_95,)",{},"{size_97: None, view_95: None}",,permute_95,size_97,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[False],True,"(16, 512, 16, 64)",torch.float32,contiguous_23
call_method,size,{contiguous_23: None},"(contiguous_23,)",{},{getitem_101: None},,contiguous_23,getitem_101,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64]]",[True],True,"(1,)",,size_97
call_function,<built-in function getitem>,{size_97: None},"(size_97, slice(None, -2, None))",{},{add_169: None},,size_97,add_169,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,getitem_101
call_function,<built-in function add>,{getitem_101: None},"(getitem_101, (1024,))",{},{view_95: None},,getitem_101,view_95,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}",[[1]],[True],True,"(1,)",,add_169
call_method,view,"{contiguous_23: None, add_169: None}","(contiguous_23, add_169)",{},{bert_encoder_layer_23_attention_output_dense: None},,add_169,bert_encoder_layer_23_attention_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.self', <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>)])}","[[16, 512, 16, 64], [1]]","[True, True]",True,"(16, 512, 1024)",torch.float32,view_95
call_module,bert.encoder.layer.23.attention.output.dense,{view_95: None},"(view_95,)",{},{bert_encoder_layer_23_attention_output_dropout: None},,view_95,bert_encoder_layer_23_attention_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.23.attention.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_23_attention_output_dense
call_module,bert.encoder.layer.23.attention.output.dropout,{bert_encoder_layer_23_attention_output_dense: None},"(bert_encoder_layer_23_attention_output_dense,)",{},{add_170: None},,bert_encoder_layer_23_attention_output_dense,add_170,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.23.attention.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_23_attention_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_23_attention_output_dropout: None, bert_encoder_layer_22_output_layer_norm: None}","(bert_encoder_layer_23_attention_output_dropout, bert_encoder_layer_22_output_layer_norm)",{},{bert_encoder_layer_23_attention_output_layer_norm: None},,bert_encoder_layer_23_attention_output_dropout,bert_encoder_layer_23_attention_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_170
call_module,bert.encoder.layer.23.attention.output.LayerNorm,{add_170: None},"(add_170,)",{},"{bert_encoder_layer_23_intermediate_dense: None, add_171: None}",,add_170,bert_encoder_layer_23_intermediate_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.attention', <class 'transformers.models.bert.modeling_bert.BertAttention'>), ('bert.encoder.layer.23.attention.output', <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>), ('bert.encoder.layer.23.attention.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_23_attention_output_layer_norm
call_module,bert.encoder.layer.23.intermediate.dense,{bert_encoder_layer_23_attention_output_layer_norm: None},"(bert_encoder_layer_23_attention_output_layer_norm,)",{},{gelu_23: None},,bert_encoder_layer_23_attention_output_layer_norm,gelu_23,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.23.intermediate.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 4096)",torch.float32,bert_encoder_layer_23_intermediate_dense
call_function,<built-in function gelu>,{bert_encoder_layer_23_intermediate_dense: None},"(bert_encoder_layer_23_intermediate_dense,)",{},{bert_encoder_layer_23_output_dense: None},,bert_encoder_layer_23_intermediate_dense,bert_encoder_layer_23_output_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.intermediate', <class 'transformers.models.bert.modeling_bert.BertIntermediate'>), ('bert.encoder.layer.23.intermediate.intermediate_act_fn', <class 'transformers.activations.GELUActivation'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 4096)",torch.float32,gelu_23
call_module,bert.encoder.layer.23.output.dense,{gelu_23: None},"(gelu_23,)",{},{bert_encoder_layer_23_output_dropout: None},,gelu_23,bert_encoder_layer_23_output_dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.23.output.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 512, 4096]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_23_output_dense
call_module,bert.encoder.layer.23.output.dropout,{bert_encoder_layer_23_output_dense: None},"(bert_encoder_layer_23_output_dense,)",{},{add_171: None},,bert_encoder_layer_23_output_dense,add_171,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.23.output.dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_23_output_dropout
call_function,<built-in function add>,"{bert_encoder_layer_23_output_dropout: None, bert_encoder_layer_23_attention_output_layer_norm: None}","(bert_encoder_layer_23_output_dropout, bert_encoder_layer_23_attention_output_layer_norm)",{},{bert_encoder_layer_23_output_layer_norm: None},,bert_encoder_layer_23_output_dropout,bert_encoder_layer_23_output_layer_norm,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>)])}","[[16, 512, 1024], [16, 512, 1024]]","[True, True]",True,"(16, 512, 1024)",torch.float32,add_171
call_module,bert.encoder.layer.23.output.LayerNorm,{add_171: None},"(add_171,)",{},{getitem_102: None},,add_171,getitem_102,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.encoder', <class 'transformers.models.bert.modeling_bert.BertEncoder'>), ('bert.encoder.layer.23', <class 'transformers.models.bert.modeling_bert.BertLayer'>), ('bert.encoder.layer.23.output', <class 'transformers.models.bert.modeling_bert.BertOutput'>), ('bert.encoder.layer.23.output.LayerNorm', <class 'torch.nn.modules.normalization.LayerNorm'>)])}","[[16, 512, 1024]]",[True],True,"(16, 512, 1024)",torch.float32,bert_encoder_layer_23_output_layer_norm
call_function,<built-in function getitem>,{bert_encoder_layer_23_output_layer_norm: None},"(bert_encoder_layer_23_output_layer_norm, (slice(None, None, None), 0))",{},{bert_pooler_dense: None},,bert_encoder_layer_23_output_layer_norm,bert_pooler_dense,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.pooler', <class 'transformers.models.bert.modeling_bert.BertPooler'>)])}","[[16, 512, 1024]]",[True],False,"(16, 1024)",torch.float32,getitem_102
call_module,bert.pooler.dense,{getitem_102: None},"(getitem_102,)",{},{bert_pooler_activation: None},,getitem_102,bert_pooler_activation,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.pooler', <class 'transformers.models.bert.modeling_bert.BertPooler'>), ('bert.pooler.dense', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 1024]]",[False],True,"(16, 1024)",torch.float32,bert_pooler_dense
call_module,bert.pooler.activation,{bert_pooler_dense: None},"(bert_pooler_dense,)",{},{dropout: None},,bert_pooler_dense,dropout,False,,"{'nn_module_stack': OrderedDict([('bert', <class 'transformers.models.bert.modeling_bert.BertModel'>), ('bert.pooler', <class 'transformers.models.bert.modeling_bert.BertPooler'>), ('bert.pooler.activation', <class 'torch.nn.modules.activation.Tanh'>)])}","[[16, 1024]]",[True],True,"(16, 1024)",torch.float32,bert_pooler_activation
call_module,dropout,{bert_pooler_activation: None},"(bert_pooler_activation,)",{},{classifier: None},,bert_pooler_activation,classifier,False,,"{'nn_module_stack': OrderedDict([('dropout', <class 'torch.nn.modules.dropout.Dropout'>)])}","[[16, 1024]]",[True],True,"(16, 1024)",torch.float32,dropout
call_module,classifier,{dropout: None},"(dropout,)",{},{output: None},,dropout,output,False,,"{'nn_module_stack': OrderedDict([('classifier', <class 'torch.nn.modules.linear.Linear'>)])}","[[16, 1024]]",[True],True,"(16, 2)",torch.float32,classifier
output,output,{classifier: None},"({'logits': classifier},)",{},{},,classifier,,False,,{},"[[16, 2]]",[True],True,"(16, 2)",torch.float32,output
